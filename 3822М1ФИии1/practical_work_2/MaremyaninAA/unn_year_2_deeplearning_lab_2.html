<!DOCTYPE html>

<html lang="en">
<head><meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<title>unn_year_2_deeplearning_lab_2</title><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.1.10/require.min.js"></script>
<style type="text/css">
    pre { line-height: 125%; }
td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }
span.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }
td.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }
span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }
.highlight .hll { background-color: var(--jp-cell-editor-active-background) }
.highlight { background: var(--jp-cell-editor-background); color: var(--jp-mirror-editor-variable-color) }
.highlight .c { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment */
.highlight .err { color: var(--jp-mirror-editor-error-color) } /* Error */
.highlight .k { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword */
.highlight .o { color: var(--jp-mirror-editor-operator-color); font-weight: bold } /* Operator */
.highlight .p { color: var(--jp-mirror-editor-punctuation-color) } /* Punctuation */
.highlight .ch { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Hashbang */
.highlight .cm { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Multiline */
.highlight .cp { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Preproc */
.highlight .cpf { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.PreprocFile */
.highlight .c1 { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Single */
.highlight .cs { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Special */
.highlight .kc { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Constant */
.highlight .kd { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Declaration */
.highlight .kn { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Namespace */
.highlight .kp { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Pseudo */
.highlight .kr { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Reserved */
.highlight .kt { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Type */
.highlight .m { color: var(--jp-mirror-editor-number-color) } /* Literal.Number */
.highlight .s { color: var(--jp-mirror-editor-string-color) } /* Literal.String */
.highlight .ow { color: var(--jp-mirror-editor-operator-color); font-weight: bold } /* Operator.Word */
.highlight .pm { color: var(--jp-mirror-editor-punctuation-color) } /* Punctuation.Marker */
.highlight .w { color: var(--jp-mirror-editor-variable-color) } /* Text.Whitespace */
.highlight .mb { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Bin */
.highlight .mf { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Float */
.highlight .mh { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Hex */
.highlight .mi { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Integer */
.highlight .mo { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Oct */
.highlight .sa { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Affix */
.highlight .sb { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Backtick */
.highlight .sc { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Char */
.highlight .dl { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Delimiter */
.highlight .sd { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Doc */
.highlight .s2 { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Double */
.highlight .se { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Escape */
.highlight .sh { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Heredoc */
.highlight .si { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Interpol */
.highlight .sx { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Other */
.highlight .sr { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Regex */
.highlight .s1 { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Single */
.highlight .ss { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Symbol */
.highlight .il { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Integer.Long */
  </style>
<style type="text/css">
/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*
 * Mozilla scrollbar styling
 */

/* use standard opaque scrollbars for most nodes */
[data-jp-theme-scrollbars='true'] {
  scrollbar-color: rgb(var(--jp-scrollbar-thumb-color))
    var(--jp-scrollbar-background-color);
}

/* for code nodes, use a transparent style of scrollbar. These selectors
 * will match lower in the tree, and so will override the above */
[data-jp-theme-scrollbars='true'] .CodeMirror-hscrollbar,
[data-jp-theme-scrollbars='true'] .CodeMirror-vscrollbar {
  scrollbar-color: rgba(var(--jp-scrollbar-thumb-color), 0.5) transparent;
}

/* tiny scrollbar */

.jp-scrollbar-tiny {
  scrollbar-color: rgba(var(--jp-scrollbar-thumb-color), 0.5) transparent;
  scrollbar-width: thin;
}

/* tiny scrollbar */

.jp-scrollbar-tiny::-webkit-scrollbar,
.jp-scrollbar-tiny::-webkit-scrollbar-corner {
  background-color: transparent;
  height: 4px;
  width: 4px;
}

.jp-scrollbar-tiny::-webkit-scrollbar-thumb {
  background: rgba(var(--jp-scrollbar-thumb-color), 0.5);
}

.jp-scrollbar-tiny::-webkit-scrollbar-track:horizontal {
  border-left: 0 solid transparent;
  border-right: 0 solid transparent;
}

.jp-scrollbar-tiny::-webkit-scrollbar-track:vertical {
  border-top: 0 solid transparent;
  border-bottom: 0 solid transparent;
}

/*
 * Lumino
 */

.lm-ScrollBar[data-orientation='horizontal'] {
  min-height: 16px;
  max-height: 16px;
  min-width: 45px;
  border-top: 1px solid #a0a0a0;
}

.lm-ScrollBar[data-orientation='vertical'] {
  min-width: 16px;
  max-width: 16px;
  min-height: 45px;
  border-left: 1px solid #a0a0a0;
}

.lm-ScrollBar-button {
  background-color: #f0f0f0;
  background-position: center center;
  min-height: 15px;
  max-height: 15px;
  min-width: 15px;
  max-width: 15px;
}

.lm-ScrollBar-button:hover {
  background-color: #dadada;
}

.lm-ScrollBar-button.lm-mod-active {
  background-color: #cdcdcd;
}

.lm-ScrollBar-track {
  background: #f0f0f0;
}

.lm-ScrollBar-thumb {
  background: #cdcdcd;
}

.lm-ScrollBar-thumb:hover {
  background: #bababa;
}

.lm-ScrollBar-thumb.lm-mod-active {
  background: #a0a0a0;
}

.lm-ScrollBar[data-orientation='horizontal'] .lm-ScrollBar-thumb {
  height: 100%;
  min-width: 15px;
  border-left: 1px solid #a0a0a0;
  border-right: 1px solid #a0a0a0;
}

.lm-ScrollBar[data-orientation='vertical'] .lm-ScrollBar-thumb {
  width: 100%;
  min-height: 15px;
  border-top: 1px solid #a0a0a0;
  border-bottom: 1px solid #a0a0a0;
}

.lm-ScrollBar[data-orientation='horizontal']
  .lm-ScrollBar-button[data-action='decrement'] {
  background-image: var(--jp-icon-caret-left);
  background-size: 17px;
}

.lm-ScrollBar[data-orientation='horizontal']
  .lm-ScrollBar-button[data-action='increment'] {
  background-image: var(--jp-icon-caret-right);
  background-size: 17px;
}

.lm-ScrollBar[data-orientation='vertical']
  .lm-ScrollBar-button[data-action='decrement'] {
  background-image: var(--jp-icon-caret-up);
  background-size: 17px;
}

.lm-ScrollBar[data-orientation='vertical']
  .lm-ScrollBar-button[data-action='increment'] {
  background-image: var(--jp-icon-caret-down);
  background-size: 17px;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-Widget {
  box-sizing: border-box;
  position: relative;
  overflow: hidden;
}

.lm-Widget.lm-mod-hidden {
  display: none !important;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

.lm-AccordionPanel[data-orientation='horizontal'] > .lm-AccordionPanel-title {
  /* Title is rotated for horizontal accordion panel using CSS */
  display: block;
  transform-origin: top left;
  transform: rotate(-90deg) translate(-100%);
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-CommandPalette {
  display: flex;
  flex-direction: column;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.lm-CommandPalette-search {
  flex: 0 0 auto;
}

.lm-CommandPalette-content {
  flex: 1 1 auto;
  margin: 0;
  padding: 0;
  min-height: 0;
  overflow: auto;
  list-style-type: none;
}

.lm-CommandPalette-header {
  overflow: hidden;
  white-space: nowrap;
  text-overflow: ellipsis;
}

.lm-CommandPalette-item {
  display: flex;
  flex-direction: row;
}

.lm-CommandPalette-itemIcon {
  flex: 0 0 auto;
}

.lm-CommandPalette-itemContent {
  flex: 1 1 auto;
  overflow: hidden;
}

.lm-CommandPalette-itemShortcut {
  flex: 0 0 auto;
}

.lm-CommandPalette-itemLabel {
  overflow: hidden;
  white-space: nowrap;
  text-overflow: ellipsis;
}

.lm-close-icon {
  border: 1px solid transparent;
  background-color: transparent;
  position: absolute;
  z-index: 1;
  right: 3%;
  top: 0;
  bottom: 0;
  margin: auto;
  padding: 7px 0;
  display: none;
  vertical-align: middle;
  outline: 0;
  cursor: pointer;
}
.lm-close-icon:after {
  content: 'X';
  display: block;
  width: 15px;
  height: 15px;
  text-align: center;
  color: #000;
  font-weight: normal;
  font-size: 12px;
  cursor: pointer;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-DockPanel {
  z-index: 0;
}

.lm-DockPanel-widget {
  z-index: 0;
}

.lm-DockPanel-tabBar {
  z-index: 1;
}

.lm-DockPanel-handle {
  z-index: 2;
}

.lm-DockPanel-handle.lm-mod-hidden {
  display: none !important;
}

.lm-DockPanel-handle:after {
  position: absolute;
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
  content: '';
}

.lm-DockPanel-handle[data-orientation='horizontal'] {
  cursor: ew-resize;
}

.lm-DockPanel-handle[data-orientation='vertical'] {
  cursor: ns-resize;
}

.lm-DockPanel-handle[data-orientation='horizontal']:after {
  left: 50%;
  min-width: 8px;
  transform: translateX(-50%);
}

.lm-DockPanel-handle[data-orientation='vertical']:after {
  top: 50%;
  min-height: 8px;
  transform: translateY(-50%);
}

.lm-DockPanel-overlay {
  z-index: 3;
  box-sizing: border-box;
  pointer-events: none;
}

.lm-DockPanel-overlay.lm-mod-hidden {
  display: none !important;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-Menu {
  z-index: 10000;
  position: absolute;
  white-space: nowrap;
  overflow-x: hidden;
  overflow-y: auto;
  outline: none;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.lm-Menu-content {
  margin: 0;
  padding: 0;
  display: table;
  list-style-type: none;
}

.lm-Menu-item {
  display: table-row;
}

.lm-Menu-item.lm-mod-hidden,
.lm-Menu-item.lm-mod-collapsed {
  display: none !important;
}

.lm-Menu-itemIcon,
.lm-Menu-itemSubmenuIcon {
  display: table-cell;
  text-align: center;
}

.lm-Menu-itemLabel {
  display: table-cell;
  text-align: left;
}

.lm-Menu-itemShortcut {
  display: table-cell;
  text-align: right;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-MenuBar {
  outline: none;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.lm-MenuBar-content {
  margin: 0;
  padding: 0;
  display: flex;
  flex-direction: row;
  list-style-type: none;
}

.lm-MenuBar-item {
  box-sizing: border-box;
}

.lm-MenuBar-itemIcon,
.lm-MenuBar-itemLabel {
  display: inline-block;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-ScrollBar {
  display: flex;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.lm-ScrollBar[data-orientation='horizontal'] {
  flex-direction: row;
}

.lm-ScrollBar[data-orientation='vertical'] {
  flex-direction: column;
}

.lm-ScrollBar-button {
  box-sizing: border-box;
  flex: 0 0 auto;
}

.lm-ScrollBar-track {
  box-sizing: border-box;
  position: relative;
  overflow: hidden;
  flex: 1 1 auto;
}

.lm-ScrollBar-thumb {
  box-sizing: border-box;
  position: absolute;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-SplitPanel-child {
  z-index: 0;
}

.lm-SplitPanel-handle {
  z-index: 1;
}

.lm-SplitPanel-handle.lm-mod-hidden {
  display: none !important;
}

.lm-SplitPanel-handle:after {
  position: absolute;
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
  content: '';
}

.lm-SplitPanel[data-orientation='horizontal'] > .lm-SplitPanel-handle {
  cursor: ew-resize;
}

.lm-SplitPanel[data-orientation='vertical'] > .lm-SplitPanel-handle {
  cursor: ns-resize;
}

.lm-SplitPanel[data-orientation='horizontal'] > .lm-SplitPanel-handle:after {
  left: 50%;
  min-width: 8px;
  transform: translateX(-50%);
}

.lm-SplitPanel[data-orientation='vertical'] > .lm-SplitPanel-handle:after {
  top: 50%;
  min-height: 8px;
  transform: translateY(-50%);
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-TabBar {
  display: flex;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.lm-TabBar[data-orientation='horizontal'] {
  flex-direction: row;
  align-items: flex-end;
}

.lm-TabBar[data-orientation='vertical'] {
  flex-direction: column;
  align-items: flex-end;
}

.lm-TabBar-content {
  margin: 0;
  padding: 0;
  display: flex;
  flex: 1 1 auto;
  list-style-type: none;
}

.lm-TabBar[data-orientation='horizontal'] > .lm-TabBar-content {
  flex-direction: row;
}

.lm-TabBar[data-orientation='vertical'] > .lm-TabBar-content {
  flex-direction: column;
}

.lm-TabBar-tab {
  display: flex;
  flex-direction: row;
  box-sizing: border-box;
  overflow: hidden;
  touch-action: none; /* Disable native Drag/Drop */
}

.lm-TabBar-tabIcon,
.lm-TabBar-tabCloseIcon {
  flex: 0 0 auto;
}

.lm-TabBar-tabLabel {
  flex: 1 1 auto;
  overflow: hidden;
  white-space: nowrap;
}

.lm-TabBar-tabInput {
  user-select: all;
  width: 100%;
  box-sizing: border-box;
}

.lm-TabBar-tab.lm-mod-hidden {
  display: none !important;
}

.lm-TabBar-addButton.lm-mod-hidden {
  display: none !important;
}

.lm-TabBar.lm-mod-dragging .lm-TabBar-tab {
  position: relative;
}

.lm-TabBar.lm-mod-dragging[data-orientation='horizontal'] .lm-TabBar-tab {
  left: 0;
  transition: left 150ms ease;
}

.lm-TabBar.lm-mod-dragging[data-orientation='vertical'] .lm-TabBar-tab {
  top: 0;
  transition: top 150ms ease;
}

.lm-TabBar.lm-mod-dragging .lm-TabBar-tab.lm-mod-dragging {
  transition: none;
}

.lm-TabBar-tabLabel .lm-TabBar-tabInput {
  user-select: all;
  width: 100%;
  box-sizing: border-box;
  background: inherit;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-TabPanel-tabBar {
  z-index: 1;
}

.lm-TabPanel-stackedPanel {
  z-index: 0;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-Collapse {
  display: flex;
  flex-direction: column;
  align-items: stretch;
}

.jp-Collapse-header {
  padding: 1px 12px;
  background-color: var(--jp-layout-color1);
  border-bottom: solid var(--jp-border-width) var(--jp-border-color2);
  color: var(--jp-ui-font-color1);
  cursor: pointer;
  display: flex;
  align-items: center;
  font-size: var(--jp-ui-font-size0);
  font-weight: 600;
  text-transform: uppercase;
  user-select: none;
}

.jp-Collapser-icon {
  height: 16px;
}

.jp-Collapse-header-collapsed .jp-Collapser-icon {
  transform: rotate(-90deg);
  margin: auto 0;
}

.jp-Collapser-title {
  line-height: 25px;
}

.jp-Collapse-contents {
  padding: 0 12px;
  background-color: var(--jp-layout-color1);
  color: var(--jp-ui-font-color1);
  overflow: auto;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* This file was auto-generated by ensureUiComponents() in @jupyterlab/buildutils */

/**
 * (DEPRECATED) Support for consuming icons as CSS background images
 */

/* Icons urls */

:root {
  --jp-icon-add-above: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTQiIGhlaWdodD0iMTQiIHZpZXdCb3g9IjAgMCAxNCAxNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPGcgY2xpcC1wYXRoPSJ1cmwoI2NsaXAwXzEzN18xOTQ5MikiPgo8cGF0aCBjbGFzcz0ianAtaWNvbjMiIGQ9Ik00Ljc1IDQuOTMwNjZINi42MjVWNi44MDU2NkM2LjYyNSA3LjAxMTkxIDYuNzkzNzUgNy4xODA2NiA3IDcuMTgwNjZDNy4yMDYyNSA3LjE4MDY2IDcuMzc1IDcuMDExOTEgNy4zNzUgNi44MDU2NlY0LjkzMDY2SDkuMjVDOS40NTYyNSA0LjkzMDY2IDkuNjI1IDQuNzYxOTEgOS42MjUgNC41NTU2NkM5LjYyNSA0LjM0OTQxIDkuNDU2MjUgNC4xODA2NiA5LjI1IDQuMTgwNjZINy4zNzVWMi4zMDU2NkM3LjM3NSAyLjA5OTQxIDcuMjA2MjUgMS45MzA2NiA3IDEuOTMwNjZDNi43OTM3NSAxLjkzMDY2IDYuNjI1IDIuMDk5NDEgNi42MjUgMi4zMDU2NlY0LjE4MDY2SDQuNzVDNC41NDM3NSA0LjE4MDY2IDQuMzc1IDQuMzQ5NDEgNC4zNzUgNC41NTU2NkM0LjM3NSA0Ljc2MTkxIDQuNTQzNzUgNC45MzA2NiA0Ljc1IDQuOTMwNjZaIiBmaWxsPSIjNjE2MTYxIiBzdHJva2U9IiM2MTYxNjEiIHN0cm9rZS13aWR0aD0iMC43Ii8+CjwvZz4KPHBhdGggY2xhc3M9ImpwLWljb24zIiBmaWxsLXJ1bGU9ImV2ZW5vZGQiIGNsaXAtcnVsZT0iZXZlbm9kZCIgZD0iTTExLjUgOS41VjExLjVMMi41IDExLjVWOS41TDExLjUgOS41Wk0xMiA4QzEyLjU1MjMgOCAxMyA4LjQ0NzcyIDEzIDlWMTJDMTMgMTIuNTUyMyAxMi41NTIzIDEzIDEyIDEzTDIgMTNDMS40NDc3MiAxMyAxIDEyLjU1MjMgMSAxMlY5QzEgOC40NDc3MiAxLjQ0NzcxIDggMiA4TDEyIDhaIiBmaWxsPSIjNjE2MTYxIi8+CjxkZWZzPgo8Y2xpcFBhdGggaWQ9ImNsaXAwXzEzN18xOTQ5MiI+CjxyZWN0IGNsYXNzPSJqcC1pY29uMyIgd2lkdGg9IjYiIGhlaWdodD0iNiIgZmlsbD0id2hpdGUiIHRyYW5zZm9ybT0ibWF0cml4KC0xIDAgMCAxIDEwIDEuNTU1NjYpIi8+CjwvY2xpcFBhdGg+CjwvZGVmcz4KPC9zdmc+Cg==);
  --jp-icon-add-below: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTQiIGhlaWdodD0iMTQiIHZpZXdCb3g9IjAgMCAxNCAxNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPGcgY2xpcC1wYXRoPSJ1cmwoI2NsaXAwXzEzN18xOTQ5OCkiPgo8cGF0aCBjbGFzcz0ianAtaWNvbjMiIGQ9Ik05LjI1IDEwLjA2OTNMNy4zNzUgMTAuMDY5M0w3LjM3NSA4LjE5NDM0QzcuMzc1IDcuOTg4MDkgNy4yMDYyNSA3LjgxOTM0IDcgNy44MTkzNEM2Ljc5Mzc1IDcuODE5MzQgNi42MjUgNy45ODgwOSA2LjYyNSA4LjE5NDM0TDYuNjI1IDEwLjA2OTNMNC43NSAxMC4wNjkzQzQuNTQzNzUgMTAuMDY5MyA0LjM3NSAxMC4yMzgxIDQuMzc1IDEwLjQ0NDNDNC4zNzUgMTAuNjUwNiA0LjU0Mzc1IDEwLjgxOTMgNC43NSAxMC44MTkzTDYuNjI1IDEwLjgxOTNMNi42MjUgMTIuNjk0M0M2LjYyNSAxMi45MDA2IDYuNzkzNzUgMTMuMDY5MyA3IDEzLjA2OTNDNy4yMDYyNSAxMy4wNjkzIDcuMzc1IDEyLjkwMDYgNy4zNzUgMTIuNjk0M0w3LjM3NSAxMC44MTkzTDkuMjUgMTAuODE5M0M5LjQ1NjI1IDEwLjgxOTMgOS42MjUgMTAuNjUwNiA5LjYyNSAxMC40NDQzQzkuNjI1IDEwLjIzODEgOS40NTYyNSAxMC4wNjkzIDkuMjUgMTAuMDY5M1oiIGZpbGw9IiM2MTYxNjEiIHN0cm9rZT0iIzYxNjE2MSIgc3Ryb2tlLXdpZHRoPSIwLjciLz4KPC9nPgo8cGF0aCBjbGFzcz0ianAtaWNvbjMiIGZpbGwtcnVsZT0iZXZlbm9kZCIgY2xpcC1ydWxlPSJldmVub2RkIiBkPSJNMi41IDUuNUwyLjUgMy41TDExLjUgMy41TDExLjUgNS41TDIuNSA1LjVaTTIgN0MxLjQ0NzcyIDcgMSA2LjU1MjI4IDEgNkwxIDNDMSAyLjQ0NzcyIDEuNDQ3NzIgMiAyIDJMMTIgMkMxMi41NTIzIDIgMTMgMi40NDc3MiAxMyAzTDEzIDZDMTMgNi41NTIyOSAxMi41NTIzIDcgMTIgN0wyIDdaIiBmaWxsPSIjNjE2MTYxIi8+CjxkZWZzPgo8Y2xpcFBhdGggaWQ9ImNsaXAwXzEzN18xOTQ5OCI+CjxyZWN0IGNsYXNzPSJqcC1pY29uMyIgd2lkdGg9IjYiIGhlaWdodD0iNiIgZmlsbD0id2hpdGUiIHRyYW5zZm9ybT0ibWF0cml4KDEgMS43NDg0NmUtMDcgMS43NDg0NmUtMDcgLTEgNCAxMy40NDQzKSIvPgo8L2NsaXBQYXRoPgo8L2RlZnM+Cjwvc3ZnPgo=);
  --jp-icon-add: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE5IDEzaC02djZoLTJ2LTZINXYtMmg2VjVoMnY2aDZ2MnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-bell: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE2IDE2IiB2ZXJzaW9uPSIxLjEiPgogICA8cGF0aCBjbGFzcz0ianAtaWNvbjIganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjMzMzMzMzIgogICAgICBkPSJtOCAwLjI5Yy0xLjQgMC0yLjcgMC43My0zLjYgMS44LTEuMiAxLjUtMS40IDMuNC0xLjUgNS4yLTAuMTggMi4yLTAuNDQgNC0yLjMgNS4zbDAuMjggMS4zaDVjMC4wMjYgMC42NiAwLjMyIDEuMSAwLjcxIDEuNSAwLjg0IDAuNjEgMiAwLjYxIDIuOCAwIDAuNTItMC40IDAuNi0xIDAuNzEtMS41aDVsMC4yOC0xLjNjLTEuOS0wLjk3LTIuMi0zLjMtMi4zLTUuMy0wLjEzLTEuOC0wLjI2LTMuNy0xLjUtNS4yLTAuODUtMS0yLjItMS44LTMuNi0xLjh6bTAgMS40YzAuODggMCAxLjkgMC41NSAyLjUgMS4zIDAuODggMS4xIDEuMSAyLjcgMS4yIDQuNCAwLjEzIDEuNyAwLjIzIDMuNiAxLjMgNS4yaC0xMGMxLjEtMS42IDEuMi0zLjQgMS4zLTUuMiAwLjEzLTEuNyAwLjMtMy4zIDEuMi00LjQgMC41OS0wLjcyIDEuNi0xLjMgMi41LTEuM3ptLTAuNzQgMTJoMS41Yy0wLjAwMTUgMC4yOCAwLjAxNSAwLjc5LTAuNzQgMC43OS0wLjczIDAuMDAxNi0wLjcyLTAuNTMtMC43NC0wLjc5eiIgLz4KPC9zdmc+Cg==);
  --jp-icon-bug-dot: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjQiIGhlaWdodD0iMjQiIHZpZXdCb3g9IjAgMCAyNCAyNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiM2MTYxNjEiPgogICAgICAgIDxwYXRoIGZpbGwtcnVsZT0iZXZlbm9kZCIgY2xpcC1ydWxlPSJldmVub2RkIiBkPSJNMTcuMTkgOEgyMFYxMEgxNy45MUMxNy45NiAxMC4zMyAxOCAxMC42NiAxOCAxMVYxMkgyMFYxNEgxOC41SDE4VjE0LjAyNzVDMTUuNzUgMTQuMjc2MiAxNCAxNi4xODM3IDE0IDE4LjVDMTQgMTkuMjA4IDE0LjE2MzUgMTkuODc3OSAxNC40NTQ5IDIwLjQ3MzlDMTMuNzA2MyAyMC44MTE3IDEyLjg3NTcgMjEgMTIgMjFDOS43OCAyMSA3Ljg1IDE5Ljc5IDYuODEgMThINFYxNkg2LjA5QzYuMDQgMTUuNjcgNiAxNS4zNCA2IDE1VjE0SDRWMTJINlYxMUM2IDEwLjY2IDYuMDQgMTAuMzMgNi4wOSAxMEg0VjhINi44MUM3LjI2IDcuMjIgNy44OCA2LjU1IDguNjIgNi4wNEw3IDQuNDFMOC40MSAzTDEwLjU5IDUuMTdDMTEuMDQgNS4wNiAxMS41MSA1IDEyIDVDMTIuNDkgNSAxMi45NiA1LjA2IDEzLjQyIDUuMTdMMTUuNTkgM0wxNyA0LjQxTDE1LjM3IDYuMDRDMTYuMTIgNi41NSAxNi43NCA3LjIyIDE3LjE5IDhaTTEwIDE2SDE0VjE0SDEwVjE2Wk0xMCAxMkgxNFYxMEgxMFYxMloiIGZpbGw9IiM2MTYxNjEiLz4KICAgICAgICA8cGF0aCBkPSJNMjIgMTguNUMyMiAyMC40MzMgMjAuNDMzIDIyIDE4LjUgMjJDMTYuNTY3IDIyIDE1IDIwLjQzMyAxNSAxOC41QzE1IDE2LjU2NyAxNi41NjcgMTUgMTguNSAxNUMyMC40MzMgMTUgMjIgMTYuNTY3IDIyIDE4LjVaIiBmaWxsPSIjNjE2MTYxIi8+CiAgICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-bug: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik0yMCA4aC0yLjgxYy0uNDUtLjc4LTEuMDctMS40NS0xLjgyLTEuOTZMMTcgNC40MSAxNS41OSAzbC0yLjE3IDIuMTdDMTIuOTYgNS4wNiAxMi40OSA1IDEyIDVjLS40OSAwLS45Ni4wNi0xLjQxLjE3TDguNDEgMyA3IDQuNDFsMS42MiAxLjYzQzcuODggNi41NSA3LjI2IDcuMjIgNi44MSA4SDR2MmgyLjA5Yy0uMDUuMzMtLjA5LjY2LS4wOSAxdjFINHYyaDJ2MWMwIC4zNC4wNC42Ny4wOSAxSDR2MmgyLjgxYzEuMDQgMS43OSAyLjk3IDMgNS4xOSAzczQuMTUtMS4yMSA1LjE5LTNIMjB2LTJoLTIuMDljLjA1LS4zMy4wOS0uNjYuMDktMXYtMWgydi0yaC0ydi0xYzAtLjM0LS4wNC0uNjctLjA5LTFIMjBWOHptLTYgOGgtNHYtMmg0djJ6bTAtNGgtNHYtMmg0djJ6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-build: url(data:image/svg+xml;base64,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);
  --jp-icon-caret-down-empty-thin: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwb2x5Z29uIGNsYXNzPSJzdDEiIHBvaW50cz0iOS45LDEzLjYgMy42LDcuNCA0LjQsNi42IDkuOSwxMi4yIDE1LjQsNi43IDE2LjEsNy40ICIvPgoJPC9nPgo8L3N2Zz4K);
  --jp-icon-caret-down-empty: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiIHNoYXBlLXJlbmRlcmluZz0iZ2VvbWV0cmljUHJlY2lzaW9uIj4KICAgIDxwYXRoIGQ9Ik01LjIsNS45TDksOS43bDMuOC0zLjhsMS4yLDEuMmwtNC45LDVsLTQuOS01TDUuMiw1Ljl6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-caret-down: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiIHNoYXBlLXJlbmRlcmluZz0iZ2VvbWV0cmljUHJlY2lzaW9uIj4KICAgIDxwYXRoIGQ9Ik01LjIsNy41TDksMTEuMmwzLjgtMy44SDUuMnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-caret-left: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwYXRoIGQ9Ik0xMC44LDEyLjhMNy4xLDlsMy44LTMuOGwwLDcuNkgxMC44eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-caret-right: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiIHNoYXBlLXJlbmRlcmluZz0iZ2VvbWV0cmljUHJlY2lzaW9uIj4KICAgIDxwYXRoIGQ9Ik03LjIsNS4yTDEwLjksOWwtMy44LDMuOFY1LjJINy4yeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-caret-up-empty-thin: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwb2x5Z29uIGNsYXNzPSJzdDEiIHBvaW50cz0iMTUuNCwxMy4zIDkuOSw3LjcgNC40LDEzLjIgMy42LDEyLjUgOS45LDYuMyAxNi4xLDEyLjYgIi8+Cgk8L2c+Cjwvc3ZnPgo=);
  --jp-icon-caret-up: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwYXRoIGQ9Ik01LjIsMTAuNUw5LDYuOGwzLjgsMy44SDUuMnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-case-sensitive: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KICA8ZyBjbGFzcz0ianAtaWNvbjIiIGZpbGw9IiM0MTQxNDEiPgogICAgPHJlY3QgeD0iMiIgeT0iMiIgd2lkdGg9IjE2IiBoZWlnaHQ9IjE2Ii8+CiAgPC9nPgogIDxnIGNsYXNzPSJqcC1pY29uLWFjY2VudDIiIGZpbGw9IiNGRkYiPgogICAgPHBhdGggZD0iTTcuNiw4aDAuOWwzLjUsOGgtMS4xTDEwLDE0SDZsLTAuOSwySDRMNy42LDh6IE04LDkuMUw2LjQsMTNoMy4yTDgsOS4xeiIvPgogICAgPHBhdGggZD0iTTE2LjYsOS44Yy0wLjIsMC4xLTAuNCwwLjEtMC43LDAuMWMtMC4yLDAtMC40LTAuMS0wLjYtMC4yYy0wLjEtMC4xLTAuMi0wLjQtMC4yLTAuNyBjLTAuMywwLjMtMC42LDAuNS0wLjksMC43Yy0wLjMsMC4xLTAuNywwLjItMS4xLDAuMmMtMC4zLDAtMC41LDAtMC43LTAuMWMtMC4yLTAuMS0wLjQtMC4yLTAuNi0wLjNjLTAuMi0wLjEtMC4zLTAuMy0wLjQtMC41IGMtMC4xLTAuMi0wLjEtMC40LTAuMS0wLjdjMC0wLjMsMC4xLTAuNiwwLjItMC44YzAuMS0wLjIsMC4zLTAuNCwwLjQtMC41QzEyLDcsMTIuMiw2LjksMTIuNSw2LjhjMC4yLTAuMSwwLjUtMC4xLDAuNy0wLjIgYzAuMy0wLjEsMC41LTAuMSwwLjctMC4xYzAuMiwwLDAuNC0wLjEsMC42LTAuMWMwLjIsMCwwLjMtMC4xLDAuNC0wLjJjMC4xLTAuMSwwLjItMC4yLDAuMi0wLjRjMC0xLTEuMS0xLTEuMy0xIGMtMC40LDAtMS40LDAtMS40LDEuMmgtMC45YzAtMC40LDAuMS0wLjcsMC4yLTFjMC4xLTAuMiwwLjMtMC40LDAuNS0wLjZjMC4yLTAuMiwwLjUtMC4zLDAuOC0wLjNDMTMuMyw0LDEzLjYsNCwxMy45LDQgYzAuMywwLDAuNSwwLDAuOCwwLjFjMC4zLDAsMC41LDAuMSwwLjcsMC4yYzAuMiwwLjEsMC40LDAuMywwLjUsMC41QzE2LDUsMTYsNS4yLDE2LDUuNnYyLjljMCwwLjIsMCwwLjQsMCwwLjUgYzAsMC4xLDAuMSwwLjIsMC4zLDAuMmMwLjEsMCwwLjIsMCwwLjMsMFY5Ljh6IE0xNS4yLDYuOWMtMS4yLDAuNi0zLjEsMC4yLTMuMSwxLjRjMCwxLjQsMy4xLDEsMy4xLTAuNVY2Ljl6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-check: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik05IDE2LjE3TDQuODMgMTJsLTEuNDIgMS40MUw5IDE5IDIxIDdsLTEuNDEtMS40MXoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-circle-empty: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyIDJDNi40NyAyIDIgNi40NyAyIDEyczQuNDcgMTAgMTAgMTAgMTAtNC40NyAxMC0xMFMxNy41MyAyIDEyIDJ6bTAgMThjLTQuNDEgMC04LTMuNTktOC04czMuNTktOCA4LTggOCAzLjU5IDggOC0zLjU5IDgtOCA4eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-circle: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMTggMTgiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPGNpcmNsZSBjeD0iOSIgY3k9IjkiIHI9IjgiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-clear: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8bWFzayBpZD0iZG9udXRIb2xlIj4KICAgIDxyZWN0IHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgZmlsbD0id2hpdGUiIC8+CiAgICA8Y2lyY2xlIGN4PSIxMiIgY3k9IjEyIiByPSI4IiBmaWxsPSJibGFjayIvPgogIDwvbWFzaz4KCiAgPGcgY2xhc3M9ImpwLWljb24zIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxyZWN0IGhlaWdodD0iMTgiIHdpZHRoPSIyIiB4PSIxMSIgeT0iMyIgdHJhbnNmb3JtPSJyb3RhdGUoMzE1LCAxMiwgMTIpIi8+CiAgICA8Y2lyY2xlIGN4PSIxMiIgY3k9IjEyIiByPSIxMCIgbWFzaz0idXJsKCNkb251dEhvbGUpIi8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-close: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbi1ub25lIGpwLWljb24tc2VsZWN0YWJsZS1pbnZlcnNlIGpwLWljb24zLWhvdmVyIiBmaWxsPSJub25lIj4KICAgIDxjaXJjbGUgY3g9IjEyIiBjeT0iMTIiIHI9IjExIi8+CiAgPC9nPgoKICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIGpwLWljb24tYWNjZW50Mi1ob3ZlciIgZmlsbD0iIzYxNjE2MSI+CiAgICA8cGF0aCBkPSJNMTkgNi40MUwxNy41OSA1IDEyIDEwLjU5IDYuNDEgNSA1IDYuNDEgMTAuNTkgMTIgNSAxNy41OSA2LjQxIDE5IDEyIDEzLjQxIDE3LjU5IDE5IDE5IDE3LjU5IDEzLjQxIDEyeiIvPgogIDwvZz4KCiAgPGcgY2xhc3M9ImpwLWljb24tbm9uZSBqcC1pY29uLWJ1c3kiIGZpbGw9Im5vbmUiPgogICAgPGNpcmNsZSBjeD0iMTIiIGN5PSIxMiIgcj0iNyIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-code-check: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNCIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBzaGFwZS1yZW5kZXJpbmc9Imdlb21ldHJpY1ByZWNpc2lvbiI+CiAgICA8cGF0aCBkPSJNNi41OSwzLjQxTDIsOEw2LjU5LDEyLjZMOCwxMS4xOEw0LjgyLDhMOCw0LjgyTDYuNTksMy40MU0xMi40MSwzLjQxTDExLDQuODJMMTQuMTgsOEwxMSwxMS4xOEwxMi40MSwxMi42TDE3LDhMMTIuNDEsMy40MU0yMS41OSwxMS41OUwxMy41LDE5LjY4TDkuODMsMTZMOC40MiwxNy40MUwxMy41LDIyLjVMMjMsMTNMMjEuNTksMTEuNTlaIiAvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-code: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjIiIGhlaWdodD0iMjIiIHZpZXdCb3g9IjAgMCAyOCAyOCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CgkJPHBhdGggZD0iTTExLjQgMTguNkw2LjggMTRMMTEuNCA5LjRMMTAgOEw0IDE0TDEwIDIwTDExLjQgMTguNlpNMTYuNiAxOC42TDIxLjIgMTRMMTYuNiA5LjRMMTggOEwyNCAxNEwxOCAyMEwxNi42IDE4LjZWMTguNloiLz4KCTwvZz4KPC9zdmc+Cg==);
  --jp-icon-collapse-all: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGgKICAgICAgICAgICAgZD0iTTggMmMxIDAgMTEgMCAxMiAwczIgMSAyIDJjMCAxIDAgMTEgMCAxMnMwIDItMiAyQzIwIDE0IDIwIDQgMjAgNFMxMCA0IDYgNGMwLTIgMS0yIDItMnoiIC8+CiAgICAgICAgPHBhdGgKICAgICAgICAgICAgZD0iTTE4IDhjMC0xLTEtMi0yLTJTNSA2IDQgNnMtMiAxLTIgMmMwIDEgMCAxMSAwIDEyczEgMiAyIDJjMSAwIDExIDAgMTIgMHMyLTEgMi0yYzAtMSAwLTExIDAtMTJ6bS0yIDB2MTJINFY4eiIgLz4KICAgICAgICA8cGF0aCBkPSJNNiAxM3YyaDh2LTJ6IiAvPgogICAgPC9nPgo8L3N2Zz4K);
  --jp-icon-console: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwMCAyMDAiPgogIDxnIGNsYXNzPSJqcC1jb25zb2xlLWljb24tYmFja2dyb3VuZC1jb2xvciBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiMwMjg4RDEiPgogICAgPHBhdGggZD0iTTIwIDE5LjhoMTYwdjE1OS45SDIweiIvPgogIDwvZz4KICA8ZyBjbGFzcz0ianAtY29uc29sZS1pY29uLWNvbG9yIGpwLWljb24tc2VsZWN0YWJsZS1pbnZlcnNlIiBmaWxsPSIjZmZmIj4KICAgIDxwYXRoIGQ9Ik0xMDUgMTI3LjNoNDB2MTIuOGgtNDB6TTUxLjEgNzdMNzQgOTkuOWwtMjMuMyAyMy4zIDEwLjUgMTAuNSAyMy4zLTIzLjNMOTUgOTkuOSA4NC41IDg5LjQgNjEuNiA2Ni41eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-copy: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMTggMTgiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTExLjksMUgzLjJDMi40LDEsMS43LDEuNywxLjcsMi41djEwLjJoMS41VjIuNWg4LjdWMXogTTE0LjEsMy45aC04Yy0wLjgsMC0xLjUsMC43LTEuNSwxLjV2MTAuMmMwLDAuOCwwLjcsMS41LDEuNSwxLjVoOCBjMC44LDAsMS41LTAuNywxLjUtMS41VjUuNEMxNS41LDQuNiwxNC45LDMuOSwxNC4xLDMuOXogTTE0LjEsMTUuNWgtOFY1LjRoOFYxNS41eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-copyright: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGVuYWJsZS1iYWNrZ3JvdW5kPSJuZXcgMCAwIDI0IDI0IiBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCI+CiAgPGcgY2xhc3M9ImpwLWljb24zIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik0xMS44OCw5LjE0YzEuMjgsMC4wNiwxLjYxLDEuMTUsMS42MywxLjY2aDEuNzljLTAuMDgtMS45OC0xLjQ5LTMuMTktMy40NS0zLjE5QzkuNjQsNy42MSw4LDksOCwxMi4xNCBjMCwxLjk0LDAuOTMsNC4yNCwzLjg0LDQuMjRjMi4yMiwwLDMuNDEtMS42NSwzLjQ0LTIuOTVoLTEuNzljLTAuMDMsMC41OS0wLjQ1LDEuMzgtMS42MywxLjQ0QzEwLjU1LDE0LjgzLDEwLDEzLjgxLDEwLDEyLjE0IEMxMCw5LjI1LDExLjI4LDkuMTYsMTEuODgsOS4xNHogTTEyLDJDNi40OCwyLDIsNi40OCwyLDEyczQuNDgsMTAsMTAsMTBzMTAtNC40OCwxMC0xMFMxNy41MiwyLDEyLDJ6IE0xMiwyMGMtNC40MSwwLTgtMy41OS04LTggczMuNTktOCw4LThzOCwzLjU5LDgsOFMxNi40MSwyMCwxMiwyMHoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-cut: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTkuNjQgNy42NGMuMjMtLjUuMzYtMS4wNS4zNi0xLjY0IDAtMi4yMS0xLjc5LTQtNC00UzIgMy43OSAyIDZzMS43OSA0IDQgNGMuNTkgMCAxLjE0LS4xMyAxLjY0LS4zNkwxMCAxMmwtMi4zNiAyLjM2QzcuMTQgMTQuMTMgNi41OSAxNCA2IDE0Yy0yLjIxIDAtNCAxLjc5LTQgNHMxLjc5IDQgNCA0IDQtMS43OSA0LTRjMC0uNTktLjEzLTEuMTQtLjM2LTEuNjRMMTIgMTRsNyA3aDN2LTFMOS42NCA3LjY0ek02IDhjLTEuMSAwLTItLjg5LTItMnMuOS0yIDItMiAyIC44OSAyIDItLjkgMi0yIDJ6bTAgMTJjLTEuMSAwLTItLjg5LTItMnMuOS0yIDItMiAyIC44OSAyIDItLjkgMi0yIDJ6bTYtNy41Yy0uMjggMC0uNS0uMjItLjUtLjVzLjIyLS41LjUtLjUuNS4yMi41LjUtLjIyLjUtLjUuNXpNMTkgM2wtNiA2IDIgMiA3LTdWM3oiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-delete: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAyNCAyNCIgd2lkdGg9IjE2cHgiIGhlaWdodD0iMTZweCI+CiAgICA8cGF0aCBkPSJNMCAwaDI0djI0SDB6IiBmaWxsPSJub25lIiAvPgogICAgPHBhdGggY2xhc3M9ImpwLWljb24zIiBmaWxsPSIjNjI2MjYyIiBkPSJNNiAxOWMwIDEuMS45IDIgMiAyaDhjMS4xIDAgMi0uOSAyLTJWN0g2djEyek0xOSA0aC0zLjVsLTEtMWgtNWwtMSAxSDV2MmgxNFY0eiIgLz4KPC9zdmc+Cg==);
  --jp-icon-download: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE5IDloLTRWM0g5djZINWw3IDcgNy03ek01IDE4djJoMTR2LTJINXoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-duplicate: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTQiIGhlaWdodD0iMTQiIHZpZXdCb3g9IjAgMCAxNCAxNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggY2xhc3M9ImpwLWljb24zIiBmaWxsLXJ1bGU9ImV2ZW5vZGQiIGNsaXAtcnVsZT0iZXZlbm9kZCIgZD0iTTIuNzk5OTggMC44NzVIOC44OTU4MkM5LjIwMDYxIDAuODc1IDkuNDQ5OTggMS4xMzkxNCA5LjQ0OTk4IDEuNDYxOThDOS40NDk5OCAxLjc4NDgyIDkuMjAwNjEgMi4wNDg5NiA4Ljg5NTgyIDIuMDQ4OTZIMy4zNTQxNUMzLjA0OTM2IDIuMDQ4OTYgMi43OTk5OCAyLjMxMzEgMi43OTk5OCAyLjYzNTk0VjkuNjc5NjlDMi43OTk5OCAxMC4wMDI1IDIuNTUwNjEgMTAuMjY2NyAyLjI0NTgyIDEwLjI2NjdDMS45NDEwMyAxMC4yNjY3IDEuNjkxNjUgMTAuMDAyNSAxLjY5MTY1IDkuNjc5NjlWMi4wNDg5NkMxLjY5MTY1IDEuNDAzMjggMi4xOTA0IDAuODc1IDIuNzk5OTggMC44NzVaTTUuMzY2NjUgMTEuOVY0LjU1SDExLjA4MzNWMTEuOUg1LjM2NjY1Wk00LjE0MTY1IDQuMTQxNjdDNC4xNDE2NSAzLjY5MDYzIDQuNTA3MjggMy4zMjUgNC45NTgzMiAzLjMyNUgxMS40OTE3QzExLjk0MjcgMy4zMjUgMTIuMzA4MyAzLjY5MDYzIDEyLjMwODMgNC4xNDE2N1YxMi4zMDgzQzEyLjMwODMgMTIuNzU5NCAxMS45NDI3IDEzLjEyNSAxMS40OTE3IDEzLjEyNUg0Ljk1ODMyQzQuNTA3MjggMTMuMTI1IDQuMTQxNjUgMTIuNzU5NCA0LjE0MTY1IDEyLjMwODNWNC4xNDE2N1oiIGZpbGw9IiM2MTYxNjEiLz4KPHBhdGggY2xhc3M9ImpwLWljb24zIiBkPSJNOS40MzU3NCA4LjI2NTA3SDguMzY0MzFWOS4zMzY1QzguMzY0MzEgOS40NTQzNSA4LjI2Nzg4IDkuNTUwNzggOC4xNTAwMiA5LjU1MDc4QzguMDMyMTcgOS41NTA3OCA3LjkzNTc0IDkuNDU0MzUgNy45MzU3NCA5LjMzNjVWOC4yNjUwN0g2Ljg2NDMxQzYuNzQ2NDUgOC4yNjUwNyA2LjY1MDAyIDguMTY4NjQgNi42NTAwMiA4LjA1MDc4QzYuNjUwMDIgNy45MzI5MiA2Ljc0NjQ1IDcuODM2NSA2Ljg2NDMxIDcuODM2NUg3LjkzNTc0VjYuNzY1MDdDNy45MzU3NCA2LjY0NzIxIDguMDMyMTcgNi41NTA3OCA4LjE1MDAyIDYuNTUwNzhDOC4yNjc4OCA2LjU1MDc4IDguMzY0MzEgNi42NDcyMSA4LjM2NDMxIDYuNzY1MDdWNy44MzY1SDkuNDM1NzRDOS41NTM2IDcuODM2NSA5LjY1MDAyIDcuOTMyOTIgOS42NTAwMiA4LjA1MDc4QzkuNjUwMDIgOC4xNjg2NCA5LjU1MzYgOC4yNjUwNyA5LjQzNTc0IDguMjY1MDdaIiBmaWxsPSIjNjE2MTYxIiBzdHJva2U9IiM2MTYxNjEiIHN0cm9rZS13aWR0aD0iMC41Ii8+Cjwvc3ZnPgo=);
  --jp-icon-edit: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTMgMTcuMjVWMjFoMy43NUwxNy44MSA5Ljk0bC0zLjc1LTMuNzVMMyAxNy4yNXpNMjAuNzEgNy4wNGMuMzktLjM5LjM5LTEuMDIgMC0xLjQxbC0yLjM0LTIuMzRjLS4zOS0uMzktMS4wMi0uMzktMS40MSAwbC0xLjgzIDEuODMgMy43NSAzLjc1IDEuODMtMS44M3oiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-ellipses: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPGNpcmNsZSBjeD0iNSIgY3k9IjEyIiByPSIyIi8+CiAgICA8Y2lyY2xlIGN4PSIxMiIgY3k9IjEyIiByPSIyIi8+CiAgICA8Y2lyY2xlIGN4PSIxOSIgY3k9IjEyIiByPSIyIi8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-error: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KPGcgY2xhc3M9ImpwLWljb24zIiBmaWxsPSIjNjE2MTYxIj48Y2lyY2xlIGN4PSIxMiIgY3k9IjE5IiByPSIyIi8+PHBhdGggZD0iTTEwIDNoNHYxMmgtNHoiLz48L2c+CjxwYXRoIGZpbGw9Im5vbmUiIGQ9Ik0wIDBoMjR2MjRIMHoiLz4KPC9zdmc+Cg==);
  --jp-icon-expand-all: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGgKICAgICAgICAgICAgZD0iTTggMmMxIDAgMTEgMCAxMiAwczIgMSAyIDJjMCAxIDAgMTEgMCAxMnMwIDItMiAyQzIwIDE0IDIwIDQgMjAgNFMxMCA0IDYgNGMwLTIgMS0yIDItMnoiIC8+CiAgICAgICAgPHBhdGgKICAgICAgICAgICAgZD0iTTE4IDhjMC0xLTEtMi0yLTJTNSA2IDQgNnMtMiAxLTIgMmMwIDEgMCAxMSAwIDEyczEgMiAyIDJjMSAwIDExIDAgMTIgMHMyLTEgMi0yYzAtMSAwLTExIDAtMTJ6bS0yIDB2MTJINFY4eiIgLz4KICAgICAgICA8cGF0aCBkPSJNMTEgMTBIOXYzSDZ2MmgzdjNoMnYtM2gzdi0yaC0zeiIgLz4KICAgIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-extension: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTIwLjUgMTFIMTlWN2MwLTEuMS0uOS0yLTItMmgtNFYzLjVDMTMgMi4xMiAxMS44OCAxIDEwLjUgMVM4IDIuMTIgOCAzLjVWNUg0Yy0xLjEgMC0xLjk5LjktMS45OSAydjMuOEgzLjVjMS40OSAwIDIuNyAxLjIxIDIuNyAyLjdzLTEuMjEgMi43LTIuNyAyLjdIMlYyMGMwIDEuMS45IDIgMiAyaDMuOHYtMS41YzAtMS40OSAxLjIxLTIuNyAyLjctMi43IDEuNDkgMCAyLjcgMS4yMSAyLjcgMi43VjIySDE3YzEuMSAwIDItLjkgMi0ydi00aDEuNWMxLjM4IDAgMi41LTEuMTIgMi41LTIuNVMyMS44OCAxMSAyMC41IDExeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-fast-forward: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTQgMThsOC41LTZMNCA2djEyem05LTEydjEybDguNS02TDEzIDZ6Ii8+CiAgICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-file-upload: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTkgMTZoNnYtNmg0bC03LTctNyA3aDR6bS00IDJoMTR2Mkg1eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-file: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTkuMyA4LjJsLTUuNS01LjVjLS4zLS4zLS43LS41LTEuMi0uNUgzLjljLS44LjEtMS42LjktMS42IDEuOHYxNC4xYzAgLjkuNyAxLjYgMS42IDEuNmgxNC4yYy45IDAgMS42LS43IDEuNi0xLjZWOS40Yy4xLS41LS4xLS45LS40LTEuMnptLTUuOC0zLjNsMy40IDMuNmgtMy40VjQuOXptMy45IDEyLjdINC43Yy0uMSAwLS4yIDAtLjItLjJWNC43YzAtLjIuMS0uMy4yLS4zaDcuMnY0LjRzMCAuOC4zIDEuMWMuMy4zIDEuMS4zIDEuMS4zaDQuM3Y3LjJzLS4xLjItLjIuMnoiLz4KPC9zdmc+Cg==);
  --jp-icon-filter-dot: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiNGRkYiPgogICAgPHBhdGggZD0iTTE0LDEyVjE5Ljg4QzE0LjA0LDIwLjE4IDEzLjk0LDIwLjUgMTMuNzEsMjAuNzFDMTMuMzIsMjEuMSAxMi42OSwyMS4xIDEyLjMsMjAuNzFMMTAuMjksMTguN0MxMC4wNiwxOC40NyA5Ljk2LDE4LjE2IDEwLDE3Ljg3VjEySDkuOTdMNC4yMSw0LjYyQzMuODcsNC4xOSAzLjk1LDMuNTYgNC4zOCwzLjIyQzQuNTcsMy4wOCA0Ljc4LDMgNSwzVjNIMTlWM0MxOS4yMiwzIDE5LjQzLDMuMDggMTkuNjIsMy4yMkMyMC4wNSwzLjU2IDIwLjEzLDQuMTkgMTkuNzksNC42MkwxNC4wMywxMkgxNFoiIC8+CiAgPC9nPgogIDxnIGNsYXNzPSJqcC1pY29uLWRvdCIgZmlsbD0iI0ZGRiI+CiAgICA8Y2lyY2xlIGN4PSIxOCIgY3k9IjE3IiByPSIzIj48L2NpcmNsZT4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-filter-list: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEwIDE4aDR2LTJoLTR2MnpNMyA2djJoMThWNkgzem0zIDdoMTJ2LTJINnYyeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-filter: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiNGRkYiPgogICAgPHBhdGggZD0iTTE0LDEyVjE5Ljg4QzE0LjA0LDIwLjE4IDEzLjk0LDIwLjUgMTMuNzEsMjAuNzFDMTMuMzIsMjEuMSAxMi42OSwyMS4xIDEyLjMsMjAuNzFMMTAuMjksMTguN0MxMC4wNiwxOC40NyA5Ljk2LDE4LjE2IDEwLDE3Ljg3VjEySDkuOTdMNC4yMSw0LjYyQzMuODcsNC4xOSAzLjk1LDMuNTYgNC4zOCwzLjIyQzQuNTcsMy4wOCA0Ljc4LDMgNSwzVjNIMTlWM0MxOS4yMiwzIDE5LjQzLDMuMDggMTkuNjIsMy4yMkMyMC4wNSwzLjU2IDIwLjEzLDQuMTkgMTkuNzksNC42MkwxNC4wMywxMkgxNFoiIC8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-folder-favorite: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGhlaWdodD0iMjRweCIgdmlld0JveD0iMCAwIDI0IDI0IiB3aWR0aD0iMjRweCIgZmlsbD0iIzAwMDAwMCI+CiAgPHBhdGggZD0iTTAgMGgyNHYyNEgwVjB6IiBmaWxsPSJub25lIi8+PHBhdGggY2xhc3M9ImpwLWljb24zIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iIzYxNjE2MSIgZD0iTTIwIDZoLThsLTItMkg0Yy0xLjEgMC0yIC45LTIgMnYxMmMwIDEuMS45IDIgMiAyaDE2YzEuMSAwIDItLjkgMi0yVjhjMC0xLjEtLjktMi0yLTJ6bS0yLjA2IDExTDE1IDE1LjI4IDEyLjA2IDE3bC43OC0zLjMzLTIuNTktMi4yNCAzLjQxLS4yOUwxNSA4bDEuMzQgMy4xNCAzLjQxLjI5LTIuNTkgMi4yNC43OCAzLjMzeiIvPgo8L3N2Zz4K);
  --jp-icon-folder: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTAgNEg0Yy0xLjEgMC0xLjk5LjktMS45OSAyTDIgMThjMCAxLjEuOSAyIDIgMmgxNmMxLjEgMCAyLS45IDItMlY4YzAtMS4xLS45LTItMi0yaC04bC0yLTJ6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-home: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGhlaWdodD0iMjRweCIgdmlld0JveD0iMCAwIDI0IDI0IiB3aWR0aD0iMjRweCIgZmlsbD0iIzAwMDAwMCI+CiAgPHBhdGggZD0iTTAgMGgyNHYyNEgweiIgZmlsbD0ibm9uZSIvPjxwYXRoIGNsYXNzPSJqcC1pY29uMyBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiM2MTYxNjEiIGQ9Ik0xMCAyMHYtNmg0djZoNXYtOGgzTDEyIDMgMiAxMmgzdjh6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-html5: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDUxMiA1MTIiPgogIDxwYXRoIGNsYXNzPSJqcC1pY29uMCBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiMwMDAiIGQ9Ik0xMDguNCAwaDIzdjIyLjhoMjEuMlYwaDIzdjY5aC0yM1Y0NmgtMjF2MjNoLTIzLjJNMjA2IDIzaC0yMC4zVjBoNjMuN3YyM0gyMjl2NDZoLTIzbTUzLjUtNjloMjQuMWwxNC44IDI0LjNMMzEzLjIgMGgyNC4xdjY5aC0yM1YzNC44bC0xNi4xIDI0LjgtMTYuMS0yNC44VjY5aC0yMi42bTg5LjItNjloMjN2NDYuMmgzMi42VjY5aC01NS42Ii8+CiAgPHBhdGggY2xhc3M9ImpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iI2U0NGQyNiIgZD0iTTEwNy42IDQ3MWwtMzMtMzcwLjRoMzYyLjhsLTMzIDM3MC4yTDI1NS43IDUxMiIvPgogIDxwYXRoIGNsYXNzPSJqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiNmMTY1MjkiIGQ9Ik0yNTYgNDgwLjVWMTMxaDE0OC4zTDM3NiA0NDciLz4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1zZWxlY3RhYmxlLWludmVyc2UiIGZpbGw9IiNlYmViZWIiIGQ9Ik0xNDIgMTc2LjNoMTE0djQ1LjRoLTY0LjJsNC4yIDQ2LjVoNjB2NDUuM0gxNTQuNG0yIDIyLjhIMjAybDMuMiAzNi4zIDUwLjggMTMuNnY0Ny40bC05My4yLTI2Ii8+CiAgPHBhdGggY2xhc3M9ImpwLWljb24tc2VsZWN0YWJsZS1pbnZlcnNlIiBmaWxsPSIjZmZmIiBkPSJNMzY5LjYgMTc2LjNIMjU1Ljh2NDUuNGgxMDkuNm0tNC4xIDQ2LjVIMjU1Ljh2NDUuNGg1NmwtNS4zIDU5LTUwLjcgMTMuNnY0Ny4ybDkzLTI1LjgiLz4KPC9zdmc+Cg==);
  --jp-icon-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1icmFuZDQganAtaWNvbi1zZWxlY3RhYmxlLWludmVyc2UiIGZpbGw9IiNGRkYiIGQ9Ik0yLjIgMi4yaDE3LjV2MTcuNUgyLjJ6Ii8+CiAgPHBhdGggY2xhc3M9ImpwLWljb24tYnJhbmQwIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iIzNGNTFCNSIgZD0iTTIuMiAyLjJ2MTcuNWgxNy41bC4xLTE3LjVIMi4yem0xMi4xIDIuMmMxLjIgMCAyLjIgMSAyLjIgMi4ycy0xIDIuMi0yLjIgMi4yLTIuMi0xLTIuMi0yLjIgMS0yLjIgMi4yLTIuMnpNNC40IDE3LjZsMy4zLTguOCAzLjMgNi42IDIuMi0zLjIgNC40IDUuNEg0LjR6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-info: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDUwLjk3OCA1MC45NzgiPgoJPGcgY2xhc3M9ImpwLWljb24zIiBmaWxsPSIjNjE2MTYxIj4KCQk8cGF0aCBkPSJNNDMuNTIsNy40NThDMzguNzExLDIuNjQ4LDMyLjMwNywwLDI1LjQ4OSwwQzE4LjY3LDAsMTIuMjY2LDIuNjQ4LDcuNDU4LDcuNDU4CgkJCWMtOS45NDMsOS45NDEtOS45NDMsMjYuMTE5LDAsMzYuMDYyYzQuODA5LDQuODA5LDExLjIxMiw3LjQ1NiwxOC4wMzEsNy40NThjMCwwLDAuMDAxLDAsMC4wMDIsMAoJCQljNi44MTYsMCwxMy4yMjEtMi42NDgsMTguMDI5LTcuNDU4YzQuODA5LTQuODA5LDcuNDU3LTExLjIxMiw3LjQ1Ny0xOC4wM0M1MC45NzcsMTguNjcsNDguMzI4LDEyLjI2Niw0My41Miw3LjQ1OHoKCQkJIE00Mi4xMDYsNDIuMTA1Yy00LjQzMiw0LjQzMS0xMC4zMzIsNi44NzItMTYuNjE1LDYuODcyaC0wLjAwMmMtNi4yODUtMC4wMDEtMTIuMTg3LTIuNDQxLTE2LjYxNy02Ljg3MgoJCQljLTkuMTYyLTkuMTYzLTkuMTYyLTI0LjA3MSwwLTMzLjIzM0MxMy4zMDMsNC40NCwxOS4yMDQsMiwyNS40ODksMmM2LjI4NCwwLDEyLjE4NiwyLjQ0LDE2LjYxNyw2Ljg3MgoJCQljNC40MzEsNC40MzEsNi44NzEsMTAuMzMyLDYuODcxLDE2LjYxN0M0OC45NzcsMzEuNzcyLDQ2LjUzNiwzNy42NzUsNDIuMTA2LDQyLjEwNXoiLz4KCQk8cGF0aCBkPSJNMjMuNTc4LDMyLjIxOGMtMC4wMjMtMS43MzQsMC4xNDMtMy4wNTksMC40OTYtMy45NzJjMC4zNTMtMC45MTMsMS4xMS0xLjk5NywyLjI3Mi0zLjI1MwoJCQljMC40NjgtMC41MzYsMC45MjMtMS4wNjIsMS4zNjctMS41NzVjMC42MjYtMC43NTMsMS4xMDQtMS40NzgsMS40MzYtMi4xNzVjMC4zMzEtMC43MDcsMC40OTUtMS41NDEsMC40OTUtMi41CgkJCWMwLTEuMDk2LTAuMjYtMi4wODgtMC43NzktMi45NzljLTAuNTY1LTAuODc5LTEuNTAxLTEuMzM2LTIuODA2LTEuMzY5Yy0xLjgwMiwwLjA1Ny0yLjk4NSwwLjY2Ny0zLjU1LDEuODMyCgkJCWMtMC4zMDEsMC41MzUtMC41MDMsMS4xNDEtMC42MDcsMS44MTRjLTAuMTM5LDAuNzA3LTAuMjA3LDEuNDMyLTAuMjA3LDIuMTc0aC0yLjkzN2MtMC4wOTEtMi4yMDgsMC40MDctNC4xMTQsMS40OTMtNS43MTkKCQkJYzEuMDYyLTEuNjQsMi44NTUtMi40ODEsNS4zNzgtMi41MjdjMi4xNiwwLjAyMywzLjg3NCwwLjYwOCw1LjE0MSwxLjc1OGMxLjI3OCwxLjE2LDEuOTI5LDIuNzY0LDEuOTUsNC44MTEKCQkJYzAsMS4xNDItMC4xMzcsMi4xMTEtMC40MSwyLjkxMWMtMC4zMDksMC44NDUtMC43MzEsMS41OTMtMS4yNjgsMi4yNDNjLTAuNDkyLDAuNjUtMS4wNjgsMS4zMTgtMS43MywyLjAwMgoJCQljLTAuNjUsMC42OTctMS4zMTMsMS40NzktMS45ODcsMi4zNDZjLTAuMjM5LDAuMzc3LTAuNDI5LDAuNzc3LTAuNTY1LDEuMTk5Yy0wLjE2LDAuOTU5LTAuMjE3LDEuOTUxLTAuMTcxLDIuOTc5CgkJCUMyNi41ODksMzIuMjE4LDIzLjU3OCwzMi4yMTgsMjMuNTc4LDMyLjIxOHogTTIzLjU3OCwzOC4yMnYtMy40ODRoMy4wNzZ2My40ODRIMjMuNTc4eiIvPgoJPC9nPgo8L3N2Zz4K);
  --jp-icon-inspector: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaW5zcGVjdG9yLWljb24tY29sb3IganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMjAgNEg0Yy0xLjEgMC0xLjk5LjktMS45OSAyTDIgMThjMCAxLjEuOSAyIDIgMmgxNmMxLjEgMCAyLS45IDItMlY2YzAtMS4xLS45LTItMi0yem0tNSAxNEg0di00aDExdjR6bTAtNUg0VjloMTF2NHptNSA1aC00VjloNHY5eiIvPgo8L3N2Zz4K);
  --jp-icon-json: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtanNvbi1pY29uLWNvbG9yIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iI0Y5QTgyNSI+CiAgICA8cGF0aCBkPSJNMjAuMiAxMS44Yy0xLjYgMC0xLjcuNS0xLjcgMSAwIC40LjEuOS4xIDEuMy4xLjUuMS45LjEgMS4zIDAgMS43LTEuNCAyLjMtMy41IDIuM2gtLjl2LTEuOWguNWMxLjEgMCAxLjQgMCAxLjQtLjggMC0uMyAwLS42LS4xLTEgMC0uNC0uMS0uOC0uMS0xLjIgMC0xLjMgMC0xLjggMS4zLTItMS4zLS4yLTEuMy0uNy0xLjMtMiAwLS40LjEtLjguMS0xLjIuMS0uNC4xLS43LjEtMSAwLS44LS40LS43LTEuNC0uOGgtLjVWNC4xaC45YzIuMiAwIDMuNS43IDMuNSAyLjMgMCAuNC0uMS45LS4xIDEuMy0uMS41LS4xLjktLjEgMS4zIDAgLjUuMiAxIDEuNyAxdjEuOHpNMS44IDEwLjFjMS42IDAgMS43LS41IDEuNy0xIDAtLjQtLjEtLjktLjEtMS4zLS4xLS41LS4xLS45LS4xLTEuMyAwLTEuNiAxLjQtMi4zIDMuNS0yLjNoLjl2MS45aC0uNWMtMSAwLTEuNCAwLTEuNC44IDAgLjMgMCAuNi4xIDEgMCAuMi4xLjYuMSAxIDAgMS4zIDAgMS44LTEuMyAyQzYgMTEuMiA2IDExLjcgNiAxM2MwIC40LS4xLjgtLjEgMS4yLS4xLjMtLjEuNy0uMSAxIDAgLjguMy44IDEuNC44aC41djEuOWgtLjljLTIuMSAwLTMuNS0uNi0zLjUtMi4zIDAtLjQuMS0uOS4xLTEuMy4xLS41LjEtLjkuMS0xLjMgMC0uNS0uMi0xLTEuNy0xdi0xLjl6Ii8+CiAgICA8Y2lyY2xlIGN4PSIxMSIgY3k9IjEzLjgiIHI9IjIuMSIvPgogICAgPGNpcmNsZSBjeD0iMTEiIGN5PSI4LjIiIHI9IjIuMSIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-julia: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDMyNSAzMDAiPgogIDxnIGNsYXNzPSJqcC1icmFuZDAganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjY2IzYzMzIj4KICAgIDxwYXRoIGQ9Ik0gMTUwLjg5ODQzOCAyMjUgQyAxNTAuODk4NDM4IDI2Ni40MjE4NzUgMTE3LjMyMDMxMiAzMDAgNzUuODk4NDM4IDMwMCBDIDM0LjQ3NjU2MiAzMDAgMC44OTg0MzggMjY2LjQyMTg3NSAwLjg5ODQzOCAyMjUgQyAwLjg5ODQzOCAxODMuNTc4MTI1IDM0LjQ3NjU2MiAxNTAgNzUuODk4NDM4IDE1MCBDIDExNy4zMjAzMTIgMTUwIDE1MC44OTg0MzggMTgzLjU3ODEyNSAxNTAuODk4NDM4IDIyNSIvPgogIDwvZz4KICA8ZyBjbGFzcz0ianAtYnJhbmQwIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iIzM4OTgyNiI+CiAgICA8cGF0aCBkPSJNIDIzNy41IDc1IEMgMjM3LjUgMTE2LjQyMTg3NSAyMDMuOTIxODc1IDE1MCAxNjIuNSAxNTAgQyAxMjEuMDc4MTI1IDE1MCA4Ny41IDExNi40MjE4NzUgODcuNSA3NSBDIDg3LjUgMzMuNTc4MTI1IDEyMS4wNzgxMjUgMCAxNjIuNSAwIEMgMjAzLjkyMTg3NSAwIDIzNy41IDMzLjU3ODEyNSAyMzcuNSA3NSIvPgogIDwvZz4KICA8ZyBjbGFzcz0ianAtYnJhbmQwIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iIzk1NThiMiI+CiAgICA8cGF0aCBkPSJNIDMyNC4xMDE1NjIgMjI1IEMgMzI0LjEwMTU2MiAyNjYuNDIxODc1IDI5MC41MjM0MzggMzAwIDI0OS4xMDE1NjIgMzAwIEMgMjA3LjY3OTY4OCAzMDAgMTc0LjEwMTU2MiAyNjYuNDIxODc1IDE3NC4xMDE1NjIgMjI1IEMgMTc0LjEwMTU2MiAxODMuNTc4MTI1IDIwNy42Nzk2ODggMTUwIDI0OS4xMDE1NjIgMTUwIEMgMjkwLjUyMzQzOCAxNTAgMzI0LjEwMTU2MiAxODMuNTc4MTI1IDMyNC4xMDE1NjIgMjI1Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-jupyter-favicon: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTUyIiBoZWlnaHQ9IjE2NSIgdmlld0JveD0iMCAwIDE1MiAxNjUiIHZlcnNpb249IjEuMSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgPGcgY2xhc3M9ImpwLWp1cHl0ZXItaWNvbi1jb2xvciIgZmlsbD0iI0YzNzcyNiI+CiAgICA8cGF0aCB0cmFuc2Zvcm09InRyYW5zbGF0ZSgwLjA3ODk0NywgMTEwLjU4MjkyNykiIGQ9Ik03NS45NDIyODQyLDI5LjU4MDQ1NjEgQzQzLjMwMjM5NDcsMjkuNTgwNDU2MSAxNC43OTY3ODMyLDE3LjY1MzQ2MzQgMCwwIEM1LjUxMDgzMjExLDE1Ljg0MDY4MjkgMTUuNzgxNTM4OSwyOS41NjY3NzMyIDI5LjM5MDQ5NDcsMzkuMjc4NDE3MSBDNDIuOTk5Nyw0OC45ODk4NTM3IDU5LjI3MzcsNTQuMjA2NzgwNSA3NS45NjA1Nzg5LDU0LjIwNjc4MDUgQzkyLjY0NzQ1NzksNTQuMjA2NzgwNSAxMDguOTIxNDU4LDQ4Ljk4OTg1MzcgMTIyLjUzMDY2MywzOS4yNzg0MTcxIEMxMzYuMTM5NDUzLDI5LjU2Njc3MzIgMTQ2LjQxMDI4NCwxNS44NDA2ODI5IDE1MS45MjExNTgsMCBDMTM3LjA4Nzg2OCwxNy42NTM0NjM0IDEwOC41ODI1ODksMjkuNTgwNDU2MSA3NS45NDIyODQyLDI5LjU4MDQ1NjEgTDc1Ljk0MjI4NDIsMjkuNTgwNDU2MSBaIiAvPgogICAgPHBhdGggdHJhbnNmb3JtPSJ0cmFuc2xhdGUoMC4wMzczNjgsIDAuNzA0ODc4KSIgZD0iTTc1Ljk3ODQ1NzksMjQuNjI2NDA3MyBDMTA4LjYxODc2MywyNC42MjY0MDczIDEzNy4xMjQ0NTgsMzYuNTUzNDQxNSAxNTEuOTIxMTU4LDU0LjIwNjc4MDUgQzE0Ni40MTAyODQsMzguMzY2MjIyIDEzNi4xMzk0NTMsMjQuNjQwMTMxNyAxMjIuNTMwNjYzLDE0LjkyODQ4NzggQzEwOC45MjE0NTgsNS4yMTY4NDM5IDkyLjY0NzQ1NzksMCA3NS45NjA1Nzg5LDAgQzU5LjI3MzcsMCA0Mi45OTk3LDUuMjE2ODQzOSAyOS4zOTA0OTQ3LDE0LjkyODQ4NzggQzE1Ljc4MTUzODksMjQuNjQwMTMxNyA1LjUxMDgzMjExLDM4LjM2NjIyMiAwLDU0LjIwNjc4MDUgQzE0LjgzMzA4MTYsMzYuNTg5OTI5MyA0My4zMzg1Njg0LDI0LjYyNjQwNzMgNzUuOTc4NDU3OSwyNC42MjY0MDczIEw3NS45Nzg0NTc5LDI0LjYyNjQwNzMgWiIgLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-jupyter: url(data:image/svg+xml;base64,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);
  --jp-icon-jupyterlab-wordmark: url(data:image/svg+xml;base64,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);
  --jp-icon-kernel: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgZmlsbD0iIzYxNjE2MSIgZD0iTTE1IDlIOXY2aDZWOXptLTIgNGgtMnYtMmgydjJ6bTgtMlY5aC0yVjdjMC0xLjEtLjktMi0yLTJoLTJWM2gtMnYyaC0yVjNIOXYySDdjLTEuMSAwLTIgLjktMiAydjJIM3YyaDJ2MkgzdjJoMnYyYzAgMS4xLjkgMiAyIDJoMnYyaDJ2LTJoMnYyaDJ2LTJoMmMxLjEgMCAyLS45IDItMnYtMmgydi0yaC0ydi0yaDJ6bS00IDZIN1Y3aDEwdjEweiIvPgo8L3N2Zz4K);
  --jp-icon-keyboard: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMjAgNUg0Yy0xLjEgMC0xLjk5LjktMS45OSAyTDIgMTdjMCAxLjEuOSAyIDIgMmgxNmMxLjEgMCAyLS45IDItMlY3YzAtMS4xLS45LTItMi0yem0tOSAzaDJ2MmgtMlY4em0wIDNoMnYyaC0ydi0yek04IDhoMnYySDhWOHptMCAzaDJ2Mkg4di0yem0tMSAySDV2LTJoMnYyem0wLTNINVY4aDJ2MnptOSA3SDh2LTJoOHYyem0wLTRoLTJ2LTJoMnYyem0wLTNoLTJWOGgydjJ6bTMgM2gtMnYtMmgydjJ6bTAtM2gtMlY4aDJ2MnoiLz4KPC9zdmc+Cg==);
  --jp-icon-launch: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMzIgMzIiIHdpZHRoPSIzMiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik0yNiwyOEg2YTIuMDAyNywyLjAwMjcsMCwwLDEtMi0yVjZBMi4wMDI3LDIuMDAyNywwLDAsMSw2LDRIMTZWNkg2VjI2SDI2VjE2aDJWMjZBMi4wMDI3LDIuMDAyNywwLDAsMSwyNiwyOFoiLz4KICAgIDxwb2x5Z29uIHBvaW50cz0iMjAgMiAyMCA0IDI2LjU4NiA0IDE4IDEyLjU4NiAxOS40MTQgMTQgMjggNS40MTQgMjggMTIgMzAgMTIgMzAgMiAyMCAyIi8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-launcher: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTkgMTlINVY1aDdWM0g1YTIgMiAwIDAwLTIgMnYxNGEyIDIgMCAwMDIgMmgxNGMxLjEgMCAyLS45IDItMnYtN2gtMnY3ek0xNCAzdjJoMy41OWwtOS44MyA5LjgzIDEuNDEgMS40MUwxOSA2LjQxVjEwaDJWM2gtN3oiLz4KPC9zdmc+Cg==);
  --jp-icon-line-form: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxwYXRoIGZpbGw9IndoaXRlIiBkPSJNNS44OCA0LjEyTDEzLjc2IDEybC03Ljg4IDcuODhMOCAyMmwxMC0xMEw4IDJ6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-link: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTMuOSAxMmMwLTEuNzEgMS4zOS0zLjEgMy4xLTMuMWg0VjdIN2MtMi43NiAwLTUgMi4yNC01IDVzMi4yNCA1IDUgNWg0di0xLjlIN2MtMS43MSAwLTMuMS0xLjM5LTMuMS0zLjF6TTggMTNoOHYtMkg4djJ6bTktNmgtNHYxLjloNGMxLjcxIDAgMy4xIDEuMzkgMy4xIDMuMXMtMS4zOSAzLjEtMy4xIDMuMWgtNFYxN2g0YzIuNzYgMCA1LTIuMjQgNS01cy0yLjI0LTUtNS01eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-list: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiM2MTYxNjEiIGQ9Ik0xOSA1djE0SDVWNWgxNG0xLjEtMkgzLjljLS41IDAtLjkuNC0uOS45djE2LjJjMCAuNC40LjkuOS45aDE2LjJjLjQgMCAuOS0uNS45LS45VjMuOWMwLS41LS41LS45LS45LS45ek0xMSA3aDZ2MmgtNlY3em0wIDRoNnYyaC02di0yem0wIDRoNnYyaC02ek03IDdoMnYySDd6bTAgNGgydjJIN3ptMCA0aDJ2Mkg3eiIvPgo8L3N2Zz4K);
  --jp-icon-markdown: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1jb250cmFzdDAganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjN0IxRkEyIiBkPSJNNSAxNC45aDEybC02LjEgNnptOS40LTYuOGMwLTEuMy0uMS0yLjktLjEtNC41LS40IDEuNC0uOSAyLjktMS4zIDQuM2wtMS4zIDQuM2gtMkw4LjUgNy45Yy0uNC0xLjMtLjctMi45LTEtNC4zLS4xIDEuNi0uMSAzLjItLjIgNC42TDcgMTIuNEg0LjhsLjctMTFoMy4zTDEwIDVjLjQgMS4yLjcgMi43IDEgMy45LjMtMS4yLjctMi42IDEtMy45bDEuMi0zLjdoMy4zbC42IDExaC0yLjRsLS4zLTQuMnoiLz4KPC9zdmc+Cg==);
  --jp-icon-move-down: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTQiIGhlaWdodD0iMTQiIHZpZXdCb3g9IjAgMCAxNCAxNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggY2xhc3M9ImpwLWljb24zIiBkPSJNMTIuNDcxIDcuNTI4OTlDMTIuNzYzMiA3LjIzNjg0IDEyLjc2MzIgNi43NjMxNiAxMi40NzEgNi40NzEwMVY2LjQ3MTAxQzEyLjE3OSA2LjE3OTA1IDExLjcwNTcgNi4xNzg4NCAxMS40MTM1IDYuNDcwNTRMNy43NSAxMC4xMjc1VjEuNzVDNy43NSAxLjMzNTc5IDcuNDE0MjEgMSA3IDFWMUM2LjU4NTc5IDEgNi4yNSAxLjMzNTc5IDYuMjUgMS43NVYxMC4xMjc1TDIuNTk3MjYgNi40NjgyMkMyLjMwMzM4IDYuMTczODEgMS44MjY0MSA2LjE3MzU5IDEuNTMyMjYgNi40Njc3NFY2LjQ2Nzc0QzEuMjM4MyA2Ljc2MTcgMS4yMzgzIDcuMjM4MyAxLjUzMjI2IDcuNTMyMjZMNi4yOTI4OSAxMi4yOTI5QzYuNjgzNDIgMTIuNjgzNCA3LjMxNjU4IDEyLjY4MzQgNy43MDcxMSAxMi4yOTI5TDEyLjQ3MSA3LjUyODk5WiIgZmlsbD0iIzYxNjE2MSIvPgo8L3N2Zz4K);
  --jp-icon-move-up: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTQiIGhlaWdodD0iMTQiIHZpZXdCb3g9IjAgMCAxNCAxNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggY2xhc3M9ImpwLWljb24zIiBkPSJNMS41Mjg5OSA2LjQ3MTAxQzEuMjM2ODQgNi43NjMxNiAxLjIzNjg0IDcuMjM2ODQgMS41Mjg5OSA3LjUyODk5VjcuNTI4OTlDMS44MjA5NSA3LjgyMDk1IDIuMjk0MjYgNy44MjExNiAyLjU4NjQ5IDcuNTI5NDZMNi4yNSAzLjg3MjVWMTIuMjVDNi4yNSAxMi42NjQyIDYuNTg1NzkgMTMgNyAxM1YxM0M3LjQxNDIxIDEzIDcuNzUgMTIuNjY0MiA3Ljc1IDEyLjI1VjMuODcyNUwxMS40MDI3IDcuNTMxNzhDMTEuNjk2NiA3LjgyNjE5IDEyLjE3MzYgNy44MjY0MSAxMi40Njc3IDcuNTMyMjZWNy41MzIyNkMxMi43NjE3IDcuMjM4MyAxMi43NjE3IDYuNzYxNyAxMi40Njc3IDYuNDY3NzRMNy43MDcxMSAxLjcwNzExQzcuMzE2NTggMS4zMTY1OCA2LjY4MzQyIDEuMzE2NTggNi4yOTI4OSAxLjcwNzExTDEuNTI4OTkgNi40NzEwMVoiIGZpbGw9IiM2MTYxNjEiLz4KPC9zdmc+Cg==);
  --jp-icon-new-folder: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTIwIDZoLThsLTItMkg0Yy0xLjExIDAtMS45OS44OS0xLjk5IDJMMiAxOGMwIDEuMTEuODkgMiAyIDJoMTZjMS4xMSAwIDItLjg5IDItMlY4YzAtMS4xMS0uODktMi0yLTJ6bS0xIDhoLTN2M2gtMnYtM2gtM3YtMmgzVjloMnYzaDN2MnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-not-trusted: url(data:image/svg+xml;base64,PHN2ZyBmaWxsPSJub25lIiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI1IDI1Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgc3Ryb2tlPSIjMzMzMzMzIiBzdHJva2Utd2lkdGg9IjIiIHRyYW5zZm9ybT0idHJhbnNsYXRlKDMgMykiIGQ9Ik0xLjg2MDk0IDExLjQ0MDlDMC44MjY0NDggOC43NzAyNyAwLjg2Mzc3OSA2LjA1NzY0IDEuMjQ5MDcgNC4xOTkzMkMyLjQ4MjA2IDMuOTMzNDcgNC4wODA2OCAzLjQwMzQ3IDUuNjAxMDIgMi44NDQ5QzcuMjM1NDkgMi4yNDQ0IDguODU2NjYgMS41ODE1IDkuOTg3NiAxLjA5NTM5QzExLjA1OTcgMS41ODM0MSAxMi42MDk0IDIuMjQ0NCAxNC4yMTggMi44NDMzOUMxNS43NTAzIDMuNDEzOTQgMTcuMzk5NSAzLjk1MjU4IDE4Ljc1MzkgNC4yMTM4NUMxOS4xMzY0IDYuMDcxNzcgMTkuMTcwOSA4Ljc3NzIyIDE4LjEzOSAxMS40NDA5QzE3LjAzMDMgMTQuMzAzMiAxNC42NjY4IDE3LjE4NDQgOS45OTk5OSAxOC45MzU0QzUuMzMzMTkgMTcuMTg0NCAyLjk2OTY4IDE0LjMwMzIgMS44NjA5NCAxMS40NDA5WiIvPgogICAgPHBhdGggY2xhc3M9ImpwLWljb24yIiBzdHJva2U9IiMzMzMzMzMiIHN0cm9rZS13aWR0aD0iMiIgdHJhbnNmb3JtPSJ0cmFuc2xhdGUoOS4zMTU5MiA5LjMyMDMxKSIgZD0iTTcuMzY4NDIgMEwwIDcuMzY0NzkiLz4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgc3Ryb2tlPSIjMzMzMzMzIiBzdHJva2Utd2lkdGg9IjIiIHRyYW5zZm9ybT0idHJhbnNsYXRlKDkuMzE1OTIgMTYuNjgzNikgc2NhbGUoMSAtMSkiIGQ9Ik03LjM2ODQyIDBMMCA3LjM2NDc5Ii8+Cjwvc3ZnPgo=);
  --jp-icon-notebook: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtbm90ZWJvb2staWNvbi1jb2xvciBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiNFRjZDMDAiPgogICAgPHBhdGggZD0iTTE4LjcgMy4zdjE1LjRIMy4zVjMuM2gxNS40bTEuNS0xLjVIMS44djE4LjNoMTguM2wuMS0xOC4zeiIvPgogICAgPHBhdGggZD0iTTE2LjUgMTYuNWwtNS40LTQuMy01LjYgNC4zdi0xMWgxMXoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-numbering: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjIiIGhlaWdodD0iMjIiIHZpZXdCb3g9IjAgMCAyOCAyOCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CgkJPHBhdGggZD0iTTQgMTlINlYxOS41SDVWMjAuNUg2VjIxSDRWMjJIN1YxOEg0VjE5Wk01IDEwSDZWNkg0VjdINVYxMFpNNCAxM0g1LjhMNCAxNS4xVjE2SDdWMTVINS4yTDcgMTIuOVYxMkg0VjEzWk05IDdWOUgyM1Y3SDlaTTkgMjFIMjNWMTlIOVYyMVpNOSAxNUgyM1YxM0g5VjE1WiIvPgoJPC9nPgo8L3N2Zz4K);
  --jp-icon-offline-bolt: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAyNCAyNCIgd2lkdGg9IjE2Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyIDIuMDJjLTUuNTEgMC05Ljk4IDQuNDctOS45OCA5Ljk4czQuNDcgOS45OCA5Ljk4IDkuOTggOS45OC00LjQ3IDkuOTgtOS45OFMxNy41MSAyLjAyIDEyIDIuMDJ6TTExLjQ4IDIwdi02LjI2SDhMMTMgNHY2LjI2aDMuMzVMMTEuNDggMjB6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-palette: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE4IDEzVjIwSDRWNkg5LjAyQzkuMDcgNS4yOSA5LjI0IDQuNjIgOS41IDRINEMyLjkgNCAyIDQuOSAyIDZWMjBDMiAyMS4xIDIuOSAyMiA0IDIySDE4QzE5LjEgMjIgMjAgMjEuMSAyMCAyMFYxNUwxOCAxM1pNMTkuMyA4Ljg5QzE5Ljc0IDguMTkgMjAgNy4zOCAyMCA2LjVDMjAgNC4wMSAxNy45OSAyIDE1LjUgMkMxMy4wMSAyIDExIDQuMDEgMTEgNi41QzExIDguOTkgMTMuMDEgMTEgMTUuNDkgMTFDMTYuMzcgMTEgMTcuMTkgMTAuNzQgMTcuODggMTAuM0wyMSAxMy40MkwyMi40MiAxMkwxOS4zIDguODlaTTE1LjUgOUMxNC4xMiA5IDEzIDcuODggMTMgNi41QzEzIDUuMTIgMTQuMTIgNCAxNS41IDRDMTYuODggNCAxOCA1LjEyIDE4IDYuNUMxOCA3Ljg4IDE2Ljg4IDkgMTUuNSA5WiIvPgogICAgPHBhdGggZmlsbC1ydWxlPSJldmVub2RkIiBjbGlwLXJ1bGU9ImV2ZW5vZGQiIGQ9Ik00IDZIOS4wMTg5NEM5LjAwNjM5IDYuMTY1MDIgOSA2LjMzMTc2IDkgNi41QzkgOC44MTU3NyAxMC4yMTEgMTAuODQ4NyAxMi4wMzQzIDEySDlWMTRIMTZWMTIuOTgxMUMxNi41NzAzIDEyLjkzNzcgMTcuMTIgMTIuODIwNyAxNy42Mzk2IDEyLjYzOTZMMTggMTNWMjBINFY2Wk04IDhINlYxMEg4VjhaTTYgMTJIOFYxNEg2VjEyWk04IDE2SDZWMThIOFYxNlpNOSAxNkgxNlYxOEg5VjE2WiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-paste: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTE5IDJoLTQuMThDMTQuNC44NCAxMy4zIDAgMTIgMGMtMS4zIDAtMi40Ljg0LTIuODIgMkg1Yy0xLjEgMC0yIC45LTIgMnYxNmMwIDEuMS45IDIgMiAyaDE0YzEuMSAwIDItLjkgMi0yVjRjMC0xLjEtLjktMi0yLTJ6bS03IDBjLjU1IDAgMSAuNDUgMSAxcy0uNDUgMS0xIDEtMS0uNDUtMS0xIC40NS0xIDEtMXptNyAxOEg1VjRoMnYzaDEwVjRoMnYxNnoiLz4KICAgIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-pdf: url(data:image/svg+xml;base64,PHN2ZwogICB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAyMiAyMiIgd2lkdGg9IjE2Ij4KICAgIDxwYXRoIHRyYW5zZm9ybT0icm90YXRlKDQ1KSIgY2xhc3M9ImpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iI0ZGMkEyQSIKICAgICAgIGQ9Im0gMjIuMzQ0MzY5LC0zLjAxNjM2NDIgaCA1LjYzODYwNCB2IDEuNTc5MjQzMyBoIC0zLjU0OTIyNyB2IDEuNTA4NjkyOTkgaCAzLjMzNzU3NiBWIDEuNjUwODE1NCBoIC0zLjMzNzU3NiB2IDMuNDM1MjYxMyBoIC0yLjA4OTM3NyB6IG0gLTcuMTM2NDQ0LDEuNTc5MjQzMyB2IDQuOTQzOTU0MyBoIDAuNzQ4OTIgcSAxLjI4MDc2MSwwIDEuOTUzNzAzLC0wLjYzNDk1MzUgMC42NzgzNjksLTAuNjM0OTUzNSAwLjY3ODM2OSwtMS44NDUxNjQxIDAsLTEuMjA0NzgzNTUgLTAuNjcyOTQyLC0xLjgzNDMxMDExIC0wLjY3Mjk0MiwtMC42Mjk1MjY1OSAtMS45NTkxMywtMC42Mjk1MjY1OSB6IG0gLTIuMDg5Mzc3LC0xLjU3OTI0MzMgaCAyLjIwMzM0MyBxIDEuODQ1MTY0LDAgMi43NDYwMzksMC4yNjU5MjA3IDAuOTA2MzAxLDAuMjYwNDkzNyAxLjU1MjEwOCwwLjg5MDAyMDMgMC41Njk4MywwLjU0ODEyMjMgMC44NDY2MDUsMS4yNjQ0ODAwNiAwLjI3Njc3NCwwLjcxNjM1NzgxIDAuMjc2Nzc0LDEuNjIyNjU4OTQgMCwwLjkxNzE1NTEgLTAuMjc2Nzc0LDEuNjM4OTM5OSAtMC4yNzY3NzUsMC43MTYzNTc4IC0wLjg0NjYwNSwxLjI2NDQ4IC0wLjY1MTIzNCwwLjYyOTUyNjYgLTEuNTYyOTYyLDAuODk1NDQ3MyAtMC45MTE3MjgsMC4yNjA0OTM3IC0yLjczNTE4NSwwLjI2MDQ5MzcgaCAtMi4yMDMzNDMgeiBtIC04LjE0NTg1NjUsMCBoIDMuNDY3ODIzIHEgMS41NDY2ODE2LDAgMi4zNzE1Nzg1LDAuNjg5MjIzIDAuODMwMzI0LDAuNjgzNzk2MSAwLjgzMDMyNCwxLjk1MzcwMzE0IDAsMS4yNzUzMzM5NyAtMC44MzAzMjQsMS45NjQ1NTcwNiBRIDkuOTg3MTk2MSwyLjI3NDkxNSA4LjQ0MDUxNDUsMi4yNzQ5MTUgSCA3LjA2MjA2ODQgViA1LjA4NjA3NjcgSCA0Ljk3MjY5MTUgWiBtIDIuMDg5Mzc2OSwxLjUxNDExOTkgdiAyLjI2MzAzOTQzIGggMS4xNTU5NDEgcSAwLjYwNzgxODgsMCAwLjkzODg2MjksLTAuMjkzMDU1NDcgMC4zMzEwNDQxLC0wLjI5ODQ4MjQxIDAuMzMxMDQ0MSwtMC44NDExNzc3MiAwLC0wLjU0MjY5NTMxIC0wLjMzMTA0NDEsLTAuODM1NzUwNzQgLTAuMzMxMDQ0MSwtMC4yOTMwNTU1IC0wLjkzODg2MjksLTAuMjkzMDU1NSB6IgovPgo8L3N2Zz4K);
  --jp-icon-python: url(data:image/svg+xml;base64,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);
  --jp-icon-r-kernel: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1jb250cmFzdDMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjMjE5NkYzIiBkPSJNNC40IDIuNWMxLjItLjEgMi45LS4zIDQuOS0uMyAyLjUgMCA0LjEuNCA1LjIgMS4zIDEgLjcgMS41IDEuOSAxLjUgMy41IDAgMi0xLjQgMy41LTIuOSA0LjEgMS4yLjQgMS43IDEuNiAyLjIgMyAuNiAxLjkgMSAzLjkgMS4zIDQuNmgtMy44Yy0uMy0uNC0uOC0xLjctMS4yLTMuN3MtMS4yLTIuNi0yLjYtMi42aC0uOXY2LjRINC40VjIuNXptMy43IDYuOWgxLjRjMS45IDAgMi45LS45IDIuOS0yLjNzLTEtMi4zLTIuOC0yLjNjLS43IDAtMS4zIDAtMS42LjJ2NC41aC4xdi0uMXoiLz4KPC9zdmc+Cg==);
  --jp-icon-react: url(data:image/svg+xml;base64,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);
  --jp-icon-redo: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGhlaWdodD0iMjQiIHZpZXdCb3g9IjAgMCAyNCAyNCIgd2lkdGg9IjE2Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgICA8cGF0aCBkPSJNMCAwaDI0djI0SDB6IiBmaWxsPSJub25lIi8+PHBhdGggZD0iTTE4LjQgMTAuNkMxNi41NSA4Ljk5IDE0LjE1IDggMTEuNSA4Yy00LjY1IDAtOC41OCAzLjAzLTkuOTYgNy4yMkwzLjkgMTZjMS4wNS0zLjE5IDQuMDUtNS41IDcuNi01LjUgMS45NSAwIDMuNzMuNzIgNS4xMiAxLjg4TDEzIDE2aDlWN2wtMy42IDMuNnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-refresh: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTkgMTMuNWMtMi40OSAwLTQuNS0yLjAxLTQuNS00LjVTNi41MSA0LjUgOSA0LjVjMS4yNCAwIDIuMzYuNTIgMy4xNyAxLjMzTDEwIDhoNVYzbC0xLjc2IDEuNzZDMTIuMTUgMy42OCAxMC42NiAzIDkgMyA1LjY5IDMgMy4wMSA1LjY5IDMuMDEgOVM1LjY5IDE1IDkgMTVjMi45NyAwIDUuNDMtMi4xNiA1LjktNWgtMS41MmMtLjQ2IDItMi4yNCAzLjUtNC4zOCAzLjV6Ii8+CiAgICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-regex: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KICA8ZyBjbGFzcz0ianAtaWNvbjIiIGZpbGw9IiM0MTQxNDEiPgogICAgPHJlY3QgeD0iMiIgeT0iMiIgd2lkdGg9IjE2IiBoZWlnaHQ9IjE2Ii8+CiAgPC9nPgoKICA8ZyBjbGFzcz0ianAtaWNvbi1hY2NlbnQyIiBmaWxsPSIjRkZGIj4KICAgIDxjaXJjbGUgY2xhc3M9InN0MiIgY3g9IjUuNSIgY3k9IjE0LjUiIHI9IjEuNSIvPgogICAgPHJlY3QgeD0iMTIiIHk9IjQiIGNsYXNzPSJzdDIiIHdpZHRoPSIxIiBoZWlnaHQ9IjgiLz4KICAgIDxyZWN0IHg9IjguNSIgeT0iNy41IiB0cmFuc2Zvcm09Im1hdHJpeCgwLjg2NiAtMC41IDAuNSAwLjg2NiAtMi4zMjU1IDcuMzIxOSkiIGNsYXNzPSJzdDIiIHdpZHRoPSI4IiBoZWlnaHQ9IjEiLz4KICAgIDxyZWN0IHg9IjEyIiB5PSI0IiB0cmFuc2Zvcm09Im1hdHJpeCgwLjUgLTAuODY2IDAuODY2IDAuNSAtMC42Nzc5IDE0LjgyNTIpIiBjbGFzcz0ic3QyIiB3aWR0aD0iMSIgaGVpZ2h0PSI4Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-run: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTggNXYxNGwxMS03eiIvPgogICAgPC9nPgo8L3N2Zz4K);
  --jp-icon-running: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDUxMiA1MTIiPgogIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICA8cGF0aCBkPSJNMjU2IDhDMTE5IDggOCAxMTkgOCAyNTZzMTExIDI0OCAyNDggMjQ4IDI0OC0xMTEgMjQ4LTI0OFMzOTMgOCAyNTYgOHptOTYgMzI4YzAgOC44LTcuMiAxNi0xNiAxNkgxNzZjLTguOCAwLTE2LTcuMi0xNi0xNlYxNzZjMC04LjggNy4yLTE2IDE2LTE2aDE2MGM4LjggMCAxNiA3LjIgMTYgMTZ2MTYweiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-save: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTE3IDNINWMtMS4xMSAwLTIgLjktMiAydjE0YzAgMS4xLjg5IDIgMiAyaDE0YzEuMSAwIDItLjkgMi0yVjdsLTQtNHptLTUgMTZjLTEuNjYgMC0zLTEuMzQtMy0zczEuMzQtMyAzLTMgMyAxLjM0IDMgMy0xLjM0IDMtMyAzem0zLTEwSDVWNWgxMHY0eiIvPgogICAgPC9nPgo8L3N2Zz4K);
  --jp-icon-search: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMTggMTgiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyLjEsMTAuOWgtMC43bC0wLjItMC4yYzAuOC0wLjksMS4zLTIuMiwxLjMtMy41YzAtMy0yLjQtNS40LTUuNC01LjRTMS44LDQuMiwxLjgsNy4xczIuNCw1LjQsNS40LDUuNCBjMS4zLDAsMi41LTAuNSwzLjUtMS4zbDAuMiwwLjJ2MC43bDQuMSw0LjFsMS4yLTEuMkwxMi4xLDEwLjl6IE03LjEsMTAuOWMtMi4xLDAtMy43LTEuNy0zLjctMy43czEuNy0zLjcsMy43LTMuN3MzLjcsMS43LDMuNywzLjcgUzkuMiwxMC45LDcuMSwxMC45eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-settings: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTkuNDMgMTIuOThjLjA0LS4zMi4wNy0uNjQuMDctLjk4cy0uMDMtLjY2LS4wNy0uOThsMi4xMS0xLjY1Yy4xOS0uMTUuMjQtLjQyLjEyLS42NGwtMi0zLjQ2Yy0uMTItLjIyLS4zOS0uMy0uNjEtLjIybC0yLjQ5IDFjLS41Mi0uNC0xLjA4LS43My0xLjY5LS45OGwtLjM4LTIuNjVBLjQ4OC40ODggMCAwMDE0IDJoLTRjLS4yNSAwLS40Ni4xOC0uNDkuNDJsLS4zOCAyLjY1Yy0uNjEuMjUtMS4xNy41OS0xLjY5Ljk4bC0yLjQ5LTFjLS4yMy0uMDktLjQ5IDAtLjYxLjIybC0yIDMuNDZjLS4xMy4yMi0uMDcuNDkuMTIuNjRsMi4xMSAxLjY1Yy0uMDQuMzItLjA3LjY1LS4wNy45OHMuMDMuNjYuMDcuOThsLTIuMTEgMS42NWMtLjE5LjE1LS4yNC40Mi0uMTIuNjRsMiAzLjQ2Yy4xMi4yMi4zOS4zLjYxLjIybDIuNDktMWMuNTIuNCAxLjA4LjczIDEuNjkuOThsLjM4IDIuNjVjLjAzLjI0LjI0LjQyLjQ5LjQyaDRjLjI1IDAgLjQ2LS4xOC40OS0uNDJsLjM4LTIuNjVjLjYxLS4yNSAxLjE3LS41OSAxLjY5LS45OGwyLjQ5IDFjLjIzLjA5LjQ5IDAgLjYxLS4yMmwyLTMuNDZjLjEyLS4yMi4wNy0uNDktLjEyLS42NGwtMi4xMS0xLjY1ek0xMiAxNS41Yy0xLjkzIDAtMy41LTEuNTctMy41LTMuNXMxLjU3LTMuNSAzLjUtMy41IDMuNSAxLjU3IDMuNSAzLjUtMS41NyAzLjUtMy41IDMuNXoiLz4KPC9zdmc+Cg==);
  --jp-icon-share: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTYiIHZpZXdCb3g9IjAgMCAyNCAyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTSAxOCAyIEMgMTYuMzU0OTkgMiAxNSAzLjM1NDk5MDQgMTUgNSBDIDE1IDUuMTkwOTUyOSAxNS4wMjE3OTEgNS4zNzcxMjI0IDE1LjA1NjY0MSA1LjU1ODU5MzggTCA3LjkyMTg3NSA5LjcyMDcwMzEgQyA3LjM5ODUzOTkgOS4yNzc4NTM5IDYuNzMyMDc3MSA5IDYgOSBDIDQuMzU0OTkwNCA5IDMgMTAuMzU0OTkgMyAxMiBDIDMgMTMuNjQ1MDEgNC4zNTQ5OTA0IDE1IDYgMTUgQyA2LjczMjA3NzEgMTUgNy4zOTg1Mzk5IDE0LjcyMjE0NiA3LjkyMTg3NSAxNC4yNzkyOTcgTCAxNS4wNTY2NDEgMTguNDM5NDUzIEMgMTUuMDIxNTU1IDE4LjYyMTUxNCAxNSAxOC44MDgzODYgMTUgMTkgQyAxNSAyMC42NDUwMSAxNi4zNTQ5OSAyMiAxOCAyMiBDIDE5LjY0NTAxIDIyIDIxIDIwLjY0NTAxIDIxIDE5IEMgMjEgMTcuMzU0OTkgMTkuNjQ1MDEgMTYgMTggMTYgQyAxNy4yNjc0OCAxNiAxNi42MDE1OTMgMTYuMjc5MzI4IDE2LjA3ODEyNSAxNi43MjI2NTYgTCA4Ljk0MzM1OTQgMTIuNTU4NTk0IEMgOC45NzgyMDk1IDEyLjM3NzEyMiA5IDEyLjE5MDk1MyA5IDEyIEMgOSAxMS44MDkwNDcgOC45NzgyMDk1IDExLjYyMjg3OCA4Ljk0MzM1OTQgMTEuNDQxNDA2IEwgMTYuMDc4MTI1IDcuMjc5Mjk2OSBDIDE2LjYwMTQ2IDcuNzIyMTQ2MSAxNy4yNjc5MjMgOCAxOCA4IEMgMTkuNjQ1MDEgOCAyMSA2LjY0NTAwOTYgMjEgNSBDIDIxIDMuMzU0OTkwNCAxOS42NDUwMSAyIDE4IDIgeiBNIDE4IDQgQyAxOC41NjQxMjkgNCAxOSA0LjQzNTg3MDYgMTkgNSBDIDE5IDUuNTY0MTI5NCAxOC41NjQxMjkgNiAxOCA2IEMgMTcuNDM1ODcxIDYgMTcgNS41NjQxMjk0IDE3IDUgQyAxNyA0LjQzNTg3MDYgMTcuNDM1ODcxIDQgMTggNCB6IE0gNiAxMSBDIDYuNTY0MTI5NCAxMSA3IDExLjQzNTg3MSA3IDEyIEMgNyAxMi41NjQxMjkgNi41NjQxMjk0IDEzIDYgMTMgQyA1LjQzNTg3MDYgMTMgNSAxMi41NjQxMjkgNSAxMiBDIDUgMTEuNDM1ODcxIDUuNDM1ODcwNiAxMSA2IDExIHogTSAxOCAxOCBDIDE4LjU2NDEyOSAxOCAxOSAxOC40MzU4NzEgMTkgMTkgQyAxOSAxOS41NjQxMjkgMTguNTY0MTI5IDIwIDE4IDIwIEMgMTcuNDM1ODcxIDIwIDE3IDE5LjU2NDEyOSAxNyAxOSBDIDE3IDE4LjQzNTg3MSAxNy40MzU4NzEgMTggMTggMTggeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-spreadsheet: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1jb250cmFzdDEganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNENBRjUwIiBkPSJNMi4yIDIuMnYxNy42aDE3LjZWMi4ySDIuMnptMTUuNCA3LjdoLTUuNVY0LjRoNS41djUuNXpNOS45IDQuNHY1LjVINC40VjQuNGg1LjV6bS01LjUgNy43aDUuNXY1LjVINC40di01LjV6bTcuNyA1LjV2LTUuNWg1LjV2NS41aC01LjV6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-stop: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTAgMGgyNHYyNEgweiIgZmlsbD0ibm9uZSIvPgogICAgICAgIDxwYXRoIGQ9Ik02IDZoMTJ2MTJINnoiLz4KICAgIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-tab: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTIxIDNIM2MtMS4xIDAtMiAuOS0yIDJ2MTRjMCAxLjEuOSAyIDIgMmgxOGMxLjEgMCAyLS45IDItMlY1YzAtMS4xLS45LTItMi0yem0wIDE2SDNWNWgxMHY0aDh2MTB6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-table-rows: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTAgMGgyNHYyNEgweiIgZmlsbD0ibm9uZSIvPgogICAgICAgIDxwYXRoIGQ9Ik0yMSw4SDNWNGgxOFY4eiBNMjEsMTBIM3Y0aDE4VjEweiBNMjEsMTZIM3Y0aDE4VjE2eiIvPgogICAgPC9nPgo8L3N2Zz4K);
  --jp-icon-tag: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjgiIGhlaWdodD0iMjgiIHZpZXdCb3g9IjAgMCA0MyAyOCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CgkJPHBhdGggZD0iTTI4LjgzMzIgMTIuMzM0TDMyLjk5OTggMTYuNTAwN0wzNy4xNjY1IDEyLjMzNEgyOC44MzMyWiIvPgoJCTxwYXRoIGQ9Ik0xNi4yMDk1IDIxLjYxMDRDMTUuNjg3MyAyMi4xMjk5IDE0Ljg0NDMgMjIuMTI5OSAxNC4zMjQ4IDIxLjYxMDRMNi45ODI5IDE0LjcyNDVDNi41NzI0IDE0LjMzOTQgNi4wODMxMyAxMy42MDk4IDYuMDQ3ODYgMTMuMDQ4MkM1Ljk1MzQ3IDExLjUyODggNi4wMjAwMiA4LjYxOTQ0IDYuMDY2MjEgNy4wNzY5NUM2LjA4MjgxIDYuNTE0NzcgNi41NTU0OCA2LjA0MzQ3IDcuMTE4MDQgNi4wMzA1NUM5LjA4ODYzIDUuOTg0NzMgMTMuMjYzOCA1LjkzNTc5IDEzLjY1MTggNi4zMjQyNUwyMS43MzY5IDEzLjYzOUMyMi4yNTYgMTQuMTU4NSAyMS43ODUxIDE1LjQ3MjQgMjEuMjYyIDE1Ljk5NDZMMTYuMjA5NSAyMS42MTA0Wk05Ljc3NTg1IDguMjY1QzkuMzM1NTEgNy44MjU2NiA4LjYyMzUxIDcuODI1NjYgOC4xODI4IDguMjY1QzcuNzQzNDYgOC43MDU3MSA3Ljc0MzQ2IDkuNDE3MzMgOC4xODI4IDkuODU2NjdDOC42MjM4MiAxMC4yOTY0IDkuMzM1ODIgMTAuMjk2NCA5Ljc3NTg1IDkuODU2NjdDMTAuMjE1NiA5LjQxNzMzIDEwLjIxNTYgOC43MDUzMyA5Ljc3NTg1IDguMjY1WiIvPgoJPC9nPgo8L3N2Zz4K);
  --jp-icon-terminal: url(data:image/svg+xml;base64,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);
  --jp-icon-text-editor: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtdGV4dC1lZGl0b3ItaWNvbi1jb2xvciBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiM2MTYxNjEiIGQ9Ik0xNSAxNUgzdjJoMTJ2LTJ6bTAtOEgzdjJoMTJWN3pNMyAxM2gxOHYtMkgzdjJ6bTAgOGgxOHYtMkgzdjJ6TTMgM3YyaDE4VjNIM3oiLz4KPC9zdmc+Cg==);
  --jp-icon-toc: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik03LDVIMjFWN0g3VjVNNywxM1YxMUgyMVYxM0g3TTQsNC41QTEuNSwxLjUgMCAwLDEgNS41LDZBMS41LDEuNSAwIDAsMSA0LDcuNUExLjUsMS41IDAgMCwxIDIuNSw2QTEuNSwxLjUgMCAwLDEgNCw0LjVNNCwxMC41QTEuNSwxLjUgMCAwLDEgNS41LDEyQTEuNSwxLjUgMCAwLDEgNCwxMy41QTEuNSwxLjUgMCAwLDEgMi41LDEyQTEuNSwxLjUgMCAwLDEgNCwxMC41TTcsMTlWMTdIMjFWMTlIN000LDE2LjVBMS41LDEuNSAwIDAsMSA1LjUsMThBMS41LDEuNSAwIDAsMSA0LDE5LjVBMS41LDEuNSAwIDAsMSAyLjUsMThBMS41LDEuNSAwIDAsMSA0LDE2LjVaIiAvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-tree-view: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTAgMGgyNHYyNEgweiIgZmlsbD0ibm9uZSIvPgogICAgICAgIDxwYXRoIGQ9Ik0yMiAxMVYzaC03djNIOVYzSDJ2OGg3VjhoMnYxMGg0djNoN3YtOGgtN3YzaC0yVjhoMnYzeiIvPgogICAgPC9nPgo8L3N2Zz4K);
  --jp-icon-trusted: url(data:image/svg+xml;base64,PHN2ZyBmaWxsPSJub25lIiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI1Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgc3Ryb2tlPSIjMzMzMzMzIiBzdHJva2Utd2lkdGg9IjIiIHRyYW5zZm9ybT0idHJhbnNsYXRlKDIgMykiIGQ9Ik0xLjg2MDk0IDExLjQ0MDlDMC44MjY0NDggOC43NzAyNyAwLjg2Mzc3OSA2LjA1NzY0IDEuMjQ5MDcgNC4xOTkzMkMyLjQ4MjA2IDMuOTMzNDcgNC4wODA2OCAzLjQwMzQ3IDUuNjAxMDIgMi44NDQ5QzcuMjM1NDkgMi4yNDQ0IDguODU2NjYgMS41ODE1IDkuOTg3NiAxLjA5NTM5QzExLjA1OTcgMS41ODM0MSAxMi42MDk0IDIuMjQ0NCAxNC4yMTggMi44NDMzOUMxNS43NTAzIDMuNDEzOTQgMTcuMzk5NSAzLjk1MjU4IDE4Ljc1MzkgNC4yMTM4NUMxOS4xMzY0IDYuMDcxNzcgMTkuMTcwOSA4Ljc3NzIyIDE4LjEzOSAxMS40NDA5QzE3LjAzMDMgMTQuMzAzMiAxNC42NjY4IDE3LjE4NDQgOS45OTk5OSAxOC45MzU0QzUuMzMzMiAxNy4xODQ0IDIuOTY5NjggMTQuMzAzMiAxLjg2MDk0IDExLjQ0MDlaIi8+CiAgICA8cGF0aCBjbGFzcz0ianAtaWNvbjIiIGZpbGw9IiMzMzMzMzMiIHN0cm9rZT0iIzMzMzMzMyIgdHJhbnNmb3JtPSJ0cmFuc2xhdGUoOCA5Ljg2NzE5KSIgZD0iTTIuODYwMTUgNC44NjUzNUwwLjcyNjU0OSAyLjk5OTU5TDAgMy42MzA0NUwyLjg2MDE1IDYuMTMxNTdMOCAwLjYzMDg3Mkw3LjI3ODU3IDBMMi44NjAxNSA0Ljg2NTM1WiIvPgo8L3N2Zz4K);
  --jp-icon-undo: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyLjUgOGMtMi42NSAwLTUuMDUuOTktNi45IDIuNkwyIDd2OWg5bC0zLjYyLTMuNjJjMS4zOS0xLjE2IDMuMTYtMS44OCA1LjEyLTEuODggMy41NCAwIDYuNTUgMi4zMSA3LjYgNS41bDIuMzctLjc4QzIxLjA4IDExLjAzIDE3LjE1IDggMTIuNSA4eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-user: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTYiIHZpZXdCb3g9IjAgMCAyNCAyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE2IDdhNCA0IDAgMTEtOCAwIDQgNCAwIDAxOCAwek0xMiAxNGE3IDcgMCAwMC03IDdoMTRhNyA3IDAgMDAtNy03eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-users: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjQiIGhlaWdodD0iMjQiIHZlcnNpb249IjEuMSIgdmlld0JveD0iMCAwIDM2IDI0IiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciPgogPGcgY2xhc3M9ImpwLWljb24zIiB0cmFuc2Zvcm09Im1hdHJpeCgxLjczMjcgMCAwIDEuNzMyNyAtMy42MjgyIC4wOTk1NzcpIiBmaWxsPSIjNjE2MTYxIj4KICA8cGF0aCB0cmFuc2Zvcm09Im1hdHJpeCgxLjUsMCwwLDEuNSwwLC02KSIgZD0ibTEyLjE4NiA3LjUwOThjLTEuMDUzNSAwLTEuOTc1NyAwLjU2NjUtMi40Nzg1IDEuNDEwMiAwLjc1MDYxIDAuMzEyNzcgMS4zOTc0IDAuODI2NDggMS44NzMgMS40NzI3aDMuNDg2M2MwLTEuNTkyLTEuMjg4OS0yLjg4MjgtMi44ODA5LTIuODgyOHoiLz4KICA8cGF0aCBkPSJtMjAuNDY1IDIuMzg5NWEyLjE4ODUgMi4xODg1IDAgMCAxLTIuMTg4NCAyLjE4ODUgMi4xODg1IDIuMTg4NSAwIDAgMS0yLjE4ODUtMi4xODg1IDIuMTg4NSAyLjE4ODUgMCAwIDEgMi4xODg1LTIuMTg4NSAyLjE4ODUgMi4xODg1IDAgMCAxIDIuMTg4NCAyLjE4ODV6Ii8+CiAgPHBhdGggdHJhbnNmb3JtPSJtYXRyaXgoMS41LDAsMCwxLjUsMCwtNikiIGQ9Im0zLjU4OTggOC40MjE5Yy0xLjExMjYgMC0yLjAxMzcgMC45MDExMS0yLjAxMzcgMi4wMTM3aDIuODE0NWMwLjI2Nzk3LTAuMzczMDkgMC41OTA3LTAuNzA0MzUgMC45NTg5OC0wLjk3ODUyLTAuMzQ0MzMtMC42MTY4OC0xLjAwMzEtMS4wMzUyLTEuNzU5OC0xLjAzNTJ6Ii8+CiAgPHBhdGggZD0ibTYuOTE1NCA0LjYyM2ExLjUyOTQgMS41Mjk0IDAgMCAxLTEuNTI5NCAxLjUyOTQgMS41Mjk0IDEuNTI5NCAwIDAgMS0xLjUyOTQtMS41Mjk0IDEuNTI5NCAxLjUyOTQgMCAwIDEgMS41Mjk0LTEuNTI5NCAxLjUyOTQgMS41Mjk0IDAgMCAxIDEuNTI5NCAxLjUyOTR6Ii8+CiAgPHBhdGggZD0ibTYuMTM1IDEzLjUzNWMwLTMuMjM5MiAyLjYyNTktNS44NjUgNS44NjUtNS44NjUgMy4yMzkyIDAgNS44NjUgMi42MjU5IDUuODY1IDUuODY1eiIvPgogIDxjaXJjbGUgY3g9IjEyIiBjeT0iMy43Njg1IiByPSIyLjk2ODUiLz4KIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-vega: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtaWNvbjEganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjMjEyMTIxIj4KICAgIDxwYXRoIGQ9Ik0xMC42IDUuNGwyLjItMy4ySDIuMnY3LjNsNC02LjZ6Ii8+CiAgICA8cGF0aCBkPSJNMTUuOCAyLjJsLTQuNCA2LjZMNyA2LjNsLTQuOCA4djUuNWgxNy42VjIuMmgtNHptLTcgMTUuNEg1LjV2LTQuNGgzLjN2NC40em00LjQgMEg5LjhWOS44aDMuNHY3Ljh6bTQuNCAwaC0zLjRWNi41aDMuNHYxMS4xeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-word: url(data:image/svg+xml;base64,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);
  --jp-icon-yaml: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtaWNvbi1jb250cmFzdDIganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjRDgxQjYwIj4KICAgIDxwYXRoIGQ9Ik03LjIgMTguNnYtNS40TDMgNS42aDMuM2wxLjQgMy4xYy4zLjkuNiAxLjYgMSAyLjUuMy0uOC42LTEuNiAxLTIuNWwxLjQtMy4xaDMuNGwtNC40IDcuNnY1LjVsLTIuOS0uMXoiLz4KICAgIDxjaXJjbGUgY2xhc3M9InN0MCIgY3g9IjE3LjYiIGN5PSIxNi41IiByPSIyLjEiLz4KICAgIDxjaXJjbGUgY2xhc3M9InN0MCIgY3g9IjE3LjYiIGN5PSIxMSIgcj0iMi4xIi8+CiAgPC9nPgo8L3N2Zz4K);
}

/* Icon CSS class declarations */

.jp-AddAboveIcon {
  background-image: var(--jp-icon-add-above);
}

.jp-AddBelowIcon {
  background-image: var(--jp-icon-add-below);
}

.jp-AddIcon {
  background-image: var(--jp-icon-add);
}

.jp-BellIcon {
  background-image: var(--jp-icon-bell);
}

.jp-BugDotIcon {
  background-image: var(--jp-icon-bug-dot);
}

.jp-BugIcon {
  background-image: var(--jp-icon-bug);
}

.jp-BuildIcon {
  background-image: var(--jp-icon-build);
}

.jp-CaretDownEmptyIcon {
  background-image: var(--jp-icon-caret-down-empty);
}

.jp-CaretDownEmptyThinIcon {
  background-image: var(--jp-icon-caret-down-empty-thin);
}

.jp-CaretDownIcon {
  background-image: var(--jp-icon-caret-down);
}

.jp-CaretLeftIcon {
  background-image: var(--jp-icon-caret-left);
}

.jp-CaretRightIcon {
  background-image: var(--jp-icon-caret-right);
}

.jp-CaretUpEmptyThinIcon {
  background-image: var(--jp-icon-caret-up-empty-thin);
}

.jp-CaretUpIcon {
  background-image: var(--jp-icon-caret-up);
}

.jp-CaseSensitiveIcon {
  background-image: var(--jp-icon-case-sensitive);
}

.jp-CheckIcon {
  background-image: var(--jp-icon-check);
}

.jp-CircleEmptyIcon {
  background-image: var(--jp-icon-circle-empty);
}

.jp-CircleIcon {
  background-image: var(--jp-icon-circle);
}

.jp-ClearIcon {
  background-image: var(--jp-icon-clear);
}

.jp-CloseIcon {
  background-image: var(--jp-icon-close);
}

.jp-CodeCheckIcon {
  background-image: var(--jp-icon-code-check);
}

.jp-CodeIcon {
  background-image: var(--jp-icon-code);
}

.jp-CollapseAllIcon {
  background-image: var(--jp-icon-collapse-all);
}

.jp-ConsoleIcon {
  background-image: var(--jp-icon-console);
}

.jp-CopyIcon {
  background-image: var(--jp-icon-copy);
}

.jp-CopyrightIcon {
  background-image: var(--jp-icon-copyright);
}

.jp-CutIcon {
  background-image: var(--jp-icon-cut);
}

.jp-DeleteIcon {
  background-image: var(--jp-icon-delete);
}

.jp-DownloadIcon {
  background-image: var(--jp-icon-download);
}

.jp-DuplicateIcon {
  background-image: var(--jp-icon-duplicate);
}

.jp-EditIcon {
  background-image: var(--jp-icon-edit);
}

.jp-EllipsesIcon {
  background-image: var(--jp-icon-ellipses);
}

.jp-ErrorIcon {
  background-image: var(--jp-icon-error);
}

.jp-ExpandAllIcon {
  background-image: var(--jp-icon-expand-all);
}

.jp-ExtensionIcon {
  background-image: var(--jp-icon-extension);
}

.jp-FastForwardIcon {
  background-image: var(--jp-icon-fast-forward);
}

.jp-FileIcon {
  background-image: var(--jp-icon-file);
}

.jp-FileUploadIcon {
  background-image: var(--jp-icon-file-upload);
}

.jp-FilterDotIcon {
  background-image: var(--jp-icon-filter-dot);
}

.jp-FilterIcon {
  background-image: var(--jp-icon-filter);
}

.jp-FilterListIcon {
  background-image: var(--jp-icon-filter-list);
}

.jp-FolderFavoriteIcon {
  background-image: var(--jp-icon-folder-favorite);
}

.jp-FolderIcon {
  background-image: var(--jp-icon-folder);
}

.jp-HomeIcon {
  background-image: var(--jp-icon-home);
}

.jp-Html5Icon {
  background-image: var(--jp-icon-html5);
}

.jp-ImageIcon {
  background-image: var(--jp-icon-image);
}

.jp-InfoIcon {
  background-image: var(--jp-icon-info);
}

.jp-InspectorIcon {
  background-image: var(--jp-icon-inspector);
}

.jp-JsonIcon {
  background-image: var(--jp-icon-json);
}

.jp-JuliaIcon {
  background-image: var(--jp-icon-julia);
}

.jp-JupyterFaviconIcon {
  background-image: var(--jp-icon-jupyter-favicon);
}

.jp-JupyterIcon {
  background-image: var(--jp-icon-jupyter);
}

.jp-JupyterlabWordmarkIcon {
  background-image: var(--jp-icon-jupyterlab-wordmark);
}

.jp-KernelIcon {
  background-image: var(--jp-icon-kernel);
}

.jp-KeyboardIcon {
  background-image: var(--jp-icon-keyboard);
}

.jp-LaunchIcon {
  background-image: var(--jp-icon-launch);
}

.jp-LauncherIcon {
  background-image: var(--jp-icon-launcher);
}

.jp-LineFormIcon {
  background-image: var(--jp-icon-line-form);
}

.jp-LinkIcon {
  background-image: var(--jp-icon-link);
}

.jp-ListIcon {
  background-image: var(--jp-icon-list);
}

.jp-MarkdownIcon {
  background-image: var(--jp-icon-markdown);
}

.jp-MoveDownIcon {
  background-image: var(--jp-icon-move-down);
}

.jp-MoveUpIcon {
  background-image: var(--jp-icon-move-up);
}

.jp-NewFolderIcon {
  background-image: var(--jp-icon-new-folder);
}

.jp-NotTrustedIcon {
  background-image: var(--jp-icon-not-trusted);
}

.jp-NotebookIcon {
  background-image: var(--jp-icon-notebook);
}

.jp-NumberingIcon {
  background-image: var(--jp-icon-numbering);
}

.jp-OfflineBoltIcon {
  background-image: var(--jp-icon-offline-bolt);
}

.jp-PaletteIcon {
  background-image: var(--jp-icon-palette);
}

.jp-PasteIcon {
  background-image: var(--jp-icon-paste);
}

.jp-PdfIcon {
  background-image: var(--jp-icon-pdf);
}

.jp-PythonIcon {
  background-image: var(--jp-icon-python);
}

.jp-RKernelIcon {
  background-image: var(--jp-icon-r-kernel);
}

.jp-ReactIcon {
  background-image: var(--jp-icon-react);
}

.jp-RedoIcon {
  background-image: var(--jp-icon-redo);
}

.jp-RefreshIcon {
  background-image: var(--jp-icon-refresh);
}

.jp-RegexIcon {
  background-image: var(--jp-icon-regex);
}

.jp-RunIcon {
  background-image: var(--jp-icon-run);
}

.jp-RunningIcon {
  background-image: var(--jp-icon-running);
}

.jp-SaveIcon {
  background-image: var(--jp-icon-save);
}

.jp-SearchIcon {
  background-image: var(--jp-icon-search);
}

.jp-SettingsIcon {
  background-image: var(--jp-icon-settings);
}

.jp-ShareIcon {
  background-image: var(--jp-icon-share);
}

.jp-SpreadsheetIcon {
  background-image: var(--jp-icon-spreadsheet);
}

.jp-StopIcon {
  background-image: var(--jp-icon-stop);
}

.jp-TabIcon {
  background-image: var(--jp-icon-tab);
}

.jp-TableRowsIcon {
  background-image: var(--jp-icon-table-rows);
}

.jp-TagIcon {
  background-image: var(--jp-icon-tag);
}

.jp-TerminalIcon {
  background-image: var(--jp-icon-terminal);
}

.jp-TextEditorIcon {
  background-image: var(--jp-icon-text-editor);
}

.jp-TocIcon {
  background-image: var(--jp-icon-toc);
}

.jp-TreeViewIcon {
  background-image: var(--jp-icon-tree-view);
}

.jp-TrustedIcon {
  background-image: var(--jp-icon-trusted);
}

.jp-UndoIcon {
  background-image: var(--jp-icon-undo);
}

.jp-UserIcon {
  background-image: var(--jp-icon-user);
}

.jp-UsersIcon {
  background-image: var(--jp-icon-users);
}

.jp-VegaIcon {
  background-image: var(--jp-icon-vega);
}

.jp-WordIcon {
  background-image: var(--jp-icon-word);
}

.jp-YamlIcon {
  background-image: var(--jp-icon-yaml);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/**
 * (DEPRECATED) Support for consuming icons as CSS background images
 */

.jp-Icon,
.jp-MaterialIcon {
  background-position: center;
  background-repeat: no-repeat;
  background-size: 16px;
  min-width: 16px;
  min-height: 16px;
}

.jp-Icon-cover {
  background-position: center;
  background-repeat: no-repeat;
  background-size: cover;
}

/**
 * (DEPRECATED) Support for specific CSS icon sizes
 */

.jp-Icon-16 {
  background-size: 16px;
  min-width: 16px;
  min-height: 16px;
}

.jp-Icon-18 {
  background-size: 18px;
  min-width: 18px;
  min-height: 18px;
}

.jp-Icon-20 {
  background-size: 20px;
  min-width: 20px;
  min-height: 20px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.lm-TabBar .lm-TabBar-addButton {
  align-items: center;
  display: flex;
  padding: 4px;
  padding-bottom: 5px;
  margin-right: 1px;
  background-color: var(--jp-layout-color2);
}

.lm-TabBar .lm-TabBar-addButton:hover {
  background-color: var(--jp-layout-color1);
}

.lm-DockPanel-tabBar .lm-TabBar-tab {
  width: var(--jp-private-horizontal-tab-width);
}

.lm-DockPanel-tabBar .lm-TabBar-content {
  flex: unset;
}

.lm-DockPanel-tabBar[data-orientation='horizontal'] {
  flex: 1 1 auto;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/**
 * Support for icons as inline SVG HTMLElements
 */

/* recolor the primary elements of an icon */
.jp-icon0[fill] {
  fill: var(--jp-inverse-layout-color0);
}

.jp-icon1[fill] {
  fill: var(--jp-inverse-layout-color1);
}

.jp-icon2[fill] {
  fill: var(--jp-inverse-layout-color2);
}

.jp-icon3[fill] {
  fill: var(--jp-inverse-layout-color3);
}

.jp-icon4[fill] {
  fill: var(--jp-inverse-layout-color4);
}

.jp-icon0[stroke] {
  stroke: var(--jp-inverse-layout-color0);
}

.jp-icon1[stroke] {
  stroke: var(--jp-inverse-layout-color1);
}

.jp-icon2[stroke] {
  stroke: var(--jp-inverse-layout-color2);
}

.jp-icon3[stroke] {
  stroke: var(--jp-inverse-layout-color3);
}

.jp-icon4[stroke] {
  stroke: var(--jp-inverse-layout-color4);
}

/* recolor the accent elements of an icon */
.jp-icon-accent0[fill] {
  fill: var(--jp-layout-color0);
}

.jp-icon-accent1[fill] {
  fill: var(--jp-layout-color1);
}

.jp-icon-accent2[fill] {
  fill: var(--jp-layout-color2);
}

.jp-icon-accent3[fill] {
  fill: var(--jp-layout-color3);
}

.jp-icon-accent4[fill] {
  fill: var(--jp-layout-color4);
}

.jp-icon-accent0[stroke] {
  stroke: var(--jp-layout-color0);
}

.jp-icon-accent1[stroke] {
  stroke: var(--jp-layout-color1);
}

.jp-icon-accent2[stroke] {
  stroke: var(--jp-layout-color2);
}

.jp-icon-accent3[stroke] {
  stroke: var(--jp-layout-color3);
}

.jp-icon-accent4[stroke] {
  stroke: var(--jp-layout-color4);
}

/* set the color of an icon to transparent */
.jp-icon-none[fill] {
  fill: none;
}

.jp-icon-none[stroke] {
  stroke: none;
}

/* brand icon colors. Same for light and dark */
.jp-icon-brand0[fill] {
  fill: var(--jp-brand-color0);
}

.jp-icon-brand1[fill] {
  fill: var(--jp-brand-color1);
}

.jp-icon-brand2[fill] {
  fill: var(--jp-brand-color2);
}

.jp-icon-brand3[fill] {
  fill: var(--jp-brand-color3);
}

.jp-icon-brand4[fill] {
  fill: var(--jp-brand-color4);
}

.jp-icon-brand0[stroke] {
  stroke: var(--jp-brand-color0);
}

.jp-icon-brand1[stroke] {
  stroke: var(--jp-brand-color1);
}

.jp-icon-brand2[stroke] {
  stroke: var(--jp-brand-color2);
}

.jp-icon-brand3[stroke] {
  stroke: var(--jp-brand-color3);
}

.jp-icon-brand4[stroke] {
  stroke: var(--jp-brand-color4);
}

/* warn icon colors. Same for light and dark */
.jp-icon-warn0[fill] {
  fill: var(--jp-warn-color0);
}

.jp-icon-warn1[fill] {
  fill: var(--jp-warn-color1);
}

.jp-icon-warn2[fill] {
  fill: var(--jp-warn-color2);
}

.jp-icon-warn3[fill] {
  fill: var(--jp-warn-color3);
}

.jp-icon-warn0[stroke] {
  stroke: var(--jp-warn-color0);
}

.jp-icon-warn1[stroke] {
  stroke: var(--jp-warn-color1);
}

.jp-icon-warn2[stroke] {
  stroke: var(--jp-warn-color2);
}

.jp-icon-warn3[stroke] {
  stroke: var(--jp-warn-color3);
}

/* icon colors that contrast well with each other and most backgrounds */
.jp-icon-contrast0[fill] {
  fill: var(--jp-icon-contrast-color0);
}

.jp-icon-contrast1[fill] {
  fill: var(--jp-icon-contrast-color1);
}

.jp-icon-contrast2[fill] {
  fill: var(--jp-icon-contrast-color2);
}

.jp-icon-contrast3[fill] {
  fill: var(--jp-icon-contrast-color3);
}

.jp-icon-contrast0[stroke] {
  stroke: var(--jp-icon-contrast-color0);
}

.jp-icon-contrast1[stroke] {
  stroke: var(--jp-icon-contrast-color1);
}

.jp-icon-contrast2[stroke] {
  stroke: var(--jp-icon-contrast-color2);
}

.jp-icon-contrast3[stroke] {
  stroke: var(--jp-icon-contrast-color3);
}

.jp-icon-dot[fill] {
  fill: var(--jp-warn-color0);
}

.jp-jupyter-icon-color[fill] {
  fill: var(--jp-jupyter-icon-color, var(--jp-warn-color0));
}

.jp-notebook-icon-color[fill] {
  fill: var(--jp-notebook-icon-color, var(--jp-warn-color0));
}

.jp-json-icon-color[fill] {
  fill: var(--jp-json-icon-color, var(--jp-warn-color1));
}

.jp-console-icon-color[fill] {
  fill: var(--jp-console-icon-color, white);
}

.jp-console-icon-background-color[fill] {
  fill: var(--jp-console-icon-background-color, var(--jp-brand-color1));
}

.jp-terminal-icon-color[fill] {
  fill: var(--jp-terminal-icon-color, var(--jp-layout-color2));
}

.jp-terminal-icon-background-color[fill] {
  fill: var(
    --jp-terminal-icon-background-color,
    var(--jp-inverse-layout-color2)
  );
}

.jp-text-editor-icon-color[fill] {
  fill: var(--jp-text-editor-icon-color, var(--jp-inverse-layout-color3));
}

.jp-inspector-icon-color[fill] {
  fill: var(--jp-inspector-icon-color, var(--jp-inverse-layout-color3));
}

/* CSS for icons in selected filebrowser listing items */
.jp-DirListing-item.jp-mod-selected .jp-icon-selectable[fill] {
  fill: #fff;
}

.jp-DirListing-item.jp-mod-selected .jp-icon-selectable-inverse[fill] {
  fill: var(--jp-brand-color1);
}

/* stylelint-disable selector-max-class, selector-max-compound-selectors */

/**
* TODO: come up with non css-hack solution for showing the busy icon on top
*  of the close icon
* CSS for complex behavior of close icon of tabs in the main area tabbar
*/
.lm-DockPanel-tabBar
  .lm-TabBar-tab.lm-mod-closable.jp-mod-dirty
  > .lm-TabBar-tabCloseIcon
  > :not(:hover)
  > .jp-icon3[fill] {
  fill: none;
}

.lm-DockPanel-tabBar
  .lm-TabBar-tab.lm-mod-closable.jp-mod-dirty
  > .lm-TabBar-tabCloseIcon
  > :not(:hover)
  > .jp-icon-busy[fill] {
  fill: var(--jp-inverse-layout-color3);
}

/* stylelint-enable selector-max-class, selector-max-compound-selectors */

/* CSS for icons in status bar */
#jp-main-statusbar .jp-mod-selected .jp-icon-selectable[fill] {
  fill: #fff;
}

#jp-main-statusbar .jp-mod-selected .jp-icon-selectable-inverse[fill] {
  fill: var(--jp-brand-color1);
}

/* special handling for splash icon CSS. While the theme CSS reloads during
   splash, the splash icon can loose theming. To prevent that, we set a
   default for its color variable */
:root {
  --jp-warn-color0: var(--md-orange-700);
}

/* not sure what to do with this one, used in filebrowser listing */
.jp-DragIcon {
  margin-right: 4px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/**
 * Support for alt colors for icons as inline SVG HTMLElements
 */

/* alt recolor the primary elements of an icon */
.jp-icon-alt .jp-icon0[fill] {
  fill: var(--jp-layout-color0);
}

.jp-icon-alt .jp-icon1[fill] {
  fill: var(--jp-layout-color1);
}

.jp-icon-alt .jp-icon2[fill] {
  fill: var(--jp-layout-color2);
}

.jp-icon-alt .jp-icon3[fill] {
  fill: var(--jp-layout-color3);
}

.jp-icon-alt .jp-icon4[fill] {
  fill: var(--jp-layout-color4);
}

.jp-icon-alt .jp-icon0[stroke] {
  stroke: var(--jp-layout-color0);
}

.jp-icon-alt .jp-icon1[stroke] {
  stroke: var(--jp-layout-color1);
}

.jp-icon-alt .jp-icon2[stroke] {
  stroke: var(--jp-layout-color2);
}

.jp-icon-alt .jp-icon3[stroke] {
  stroke: var(--jp-layout-color3);
}

.jp-icon-alt .jp-icon4[stroke] {
  stroke: var(--jp-layout-color4);
}

/* alt recolor the accent elements of an icon */
.jp-icon-alt .jp-icon-accent0[fill] {
  fill: var(--jp-inverse-layout-color0);
}

.jp-icon-alt .jp-icon-accent1[fill] {
  fill: var(--jp-inverse-layout-color1);
}

.jp-icon-alt .jp-icon-accent2[fill] {
  fill: var(--jp-inverse-layout-color2);
}

.jp-icon-alt .jp-icon-accent3[fill] {
  fill: var(--jp-inverse-layout-color3);
}

.jp-icon-alt .jp-icon-accent4[fill] {
  fill: var(--jp-inverse-layout-color4);
}

.jp-icon-alt .jp-icon-accent0[stroke] {
  stroke: var(--jp-inverse-layout-color0);
}

.jp-icon-alt .jp-icon-accent1[stroke] {
  stroke: var(--jp-inverse-layout-color1);
}

.jp-icon-alt .jp-icon-accent2[stroke] {
  stroke: var(--jp-inverse-layout-color2);
}

.jp-icon-alt .jp-icon-accent3[stroke] {
  stroke: var(--jp-inverse-layout-color3);
}

.jp-icon-alt .jp-icon-accent4[stroke] {
  stroke: var(--jp-inverse-layout-color4);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-icon-hoverShow:not(:hover) .jp-icon-hoverShow-content {
  display: none !important;
}

/**
 * Support for hover colors for icons as inline SVG HTMLElements
 */

/**
 * regular colors
 */

/* recolor the primary elements of an icon */
.jp-icon-hover :hover .jp-icon0-hover[fill] {
  fill: var(--jp-inverse-layout-color0);
}

.jp-icon-hover :hover .jp-icon1-hover[fill] {
  fill: var(--jp-inverse-layout-color1);
}

.jp-icon-hover :hover .jp-icon2-hover[fill] {
  fill: var(--jp-inverse-layout-color2);
}

.jp-icon-hover :hover .jp-icon3-hover[fill] {
  fill: var(--jp-inverse-layout-color3);
}

.jp-icon-hover :hover .jp-icon4-hover[fill] {
  fill: var(--jp-inverse-layout-color4);
}

.jp-icon-hover :hover .jp-icon0-hover[stroke] {
  stroke: var(--jp-inverse-layout-color0);
}

.jp-icon-hover :hover .jp-icon1-hover[stroke] {
  stroke: var(--jp-inverse-layout-color1);
}

.jp-icon-hover :hover .jp-icon2-hover[stroke] {
  stroke: var(--jp-inverse-layout-color2);
}

.jp-icon-hover :hover .jp-icon3-hover[stroke] {
  stroke: var(--jp-inverse-layout-color3);
}

.jp-icon-hover :hover .jp-icon4-hover[stroke] {
  stroke: var(--jp-inverse-layout-color4);
}

/* recolor the accent elements of an icon */
.jp-icon-hover :hover .jp-icon-accent0-hover[fill] {
  fill: var(--jp-layout-color0);
}

.jp-icon-hover :hover .jp-icon-accent1-hover[fill] {
  fill: var(--jp-layout-color1);
}

.jp-icon-hover :hover .jp-icon-accent2-hover[fill] {
  fill: var(--jp-layout-color2);
}

.jp-icon-hover :hover .jp-icon-accent3-hover[fill] {
  fill: var(--jp-layout-color3);
}

.jp-icon-hover :hover .jp-icon-accent4-hover[fill] {
  fill: var(--jp-layout-color4);
}

.jp-icon-hover :hover .jp-icon-accent0-hover[stroke] {
  stroke: var(--jp-layout-color0);
}

.jp-icon-hover :hover .jp-icon-accent1-hover[stroke] {
  stroke: var(--jp-layout-color1);
}

.jp-icon-hover :hover .jp-icon-accent2-hover[stroke] {
  stroke: var(--jp-layout-color2);
}

.jp-icon-hover :hover .jp-icon-accent3-hover[stroke] {
  stroke: var(--jp-layout-color3);
}

.jp-icon-hover :hover .jp-icon-accent4-hover[stroke] {
  stroke: var(--jp-layout-color4);
}

/* set the color of an icon to transparent */
.jp-icon-hover :hover .jp-icon-none-hover[fill] {
  fill: none;
}

.jp-icon-hover :hover .jp-icon-none-hover[stroke] {
  stroke: none;
}

/**
 * inverse colors
 */

/* inverse recolor the primary elements of an icon */
.jp-icon-hover.jp-icon-alt :hover .jp-icon0-hover[fill] {
  fill: var(--jp-layout-color0);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon1-hover[fill] {
  fill: var(--jp-layout-color1);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon2-hover[fill] {
  fill: var(--jp-layout-color2);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon3-hover[fill] {
  fill: var(--jp-layout-color3);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon4-hover[fill] {
  fill: var(--jp-layout-color4);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon0-hover[stroke] {
  stroke: var(--jp-layout-color0);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon1-hover[stroke] {
  stroke: var(--jp-layout-color1);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon2-hover[stroke] {
  stroke: var(--jp-layout-color2);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon3-hover[stroke] {
  stroke: var(--jp-layout-color3);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon4-hover[stroke] {
  stroke: var(--jp-layout-color4);
}

/* inverse recolor the accent elements of an icon */
.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent0-hover[fill] {
  fill: var(--jp-inverse-layout-color0);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent1-hover[fill] {
  fill: var(--jp-inverse-layout-color1);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent2-hover[fill] {
  fill: var(--jp-inverse-layout-color2);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent3-hover[fill] {
  fill: var(--jp-inverse-layout-color3);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent4-hover[fill] {
  fill: var(--jp-inverse-layout-color4);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent0-hover[stroke] {
  stroke: var(--jp-inverse-layout-color0);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent1-hover[stroke] {
  stroke: var(--jp-inverse-layout-color1);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent2-hover[stroke] {
  stroke: var(--jp-inverse-layout-color2);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent3-hover[stroke] {
  stroke: var(--jp-inverse-layout-color3);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent4-hover[stroke] {
  stroke: var(--jp-inverse-layout-color4);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-IFrame {
  width: 100%;
  height: 100%;
}

.jp-IFrame > iframe {
  border: none;
}

/*
When drag events occur, `lm-mod-override-cursor` is added to the body.
Because iframes steal all cursor events, the following two rules are necessary
to suppress pointer events while resize drags are occurring. There may be a
better solution to this problem.
*/
body.lm-mod-override-cursor .jp-IFrame {
  position: relative;
}

body.lm-mod-override-cursor .jp-IFrame::before {
  content: '';
  position: absolute;
  top: 0;
  left: 0;
  right: 0;
  bottom: 0;
  background: transparent;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2016, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-HoverBox {
  position: fixed;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-FormGroup-content fieldset {
  border: none;
  padding: 0;
  min-width: 0;
  width: 100%;
}

/* stylelint-disable selector-max-type */

.jp-FormGroup-content fieldset .jp-inputFieldWrapper input,
.jp-FormGroup-content fieldset .jp-inputFieldWrapper select,
.jp-FormGroup-content fieldset .jp-inputFieldWrapper textarea {
  font-size: var(--jp-content-font-size2);
  border-color: var(--jp-input-border-color);
  border-style: solid;
  border-radius: var(--jp-border-radius);
  border-width: 1px;
  padding: 6px 8px;
  background: none;
  color: var(--jp-ui-font-color0);
  height: inherit;
}

.jp-FormGroup-content fieldset input[type='checkbox'] {
  position: relative;
  top: 2px;
  margin-left: 0;
}

.jp-FormGroup-content button.jp-mod-styled {
  cursor: pointer;
}

.jp-FormGroup-content .checkbox label {
  cursor: pointer;
  font-size: var(--jp-content-font-size1);
}

.jp-FormGroup-content .jp-root > fieldset > legend {
  display: none;
}

.jp-FormGroup-content .jp-root > fieldset > p {
  display: none;
}

/** copy of `input.jp-mod-styled:focus` style */
.jp-FormGroup-content fieldset input:focus,
.jp-FormGroup-content fieldset select:focus {
  -moz-outline-radius: unset;
  outline: var(--jp-border-width) solid var(--md-blue-500);
  outline-offset: -1px;
  box-shadow: inset 0 0 4px var(--md-blue-300);
}

.jp-FormGroup-content fieldset input:hover:not(:focus),
.jp-FormGroup-content fieldset select:hover:not(:focus) {
  background-color: var(--jp-border-color2);
}

/* stylelint-enable selector-max-type */

.jp-FormGroup-content .checkbox .field-description {
  /* Disable default description field for checkbox:
   because other widgets do not have description fields,
   we add descriptions to each widget on the field level.
  */
  display: none;
}

.jp-FormGroup-content #root__description {
  display: none;
}

.jp-FormGroup-content .jp-modifiedIndicator {
  width: 5px;
  background-color: var(--jp-brand-color2);
  margin-top: 0;
  margin-left: calc(var(--jp-private-settingeditor-modifier-indent) * -1);
  flex-shrink: 0;
}

.jp-FormGroup-content .jp-modifiedIndicator.jp-errorIndicator {
  background-color: var(--jp-error-color0);
  margin-right: 0.5em;
}

/* RJSF ARRAY style */

.jp-arrayFieldWrapper legend {
  font-size: var(--jp-content-font-size2);
  color: var(--jp-ui-font-color0);
  flex-basis: 100%;
  padding: 4px 0;
  font-weight: var(--jp-content-heading-font-weight);
  border-bottom: 1px solid var(--jp-border-color2);
}

.jp-arrayFieldWrapper .field-description {
  padding: 4px 0;
  white-space: pre-wrap;
}

.jp-arrayFieldWrapper .array-item {
  width: 100%;
  border: 1px solid var(--jp-border-color2);
  border-radius: 4px;
  margin: 4px;
}

.jp-ArrayOperations {
  display: flex;
  margin-left: 8px;
}

.jp-ArrayOperationsButton {
  margin: 2px;
}

.jp-ArrayOperationsButton .jp-icon3[fill] {
  fill: var(--jp-ui-font-color0);
}

button.jp-ArrayOperationsButton.jp-mod-styled:disabled {
  cursor: not-allowed;
  opacity: 0.5;
}

/* RJSF form validation error */

.jp-FormGroup-content .validationErrors {
  color: var(--jp-error-color0);
}

/* Hide panel level error as duplicated the field level error */
.jp-FormGroup-content .panel.errors {
  display: none;
}

/* RJSF normal content (settings-editor) */

.jp-FormGroup-contentNormal {
  display: flex;
  align-items: center;
  flex-wrap: wrap;
}

.jp-FormGroup-contentNormal .jp-FormGroup-contentItem {
  margin-left: 7px;
  color: var(--jp-ui-font-color0);
}

.jp-FormGroup-contentNormal .jp-FormGroup-description {
  flex-basis: 100%;
  padding: 4px 7px;
}

.jp-FormGroup-contentNormal .jp-FormGroup-default {
  flex-basis: 100%;
  padding: 4px 7px;
}

.jp-FormGroup-contentNormal .jp-FormGroup-fieldLabel {
  font-size: var(--jp-content-font-size1);
  font-weight: normal;
  min-width: 120px;
}

.jp-FormGroup-contentNormal fieldset:not(:first-child) {
  margin-left: 7px;
}

.jp-FormGroup-contentNormal .field-array-of-string .array-item {
  /* Display `jp-ArrayOperations` buttons side-by-side with content except
    for small screens where flex-wrap will place them one below the other.
  */
  display: flex;
  align-items: center;
  flex-wrap: wrap;
}

.jp-FormGroup-contentNormal .jp-objectFieldWrapper .form-group {
  padding: 2px 8px 2px var(--jp-private-settingeditor-modifier-indent);
  margin-top: 2px;
}

/* RJSF compact content (metadata-form) */

.jp-FormGroup-content.jp-FormGroup-contentCompact {
  width: 100%;
}

.jp-FormGroup-contentCompact .form-group {
  display: flex;
  padding: 0.5em 0.2em 0.5em 0;
}

.jp-FormGroup-contentCompact
  .jp-FormGroup-compactTitle
  .jp-FormGroup-description {
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color2);
}

.jp-FormGroup-contentCompact .jp-FormGroup-fieldLabel {
  padding-bottom: 0.3em;
}

.jp-FormGroup-contentCompact .jp-inputFieldWrapper .form-control {
  width: 100%;
  box-sizing: border-box;
}

.jp-FormGroup-contentCompact .jp-arrayFieldWrapper .jp-FormGroup-compactTitle {
  padding-bottom: 7px;
}

.jp-FormGroup-contentCompact
  .jp-objectFieldWrapper
  .jp-objectFieldWrapper
  .form-group {
  padding: 2px 8px 2px var(--jp-private-settingeditor-modifier-indent);
  margin-top: 2px;
}

.jp-FormGroup-contentCompact ul.error-detail {
  margin-block-start: 0.5em;
  margin-block-end: 0.5em;
  padding-inline-start: 1em;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

.jp-SidePanel {
  display: flex;
  flex-direction: column;
  min-width: var(--jp-sidebar-min-width);
  overflow-y: auto;
  color: var(--jp-ui-font-color1);
  background: var(--jp-layout-color1);
  font-size: var(--jp-ui-font-size1);
}

.jp-SidePanel-header {
  flex: 0 0 auto;
  display: flex;
  border-bottom: var(--jp-border-width) solid var(--jp-border-color2);
  font-size: var(--jp-ui-font-size0);
  font-weight: 600;
  letter-spacing: 1px;
  margin: 0;
  padding: 2px;
  text-transform: uppercase;
}

.jp-SidePanel-toolbar {
  flex: 0 0 auto;
}

.jp-SidePanel-content {
  flex: 1 1 auto;
}

.jp-SidePanel-toolbar,
.jp-AccordionPanel-toolbar {
  height: var(--jp-private-toolbar-height);
}

.jp-SidePanel-toolbar.jp-Toolbar-micro {
  display: none;
}

.lm-AccordionPanel .jp-AccordionPanel-title {
  box-sizing: border-box;
  line-height: 25px;
  margin: 0;
  display: flex;
  align-items: center;
  background: var(--jp-layout-color1);
  color: var(--jp-ui-font-color1);
  border-bottom: var(--jp-border-width) solid var(--jp-toolbar-border-color);
  box-shadow: var(--jp-toolbar-box-shadow);
  font-size: var(--jp-ui-font-size0);
}

.jp-AccordionPanel-title {
  cursor: pointer;
  user-select: none;
  -moz-user-select: none;
  -webkit-user-select: none;
  text-transform: uppercase;
}

.lm-AccordionPanel[data-orientation='horizontal'] > .jp-AccordionPanel-title {
  /* Title is rotated for horizontal accordion panel using CSS */
  display: block;
  transform-origin: top left;
  transform: rotate(-90deg) translate(-100%);
}

.jp-AccordionPanel-title .lm-AccordionPanel-titleLabel {
  user-select: none;
  text-overflow: ellipsis;
  white-space: nowrap;
  overflow: hidden;
}

.jp-AccordionPanel-title .lm-AccordionPanel-titleCollapser {
  transform: rotate(-90deg);
  margin: auto 0;
  height: 16px;
}

.jp-AccordionPanel-title.lm-mod-expanded .lm-AccordionPanel-titleCollapser {
  transform: rotate(0deg);
}

.lm-AccordionPanel .jp-AccordionPanel-toolbar {
  background: none;
  box-shadow: none;
  border: none;
  margin-left: auto;
}

.lm-AccordionPanel .lm-SplitPanel-handle:hover {
  background: var(--jp-layout-color3);
}

.jp-text-truncated {
  overflow: hidden;
  text-overflow: ellipsis;
  white-space: nowrap;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2017, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-Spinner {
  position: absolute;
  display: flex;
  justify-content: center;
  align-items: center;
  z-index: 10;
  left: 0;
  top: 0;
  width: 100%;
  height: 100%;
  background: var(--jp-layout-color0);
  outline: none;
}

.jp-SpinnerContent {
  font-size: 10px;
  margin: 50px auto;
  text-indent: -9999em;
  width: 3em;
  height: 3em;
  border-radius: 50%;
  background: var(--jp-brand-color3);
  background: linear-gradient(
    to right,
    #f37626 10%,
    rgba(255, 255, 255, 0) 42%
  );
  position: relative;
  animation: load3 1s infinite linear, fadeIn 1s;
}

.jp-SpinnerContent::before {
  width: 50%;
  height: 50%;
  background: #f37626;
  border-radius: 100% 0 0;
  position: absolute;
  top: 0;
  left: 0;
  content: '';
}

.jp-SpinnerContent::after {
  background: var(--jp-layout-color0);
  width: 75%;
  height: 75%;
  border-radius: 50%;
  content: '';
  margin: auto;
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  right: 0;
}

@keyframes fadeIn {
  0% {
    opacity: 0;
  }

  100% {
    opacity: 1;
  }
}

@keyframes load3 {
  0% {
    transform: rotate(0deg);
  }

  100% {
    transform: rotate(360deg);
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2017, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

button.jp-mod-styled {
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color0);
  border: none;
  box-sizing: border-box;
  text-align: center;
  line-height: 32px;
  height: 32px;
  padding: 0 12px;
  letter-spacing: 0.8px;
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
}

input.jp-mod-styled {
  background: var(--jp-input-background);
  height: 28px;
  box-sizing: border-box;
  border: var(--jp-border-width) solid var(--jp-border-color1);
  padding-left: 7px;
  padding-right: 7px;
  font-size: var(--jp-ui-font-size2);
  color: var(--jp-ui-font-color0);
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
}

input[type='checkbox'].jp-mod-styled {
  appearance: checkbox;
  -webkit-appearance: checkbox;
  -moz-appearance: checkbox;
  height: auto;
}

input.jp-mod-styled:focus {
  border: var(--jp-border-width) solid var(--md-blue-500);
  box-shadow: inset 0 0 4px var(--md-blue-300);
}

.jp-select-wrapper {
  display: flex;
  position: relative;
  flex-direction: column;
  padding: 1px;
  background-color: var(--jp-layout-color1);
  box-sizing: border-box;
  margin-bottom: 12px;
}

.jp-select-wrapper:not(.multiple) {
  height: 28px;
}

.jp-select-wrapper.jp-mod-focused select.jp-mod-styled {
  border: var(--jp-border-width) solid var(--jp-input-active-border-color);
  box-shadow: var(--jp-input-box-shadow);
  background-color: var(--jp-input-active-background);
}

select.jp-mod-styled:hover {
  cursor: pointer;
  color: var(--jp-ui-font-color0);
  background-color: var(--jp-input-hover-background);
  box-shadow: inset 0 0 1px rgba(0, 0, 0, 0.5);
}

select.jp-mod-styled {
  flex: 1 1 auto;
  width: 100%;
  font-size: var(--jp-ui-font-size2);
  background: var(--jp-input-background);
  color: var(--jp-ui-font-color0);
  padding: 0 25px 0 8px;
  border: var(--jp-border-width) solid var(--jp-input-border-color);
  border-radius: 0;
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
}

select.jp-mod-styled:not([multiple]) {
  height: 32px;
}

select.jp-mod-styled[multiple] {
  max-height: 200px;
  overflow-y: auto;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-switch {
  display: flex;
  align-items: center;
  padding-left: 4px;
  padding-right: 4px;
  font-size: var(--jp-ui-font-size1);
  background-color: transparent;
  color: var(--jp-ui-font-color1);
  border: none;
  height: 20px;
}

.jp-switch:hover {
  background-color: var(--jp-layout-color2);
}

.jp-switch-label {
  margin-right: 5px;
  font-family: var(--jp-ui-font-family);
}

.jp-switch-track {
  cursor: pointer;
  background-color: var(--jp-switch-color, var(--jp-border-color1));
  -webkit-transition: 0.4s;
  transition: 0.4s;
  border-radius: 34px;
  height: 16px;
  width: 35px;
  position: relative;
}

.jp-switch-track::before {
  content: '';
  position: absolute;
  height: 10px;
  width: 10px;
  margin: 3px;
  left: 0;
  background-color: var(--jp-ui-inverse-font-color1);
  -webkit-transition: 0.4s;
  transition: 0.4s;
  border-radius: 50%;
}

.jp-switch[aria-checked='true'] .jp-switch-track {
  background-color: var(--jp-switch-true-position-color, var(--jp-warn-color0));
}

.jp-switch[aria-checked='true'] .jp-switch-track::before {
  /* track width (35) - margins (3 + 3) - thumb width (10) */
  left: 19px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2016, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

:root {
  --jp-private-toolbar-height: calc(
    28px + var(--jp-border-width)
  ); /* leave 28px for content */
}

.jp-Toolbar {
  color: var(--jp-ui-font-color1);
  flex: 0 0 auto;
  display: flex;
  flex-direction: row;
  border-bottom: var(--jp-border-width) solid var(--jp-toolbar-border-color);
  box-shadow: var(--jp-toolbar-box-shadow);
  background: var(--jp-toolbar-background);
  min-height: var(--jp-toolbar-micro-height);
  padding: 2px;
  z-index: 8;
  overflow-x: hidden;
}

/* Toolbar items */

.jp-Toolbar > .jp-Toolbar-item.jp-Toolbar-spacer {
  flex-grow: 1;
  flex-shrink: 1;
}

.jp-Toolbar-item.jp-Toolbar-kernelStatus {
  display: inline-block;
  width: 32px;
  background-repeat: no-repeat;
  background-position: center;
  background-size: 16px;
}

.jp-Toolbar > .jp-Toolbar-item {
  flex: 0 0 auto;
  display: flex;
  padding-left: 1px;
  padding-right: 1px;
  font-size: var(--jp-ui-font-size1);
  line-height: var(--jp-private-toolbar-height);
  height: 100%;
}

/* Toolbar buttons */

/* This is the div we use to wrap the react component into a Widget */
div.jp-ToolbarButton {
  color: transparent;
  border: none;
  box-sizing: border-box;
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
  padding: 0;
  margin: 0;
}

button.jp-ToolbarButtonComponent {
  background: var(--jp-layout-color1);
  border: none;
  box-sizing: border-box;
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
  padding: 0 6px;
  margin: 0;
  height: 24px;
  border-radius: var(--jp-border-radius);
  display: flex;
  align-items: center;
  text-align: center;
  font-size: 14px;
  min-width: unset;
  min-height: unset;
}

button.jp-ToolbarButtonComponent:disabled {
  opacity: 0.4;
}

button.jp-ToolbarButtonComponent > span {
  padding: 0;
  flex: 0 0 auto;
}

button.jp-ToolbarButtonComponent .jp-ToolbarButtonComponent-label {
  font-size: var(--jp-ui-font-size1);
  line-height: 100%;
  padding-left: 2px;
  color: var(--jp-ui-font-color1);
  font-family: var(--jp-ui-font-family);
}

#jp-main-dock-panel[data-mode='single-document']
  .jp-MainAreaWidget
  > .jp-Toolbar.jp-Toolbar-micro {
  padding: 0;
  min-height: 0;
}

#jp-main-dock-panel[data-mode='single-document']
  .jp-MainAreaWidget
  > .jp-Toolbar {
  border: none;
  box-shadow: none;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

.jp-WindowedPanel-outer {
  position: relative;
  overflow-y: auto;
}

.jp-WindowedPanel-inner {
  position: relative;
}

.jp-WindowedPanel-window {
  position: absolute;
  left: 0;
  right: 0;
  overflow: visible;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* Sibling imports */

body {
  color: var(--jp-ui-font-color1);
  font-size: var(--jp-ui-font-size1);
}

/* Disable native link decoration styles everywhere outside of dialog boxes */
a {
  text-decoration: unset;
  color: unset;
}

a:hover {
  text-decoration: unset;
  color: unset;
}

/* Accessibility for links inside dialog box text */
.jp-Dialog-content a {
  text-decoration: revert;
  color: var(--jp-content-link-color);
}

.jp-Dialog-content a:hover {
  text-decoration: revert;
}

/* Styles for ui-components */
.jp-Button {
  color: var(--jp-ui-font-color2);
  border-radius: var(--jp-border-radius);
  padding: 0 12px;
  font-size: var(--jp-ui-font-size1);

  /* Copy from blueprint 3 */
  display: inline-flex;
  flex-direction: row;
  border: none;
  cursor: pointer;
  align-items: center;
  justify-content: center;
  text-align: left;
  vertical-align: middle;
  min-height: 30px;
  min-width: 30px;
}

.jp-Button:disabled {
  cursor: not-allowed;
}

.jp-Button:empty {
  padding: 0 !important;
}

.jp-Button.jp-mod-small {
  min-height: 24px;
  min-width: 24px;
  font-size: 12px;
  padding: 0 7px;
}

/* Use our own theme for hover styles */
.jp-Button.jp-mod-minimal:hover {
  background-color: var(--jp-layout-color2);
}

.jp-Button.jp-mod-minimal {
  background: none;
}

.jp-InputGroup {
  display: block;
  position: relative;
}

.jp-InputGroup input {
  box-sizing: border-box;
  border: none;
  border-radius: 0;
  background-color: transparent;
  color: var(--jp-ui-font-color0);
  box-shadow: inset 0 0 0 var(--jp-border-width) var(--jp-input-border-color);
  padding-bottom: 0;
  padding-top: 0;
  padding-left: 10px;
  padding-right: 28px;
  position: relative;
  width: 100%;
  -webkit-appearance: none;
  -moz-appearance: none;
  appearance: none;
  font-size: 14px;
  font-weight: 400;
  height: 30px;
  line-height: 30px;
  outline: none;
  vertical-align: middle;
}

.jp-InputGroup input:focus {
  box-shadow: inset 0 0 0 var(--jp-border-width)
      var(--jp-input-active-box-shadow-color),
    inset 0 0 0 3px var(--jp-input-active-box-shadow-color);
}

.jp-InputGroup input:disabled {
  cursor: not-allowed;
  resize: block;
  background-color: var(--jp-layout-color2);
  color: var(--jp-ui-font-color2);
}

.jp-InputGroup input:disabled ~ span {
  cursor: not-allowed;
  color: var(--jp-ui-font-color2);
}

.jp-InputGroup input::placeholder,
input::placeholder {
  color: var(--jp-ui-font-color2);
}

.jp-InputGroupAction {
  position: absolute;
  bottom: 1px;
  right: 0;
  padding: 6px;
}

.jp-HTMLSelect.jp-DefaultStyle select {
  background-color: initial;
  border: none;
  border-radius: 0;
  box-shadow: none;
  color: var(--jp-ui-font-color0);
  display: block;
  font-size: var(--jp-ui-font-size1);
  font-family: var(--jp-ui-font-family);
  height: 24px;
  line-height: 14px;
  padding: 0 25px 0 10px;
  text-align: left;
  -moz-appearance: none;
  -webkit-appearance: none;
}

.jp-HTMLSelect.jp-DefaultStyle select:disabled {
  background-color: var(--jp-layout-color2);
  color: var(--jp-ui-font-color2);
  cursor: not-allowed;
  resize: block;
}

.jp-HTMLSelect.jp-DefaultStyle select:disabled ~ span {
  cursor: not-allowed;
}

/* Use our own theme for hover and option styles */
/* stylelint-disable-next-line selector-max-type */
.jp-HTMLSelect.jp-DefaultStyle select:hover,
.jp-HTMLSelect.jp-DefaultStyle select > option {
  background-color: var(--jp-layout-color2);
  color: var(--jp-ui-font-color0);
}

select {
  box-sizing: border-box;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Styles
|----------------------------------------------------------------------------*/

.jp-StatusBar-Widget {
  display: flex;
  align-items: center;
  background: var(--jp-layout-color2);
  min-height: var(--jp-statusbar-height);
  justify-content: space-between;
  padding: 0 10px;
}

.jp-StatusBar-Left {
  display: flex;
  align-items: center;
  flex-direction: row;
}

.jp-StatusBar-Middle {
  display: flex;
  align-items: center;
}

.jp-StatusBar-Right {
  display: flex;
  align-items: center;
  flex-direction: row-reverse;
}

.jp-StatusBar-Item {
  max-height: var(--jp-statusbar-height);
  margin: 0 2px;
  height: var(--jp-statusbar-height);
  white-space: nowrap;
  text-overflow: ellipsis;
  color: var(--jp-ui-font-color1);
  padding: 0 6px;
}

.jp-mod-highlighted:hover {
  background-color: var(--jp-layout-color3);
}

.jp-mod-clicked {
  background-color: var(--jp-brand-color1);
}

.jp-mod-clicked:hover {
  background-color: var(--jp-brand-color0);
}

.jp-mod-clicked .jp-StatusBar-TextItem {
  color: var(--jp-ui-inverse-font-color1);
}

.jp-StatusBar-HoverItem {
  box-shadow: '0px 4px 4px rgba(0, 0, 0, 0.25)';
}

.jp-StatusBar-TextItem {
  font-size: var(--jp-ui-font-size1);
  font-family: var(--jp-ui-font-family);
  line-height: 24px;
  color: var(--jp-ui-font-color1);
}

.jp-StatusBar-GroupItem {
  display: flex;
  align-items: center;
  flex-direction: row;
}

.jp-Statusbar-ProgressCircle svg {
  display: block;
  margin: 0 auto;
  width: 16px;
  height: 24px;
  align-self: normal;
}

.jp-Statusbar-ProgressCircle path {
  fill: var(--jp-inverse-layout-color3);
}

.jp-Statusbar-ProgressBar-progress-bar {
  height: 10px;
  width: 100px;
  border: solid 0.25px var(--jp-brand-color2);
  border-radius: 3px;
  overflow: hidden;
  align-self: center;
}

.jp-Statusbar-ProgressBar-progress-bar > div {
  background-color: var(--jp-brand-color2);
  background-image: linear-gradient(
    -45deg,
    rgba(255, 255, 255, 0.2) 25%,
    transparent 25%,
    transparent 50%,
    rgba(255, 255, 255, 0.2) 50%,
    rgba(255, 255, 255, 0.2) 75%,
    transparent 75%,
    transparent
  );
  background-size: 40px 40px;
  float: left;
  width: 0%;
  height: 100%;
  font-size: 12px;
  line-height: 14px;
  color: #fff;
  text-align: center;
  animation: jp-Statusbar-ExecutionTime-progress-bar 2s linear infinite;
}

.jp-Statusbar-ProgressBar-progress-bar p {
  color: var(--jp-ui-font-color1);
  font-family: var(--jp-ui-font-family);
  font-size: var(--jp-ui-font-size1);
  line-height: 10px;
  width: 100px;
}

@keyframes jp-Statusbar-ExecutionTime-progress-bar {
  0% {
    background-position: 0 0;
  }

  100% {
    background-position: 40px 40px;
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Variables
|----------------------------------------------------------------------------*/

:root {
  --jp-private-commandpalette-search-height: 28px;
}

/*-----------------------------------------------------------------------------
| Overall styles
|----------------------------------------------------------------------------*/

.lm-CommandPalette {
  padding-bottom: 0;
  color: var(--jp-ui-font-color1);
  background: var(--jp-layout-color1);

  /* This is needed so that all font sizing of children done in ems is
   * relative to this base size */
  font-size: var(--jp-ui-font-size1);
}

/*-----------------------------------------------------------------------------
| Modal variant
|----------------------------------------------------------------------------*/

.jp-ModalCommandPalette {
  position: absolute;
  z-index: 10000;
  top: 38px;
  left: 30%;
  margin: 0;
  padding: 4px;
  width: 40%;
  box-shadow: var(--jp-elevation-z4);
  border-radius: 4px;
  background: var(--jp-layout-color0);
}

.jp-ModalCommandPalette .lm-CommandPalette {
  max-height: 40vh;
}

.jp-ModalCommandPalette .lm-CommandPalette .lm-close-icon::after {
  display: none;
}

.jp-ModalCommandPalette .lm-CommandPalette .lm-CommandPalette-header {
  display: none;
}

.jp-ModalCommandPalette .lm-CommandPalette .lm-CommandPalette-item {
  margin-left: 4px;
  margin-right: 4px;
}

.jp-ModalCommandPalette
  .lm-CommandPalette
  .lm-CommandPalette-item.lm-mod-disabled {
  display: none;
}

/*-----------------------------------------------------------------------------
| Search
|----------------------------------------------------------------------------*/

.lm-CommandPalette-search {
  padding: 4px;
  background-color: var(--jp-layout-color1);
  z-index: 2;
}

.lm-CommandPalette-wrapper {
  overflow: overlay;
  padding: 0 9px;
  background-color: var(--jp-input-active-background);
  height: 30px;
  box-shadow: inset 0 0 0 var(--jp-border-width) var(--jp-input-border-color);
}

.lm-CommandPalette.lm-mod-focused .lm-CommandPalette-wrapper {
  box-shadow: inset 0 0 0 1px var(--jp-input-active-box-shadow-color),
    inset 0 0 0 3px var(--jp-input-active-box-shadow-color);
}

.jp-SearchIconGroup {
  color: white;
  background-color: var(--jp-brand-color1);
  position: absolute;
  top: 4px;
  right: 4px;
  padding: 5px 5px 1px;
}

.jp-SearchIconGroup svg {
  height: 20px;
  width: 20px;
}

.jp-SearchIconGroup .jp-icon3[fill] {
  fill: var(--jp-layout-color0);
}

.lm-CommandPalette-input {
  background: transparent;
  width: calc(100% - 18px);
  float: left;
  border: none;
  outline: none;
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color0);
  line-height: var(--jp-private-commandpalette-search-height);
}

.lm-CommandPalette-input::-webkit-input-placeholder,
.lm-CommandPalette-input::-moz-placeholder,
.lm-CommandPalette-input:-ms-input-placeholder {
  color: var(--jp-ui-font-color2);
  font-size: var(--jp-ui-font-size1);
}

/*-----------------------------------------------------------------------------
| Results
|----------------------------------------------------------------------------*/

.lm-CommandPalette-header:first-child {
  margin-top: 0;
}

.lm-CommandPalette-header {
  border-bottom: solid var(--jp-border-width) var(--jp-border-color2);
  color: var(--jp-ui-font-color1);
  cursor: pointer;
  display: flex;
  font-size: var(--jp-ui-font-size0);
  font-weight: 600;
  letter-spacing: 1px;
  margin-top: 8px;
  padding: 8px 0 8px 12px;
  text-transform: uppercase;
}

.lm-CommandPalette-header.lm-mod-active {
  background: var(--jp-layout-color2);
}

.lm-CommandPalette-header > mark {
  background-color: transparent;
  font-weight: bold;
  color: var(--jp-ui-font-color1);
}

.lm-CommandPalette-item {
  padding: 4px 12px 4px 4px;
  color: var(--jp-ui-font-color1);
  font-size: var(--jp-ui-font-size1);
  font-weight: 400;
  display: flex;
}

.lm-CommandPalette-item.lm-mod-disabled {
  color: var(--jp-ui-font-color2);
}

.lm-CommandPalette-item.lm-mod-active {
  color: var(--jp-ui-inverse-font-color1);
  background: var(--jp-brand-color1);
}

.lm-CommandPalette-item.lm-mod-active .lm-CommandPalette-itemLabel > mark {
  color: var(--jp-ui-inverse-font-color0);
}

.lm-CommandPalette-item.lm-mod-active .jp-icon-selectable[fill] {
  fill: var(--jp-layout-color0);
}

.lm-CommandPalette-item.lm-mod-active:hover:not(.lm-mod-disabled) {
  color: var(--jp-ui-inverse-font-color1);
  background: var(--jp-brand-color1);
}

.lm-CommandPalette-item:hover:not(.lm-mod-active):not(.lm-mod-disabled) {
  background: var(--jp-layout-color2);
}

.lm-CommandPalette-itemContent {
  overflow: hidden;
}

.lm-CommandPalette-itemLabel > mark {
  color: var(--jp-ui-font-color0);
  background-color: transparent;
  font-weight: bold;
}

.lm-CommandPalette-item.lm-mod-disabled mark {
  color: var(--jp-ui-font-color2);
}

.lm-CommandPalette-item .lm-CommandPalette-itemIcon {
  margin: 0 4px 0 0;
  position: relative;
  width: 16px;
  top: 2px;
  flex: 0 0 auto;
}

.lm-CommandPalette-item.lm-mod-disabled .lm-CommandPalette-itemIcon {
  opacity: 0.6;
}

.lm-CommandPalette-item .lm-CommandPalette-itemShortcut {
  flex: 0 0 auto;
}

.lm-CommandPalette-itemCaption {
  display: none;
}

.lm-CommandPalette-content {
  background-color: var(--jp-layout-color1);
}

.lm-CommandPalette-content:empty::after {
  content: 'No results';
  margin: auto;
  margin-top: 20px;
  width: 100px;
  display: block;
  font-size: var(--jp-ui-font-size2);
  font-family: var(--jp-ui-font-family);
  font-weight: lighter;
}

.lm-CommandPalette-emptyMessage {
  text-align: center;
  margin-top: 24px;
  line-height: 1.32;
  padding: 0 8px;
  color: var(--jp-content-font-color3);
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2017, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-Dialog {
  position: absolute;
  z-index: 10000;
  display: flex;
  flex-direction: column;
  align-items: center;
  justify-content: center;
  top: 0;
  left: 0;
  margin: 0;
  padding: 0;
  width: 100%;
  height: 100%;
  background: var(--jp-dialog-background);
}

.jp-Dialog-content {
  display: flex;
  flex-direction: column;
  margin-left: auto;
  margin-right: auto;
  background: var(--jp-layout-color1);
  padding: 24px 24px 12px;
  min-width: 300px;
  min-height: 150px;
  max-width: 1000px;
  max-height: 500px;
  box-sizing: border-box;
  box-shadow: var(--jp-elevation-z20);
  word-wrap: break-word;
  border-radius: var(--jp-border-radius);

  /* This is needed so that all font sizing of children done in ems is
   * relative to this base size */
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color1);
  resize: both;
}

.jp-Dialog-content.jp-Dialog-content-small {
  max-width: 500px;
}

.jp-Dialog-button {
  overflow: visible;
}

button.jp-Dialog-button:focus {
  outline: 1px solid var(--jp-brand-color1);
  outline-offset: 4px;
  -moz-outline-radius: 0;
}

button.jp-Dialog-button:focus::-moz-focus-inner {
  border: 0;
}

button.jp-Dialog-button.jp-mod-styled.jp-mod-accept:focus,
button.jp-Dialog-button.jp-mod-styled.jp-mod-warn:focus,
button.jp-Dialog-button.jp-mod-styled.jp-mod-reject:focus {
  outline-offset: 4px;
  -moz-outline-radius: 0;
}

button.jp-Dialog-button.jp-mod-styled.jp-mod-accept:focus {
  outline: 1px solid var(--jp-accept-color-normal, var(--jp-brand-color1));
}

button.jp-Dialog-button.jp-mod-styled.jp-mod-warn:focus {
  outline: 1px solid var(--jp-warn-color-normal, var(--jp-error-color1));
}

button.jp-Dialog-button.jp-mod-styled.jp-mod-reject:focus {
  outline: 1px solid var(--jp-reject-color-normal, var(--md-grey-600));
}

button.jp-Dialog-close-button {
  padding: 0;
  height: 100%;
  min-width: unset;
  min-height: unset;
}

.jp-Dialog-header {
  display: flex;
  justify-content: space-between;
  flex: 0 0 auto;
  padding-bottom: 12px;
  font-size: var(--jp-ui-font-size3);
  font-weight: 400;
  color: var(--jp-ui-font-color1);
}

.jp-Dialog-body {
  display: flex;
  flex-direction: column;
  flex: 1 1 auto;
  font-size: var(--jp-ui-font-size1);
  background: var(--jp-layout-color1);
  color: var(--jp-ui-font-color1);
  overflow: auto;
}

.jp-Dialog-footer {
  display: flex;
  flex-direction: row;
  justify-content: flex-end;
  align-items: center;
  flex: 0 0 auto;
  margin-left: -12px;
  margin-right: -12px;
  padding: 12px;
}

.jp-Dialog-checkbox {
  padding-right: 5px;
}

.jp-Dialog-checkbox > input:focus-visible {
  outline: 1px solid var(--jp-input-active-border-color);
  outline-offset: 1px;
}

.jp-Dialog-spacer {
  flex: 1 1 auto;
}

.jp-Dialog-title {
  overflow: hidden;
  white-space: nowrap;
  text-overflow: ellipsis;
}

.jp-Dialog-body > .jp-select-wrapper {
  width: 100%;
}

.jp-Dialog-body > button {
  padding: 0 16px;
}

.jp-Dialog-body > label {
  line-height: 1.4;
  color: var(--jp-ui-font-color0);
}

.jp-Dialog-button.jp-mod-styled:not(:last-child) {
  margin-right: 12px;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

.jp-Input-Boolean-Dialog {
  flex-direction: row-reverse;
  align-items: end;
  width: 100%;
}

.jp-Input-Boolean-Dialog > label {
  flex: 1 1 auto;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2016, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-MainAreaWidget > :focus {
  outline: none;
}

.jp-MainAreaWidget .jp-MainAreaWidget-error {
  padding: 6px;
}

.jp-MainAreaWidget .jp-MainAreaWidget-error > pre {
  width: auto;
  padding: 10px;
  background: var(--jp-error-color3);
  border: var(--jp-border-width) solid var(--jp-error-color1);
  border-radius: var(--jp-border-radius);
  color: var(--jp-ui-font-color1);
  font-size: var(--jp-ui-font-size1);
  white-space: pre-wrap;
  word-wrap: break-word;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/**
 * google-material-color v1.2.6
 * https://github.com/danlevan/google-material-color
 */
:root {
  --md-red-50: #ffebee;
  --md-red-100: #ffcdd2;
  --md-red-200: #ef9a9a;
  --md-red-300: #e57373;
  --md-red-400: #ef5350;
  --md-red-500: #f44336;
  --md-red-600: #e53935;
  --md-red-700: #d32f2f;
  --md-red-800: #c62828;
  --md-red-900: #b71c1c;
  --md-red-A100: #ff8a80;
  --md-red-A200: #ff5252;
  --md-red-A400: #ff1744;
  --md-red-A700: #d50000;
  --md-pink-50: #fce4ec;
  --md-pink-100: #f8bbd0;
  --md-pink-200: #f48fb1;
  --md-pink-300: #f06292;
  --md-pink-400: #ec407a;
  --md-pink-500: #e91e63;
  --md-pink-600: #d81b60;
  --md-pink-700: #c2185b;
  --md-pink-800: #ad1457;
  --md-pink-900: #880e4f;
  --md-pink-A100: #ff80ab;
  --md-pink-A200: #ff4081;
  --md-pink-A400: #f50057;
  --md-pink-A700: #c51162;
  --md-purple-50: #f3e5f5;
  --md-purple-100: #e1bee7;
  --md-purple-200: #ce93d8;
  --md-purple-300: #ba68c8;
  --md-purple-400: #ab47bc;
  --md-purple-500: #9c27b0;
  --md-purple-600: #8e24aa;
  --md-purple-700: #7b1fa2;
  --md-purple-800: #6a1b9a;
  --md-purple-900: #4a148c;
  --md-purple-A100: #ea80fc;
  --md-purple-A200: #e040fb;
  --md-purple-A400: #d500f9;
  --md-purple-A700: #a0f;
  --md-deep-purple-50: #ede7f6;
  --md-deep-purple-100: #d1c4e9;
  --md-deep-purple-200: #b39ddb;
  --md-deep-purple-300: #9575cd;
  --md-deep-purple-400: #7e57c2;
  --md-deep-purple-500: #673ab7;
  --md-deep-purple-600: #5e35b1;
  --md-deep-purple-700: #512da8;
  --md-deep-purple-800: #4527a0;
  --md-deep-purple-900: #311b92;
  --md-deep-purple-A100: #b388ff;
  --md-deep-purple-A200: #7c4dff;
  --md-deep-purple-A400: #651fff;
  --md-deep-purple-A700: #6200ea;
  --md-indigo-50: #e8eaf6;
  --md-indigo-100: #c5cae9;
  --md-indigo-200: #9fa8da;
  --md-indigo-300: #7986cb;
  --md-indigo-400: #5c6bc0;
  --md-indigo-500: #3f51b5;
  --md-indigo-600: #3949ab;
  --md-indigo-700: #303f9f;
  --md-indigo-800: #283593;
  --md-indigo-900: #1a237e;
  --md-indigo-A100: #8c9eff;
  --md-indigo-A200: #536dfe;
  --md-indigo-A400: #3d5afe;
  --md-indigo-A700: #304ffe;
  --md-blue-50: #e3f2fd;
  --md-blue-100: #bbdefb;
  --md-blue-200: #90caf9;
  --md-blue-300: #64b5f6;
  --md-blue-400: #42a5f5;
  --md-blue-500: #2196f3;
  --md-blue-600: #1e88e5;
  --md-blue-700: #1976d2;
  --md-blue-800: #1565c0;
  --md-blue-900: #0d47a1;
  --md-blue-A100: #82b1ff;
  --md-blue-A200: #448aff;
  --md-blue-A400: #2979ff;
  --md-blue-A700: #2962ff;
  --md-light-blue-50: #e1f5fe;
  --md-light-blue-100: #b3e5fc;
  --md-light-blue-200: #81d4fa;
  --md-light-blue-300: #4fc3f7;
  --md-light-blue-400: #29b6f6;
  --md-light-blue-500: #03a9f4;
  --md-light-blue-600: #039be5;
  --md-light-blue-700: #0288d1;
  --md-light-blue-800: #0277bd;
  --md-light-blue-900: #01579b;
  --md-light-blue-A100: #80d8ff;
  --md-light-blue-A200: #40c4ff;
  --md-light-blue-A400: #00b0ff;
  --md-light-blue-A700: #0091ea;
  --md-cyan-50: #e0f7fa;
  --md-cyan-100: #b2ebf2;
  --md-cyan-200: #80deea;
  --md-cyan-300: #4dd0e1;
  --md-cyan-400: #26c6da;
  --md-cyan-500: #00bcd4;
  --md-cyan-600: #00acc1;
  --md-cyan-700: #0097a7;
  --md-cyan-800: #00838f;
  --md-cyan-900: #006064;
  --md-cyan-A100: #84ffff;
  --md-cyan-A200: #18ffff;
  --md-cyan-A400: #00e5ff;
  --md-cyan-A700: #00b8d4;
  --md-teal-50: #e0f2f1;
  --md-teal-100: #b2dfdb;
  --md-teal-200: #80cbc4;
  --md-teal-300: #4db6ac;
  --md-teal-400: #26a69a;
  --md-teal-500: #009688;
  --md-teal-600: #00897b;
  --md-teal-700: #00796b;
  --md-teal-800: #00695c;
  --md-teal-900: #004d40;
  --md-teal-A100: #a7ffeb;
  --md-teal-A200: #64ffda;
  --md-teal-A400: #1de9b6;
  --md-teal-A700: #00bfa5;
  --md-green-50: #e8f5e9;
  --md-green-100: #c8e6c9;
  --md-green-200: #a5d6a7;
  --md-green-300: #81c784;
  --md-green-400: #66bb6a;
  --md-green-500: #4caf50;
  --md-green-600: #43a047;
  --md-green-700: #388e3c;
  --md-green-800: #2e7d32;
  --md-green-900: #1b5e20;
  --md-green-A100: #b9f6ca;
  --md-green-A200: #69f0ae;
  --md-green-A400: #00e676;
  --md-green-A700: #00c853;
  --md-light-green-50: #f1f8e9;
  --md-light-green-100: #dcedc8;
  --md-light-green-200: #c5e1a5;
  --md-light-green-300: #aed581;
  --md-light-green-400: #9ccc65;
  --md-light-green-500: #8bc34a;
  --md-light-green-600: #7cb342;
  --md-light-green-700: #689f38;
  --md-light-green-800: #558b2f;
  --md-light-green-900: #33691e;
  --md-light-green-A100: #ccff90;
  --md-light-green-A200: #b2ff59;
  --md-light-green-A400: #76ff03;
  --md-light-green-A700: #64dd17;
  --md-lime-50: #f9fbe7;
  --md-lime-100: #f0f4c3;
  --md-lime-200: #e6ee9c;
  --md-lime-300: #dce775;
  --md-lime-400: #d4e157;
  --md-lime-500: #cddc39;
  --md-lime-600: #c0ca33;
  --md-lime-700: #afb42b;
  --md-lime-800: #9e9d24;
  --md-lime-900: #827717;
  --md-lime-A100: #f4ff81;
  --md-lime-A200: #eeff41;
  --md-lime-A400: #c6ff00;
  --md-lime-A700: #aeea00;
  --md-yellow-50: #fffde7;
  --md-yellow-100: #fff9c4;
  --md-yellow-200: #fff59d;
  --md-yellow-300: #fff176;
  --md-yellow-400: #ffee58;
  --md-yellow-500: #ffeb3b;
  --md-yellow-600: #fdd835;
  --md-yellow-700: #fbc02d;
  --md-yellow-800: #f9a825;
  --md-yellow-900: #f57f17;
  --md-yellow-A100: #ffff8d;
  --md-yellow-A200: #ff0;
  --md-yellow-A400: #ffea00;
  --md-yellow-A700: #ffd600;
  --md-amber-50: #fff8e1;
  --md-amber-100: #ffecb3;
  --md-amber-200: #ffe082;
  --md-amber-300: #ffd54f;
  --md-amber-400: #ffca28;
  --md-amber-500: #ffc107;
  --md-amber-600: #ffb300;
  --md-amber-700: #ffa000;
  --md-amber-800: #ff8f00;
  --md-amber-900: #ff6f00;
  --md-amber-A100: #ffe57f;
  --md-amber-A200: #ffd740;
  --md-amber-A400: #ffc400;
  --md-amber-A700: #ffab00;
  --md-orange-50: #fff3e0;
  --md-orange-100: #ffe0b2;
  --md-orange-200: #ffcc80;
  --md-orange-300: #ffb74d;
  --md-orange-400: #ffa726;
  --md-orange-500: #ff9800;
  --md-orange-600: #fb8c00;
  --md-orange-700: #f57c00;
  --md-orange-800: #ef6c00;
  --md-orange-900: #e65100;
  --md-orange-A100: #ffd180;
  --md-orange-A200: #ffab40;
  --md-orange-A400: #ff9100;
  --md-orange-A700: #ff6d00;
  --md-deep-orange-50: #fbe9e7;
  --md-deep-orange-100: #ffccbc;
  --md-deep-orange-200: #ffab91;
  --md-deep-orange-300: #ff8a65;
  --md-deep-orange-400: #ff7043;
  --md-deep-orange-500: #ff5722;
  --md-deep-orange-600: #f4511e;
  --md-deep-orange-700: #e64a19;
  --md-deep-orange-800: #d84315;
  --md-deep-orange-900: #bf360c;
  --md-deep-orange-A100: #ff9e80;
  --md-deep-orange-A200: #ff6e40;
  --md-deep-orange-A400: #ff3d00;
  --md-deep-orange-A700: #dd2c00;
  --md-brown-50: #efebe9;
  --md-brown-100: #d7ccc8;
  --md-brown-200: #bcaaa4;
  --md-brown-300: #a1887f;
  --md-brown-400: #8d6e63;
  --md-brown-500: #795548;
  --md-brown-600: #6d4c41;
  --md-brown-700: #5d4037;
  --md-brown-800: #4e342e;
  --md-brown-900: #3e2723;
  --md-grey-50: #fafafa;
  --md-grey-100: #f5f5f5;
  --md-grey-200: #eee;
  --md-grey-300: #e0e0e0;
  --md-grey-400: #bdbdbd;
  --md-grey-500: #9e9e9e;
  --md-grey-600: #757575;
  --md-grey-700: #616161;
  --md-grey-800: #424242;
  --md-grey-900: #212121;
  --md-blue-grey-50: #eceff1;
  --md-blue-grey-100: #cfd8dc;
  --md-blue-grey-200: #b0bec5;
  --md-blue-grey-300: #90a4ae;
  --md-blue-grey-400: #78909c;
  --md-blue-grey-500: #607d8b;
  --md-blue-grey-600: #546e7a;
  --md-blue-grey-700: #455a64;
  --md-blue-grey-800: #37474f;
  --md-blue-grey-900: #263238;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2017, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| RenderedText
|----------------------------------------------------------------------------*/

:root {
  /* This is the padding value to fill the gaps between lines containing spans with background color. */
  --jp-private-code-span-padding: calc(
    (var(--jp-code-line-height) - 1) * var(--jp-code-font-size) / 2
  );
}

.jp-RenderedText {
  text-align: left;
  padding-left: var(--jp-code-padding);
  line-height: var(--jp-code-line-height);
  font-family: var(--jp-code-font-family);
}

.jp-RenderedText pre,
.jp-RenderedJavaScript pre,
.jp-RenderedHTMLCommon pre {
  color: var(--jp-content-font-color1);
  font-size: var(--jp-code-font-size);
  border: none;
  margin: 0;
  padding: 0;
}

.jp-RenderedText pre a:link {
  text-decoration: none;
  color: var(--jp-content-link-color);
}

.jp-RenderedText pre a:hover {
  text-decoration: underline;
  color: var(--jp-content-link-color);
}

.jp-RenderedText pre a:visited {
  text-decoration: none;
  color: var(--jp-content-link-color);
}

/* console foregrounds and backgrounds */
.jp-RenderedText pre .ansi-black-fg {
  color: #3e424d;
}

.jp-RenderedText pre .ansi-red-fg {
  color: #e75c58;
}

.jp-RenderedText pre .ansi-green-fg {
  color: #00a250;
}

.jp-RenderedText pre .ansi-yellow-fg {
  color: #ddb62b;
}

.jp-RenderedText pre .ansi-blue-fg {
  color: #208ffb;
}

.jp-RenderedText pre .ansi-magenta-fg {
  color: #d160c4;
}

.jp-RenderedText pre .ansi-cyan-fg {
  color: #60c6c8;
}

.jp-RenderedText pre .ansi-white-fg {
  color: #c5c1b4;
}

.jp-RenderedText pre .ansi-black-bg {
  background-color: #3e424d;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-red-bg {
  background-color: #e75c58;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-green-bg {
  background-color: #00a250;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-yellow-bg {
  background-color: #ddb62b;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-blue-bg {
  background-color: #208ffb;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-magenta-bg {
  background-color: #d160c4;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-cyan-bg {
  background-color: #60c6c8;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-white-bg {
  background-color: #c5c1b4;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-black-intense-fg {
  color: #282c36;
}

.jp-RenderedText pre .ansi-red-intense-fg {
  color: #b22b31;
}

.jp-RenderedText pre .ansi-green-intense-fg {
  color: #007427;
}

.jp-RenderedText pre .ansi-yellow-intense-fg {
  color: #b27d12;
}

.jp-RenderedText pre .ansi-blue-intense-fg {
  color: #0065ca;
}

.jp-RenderedText pre .ansi-magenta-intense-fg {
  color: #a03196;
}

.jp-RenderedText pre .ansi-cyan-intense-fg {
  color: #258f8f;
}

.jp-RenderedText pre .ansi-white-intense-fg {
  color: #a1a6b2;
}

.jp-RenderedText pre .ansi-black-intense-bg {
  background-color: #282c36;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-red-intense-bg {
  background-color: #b22b31;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-green-intense-bg {
  background-color: #007427;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-yellow-intense-bg {
  background-color: #b27d12;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-blue-intense-bg {
  background-color: #0065ca;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-magenta-intense-bg {
  background-color: #a03196;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-cyan-intense-bg {
  background-color: #258f8f;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-white-intense-bg {
  background-color: #a1a6b2;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-default-inverse-fg {
  color: var(--jp-ui-inverse-font-color0);
}

.jp-RenderedText pre .ansi-default-inverse-bg {
  background-color: var(--jp-inverse-layout-color0);
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-bold {
  font-weight: bold;
}

.jp-RenderedText pre .ansi-underline {
  text-decoration: underline;
}

.jp-RenderedText[data-mime-type='application/vnd.jupyter.stderr'] {
  background: var(--jp-rendermime-error-background);
  padding-top: var(--jp-code-padding);
}

/*-----------------------------------------------------------------------------
| RenderedLatex
|----------------------------------------------------------------------------*/

.jp-RenderedLatex {
  color: var(--jp-content-font-color1);
  font-size: var(--jp-content-font-size1);
  line-height: var(--jp-content-line-height);
}

/* Left-justify outputs.*/
.jp-OutputArea-output.jp-RenderedLatex {
  padding: var(--jp-code-padding);
  text-align: left;
}

/*-----------------------------------------------------------------------------
| RenderedHTML
|----------------------------------------------------------------------------*/

.jp-RenderedHTMLCommon {
  color: var(--jp-content-font-color1);
  font-family: var(--jp-content-font-family);
  font-size: var(--jp-content-font-size1);
  line-height: var(--jp-content-line-height);

  /* Give a bit more R padding on Markdown text to keep line lengths reasonable */
  padding-right: 20px;
}

.jp-RenderedHTMLCommon em {
  font-style: italic;
}

.jp-RenderedHTMLCommon strong {
  font-weight: bold;
}

.jp-RenderedHTMLCommon u {
  text-decoration: underline;
}

.jp-RenderedHTMLCommon a:link {
  text-decoration: none;
  color: var(--jp-content-link-color);
}

.jp-RenderedHTMLCommon a:hover {
  text-decoration: underline;
  color: var(--jp-content-link-color);
}

.jp-RenderedHTMLCommon a:visited {
  text-decoration: none;
  color: var(--jp-content-link-color);
}

/* Headings */

.jp-RenderedHTMLCommon h1,
.jp-RenderedHTMLCommon h2,
.jp-RenderedHTMLCommon h3,
.jp-RenderedHTMLCommon h4,
.jp-RenderedHTMLCommon h5,
.jp-RenderedHTMLCommon h6 {
  line-height: var(--jp-content-heading-line-height);
  font-weight: var(--jp-content-heading-font-weight);
  font-style: normal;
  margin: var(--jp-content-heading-margin-top) 0
    var(--jp-content-heading-margin-bottom) 0;
}

.jp-RenderedHTMLCommon h1:first-child,
.jp-RenderedHTMLCommon h2:first-child,
.jp-RenderedHTMLCommon h3:first-child,
.jp-RenderedHTMLCommon h4:first-child,
.jp-RenderedHTMLCommon h5:first-child,
.jp-RenderedHTMLCommon h6:first-child {
  margin-top: calc(0.5 * var(--jp-content-heading-margin-top));
}

.jp-RenderedHTMLCommon h1:last-child,
.jp-RenderedHTMLCommon h2:last-child,
.jp-RenderedHTMLCommon h3:last-child,
.jp-RenderedHTMLCommon h4:last-child,
.jp-RenderedHTMLCommon h5:last-child,
.jp-RenderedHTMLCommon h6:last-child {
  margin-bottom: calc(0.5 * var(--jp-content-heading-margin-bottom));
}

.jp-RenderedHTMLCommon h1 {
  font-size: var(--jp-content-font-size5);
}

.jp-RenderedHTMLCommon h2 {
  font-size: var(--jp-content-font-size4);
}

.jp-RenderedHTMLCommon h3 {
  font-size: var(--jp-content-font-size3);
}

.jp-RenderedHTMLCommon h4 {
  font-size: var(--jp-content-font-size2);
}

.jp-RenderedHTMLCommon h5 {
  font-size: var(--jp-content-font-size1);
}

.jp-RenderedHTMLCommon h6 {
  font-size: var(--jp-content-font-size0);
}

/* Lists */

/* stylelint-disable selector-max-type, selector-max-compound-selectors */

.jp-RenderedHTMLCommon ul:not(.list-inline),
.jp-RenderedHTMLCommon ol:not(.list-inline) {
  padding-left: 2em;
}

.jp-RenderedHTMLCommon ul {
  list-style: disc;
}

.jp-RenderedHTMLCommon ul ul {
  list-style: square;
}

.jp-RenderedHTMLCommon ul ul ul {
  list-style: circle;
}

.jp-RenderedHTMLCommon ol {
  list-style: decimal;
}

.jp-RenderedHTMLCommon ol ol {
  list-style: upper-alpha;
}

.jp-RenderedHTMLCommon ol ol ol {
  list-style: lower-alpha;
}

.jp-RenderedHTMLCommon ol ol ol ol {
  list-style: lower-roman;
}

.jp-RenderedHTMLCommon ol ol ol ol ol {
  list-style: decimal;
}

.jp-RenderedHTMLCommon ol,
.jp-RenderedHTMLCommon ul {
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon ul ul,
.jp-RenderedHTMLCommon ul ol,
.jp-RenderedHTMLCommon ol ul,
.jp-RenderedHTMLCommon ol ol {
  margin-bottom: 0;
}

/* stylelint-enable selector-max-type, selector-max-compound-selectors */

.jp-RenderedHTMLCommon hr {
  color: var(--jp-border-color2);
  background-color: var(--jp-border-color1);
  margin-top: 1em;
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon > pre {
  margin: 1.5em 2em;
}

.jp-RenderedHTMLCommon pre,
.jp-RenderedHTMLCommon code {
  border: 0;
  background-color: var(--jp-layout-color0);
  color: var(--jp-content-font-color1);
  font-family: var(--jp-code-font-family);
  font-size: inherit;
  line-height: var(--jp-code-line-height);
  padding: 0;
  white-space: pre-wrap;
}

.jp-RenderedHTMLCommon :not(pre) > code {
  background-color: var(--jp-layout-color2);
  padding: 1px 5px;
}

/* Tables */

.jp-RenderedHTMLCommon table {
  border-collapse: collapse;
  border-spacing: 0;
  border: none;
  color: var(--jp-ui-font-color1);
  font-size: var(--jp-ui-font-size1);
  table-layout: fixed;
  margin-left: auto;
  margin-bottom: 1em;
  margin-right: auto;
}

.jp-RenderedHTMLCommon thead {
  border-bottom: var(--jp-border-width) solid var(--jp-border-color1);
  vertical-align: bottom;
}

.jp-RenderedHTMLCommon td,
.jp-RenderedHTMLCommon th,
.jp-RenderedHTMLCommon tr {
  vertical-align: middle;
  padding: 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}

.jp-RenderedMarkdown.jp-RenderedHTMLCommon td,
.jp-RenderedMarkdown.jp-RenderedHTMLCommon th {
  max-width: none;
}

:not(.jp-RenderedMarkdown).jp-RenderedHTMLCommon td,
:not(.jp-RenderedMarkdown).jp-RenderedHTMLCommon th,
:not(.jp-RenderedMarkdown).jp-RenderedHTMLCommon tr {
  text-align: right;
}

.jp-RenderedHTMLCommon th {
  font-weight: bold;
}

.jp-RenderedHTMLCommon tbody tr:nth-child(odd) {
  background: var(--jp-layout-color0);
}

.jp-RenderedHTMLCommon tbody tr:nth-child(even) {
  background: var(--jp-rendermime-table-row-background);
}

.jp-RenderedHTMLCommon tbody tr:hover {
  background: var(--jp-rendermime-table-row-hover-background);
}

.jp-RenderedHTMLCommon p {
  text-align: left;
  margin: 0;
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon img {
  -moz-force-broken-image-icon: 1;
}

/* Restrict to direct children as other images could be nested in other content. */
.jp-RenderedHTMLCommon > img {
  display: block;
  margin-left: 0;
  margin-right: 0;
  margin-bottom: 1em;
}

/* Change color behind transparent images if they need it... */
[data-jp-theme-light='false'] .jp-RenderedImage img.jp-needs-light-background {
  background-color: var(--jp-inverse-layout-color1);
}

[data-jp-theme-light='true'] .jp-RenderedImage img.jp-needs-dark-background {
  background-color: var(--jp-inverse-layout-color1);
}

.jp-RenderedHTMLCommon img,
.jp-RenderedImage img,
.jp-RenderedHTMLCommon svg,
.jp-RenderedSVG svg {
  max-width: 100%;
  height: auto;
}

.jp-RenderedHTMLCommon img.jp-mod-unconfined,
.jp-RenderedImage img.jp-mod-unconfined,
.jp-RenderedHTMLCommon svg.jp-mod-unconfined,
.jp-RenderedSVG svg.jp-mod-unconfined {
  max-width: none;
}

.jp-RenderedHTMLCommon .alert {
  padding: var(--jp-notebook-padding);
  border: var(--jp-border-width) solid transparent;
  border-radius: var(--jp-border-radius);
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon .alert-info {
  color: var(--jp-info-color0);
  background-color: var(--jp-info-color3);
  border-color: var(--jp-info-color2);
}

.jp-RenderedHTMLCommon .alert-info hr {
  border-color: var(--jp-info-color3);
}

.jp-RenderedHTMLCommon .alert-info > p:last-child,
.jp-RenderedHTMLCommon .alert-info > ul:last-child {
  margin-bottom: 0;
}

.jp-RenderedHTMLCommon .alert-warning {
  color: var(--jp-warn-color0);
  background-color: var(--jp-warn-color3);
  border-color: var(--jp-warn-color2);
}

.jp-RenderedHTMLCommon .alert-warning hr {
  border-color: var(--jp-warn-color3);
}

.jp-RenderedHTMLCommon .alert-warning > p:last-child,
.jp-RenderedHTMLCommon .alert-warning > ul:last-child {
  margin-bottom: 0;
}

.jp-RenderedHTMLCommon .alert-success {
  color: var(--jp-success-color0);
  background-color: var(--jp-success-color3);
  border-color: var(--jp-success-color2);
}

.jp-RenderedHTMLCommon .alert-success hr {
  border-color: var(--jp-success-color3);
}

.jp-RenderedHTMLCommon .alert-success > p:last-child,
.jp-RenderedHTMLCommon .alert-success > ul:last-child {
  margin-bottom: 0;
}

.jp-RenderedHTMLCommon .alert-danger {
  color: var(--jp-error-color0);
  background-color: var(--jp-error-color3);
  border-color: var(--jp-error-color2);
}

.jp-RenderedHTMLCommon .alert-danger hr {
  border-color: var(--jp-error-color3);
}

.jp-RenderedHTMLCommon .alert-danger > p:last-child,
.jp-RenderedHTMLCommon .alert-danger > ul:last-child {
  margin-bottom: 0;
}

.jp-RenderedHTMLCommon blockquote {
  margin: 1em 2em;
  padding: 0 1em;
  border-left: 5px solid var(--jp-border-color2);
}

a.jp-InternalAnchorLink {
  visibility: hidden;
  margin-left: 8px;
  color: var(--md-blue-800);
}

h1:hover .jp-InternalAnchorLink,
h2:hover .jp-InternalAnchorLink,
h3:hover .jp-InternalAnchorLink,
h4:hover .jp-InternalAnchorLink,
h5:hover .jp-InternalAnchorLink,
h6:hover .jp-InternalAnchorLink {
  visibility: visible;
}

.jp-RenderedHTMLCommon kbd {
  background-color: var(--jp-rendermime-table-row-background);
  border: 1px solid var(--jp-border-color0);
  border-bottom-color: var(--jp-border-color2);
  border-radius: 3px;
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.25);
  display: inline-block;
  font-size: var(--jp-ui-font-size0);
  line-height: 1em;
  padding: 0.2em 0.5em;
}

/* Most direct children of .jp-RenderedHTMLCommon have a margin-bottom of 1.0.
 * At the bottom of cells this is a bit too much as there is also spacing
 * between cells. Going all the way to 0 gets too tight between markdown and
 * code cells.
 */
.jp-RenderedHTMLCommon > *:last-child {
  margin-bottom: 0.5em;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-cursor-backdrop {
  position: fixed;
  width: 200px;
  height: 200px;
  margin-top: -100px;
  margin-left: -100px;
  will-change: transform;
  z-index: 100;
}

.lm-mod-drag-image {
  will-change: transform;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

.jp-lineFormSearch {
  padding: 4px 12px;
  background-color: var(--jp-layout-color2);
  box-shadow: var(--jp-toolbar-box-shadow);
  z-index: 2;
  font-size: var(--jp-ui-font-size1);
}

.jp-lineFormCaption {
  font-size: var(--jp-ui-font-size0);
  line-height: var(--jp-ui-font-size1);
  margin-top: 4px;
  color: var(--jp-ui-font-color0);
}

.jp-baseLineForm {
  border: none;
  border-radius: 0;
  position: absolute;
  background-size: 16px;
  background-repeat: no-repeat;
  background-position: center;
  outline: none;
}

.jp-lineFormButtonContainer {
  top: 4px;
  right: 8px;
  height: 24px;
  padding: 0 12px;
  width: 12px;
}

.jp-lineFormButtonIcon {
  top: 0;
  right: 0;
  background-color: var(--jp-brand-color1);
  height: 100%;
  width: 100%;
  box-sizing: border-box;
  padding: 4px 6px;
}

.jp-lineFormButton {
  top: 0;
  right: 0;
  background-color: transparent;
  height: 100%;
  width: 100%;
  box-sizing: border-box;
}

.jp-lineFormWrapper {
  overflow: hidden;
  padding: 0 8px;
  border: 1px solid var(--jp-border-color0);
  background-color: var(--jp-input-active-background);
  height: 22px;
}

.jp-lineFormWrapperFocusWithin {
  border: var(--jp-border-width) solid var(--md-blue-500);
  box-shadow: inset 0 0 4px var(--md-blue-300);
}

.jp-lineFormInput {
  background: transparent;
  width: 200px;
  height: 100%;
  border: none;
  outline: none;
  color: var(--jp-ui-font-color0);
  line-height: 28px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2016, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-JSONEditor {
  display: flex;
  flex-direction: column;
  width: 100%;
}

.jp-JSONEditor-host {
  flex: 1 1 auto;
  border: var(--jp-border-width) solid var(--jp-input-border-color);
  border-radius: 0;
  background: var(--jp-layout-color0);
  min-height: 50px;
  padding: 1px;
}

.jp-JSONEditor.jp-mod-error .jp-JSONEditor-host {
  border-color: red;
  outline-color: red;
}

.jp-JSONEditor-header {
  display: flex;
  flex: 1 0 auto;
  padding: 0 0 0 12px;
}

.jp-JSONEditor-header label {
  flex: 0 0 auto;
}

.jp-JSONEditor-commitButton {
  height: 16px;
  width: 16px;
  background-size: 18px;
  background-repeat: no-repeat;
  background-position: center;
}

.jp-JSONEditor-host.jp-mod-focused {
  background-color: var(--jp-input-active-background);
  border: 1px solid var(--jp-input-active-border-color);
  box-shadow: var(--jp-input-box-shadow);
}

.jp-Editor.jp-mod-dropTarget {
  border: var(--jp-border-width) solid var(--jp-input-active-border-color);
  box-shadow: var(--jp-input-box-shadow);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/
.jp-DocumentSearch-input {
  border: none;
  outline: none;
  color: var(--jp-ui-font-color0);
  font-size: var(--jp-ui-font-size1);
  background-color: var(--jp-layout-color0);
  font-family: var(--jp-ui-font-family);
  padding: 2px 1px;
  resize: none;
}

.jp-DocumentSearch-overlay {
  position: absolute;
  background-color: var(--jp-toolbar-background);
  border-bottom: var(--jp-border-width) solid var(--jp-toolbar-border-color);
  border-left: var(--jp-border-width) solid var(--jp-toolbar-border-color);
  top: 0;
  right: 0;
  z-index: 7;
  min-width: 405px;
  padding: 2px;
  font-size: var(--jp-ui-font-size1);

  --jp-private-document-search-button-height: 20px;
}

.jp-DocumentSearch-overlay button {
  background-color: var(--jp-toolbar-background);
  outline: 0;
}

.jp-DocumentSearch-overlay button:hover {
  background-color: var(--jp-layout-color2);
}

.jp-DocumentSearch-overlay button:active {
  background-color: var(--jp-layout-color3);
}

.jp-DocumentSearch-overlay-row {
  display: flex;
  align-items: center;
  margin-bottom: 2px;
}

.jp-DocumentSearch-button-content {
  display: inline-block;
  cursor: pointer;
  box-sizing: border-box;
  width: 100%;
  height: 100%;
}

.jp-DocumentSearch-button-content svg {
  width: 100%;
  height: 100%;
}

.jp-DocumentSearch-input-wrapper {
  border: var(--jp-border-width) solid var(--jp-border-color0);
  display: flex;
  background-color: var(--jp-layout-color0);
  margin: 2px;
}

.jp-DocumentSearch-input-wrapper:focus-within {
  border-color: var(--jp-cell-editor-active-border-color);
}

.jp-DocumentSearch-toggle-wrapper,
.jp-DocumentSearch-button-wrapper {
  all: initial;
  overflow: hidden;
  display: inline-block;
  border: none;
  box-sizing: border-box;
}

.jp-DocumentSearch-toggle-wrapper {
  width: 14px;
  height: 14px;
}

.jp-DocumentSearch-button-wrapper {
  width: var(--jp-private-document-search-button-height);
  height: var(--jp-private-document-search-button-height);
}

.jp-DocumentSearch-toggle-wrapper:focus,
.jp-DocumentSearch-button-wrapper:focus {
  outline: var(--jp-border-width) solid
    var(--jp-cell-editor-active-border-color);
  outline-offset: -1px;
}

.jp-DocumentSearch-toggle-wrapper,
.jp-DocumentSearch-button-wrapper,
.jp-DocumentSearch-button-content:focus {
  outline: none;
}

.jp-DocumentSearch-toggle-placeholder {
  width: 5px;
}

.jp-DocumentSearch-input-button::before {
  display: block;
  padding-top: 100%;
}

.jp-DocumentSearch-input-button-off {
  opacity: var(--jp-search-toggle-off-opacity);
}

.jp-DocumentSearch-input-button-off:hover {
  opacity: var(--jp-search-toggle-hover-opacity);
}

.jp-DocumentSearch-input-button-on {
  opacity: var(--jp-search-toggle-on-opacity);
}

.jp-DocumentSearch-index-counter {
  padding-left: 10px;
  padding-right: 10px;
  user-select: none;
  min-width: 35px;
  display: inline-block;
}

.jp-DocumentSearch-up-down-wrapper {
  display: inline-block;
  padding-right: 2px;
  margin-left: auto;
  white-space: nowrap;
}

.jp-DocumentSearch-spacer {
  margin-left: auto;
}

.jp-DocumentSearch-up-down-wrapper button {
  outline: 0;
  border: none;
  width: var(--jp-private-document-search-button-height);
  height: var(--jp-private-document-search-button-height);
  vertical-align: middle;
  margin: 1px 5px 2px;
}

.jp-DocumentSearch-up-down-button:hover {
  background-color: var(--jp-layout-color2);
}

.jp-DocumentSearch-up-down-button:active {
  background-color: var(--jp-layout-color3);
}

.jp-DocumentSearch-filter-button {
  border-radius: var(--jp-border-radius);
}

.jp-DocumentSearch-filter-button:hover {
  background-color: var(--jp-layout-color2);
}

.jp-DocumentSearch-filter-button-enabled {
  background-color: var(--jp-layout-color2);
}

.jp-DocumentSearch-filter-button-enabled:hover {
  background-color: var(--jp-layout-color3);
}

.jp-DocumentSearch-search-options {
  padding: 0 8px;
  margin-left: 3px;
  width: 100%;
  display: grid;
  justify-content: start;
  grid-template-columns: 1fr 1fr;
  align-items: center;
  justify-items: stretch;
}

.jp-DocumentSearch-search-filter-disabled {
  color: var(--jp-ui-font-color2);
}

.jp-DocumentSearch-search-filter {
  display: flex;
  align-items: center;
  user-select: none;
}

.jp-DocumentSearch-regex-error {
  color: var(--jp-error-color0);
}

.jp-DocumentSearch-replace-button-wrapper {
  overflow: hidden;
  display: inline-block;
  box-sizing: border-box;
  border: var(--jp-border-width) solid var(--jp-border-color0);
  margin: auto 2px;
  padding: 1px 4px;
  height: calc(var(--jp-private-document-search-button-height) + 2px);
}

.jp-DocumentSearch-replace-button-wrapper:focus {
  border: var(--jp-border-width) solid var(--jp-cell-editor-active-border-color);
}

.jp-DocumentSearch-replace-button {
  display: inline-block;
  text-align: center;
  cursor: pointer;
  box-sizing: border-box;
  color: var(--jp-ui-font-color1);

  /* height - 2 * (padding of wrapper) */
  line-height: calc(var(--jp-private-document-search-button-height) - 2px);
  width: 100%;
  height: 100%;
}

.jp-DocumentSearch-replace-button:focus {
  outline: none;
}

.jp-DocumentSearch-replace-wrapper-class {
  margin-left: 14px;
  display: flex;
}

.jp-DocumentSearch-replace-toggle {
  border: none;
  background-color: var(--jp-toolbar-background);
  border-radius: var(--jp-border-radius);
}

.jp-DocumentSearch-replace-toggle:hover {
  background-color: var(--jp-layout-color2);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.cm-editor {
  line-height: var(--jp-code-line-height);
  font-size: var(--jp-code-font-size);
  font-family: var(--jp-code-font-family);
  border: 0;
  border-radius: 0;
  height: auto;

  /* Changed to auto to autogrow */
}

.cm-editor pre {
  padding: 0 var(--jp-code-padding);
}

.jp-CodeMirrorEditor[data-type='inline'] .cm-dialog {
  background-color: var(--jp-layout-color0);
  color: var(--jp-content-font-color1);
}

.jp-CodeMirrorEditor {
  cursor: text;
}

/* When zoomed out 67% and 33% on a screen of 1440 width x 900 height */
@media screen and (min-width: 2138px) and (max-width: 4319px) {
  .jp-CodeMirrorEditor[data-type='inline'] .cm-cursor {
    border-left: var(--jp-code-cursor-width1) solid
      var(--jp-editor-cursor-color);
  }
}

/* When zoomed out less than 33% */
@media screen and (min-width: 4320px) {
  .jp-CodeMirrorEditor[data-type='inline'] .cm-cursor {
    border-left: var(--jp-code-cursor-width2) solid
      var(--jp-editor-cursor-color);
  }
}

.cm-editor.jp-mod-readOnly .cm-cursor {
  display: none;
}

.jp-CollaboratorCursor {
  border-left: 5px solid transparent;
  border-right: 5px solid transparent;
  border-top: none;
  border-bottom: 3px solid;
  background-clip: content-box;
  margin-left: -5px;
  margin-right: -5px;
}

.cm-searching,
.cm-searching span {
  /* `.cm-searching span`: we need to override syntax highlighting */
  background-color: var(--jp-search-unselected-match-background-color);
  color: var(--jp-search-unselected-match-color);
}

.cm-searching::selection,
.cm-searching span::selection {
  background-color: var(--jp-search-unselected-match-background-color);
  color: var(--jp-search-unselected-match-color);
}

.jp-current-match > .cm-searching,
.jp-current-match > .cm-searching span,
.cm-searching > .jp-current-match,
.cm-searching > .jp-current-match span {
  background-color: var(--jp-search-selected-match-background-color);
  color: var(--jp-search-selected-match-color);
}

.jp-current-match > .cm-searching::selection,
.cm-searching > .jp-current-match::selection,
.jp-current-match > .cm-searching span::selection {
  background-color: var(--jp-search-selected-match-background-color);
  color: var(--jp-search-selected-match-color);
}

.cm-trailingspace {
  background-image: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAgAAAAFCAYAAAB4ka1VAAAAsElEQVQIHQGlAFr/AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA7+r3zKmT0/+pk9P/7+r3zAAAAAAAAAAABAAAAAAAAAAA6OPzM+/q9wAAAAAA6OPzMwAAAAAAAAAAAgAAAAAAAAAAGR8NiRQaCgAZIA0AGR8NiQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAQyoYJ/SY80UAAAAASUVORK5CYII=);
  background-position: center left;
  background-repeat: repeat-x;
}

.jp-CollaboratorCursor-hover {
  position: absolute;
  z-index: 1;
  transform: translateX(-50%);
  color: white;
  border-radius: 3px;
  padding-left: 4px;
  padding-right: 4px;
  padding-top: 1px;
  padding-bottom: 1px;
  text-align: center;
  font-size: var(--jp-ui-font-size1);
  white-space: nowrap;
}

.jp-CodeMirror-ruler {
  border-left: 1px dashed var(--jp-border-color2);
}

/* Styles for shared cursors (remote cursor locations and selected ranges) */
.jp-CodeMirrorEditor .cm-ySelectionCaret {
  position: relative;
  border-left: 1px solid black;
  margin-left: -1px;
  margin-right: -1px;
  box-sizing: border-box;
}

.jp-CodeMirrorEditor .cm-ySelectionCaret > .cm-ySelectionInfo {
  white-space: nowrap;
  position: absolute;
  top: -1.15em;
  padding-bottom: 0.05em;
  left: -1px;
  font-size: 0.95em;
  font-family: var(--jp-ui-font-family);
  font-weight: bold;
  line-height: normal;
  user-select: none;
  color: white;
  padding-left: 2px;
  padding-right: 2px;
  z-index: 101;
  transition: opacity 0.3s ease-in-out;
}

.jp-CodeMirrorEditor .cm-ySelectionInfo {
  transition-delay: 0.7s;
  opacity: 0;
}

.jp-CodeMirrorEditor .cm-ySelectionCaret:hover > .cm-ySelectionInfo {
  opacity: 1;
  transition-delay: 0s;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-MimeDocument {
  outline: none;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Variables
|----------------------------------------------------------------------------*/

:root {
  --jp-private-filebrowser-button-height: 28px;
  --jp-private-filebrowser-button-width: 48px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-FileBrowser .jp-SidePanel-content {
  display: flex;
  flex-direction: column;
}

.jp-FileBrowser-toolbar.jp-Toolbar {
  flex-wrap: wrap;
  row-gap: 12px;
  border-bottom: none;
  height: auto;
  margin: 8px 12px 0;
  box-shadow: none;
  padding: 0;
  justify-content: flex-start;
}

.jp-FileBrowser-Panel {
  flex: 1 1 auto;
  display: flex;
  flex-direction: column;
}

.jp-BreadCrumbs {
  flex: 0 0 auto;
  margin: 8px 12px;
}

.jp-BreadCrumbs-item {
  margin: 0 2px;
  padding: 0 2px;
  border-radius: var(--jp-border-radius);
  cursor: pointer;
}

.jp-BreadCrumbs-item:hover {
  background-color: var(--jp-layout-color2);
}

.jp-BreadCrumbs-item:first-child {
  margin-left: 0;
}

.jp-BreadCrumbs-item.jp-mod-dropTarget {
  background-color: var(--jp-brand-color2);
  opacity: 0.7;
}

/*-----------------------------------------------------------------------------
| Buttons
|----------------------------------------------------------------------------*/

.jp-FileBrowser-toolbar > .jp-Toolbar-item {
  flex: 0 0 auto;
  padding-left: 0;
  padding-right: 2px;
  align-items: center;
  height: unset;
}

.jp-FileBrowser-toolbar > .jp-Toolbar-item .jp-ToolbarButtonComponent {
  width: 40px;
}

/*-----------------------------------------------------------------------------
| Other styles
|----------------------------------------------------------------------------*/

.jp-FileDialog.jp-mod-conflict input {
  color: var(--jp-error-color1);
}

.jp-FileDialog .jp-new-name-title {
  margin-top: 12px;
}

.jp-LastModified-hidden {
  display: none;
}

.jp-FileSize-hidden {
  display: none;
}

.jp-FileBrowser .lm-AccordionPanel > h3:first-child {
  display: none;
}

/*-----------------------------------------------------------------------------
| DirListing
|----------------------------------------------------------------------------*/

.jp-DirListing {
  flex: 1 1 auto;
  display: flex;
  flex-direction: column;
  outline: 0;
}

.jp-DirListing-header {
  flex: 0 0 auto;
  display: flex;
  flex-direction: row;
  align-items: center;
  overflow: hidden;
  border-top: var(--jp-border-width) solid var(--jp-border-color2);
  border-bottom: var(--jp-border-width) solid var(--jp-border-color1);
  box-shadow: var(--jp-toolbar-box-shadow);
  z-index: 2;
}

.jp-DirListing-headerItem {
  padding: 4px 12px 2px;
  font-weight: 500;
}

.jp-DirListing-headerItem:hover {
  background: var(--jp-layout-color2);
}

.jp-DirListing-headerItem.jp-id-name {
  flex: 1 0 84px;
}

.jp-DirListing-headerItem.jp-id-modified {
  flex: 0 0 112px;
  border-left: var(--jp-border-width) solid var(--jp-border-color2);
  text-align: right;
}

.jp-DirListing-headerItem.jp-id-filesize {
  flex: 0 0 75px;
  border-left: var(--jp-border-width) solid var(--jp-border-color2);
  text-align: right;
}

.jp-id-narrow {
  display: none;
  flex: 0 0 5px;
  padding: 4px;
  border-left: var(--jp-border-width) solid var(--jp-border-color2);
  text-align: right;
  color: var(--jp-border-color2);
}

.jp-DirListing-narrow .jp-id-narrow {
  display: block;
}

.jp-DirListing-narrow .jp-id-modified,
.jp-DirListing-narrow .jp-DirListing-itemModified {
  display: none;
}

.jp-DirListing-headerItem.jp-mod-selected {
  font-weight: 600;
}

/* increase specificity to override bundled default */
.jp-DirListing-content {
  flex: 1 1 auto;
  margin: 0;
  padding: 0;
  list-style-type: none;
  overflow: auto;
  background-color: var(--jp-layout-color1);
}

.jp-DirListing-content mark {
  color: var(--jp-ui-font-color0);
  background-color: transparent;
  font-weight: bold;
}

.jp-DirListing-content .jp-DirListing-item.jp-mod-selected mark {
  color: var(--jp-ui-inverse-font-color0);
}

/* Style the directory listing content when a user drops a file to upload */
.jp-DirListing.jp-mod-native-drop .jp-DirListing-content {
  outline: 5px dashed rgba(128, 128, 128, 0.5);
  outline-offset: -10px;
  cursor: copy;
}

.jp-DirListing-item {
  display: flex;
  flex-direction: row;
  align-items: center;
  padding: 4px 12px;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.jp-DirListing-checkboxWrapper {
  /* Increases hit area of checkbox. */
  padding: 4px;
}

.jp-DirListing-header
  .jp-DirListing-checkboxWrapper
  + .jp-DirListing-headerItem {
  padding-left: 4px;
}

.jp-DirListing-content .jp-DirListing-checkboxWrapper {
  position: relative;
  left: -4px;
  margin: -4px 0 -4px -8px;
}

.jp-DirListing-checkboxWrapper.jp-mod-visible {
  visibility: visible;
}

/* For devices that support hovering, hide checkboxes until hovered, selected...
*/
@media (hover: hover) {
  .jp-DirListing-checkboxWrapper {
    visibility: hidden;
  }

  .jp-DirListing-item:hover .jp-DirListing-checkboxWrapper,
  .jp-DirListing-item.jp-mod-selected .jp-DirListing-checkboxWrapper {
    visibility: visible;
  }
}

.jp-DirListing-item[data-is-dot] {
  opacity: 75%;
}

.jp-DirListing-item.jp-mod-selected {
  color: var(--jp-ui-inverse-font-color1);
  background: var(--jp-brand-color1);
}

.jp-DirListing-item.jp-mod-dropTarget {
  background: var(--jp-brand-color3);
}

.jp-DirListing-item:hover:not(.jp-mod-selected) {
  background: var(--jp-layout-color2);
}

.jp-DirListing-itemIcon {
  flex: 0 0 20px;
  margin-right: 4px;
}

.jp-DirListing-itemText {
  flex: 1 0 64px;
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;
  user-select: none;
}

.jp-DirListing-itemText:focus {
  outline-width: 2px;
  outline-color: var(--jp-inverse-layout-color1);
  outline-style: solid;
  outline-offset: 1px;
}

.jp-DirListing-item.jp-mod-selected .jp-DirListing-itemText:focus {
  outline-color: var(--jp-layout-color1);
}

.jp-DirListing-itemModified {
  flex: 0 0 125px;
  text-align: right;
}

.jp-DirListing-itemFileSize {
  flex: 0 0 90px;
  text-align: right;
}

.jp-DirListing-editor {
  flex: 1 0 64px;
  outline: none;
  border: none;
  color: var(--jp-ui-font-color1);
  background-color: var(--jp-layout-color1);
}

.jp-DirListing-item.jp-mod-running .jp-DirListing-itemIcon::before {
  color: var(--jp-success-color1);
  content: '\25CF';
  font-size: 8px;
  position: absolute;
  left: -8px;
}

.jp-DirListing-item.jp-mod-running.jp-mod-selected
  .jp-DirListing-itemIcon::before {
  color: var(--jp-ui-inverse-font-color1);
}

.jp-DirListing-item.lm-mod-drag-image,
.jp-DirListing-item.jp-mod-selected.lm-mod-drag-image {
  font-size: var(--jp-ui-font-size1);
  padding-left: 4px;
  margin-left: 4px;
  width: 160px;
  background-color: var(--jp-ui-inverse-font-color2);
  box-shadow: var(--jp-elevation-z2);
  border-radius: 0;
  color: var(--jp-ui-font-color1);
  transform: translateX(-40%) translateY(-58%);
}

.jp-Document {
  min-width: 120px;
  min-height: 120px;
  outline: none;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Main OutputArea
| OutputArea has a list of Outputs
|----------------------------------------------------------------------------*/

.jp-OutputArea {
  overflow-y: auto;
}

.jp-OutputArea-child {
  display: table;
  table-layout: fixed;
  width: 100%;
  overflow: hidden;
}

.jp-OutputPrompt {
  width: var(--jp-cell-prompt-width);
  color: var(--jp-cell-outprompt-font-color);
  font-family: var(--jp-cell-prompt-font-family);
  padding: var(--jp-code-padding);
  letter-spacing: var(--jp-cell-prompt-letter-spacing);
  line-height: var(--jp-code-line-height);
  font-size: var(--jp-code-font-size);
  border: var(--jp-border-width) solid transparent;
  opacity: var(--jp-cell-prompt-opacity);

  /* Right align prompt text, don't wrap to handle large prompt numbers */
  text-align: right;
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;

  /* Disable text selection */
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.jp-OutputArea-prompt {
  display: table-cell;
  vertical-align: top;
}

.jp-OutputArea-output {
  display: table-cell;
  width: 100%;
  height: auto;
  overflow: auto;
  user-select: text;
  -moz-user-select: text;
  -webkit-user-select: text;
  -ms-user-select: text;
}

.jp-OutputArea .jp-RenderedText {
  padding-left: 1ch;
}

/**
 * Prompt overlay.
 */

.jp-OutputArea-promptOverlay {
  position: absolute;
  top: 0;
  width: var(--jp-cell-prompt-width);
  height: 100%;
  opacity: 0.5;
}

.jp-OutputArea-promptOverlay:hover {
  background: var(--jp-layout-color2);
  box-shadow: inset 0 0 1px var(--jp-inverse-layout-color0);
  cursor: zoom-out;
}

.jp-mod-outputsScrolled .jp-OutputArea-promptOverlay:hover {
  cursor: zoom-in;
}

/**
 * Isolated output.
 */
.jp-OutputArea-output.jp-mod-isolated {
  width: 100%;
  display: block;
}

/*
When drag events occur, `lm-mod-override-cursor` is added to the body.
Because iframes steal all cursor events, the following two rules are necessary
to suppress pointer events while resize drags are occurring. There may be a
better solution to this problem.
*/
body.lm-mod-override-cursor .jp-OutputArea-output.jp-mod-isolated {
  position: relative;
}

body.lm-mod-override-cursor .jp-OutputArea-output.jp-mod-isolated::before {
  content: '';
  position: absolute;
  top: 0;
  left: 0;
  right: 0;
  bottom: 0;
  background: transparent;
}

/* pre */

.jp-OutputArea-output pre {
  border: none;
  margin: 0;
  padding: 0;
  overflow-x: auto;
  overflow-y: auto;
  word-break: break-all;
  word-wrap: break-word;
  white-space: pre-wrap;
}

/* tables */

.jp-OutputArea-output.jp-RenderedHTMLCommon table {
  margin-left: 0;
  margin-right: 0;
}

/* description lists */

.jp-OutputArea-output dl,
.jp-OutputArea-output dt,
.jp-OutputArea-output dd {
  display: block;
}

.jp-OutputArea-output dl {
  width: 100%;
  overflow: hidden;
  padding: 0;
  margin: 0;
}

.jp-OutputArea-output dt {
  font-weight: bold;
  float: left;
  width: 20%;
  padding: 0;
  margin: 0;
}

.jp-OutputArea-output dd {
  float: left;
  width: 80%;
  padding: 0;
  margin: 0;
}

.jp-TrimmedOutputs pre {
  background: var(--jp-layout-color3);
  font-size: calc(var(--jp-code-font-size) * 1.4);
  text-align: center;
  text-transform: uppercase;
}

/* Hide the gutter in case of
 *  - nested output areas (e.g. in the case of output widgets)
 *  - mirrored output areas
 */
.jp-OutputArea .jp-OutputArea .jp-OutputArea-prompt {
  display: none;
}

/* Hide empty lines in the output area, for instance due to cleared widgets */
.jp-OutputArea-prompt:empty {
  padding: 0;
  border: 0;
}

/*-----------------------------------------------------------------------------
| executeResult is added to any Output-result for the display of the object
| returned by a cell
|----------------------------------------------------------------------------*/

.jp-OutputArea-output.jp-OutputArea-executeResult {
  margin-left: 0;
  width: 100%;
}

/* Text output with the Out[] prompt needs a top padding to match the
 * alignment of the Out[] prompt itself.
 */
.jp-OutputArea-executeResult .jp-RenderedText.jp-OutputArea-output {
  padding-top: var(--jp-code-padding);
  border-top: var(--jp-border-width) solid transparent;
}

/*-----------------------------------------------------------------------------
| The Stdin output
|----------------------------------------------------------------------------*/

.jp-Stdin-prompt {
  color: var(--jp-content-font-color0);
  padding-right: var(--jp-code-padding);
  vertical-align: baseline;
  flex: 0 0 auto;
}

.jp-Stdin-input {
  font-family: var(--jp-code-font-family);
  font-size: inherit;
  color: inherit;
  background-color: inherit;
  width: 42%;
  min-width: 200px;

  /* make sure input baseline aligns with prompt */
  vertical-align: baseline;

  /* padding + margin = 0.5em between prompt and cursor */
  padding: 0 0.25em;
  margin: 0 0.25em;
  flex: 0 0 70%;
}

.jp-Stdin-input::placeholder {
  opacity: 0;
}

.jp-Stdin-input:focus {
  box-shadow: none;
}

.jp-Stdin-input:focus::placeholder {
  opacity: 1;
}

/*-----------------------------------------------------------------------------
| Output Area View
|----------------------------------------------------------------------------*/

.jp-LinkedOutputView .jp-OutputArea {
  height: 100%;
  display: block;
}

.jp-LinkedOutputView .jp-OutputArea-output:only-child {
  height: 100%;
}

/*-----------------------------------------------------------------------------
| Printing
|----------------------------------------------------------------------------*/

@media print {
  .jp-OutputArea-child {
    break-inside: avoid-page;
  }
}

/*-----------------------------------------------------------------------------
| Mobile
|----------------------------------------------------------------------------*/
@media only screen and (max-width: 760px) {
  .jp-OutputPrompt {
    display: table-row;
    text-align: left;
  }

  .jp-OutputArea-child .jp-OutputArea-output {
    display: table-row;
    margin-left: var(--jp-notebook-padding);
  }
}

/* Trimmed outputs warning */
.jp-TrimmedOutputs > a {
  margin: 10px;
  text-decoration: none;
  cursor: pointer;
}

.jp-TrimmedOutputs > a:hover {
  text-decoration: none;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Table of Contents
|----------------------------------------------------------------------------*/

:root {
  --jp-private-toc-active-width: 4px;
}

.jp-TableOfContents {
  display: flex;
  flex-direction: column;
  background: var(--jp-layout-color1);
  color: var(--jp-ui-font-color1);
  font-size: var(--jp-ui-font-size1);
  height: 100%;
}

.jp-TableOfContents-placeholder {
  text-align: center;
}

.jp-TableOfContents-placeholderContent {
  color: var(--jp-content-font-color2);
  padding: 8px;
}

.jp-TableOfContents-placeholderContent > h3 {
  margin-bottom: var(--jp-content-heading-margin-bottom);
}

.jp-TableOfContents .jp-SidePanel-content {
  overflow-y: auto;
}

.jp-TableOfContents-tree {
  margin: 4px;
}

.jp-TableOfContents ol {
  list-style-type: none;
}

/* stylelint-disable-next-line selector-max-type */
.jp-TableOfContents li > ol {
  /* Align left border with triangle icon center */
  padding-left: 11px;
}

.jp-TableOfContents-content {
  /* left margin for the active heading indicator */
  margin: 0 0 0 var(--jp-private-toc-active-width);
  padding: 0;
  background-color: var(--jp-layout-color1);
}

.jp-tocItem {
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.jp-tocItem-heading {
  display: flex;
  cursor: pointer;
}

.jp-tocItem-heading:hover {
  background-color: var(--jp-layout-color2);
}

.jp-tocItem-content {
  display: block;
  padding: 4px 0;
  white-space: nowrap;
  text-overflow: ellipsis;
  overflow-x: hidden;
}

.jp-tocItem-collapser {
  height: 20px;
  margin: 2px 2px 0;
  padding: 0;
  background: none;
  border: none;
  cursor: pointer;
}

.jp-tocItem-collapser:hover {
  background-color: var(--jp-layout-color3);
}

/* Active heading indicator */

.jp-tocItem-heading::before {
  content: ' ';
  background: transparent;
  width: var(--jp-private-toc-active-width);
  height: 24px;
  position: absolute;
  left: 0;
  border-radius: var(--jp-border-radius);
}

.jp-tocItem-heading.jp-tocItem-active::before {
  background-color: var(--jp-brand-color1);
}

.jp-tocItem-heading:hover.jp-tocItem-active::before {
  background: var(--jp-brand-color0);
  opacity: 1;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-Collapser {
  flex: 0 0 var(--jp-cell-collapser-width);
  padding: 0;
  margin: 0;
  border: none;
  outline: none;
  background: transparent;
  border-radius: var(--jp-border-radius);
  opacity: 1;
}

.jp-Collapser-child {
  display: block;
  width: 100%;
  box-sizing: border-box;

  /* height: 100% doesn't work because the height of its parent is computed from content */
  position: absolute;
  top: 0;
  bottom: 0;
}

/*-----------------------------------------------------------------------------
| Printing
|----------------------------------------------------------------------------*/

/*
Hiding collapsers in print mode.

Note: input and output wrappers have "display: block" propery in print mode.
*/

@media print {
  .jp-Collapser {
    display: none;
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Header/Footer
|----------------------------------------------------------------------------*/

/* Hidden by zero height by default */
.jp-CellHeader,
.jp-CellFooter {
  height: 0;
  width: 100%;
  padding: 0;
  margin: 0;
  border: none;
  outline: none;
  background: transparent;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Input
|----------------------------------------------------------------------------*/

/* All input areas */
.jp-InputArea {
  display: table;
  table-layout: fixed;
  width: 100%;
  overflow: hidden;
}

.jp-InputArea-editor {
  display: table-cell;
  overflow: hidden;
  vertical-align: top;

  /* This is the non-active, default styling */
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  border-radius: 0;
  background: var(--jp-cell-editor-background);
}

.jp-InputPrompt {
  display: table-cell;
  vertical-align: top;
  width: var(--jp-cell-prompt-width);
  color: var(--jp-cell-inprompt-font-color);
  font-family: var(--jp-cell-prompt-font-family);
  padding: var(--jp-code-padding);
  letter-spacing: var(--jp-cell-prompt-letter-spacing);
  opacity: var(--jp-cell-prompt-opacity);
  line-height: var(--jp-code-line-height);
  font-size: var(--jp-code-font-size);
  border: var(--jp-border-width) solid transparent;

  /* Right align prompt text, don't wrap to handle large prompt numbers */
  text-align: right;
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;

  /* Disable text selection */
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

/*-----------------------------------------------------------------------------
| Mobile
|----------------------------------------------------------------------------*/
@media only screen and (max-width: 760px) {
  .jp-InputArea-editor {
    display: table-row;
    margin-left: var(--jp-notebook-padding);
  }

  .jp-InputPrompt {
    display: table-row;
    text-align: left;
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Placeholder
|----------------------------------------------------------------------------*/

.jp-Placeholder {
  display: table;
  table-layout: fixed;
  width: 100%;
}

.jp-Placeholder-prompt {
  display: table-cell;
  box-sizing: border-box;
}

.jp-Placeholder-content {
  display: table-cell;
  padding: 4px 6px;
  border: 1px solid transparent;
  border-radius: 0;
  background: none;
  box-sizing: border-box;
  cursor: pointer;
}

.jp-Placeholder-contentContainer {
  display: flex;
}

.jp-Placeholder-content:hover,
.jp-InputPlaceholder > .jp-Placeholder-content:hover {
  border-color: var(--jp-layout-color3);
}

.jp-Placeholder-content .jp-MoreHorizIcon {
  width: 32px;
  height: 16px;
  border: 1px solid transparent;
  border-radius: var(--jp-border-radius);
}

.jp-Placeholder-content .jp-MoreHorizIcon:hover {
  border: 1px solid var(--jp-border-color1);
  box-shadow: 0 0 2px 0 rgba(0, 0, 0, 0.25);
  background-color: var(--jp-layout-color0);
}

.jp-PlaceholderText {
  white-space: nowrap;
  overflow-x: hidden;
  color: var(--jp-inverse-layout-color3);
  font-family: var(--jp-code-font-family);
}

.jp-InputPlaceholder > .jp-Placeholder-content {
  border-color: var(--jp-cell-editor-border-color);
  background: var(--jp-cell-editor-background);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Private CSS variables
|----------------------------------------------------------------------------*/

:root {
  --jp-private-cell-scrolling-output-offset: 5px;
}

/*-----------------------------------------------------------------------------
| Cell
|----------------------------------------------------------------------------*/

.jp-Cell {
  padding: var(--jp-cell-padding);
  margin: 0;
  border: none;
  outline: none;
  background: transparent;
}

/*-----------------------------------------------------------------------------
| Common input/output
|----------------------------------------------------------------------------*/

.jp-Cell-inputWrapper,
.jp-Cell-outputWrapper {
  display: flex;
  flex-direction: row;
  padding: 0;
  margin: 0;

  /* Added to reveal the box-shadow on the input and output collapsers. */
  overflow: visible;
}

/* Only input/output areas inside cells */
.jp-Cell-inputArea,
.jp-Cell-outputArea {
  flex: 1 1 auto;
}

/*-----------------------------------------------------------------------------
| Collapser
|----------------------------------------------------------------------------*/

/* Make the output collapser disappear when there is not output, but do so
 * in a manner that leaves it in the layout and preserves its width.
 */
.jp-Cell.jp-mod-noOutputs .jp-Cell-outputCollapser {
  border: none !important;
  background: transparent !important;
}

.jp-Cell:not(.jp-mod-noOutputs) .jp-Cell-outputCollapser {
  min-height: var(--jp-cell-collapser-min-height);
}

/*-----------------------------------------------------------------------------
| Output
|----------------------------------------------------------------------------*/

/* Put a space between input and output when there IS output */
.jp-Cell:not(.jp-mod-noOutputs) .jp-Cell-outputWrapper {
  margin-top: 5px;
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-Cell-outputArea {
  overflow-y: auto;
  max-height: 24em;
  margin-left: var(--jp-private-cell-scrolling-output-offset);
  resize: vertical;
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-Cell-outputArea[style*='height'] {
  max-height: unset;
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-Cell-outputArea::after {
  content: ' ';
  box-shadow: inset 0 0 6px 2px rgb(0 0 0 / 30%);
  width: 100%;
  height: 100%;
  position: sticky;
  bottom: 0;
  top: 0;
  margin-top: -50%;
  float: left;
  display: block;
  pointer-events: none;
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-OutputArea-child {
  padding-top: 6px;
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-OutputArea-prompt {
  width: calc(
    var(--jp-cell-prompt-width) - var(--jp-private-cell-scrolling-output-offset)
  );
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-OutputArea-promptOverlay {
  left: calc(-1 * var(--jp-private-cell-scrolling-output-offset));
}

/*-----------------------------------------------------------------------------
| CodeCell
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| MarkdownCell
|----------------------------------------------------------------------------*/

.jp-MarkdownOutput {
  display: table-cell;
  width: 100%;
  margin-top: 0;
  margin-bottom: 0;
  padding-left: var(--jp-code-padding);
}

.jp-MarkdownOutput.jp-RenderedHTMLCommon {
  overflow: auto;
}

/* collapseHeadingButton (show always if hiddenCellsButton is _not_ shown) */
.jp-collapseHeadingButton {
  display: flex;
  min-height: var(--jp-cell-collapser-min-height);
  font-size: var(--jp-code-font-size);
  position: absolute;
  background-color: transparent;
  background-size: 25px;
  background-repeat: no-repeat;
  background-position-x: center;
  background-position-y: top;
  background-image: var(--jp-icon-caret-down);
  right: 0;
  top: 0;
  bottom: 0;
}

.jp-collapseHeadingButton.jp-mod-collapsed {
  background-image: var(--jp-icon-caret-right);
}

/*
 set the container font size to match that of content
 so that the nested collapse buttons have the right size
*/
.jp-MarkdownCell .jp-InputPrompt {
  font-size: var(--jp-content-font-size1);
}

/*
  Align collapseHeadingButton with cell top header
  The font sizes are identical to the ones in packages/rendermime/style/base.css
*/
.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='1'] {
  font-size: var(--jp-content-font-size5);
  background-position-y: calc(0.3 * var(--jp-content-font-size5));
}

.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='2'] {
  font-size: var(--jp-content-font-size4);
  background-position-y: calc(0.3 * var(--jp-content-font-size4));
}

.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='3'] {
  font-size: var(--jp-content-font-size3);
  background-position-y: calc(0.3 * var(--jp-content-font-size3));
}

.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='4'] {
  font-size: var(--jp-content-font-size2);
  background-position-y: calc(0.3 * var(--jp-content-font-size2));
}

.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='5'] {
  font-size: var(--jp-content-font-size1);
  background-position-y: top;
}

.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='6'] {
  font-size: var(--jp-content-font-size0);
  background-position-y: top;
}

/* collapseHeadingButton (show only on (hover,active) if hiddenCellsButton is shown) */
.jp-Notebook.jp-mod-showHiddenCellsButton .jp-collapseHeadingButton {
  display: none;
}

.jp-Notebook.jp-mod-showHiddenCellsButton
  :is(.jp-MarkdownCell:hover, .jp-mod-active)
  .jp-collapseHeadingButton {
  display: flex;
}

/* showHiddenCellsButton (only show if jp-mod-showHiddenCellsButton is set, which
is a consequence of the showHiddenCellsButton option in Notebook Settings)*/
.jp-Notebook.jp-mod-showHiddenCellsButton .jp-showHiddenCellsButton {
  margin-left: calc(var(--jp-cell-prompt-width) + 2 * var(--jp-code-padding));
  margin-top: var(--jp-code-padding);
  border: 1px solid var(--jp-border-color2);
  background-color: var(--jp-border-color3) !important;
  color: var(--jp-content-font-color0) !important;
  display: flex;
}

.jp-Notebook.jp-mod-showHiddenCellsButton .jp-showHiddenCellsButton:hover {
  background-color: var(--jp-border-color2) !important;
}

.jp-showHiddenCellsButton {
  display: none;
}

/*-----------------------------------------------------------------------------
| Printing
|----------------------------------------------------------------------------*/

/*
Using block instead of flex to allow the use of the break-inside CSS property for
cell outputs.
*/

@media print {
  .jp-Cell-inputWrapper,
  .jp-Cell-outputWrapper {
    display: block;
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Variables
|----------------------------------------------------------------------------*/

:root {
  --jp-notebook-toolbar-padding: 2px 5px 2px 2px;
}

/*-----------------------------------------------------------------------------

/*-----------------------------------------------------------------------------
| Styles
|----------------------------------------------------------------------------*/

.jp-NotebookPanel-toolbar {
  padding: var(--jp-notebook-toolbar-padding);

  /* disable paint containment from lumino 2.0 default strict CSS containment */
  contain: style size !important;
}

.jp-Toolbar-item.jp-Notebook-toolbarCellType .jp-select-wrapper.jp-mod-focused {
  border: none;
  box-shadow: none;
}

.jp-Notebook-toolbarCellTypeDropdown select {
  height: 24px;
  font-size: var(--jp-ui-font-size1);
  line-height: 14px;
  border-radius: 0;
  display: block;
}

.jp-Notebook-toolbarCellTypeDropdown span {
  top: 5px !important;
}

.jp-Toolbar-responsive-popup {
  position: absolute;
  height: fit-content;
  display: flex;
  flex-direction: row;
  flex-wrap: wrap;
  justify-content: flex-end;
  border-bottom: var(--jp-border-width) solid var(--jp-toolbar-border-color);
  box-shadow: var(--jp-toolbar-box-shadow);
  background: var(--jp-toolbar-background);
  min-height: var(--jp-toolbar-micro-height);
  padding: var(--jp-notebook-toolbar-padding);
  z-index: 1;
  right: 0;
  top: 0;
}

.jp-Toolbar > .jp-Toolbar-responsive-opener {
  margin-left: auto;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Variables
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------

/*-----------------------------------------------------------------------------
| Styles
|----------------------------------------------------------------------------*/

.jp-Notebook-ExecutionIndicator {
  position: relative;
  display: inline-block;
  height: 100%;
  z-index: 9997;
}

.jp-Notebook-ExecutionIndicator-tooltip {
  visibility: hidden;
  height: auto;
  width: max-content;
  width: -moz-max-content;
  background-color: var(--jp-layout-color2);
  color: var(--jp-ui-font-color1);
  text-align: justify;
  border-radius: 6px;
  padding: 0 5px;
  position: fixed;
  display: table;
}

.jp-Notebook-ExecutionIndicator-tooltip.up {
  transform: translateX(-50%) translateY(-100%) translateY(-32px);
}

.jp-Notebook-ExecutionIndicator-tooltip.down {
  transform: translateX(calc(-100% + 16px)) translateY(5px);
}

.jp-Notebook-ExecutionIndicator-tooltip.hidden {
  display: none;
}

.jp-Notebook-ExecutionIndicator:hover .jp-Notebook-ExecutionIndicator-tooltip {
  visibility: visible;
}

.jp-Notebook-ExecutionIndicator span {
  font-size: var(--jp-ui-font-size1);
  font-family: var(--jp-ui-font-family);
  color: var(--jp-ui-font-color1);
  line-height: 24px;
  display: block;
}

.jp-Notebook-ExecutionIndicator-progress-bar {
  display: flex;
  justify-content: center;
  height: 100%;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*
 * Execution indicator
 */
.jp-tocItem-content::after {
  content: '';

  /* Must be identical to form a circle */
  width: 12px;
  height: 12px;
  background: none;
  border: none;
  position: absolute;
  right: 0;
}

.jp-tocItem-content[data-running='0']::after {
  border-radius: 50%;
  border: var(--jp-border-width) solid var(--jp-inverse-layout-color3);
  background: none;
}

.jp-tocItem-content[data-running='1']::after {
  border-radius: 50%;
  border: var(--jp-border-width) solid var(--jp-inverse-layout-color3);
  background-color: var(--jp-inverse-layout-color3);
}

.jp-tocItem-content[data-running='0'],
.jp-tocItem-content[data-running='1'] {
  margin-right: 12px;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

.jp-Notebook-footer {
  height: 27px;
  margin-left: calc(
    var(--jp-cell-prompt-width) + var(--jp-cell-collapser-width) +
      var(--jp-cell-padding)
  );
  width: calc(
    100% -
      (
        var(--jp-cell-prompt-width) + var(--jp-cell-collapser-width) +
          var(--jp-cell-padding) + var(--jp-cell-padding)
      )
  );
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  color: var(--jp-ui-font-color3);
  margin-top: 6px;
  background: none;
  cursor: pointer;
}

.jp-Notebook-footer:focus {
  border-color: var(--jp-cell-editor-active-border-color);
}

/* For devices that support hovering, hide footer until hover */
@media (hover: hover) {
  .jp-Notebook-footer {
    opacity: 0;
  }

  .jp-Notebook-footer:focus,
  .jp-Notebook-footer:hover {
    opacity: 1;
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Imports
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| CSS variables
|----------------------------------------------------------------------------*/

:root {
  --jp-side-by-side-output-size: 1fr;
  --jp-side-by-side-resized-cell: var(--jp-side-by-side-output-size);
  --jp-private-notebook-dragImage-width: 304px;
  --jp-private-notebook-dragImage-height: 36px;
  --jp-private-notebook-selected-color: var(--md-blue-400);
  --jp-private-notebook-active-color: var(--md-green-400);
}

/*-----------------------------------------------------------------------------
| Notebook
|----------------------------------------------------------------------------*/

/* stylelint-disable selector-max-class */

.jp-NotebookPanel {
  display: block;
  height: 100%;
}

.jp-NotebookPanel.jp-Document {
  min-width: 240px;
  min-height: 120px;
}

.jp-Notebook {
  padding: var(--jp-notebook-padding);
  outline: none;
  overflow: auto;
  background: var(--jp-layout-color0);
}

.jp-Notebook.jp-mod-scrollPastEnd::after {
  display: block;
  content: '';
  min-height: var(--jp-notebook-scroll-padding);
}

.jp-MainAreaWidget-ContainStrict .jp-Notebook * {
  contain: strict;
}

.jp-Notebook .jp-Cell {
  overflow: visible;
}

.jp-Notebook .jp-Cell .jp-InputPrompt {
  cursor: move;
}

/*-----------------------------------------------------------------------------
| Notebook state related styling
|
| The notebook and cells each have states, here are the possibilities:
|
| - Notebook
|   - Command
|   - Edit
| - Cell
|   - None
|   - Active (only one can be active)
|   - Selected (the cells actions are applied to)
|   - Multiselected (when multiple selected, the cursor)
|   - No outputs
|----------------------------------------------------------------------------*/

/* Command or edit modes */

.jp-Notebook .jp-Cell:not(.jp-mod-active) .jp-InputPrompt {
  opacity: var(--jp-cell-prompt-not-active-opacity);
  color: var(--jp-cell-prompt-not-active-font-color);
}

.jp-Notebook .jp-Cell:not(.jp-mod-active) .jp-OutputPrompt {
  opacity: var(--jp-cell-prompt-not-active-opacity);
  color: var(--jp-cell-prompt-not-active-font-color);
}

/* cell is active */
.jp-Notebook .jp-Cell.jp-mod-active .jp-Collapser {
  background: var(--jp-brand-color1);
}

/* cell is dirty */
.jp-Notebook .jp-Cell.jp-mod-dirty .jp-InputPrompt {
  color: var(--jp-warn-color1);
}

.jp-Notebook .jp-Cell.jp-mod-dirty .jp-InputPrompt::before {
  color: var(--jp-warn-color1);
  content: '•';
}

.jp-Notebook .jp-Cell.jp-mod-active.jp-mod-dirty .jp-Collapser {
  background: var(--jp-warn-color1);
}

/* collapser is hovered */
.jp-Notebook .jp-Cell .jp-Collapser:hover {
  box-shadow: var(--jp-elevation-z2);
  background: var(--jp-brand-color1);
  opacity: var(--jp-cell-collapser-not-active-hover-opacity);
}

/* cell is active and collapser is hovered */
.jp-Notebook .jp-Cell.jp-mod-active .jp-Collapser:hover {
  background: var(--jp-brand-color0);
  opacity: 1;
}

/* Command mode */

.jp-Notebook.jp-mod-commandMode .jp-Cell.jp-mod-selected {
  background: var(--jp-notebook-multiselected-color);
}

.jp-Notebook.jp-mod-commandMode
  .jp-Cell.jp-mod-active.jp-mod-selected:not(.jp-mod-multiSelected) {
  background: transparent;
}

/* Edit mode */

.jp-Notebook.jp-mod-editMode .jp-Cell.jp-mod-active .jp-InputArea-editor {
  border: var(--jp-border-width) solid var(--jp-cell-editor-active-border-color);
  box-shadow: var(--jp-input-box-shadow);
  background-color: var(--jp-cell-editor-active-background);
}

/*-----------------------------------------------------------------------------
| Notebook drag and drop
|----------------------------------------------------------------------------*/

.jp-Notebook-cell.jp-mod-dropSource {
  opacity: 0.5;
}

.jp-Notebook-cell.jp-mod-dropTarget,
.jp-Notebook.jp-mod-commandMode
  .jp-Notebook-cell.jp-mod-active.jp-mod-selected.jp-mod-dropTarget {
  border-top-color: var(--jp-private-notebook-selected-color);
  border-top-style: solid;
  border-top-width: 2px;
}

.jp-dragImage {
  display: block;
  flex-direction: row;
  width: var(--jp-private-notebook-dragImage-width);
  height: var(--jp-private-notebook-dragImage-height);
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  background: var(--jp-cell-editor-background);
  overflow: visible;
}

.jp-dragImage-singlePrompt {
  box-shadow: 2px 2px 4px 0 rgba(0, 0, 0, 0.12);
}

.jp-dragImage .jp-dragImage-content {
  flex: 1 1 auto;
  z-index: 2;
  font-size: var(--jp-code-font-size);
  font-family: var(--jp-code-font-family);
  line-height: var(--jp-code-line-height);
  padding: var(--jp-code-padding);
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  background: var(--jp-cell-editor-background-color);
  color: var(--jp-content-font-color3);
  text-align: left;
  margin: 4px 4px 4px 0;
}

.jp-dragImage .jp-dragImage-prompt {
  flex: 0 0 auto;
  min-width: 36px;
  color: var(--jp-cell-inprompt-font-color);
  padding: var(--jp-code-padding);
  padding-left: 12px;
  font-family: var(--jp-cell-prompt-font-family);
  letter-spacing: var(--jp-cell-prompt-letter-spacing);
  line-height: 1.9;
  font-size: var(--jp-code-font-size);
  border: var(--jp-border-width) solid transparent;
}

.jp-dragImage-multipleBack {
  z-index: -1;
  position: absolute;
  height: 32px;
  width: 300px;
  top: 8px;
  left: 8px;
  background: var(--jp-layout-color2);
  border: var(--jp-border-width) solid var(--jp-input-border-color);
  box-shadow: 2px 2px 4px 0 rgba(0, 0, 0, 0.12);
}

/*-----------------------------------------------------------------------------
| Cell toolbar
|----------------------------------------------------------------------------*/

.jp-NotebookTools {
  display: block;
  min-width: var(--jp-sidebar-min-width);
  color: var(--jp-ui-font-color1);
  background: var(--jp-layout-color1);

  /* This is needed so that all font sizing of children done in ems is
    * relative to this base size */
  font-size: var(--jp-ui-font-size1);
  overflow: auto;
}

.jp-ActiveCellTool {
  padding: 12px 0;
  display: flex;
}

.jp-ActiveCellTool-Content {
  flex: 1 1 auto;
}

.jp-ActiveCellTool .jp-ActiveCellTool-CellContent {
  background: var(--jp-cell-editor-background);
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  border-radius: 0;
  min-height: 29px;
}

.jp-ActiveCellTool .jp-InputPrompt {
  min-width: calc(var(--jp-cell-prompt-width) * 0.75);
}

.jp-ActiveCellTool-CellContent > pre {
  padding: 5px 4px;
  margin: 0;
  white-space: normal;
}

.jp-MetadataEditorTool {
  flex-direction: column;
  padding: 12px 0;
}

.jp-RankedPanel > :not(:first-child) {
  margin-top: 12px;
}

.jp-KeySelector select.jp-mod-styled {
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color0);
  border: var(--jp-border-width) solid var(--jp-border-color1);
}

.jp-KeySelector label,
.jp-MetadataEditorTool label,
.jp-NumberSetter label {
  line-height: 1.4;
}

.jp-NotebookTools .jp-select-wrapper {
  margin-top: 4px;
  margin-bottom: 0;
}

.jp-NumberSetter input {
  width: 100%;
  margin-top: 4px;
}

.jp-NotebookTools .jp-Collapse {
  margin-top: 16px;
}

/*-----------------------------------------------------------------------------
| Presentation Mode (.jp-mod-presentationMode)
|----------------------------------------------------------------------------*/

.jp-mod-presentationMode .jp-Notebook {
  --jp-content-font-size1: var(--jp-content-presentation-font-size1);
  --jp-code-font-size: var(--jp-code-presentation-font-size);
}

.jp-mod-presentationMode .jp-Notebook .jp-Cell .jp-InputPrompt,
.jp-mod-presentationMode .jp-Notebook .jp-Cell .jp-OutputPrompt {
  flex: 0 0 110px;
}

/*-----------------------------------------------------------------------------
| Side-by-side Mode (.jp-mod-sideBySide)
|----------------------------------------------------------------------------*/
.jp-mod-sideBySide.jp-Notebook .jp-Notebook-cell {
  margin-top: 3em;
  margin-bottom: 3em;
  margin-left: 5%;
  margin-right: 5%;
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell {
  display: grid;
  grid-template-columns: minmax(0, 1fr) min-content minmax(
      0,
      var(--jp-side-by-side-output-size)
    );
  grid-template-rows: auto minmax(0, 1fr) auto;
  grid-template-areas:
    'header header header'
    'input handle output'
    'footer footer footer';
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell.jp-mod-resizedCell {
  grid-template-columns: minmax(0, 1fr) min-content minmax(
      0,
      var(--jp-side-by-side-resized-cell)
    );
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-CellHeader {
  grid-area: header;
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-Cell-inputWrapper {
  grid-area: input;
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-Cell-outputWrapper {
  /* overwrite the default margin (no vertical separation needed in side by side move */
  margin-top: 0;
  grid-area: output;
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-CellFooter {
  grid-area: footer;
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-CellResizeHandle {
  grid-area: handle;
  user-select: none;
  display: block;
  height: 100%;
  cursor: ew-resize;
  padding: 0 var(--jp-cell-padding);
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-CellResizeHandle::after {
  content: '';
  display: block;
  background: var(--jp-border-color2);
  height: 100%;
  width: 5px;
}

.jp-mod-sideBySide.jp-Notebook
  .jp-CodeCell.jp-mod-resizedCell
  .jp-CellResizeHandle::after {
  background: var(--jp-border-color0);
}

.jp-CellResizeHandle {
  display: none;
}

/*-----------------------------------------------------------------------------
| Placeholder
|----------------------------------------------------------------------------*/

.jp-Cell-Placeholder {
  padding-left: 55px;
}

.jp-Cell-Placeholder-wrapper {
  background: #fff;
  border: 1px solid;
  border-color: #e5e6e9 #dfe0e4 #d0d1d5;
  border-radius: 4px;
  -webkit-border-radius: 4px;
  margin: 10px 15px;
}

.jp-Cell-Placeholder-wrapper-inner {
  padding: 15px;
  position: relative;
}

.jp-Cell-Placeholder-wrapper-body {
  background-repeat: repeat;
  background-size: 50% auto;
}

.jp-Cell-Placeholder-wrapper-body div {
  background: #f6f7f8;
  background-image: -webkit-linear-gradient(
    left,
    #f6f7f8 0%,
    #edeef1 20%,
    #f6f7f8 40%,
    #f6f7f8 100%
  );
  background-repeat: no-repeat;
  background-size: 800px 104px;
  height: 104px;
  position: absolute;
  right: 15px;
  left: 15px;
  top: 15px;
}

div.jp-Cell-Placeholder-h1 {
  top: 20px;
  height: 20px;
  left: 15px;
  width: 150px;
}

div.jp-Cell-Placeholder-h2 {
  left: 15px;
  top: 50px;
  height: 10px;
  width: 100px;
}

div.jp-Cell-Placeholder-content-1,
div.jp-Cell-Placeholder-content-2,
div.jp-Cell-Placeholder-content-3 {
  left: 15px;
  right: 15px;
  height: 10px;
}

div.jp-Cell-Placeholder-content-1 {
  top: 100px;
}

div.jp-Cell-Placeholder-content-2 {
  top: 120px;
}

div.jp-Cell-Placeholder-content-3 {
  top: 140px;
}

</style>
<style type="text/css">
/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*
The following CSS variables define the main, public API for styling JupyterLab.
These variables should be used by all plugins wherever possible. In other
words, plugins should not define custom colors, sizes, etc unless absolutely
necessary. This enables users to change the visual theme of JupyterLab
by changing these variables.

Many variables appear in an ordered sequence (0,1,2,3). These sequences
are designed to work well together, so for example, `--jp-border-color1` should
be used with `--jp-layout-color1`. The numbers have the following meanings:

* 0: super-primary, reserved for special emphasis
* 1: primary, most important under normal situations
* 2: secondary, next most important under normal situations
* 3: tertiary, next most important under normal situations

Throughout JupyterLab, we are mostly following principles from Google's
Material Design when selecting colors. We are not, however, following
all of MD as it is not optimized for dense, information rich UIs.
*/

:root {
  /* Elevation
   *
   * We style box-shadows using Material Design's idea of elevation. These particular numbers are taken from here:
   *
   * https://github.com/material-components/material-components-web
   * https://material-components-web.appspot.com/elevation.html
   */

  --jp-shadow-base-lightness: 0;
  --jp-shadow-umbra-color: rgba(
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    0.2
  );
  --jp-shadow-penumbra-color: rgba(
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    0.14
  );
  --jp-shadow-ambient-color: rgba(
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    0.12
  );
  --jp-elevation-z0: none;
  --jp-elevation-z1: 0 2px 1px -1px var(--jp-shadow-umbra-color),
    0 1px 1px 0 var(--jp-shadow-penumbra-color),
    0 1px 3px 0 var(--jp-shadow-ambient-color);
  --jp-elevation-z2: 0 3px 1px -2px var(--jp-shadow-umbra-color),
    0 2px 2px 0 var(--jp-shadow-penumbra-color),
    0 1px 5px 0 var(--jp-shadow-ambient-color);
  --jp-elevation-z4: 0 2px 4px -1px var(--jp-shadow-umbra-color),
    0 4px 5px 0 var(--jp-shadow-penumbra-color),
    0 1px 10px 0 var(--jp-shadow-ambient-color);
  --jp-elevation-z6: 0 3px 5px -1px var(--jp-shadow-umbra-color),
    0 6px 10px 0 var(--jp-shadow-penumbra-color),
    0 1px 18px 0 var(--jp-shadow-ambient-color);
  --jp-elevation-z8: 0 5px 5px -3px var(--jp-shadow-umbra-color),
    0 8px 10px 1px var(--jp-shadow-penumbra-color),
    0 3px 14px 2px var(--jp-shadow-ambient-color);
  --jp-elevation-z12: 0 7px 8px -4px var(--jp-shadow-umbra-color),
    0 12px 17px 2px var(--jp-shadow-penumbra-color),
    0 5px 22px 4px var(--jp-shadow-ambient-color);
  --jp-elevation-z16: 0 8px 10px -5px var(--jp-shadow-umbra-color),
    0 16px 24px 2px var(--jp-shadow-penumbra-color),
    0 6px 30px 5px var(--jp-shadow-ambient-color);
  --jp-elevation-z20: 0 10px 13px -6px var(--jp-shadow-umbra-color),
    0 20px 31px 3px var(--jp-shadow-penumbra-color),
    0 8px 38px 7px var(--jp-shadow-ambient-color);
  --jp-elevation-z24: 0 11px 15px -7px var(--jp-shadow-umbra-color),
    0 24px 38px 3px var(--jp-shadow-penumbra-color),
    0 9px 46px 8px var(--jp-shadow-ambient-color);

  /* Borders
   *
   * The following variables, specify the visual styling of borders in JupyterLab.
   */

  --jp-border-width: 1px;
  --jp-border-color0: var(--md-grey-400);
  --jp-border-color1: var(--md-grey-400);
  --jp-border-color2: var(--md-grey-300);
  --jp-border-color3: var(--md-grey-200);
  --jp-inverse-border-color: var(--md-grey-600);
  --jp-border-radius: 2px;

  /* UI Fonts
   *
   * The UI font CSS variables are used for the typography all of the JupyterLab
   * user interface elements that are not directly user generated content.
   *
   * The font sizing here is done assuming that the body font size of --jp-ui-font-size1
   * is applied to a parent element. When children elements, such as headings, are sized
   * in em all things will be computed relative to that body size.
   */

  --jp-ui-font-scale-factor: 1.2;
  --jp-ui-font-size0: 0.83333em;
  --jp-ui-font-size1: 13px; /* Base font size */
  --jp-ui-font-size2: 1.2em;
  --jp-ui-font-size3: 1.44em;
  --jp-ui-font-family: system-ui, -apple-system, blinkmacsystemfont, 'Segoe UI',
    helvetica, arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji',
    'Segoe UI Symbol';

  /*
   * Use these font colors against the corresponding main layout colors.
   * In a light theme, these go from dark to light.
   */

  /* Defaults use Material Design specification */
  --jp-ui-font-color0: rgba(0, 0, 0, 1);
  --jp-ui-font-color1: rgba(0, 0, 0, 0.87);
  --jp-ui-font-color2: rgba(0, 0, 0, 0.54);
  --jp-ui-font-color3: rgba(0, 0, 0, 0.38);

  /*
   * Use these against the brand/accent/warn/error colors.
   * These will typically go from light to darker, in both a dark and light theme.
   */

  --jp-ui-inverse-font-color0: rgba(255, 255, 255, 1);
  --jp-ui-inverse-font-color1: rgba(255, 255, 255, 1);
  --jp-ui-inverse-font-color2: rgba(255, 255, 255, 0.7);
  --jp-ui-inverse-font-color3: rgba(255, 255, 255, 0.5);

  /* Content Fonts
   *
   * Content font variables are used for typography of user generated content.
   *
   * The font sizing here is done assuming that the body font size of --jp-content-font-size1
   * is applied to a parent element. When children elements, such as headings, are sized
   * in em all things will be computed relative to that body size.
   */

  --jp-content-line-height: 1.6;
  --jp-content-font-scale-factor: 1.2;
  --jp-content-font-size0: 0.83333em;
  --jp-content-font-size1: 14px; /* Base font size */
  --jp-content-font-size2: 1.2em;
  --jp-content-font-size3: 1.44em;
  --jp-content-font-size4: 1.728em;
  --jp-content-font-size5: 2.0736em;

  /* This gives a magnification of about 125% in presentation mode over normal. */
  --jp-content-presentation-font-size1: 17px;
  --jp-content-heading-line-height: 1;
  --jp-content-heading-margin-top: 1.2em;
  --jp-content-heading-margin-bottom: 0.8em;
  --jp-content-heading-font-weight: 500;

  /* Defaults use Material Design specification */
  --jp-content-font-color0: rgba(0, 0, 0, 1);
  --jp-content-font-color1: rgba(0, 0, 0, 0.87);
  --jp-content-font-color2: rgba(0, 0, 0, 0.54);
  --jp-content-font-color3: rgba(0, 0, 0, 0.38);
  --jp-content-link-color: var(--md-blue-900);
  --jp-content-font-family: system-ui, -apple-system, blinkmacsystemfont,
    'Segoe UI', helvetica, arial, sans-serif, 'Apple Color Emoji',
    'Segoe UI Emoji', 'Segoe UI Symbol';

  /*
   * Code Fonts
   *
   * Code font variables are used for typography of code and other monospaces content.
   */

  --jp-code-font-size: 13px;
  --jp-code-line-height: 1.3077; /* 17px for 13px base */
  --jp-code-padding: 5px; /* 5px for 13px base, codemirror highlighting needs integer px value */
  --jp-code-font-family-default: menlo, consolas, 'DejaVu Sans Mono', monospace;
  --jp-code-font-family: var(--jp-code-font-family-default);

  /* This gives a magnification of about 125% in presentation mode over normal. */
  --jp-code-presentation-font-size: 16px;

  /* may need to tweak cursor width if you change font size */
  --jp-code-cursor-width0: 1.4px;
  --jp-code-cursor-width1: 2px;
  --jp-code-cursor-width2: 4px;

  /* Layout
   *
   * The following are the main layout colors use in JupyterLab. In a light
   * theme these would go from light to dark.
   */

  --jp-layout-color0: white;
  --jp-layout-color1: white;
  --jp-layout-color2: var(--md-grey-200);
  --jp-layout-color3: var(--md-grey-400);
  --jp-layout-color4: var(--md-grey-600);

  /* Inverse Layout
   *
   * The following are the inverse layout colors use in JupyterLab. In a light
   * theme these would go from dark to light.
   */

  --jp-inverse-layout-color0: #111;
  --jp-inverse-layout-color1: var(--md-grey-900);
  --jp-inverse-layout-color2: var(--md-grey-800);
  --jp-inverse-layout-color3: var(--md-grey-700);
  --jp-inverse-layout-color4: var(--md-grey-600);

  /* Brand/accent */

  --jp-brand-color0: var(--md-blue-900);
  --jp-brand-color1: var(--md-blue-700);
  --jp-brand-color2: var(--md-blue-300);
  --jp-brand-color3: var(--md-blue-100);
  --jp-brand-color4: var(--md-blue-50);
  --jp-accent-color0: var(--md-green-900);
  --jp-accent-color1: var(--md-green-700);
  --jp-accent-color2: var(--md-green-300);
  --jp-accent-color3: var(--md-green-100);

  /* State colors (warn, error, success, info) */

  --jp-warn-color0: var(--md-orange-900);
  --jp-warn-color1: var(--md-orange-700);
  --jp-warn-color2: var(--md-orange-300);
  --jp-warn-color3: var(--md-orange-100);
  --jp-error-color0: var(--md-red-900);
  --jp-error-color1: var(--md-red-700);
  --jp-error-color2: var(--md-red-300);
  --jp-error-color3: var(--md-red-100);
  --jp-success-color0: var(--md-green-900);
  --jp-success-color1: var(--md-green-700);
  --jp-success-color2: var(--md-green-300);
  --jp-success-color3: var(--md-green-100);
  --jp-info-color0: var(--md-cyan-900);
  --jp-info-color1: var(--md-cyan-700);
  --jp-info-color2: var(--md-cyan-300);
  --jp-info-color3: var(--md-cyan-100);

  /* Cell specific styles */

  --jp-cell-padding: 5px;
  --jp-cell-collapser-width: 8px;
  --jp-cell-collapser-min-height: 20px;
  --jp-cell-collapser-not-active-hover-opacity: 0.6;
  --jp-cell-editor-background: var(--md-grey-100);
  --jp-cell-editor-border-color: var(--md-grey-300);
  --jp-cell-editor-box-shadow: inset 0 0 2px var(--md-blue-300);
  --jp-cell-editor-active-background: var(--jp-layout-color0);
  --jp-cell-editor-active-border-color: var(--jp-brand-color1);
  --jp-cell-prompt-width: 64px;
  --jp-cell-prompt-font-family: var(--jp-code-font-family-default);
  --jp-cell-prompt-letter-spacing: 0;
  --jp-cell-prompt-opacity: 1;
  --jp-cell-prompt-not-active-opacity: 0.5;
  --jp-cell-prompt-not-active-font-color: var(--md-grey-700);

  /* A custom blend of MD grey and blue 600
   * See https://meyerweb.com/eric/tools/color-blend/#546E7A:1E88E5:5:hex */
  --jp-cell-inprompt-font-color: #307fc1;

  /* A custom blend of MD grey and orange 600
   * https://meyerweb.com/eric/tools/color-blend/#546E7A:F4511E:5:hex */
  --jp-cell-outprompt-font-color: #bf5b3d;

  /* Notebook specific styles */

  --jp-notebook-padding: 10px;
  --jp-notebook-select-background: var(--jp-layout-color1);
  --jp-notebook-multiselected-color: var(--md-blue-50);

  /* The scroll padding is calculated to fill enough space at the bottom of the
  notebook to show one single-line cell (with appropriate padding) at the top
  when the notebook is scrolled all the way to the bottom. We also subtract one
  pixel so that no scrollbar appears if we have just one single-line cell in the
  notebook. This padding is to enable a 'scroll past end' feature in a notebook.
  */
  --jp-notebook-scroll-padding: calc(
    100% - var(--jp-code-font-size) * var(--jp-code-line-height) -
      var(--jp-code-padding) - var(--jp-cell-padding) - 1px
  );

  /* Rendermime styles */

  --jp-rendermime-error-background: #fdd;
  --jp-rendermime-table-row-background: var(--md-grey-100);
  --jp-rendermime-table-row-hover-background: var(--md-light-blue-50);

  /* Dialog specific styles */

  --jp-dialog-background: rgba(0, 0, 0, 0.25);

  /* Console specific styles */

  --jp-console-padding: 10px;

  /* Toolbar specific styles */

  --jp-toolbar-border-color: var(--jp-border-color1);
  --jp-toolbar-micro-height: 8px;
  --jp-toolbar-background: var(--jp-layout-color1);
  --jp-toolbar-box-shadow: 0 0 2px 0 rgba(0, 0, 0, 0.24);
  --jp-toolbar-header-margin: 4px 4px 0 4px;
  --jp-toolbar-active-background: var(--md-grey-300);

  /* Statusbar specific styles */

  --jp-statusbar-height: 24px;

  /* Input field styles */

  --jp-input-box-shadow: inset 0 0 2px var(--md-blue-300);
  --jp-input-active-background: var(--jp-layout-color1);
  --jp-input-hover-background: var(--jp-layout-color1);
  --jp-input-background: var(--md-grey-100);
  --jp-input-border-color: var(--jp-inverse-border-color);
  --jp-input-active-border-color: var(--jp-brand-color1);
  --jp-input-active-box-shadow-color: rgba(19, 124, 189, 0.3);

  /* General editor styles */

  --jp-editor-selected-background: #d9d9d9;
  --jp-editor-selected-focused-background: #d7d4f0;
  --jp-editor-cursor-color: var(--jp-ui-font-color0);

  /* Code mirror specific styles */

  --jp-mirror-editor-keyword-color: #008000;
  --jp-mirror-editor-atom-color: #88f;
  --jp-mirror-editor-number-color: #080;
  --jp-mirror-editor-def-color: #00f;
  --jp-mirror-editor-variable-color: var(--md-grey-900);
  --jp-mirror-editor-variable-2-color: rgb(0, 54, 109);
  --jp-mirror-editor-variable-3-color: #085;
  --jp-mirror-editor-punctuation-color: #05a;
  --jp-mirror-editor-property-color: #05a;
  --jp-mirror-editor-operator-color: #a2f;
  --jp-mirror-editor-comment-color: #408080;
  --jp-mirror-editor-string-color: #ba2121;
  --jp-mirror-editor-string-2-color: #708;
  --jp-mirror-editor-meta-color: #a2f;
  --jp-mirror-editor-qualifier-color: #555;
  --jp-mirror-editor-builtin-color: #008000;
  --jp-mirror-editor-bracket-color: #997;
  --jp-mirror-editor-tag-color: #170;
  --jp-mirror-editor-attribute-color: #00c;
  --jp-mirror-editor-header-color: blue;
  --jp-mirror-editor-quote-color: #090;
  --jp-mirror-editor-link-color: #00c;
  --jp-mirror-editor-error-color: #f00;
  --jp-mirror-editor-hr-color: #999;

  /*
    RTC user specific colors.
    These colors are used for the cursor, username in the editor,
    and the icon of the user.
  */

  --jp-collaborator-color1: #ffad8e;
  --jp-collaborator-color2: #dac83d;
  --jp-collaborator-color3: #72dd76;
  --jp-collaborator-color4: #00e4d0;
  --jp-collaborator-color5: #45d4ff;
  --jp-collaborator-color6: #e2b1ff;
  --jp-collaborator-color7: #ff9de6;

  /* Vega extension styles */

  --jp-vega-background: white;

  /* Sidebar-related styles */

  --jp-sidebar-min-width: 250px;

  /* Search-related styles */

  --jp-search-toggle-off-opacity: 0.5;
  --jp-search-toggle-hover-opacity: 0.8;
  --jp-search-toggle-on-opacity: 1;
  --jp-search-selected-match-background-color: rgb(245, 200, 0);
  --jp-search-selected-match-color: black;
  --jp-search-unselected-match-background-color: var(
    --jp-inverse-layout-color0
  );
  --jp-search-unselected-match-color: var(--jp-ui-inverse-font-color0);

  /* Icon colors that work well with light or dark backgrounds */
  --jp-icon-contrast-color0: var(--md-purple-600);
  --jp-icon-contrast-color1: var(--md-green-600);
  --jp-icon-contrast-color2: var(--md-pink-600);
  --jp-icon-contrast-color3: var(--md-blue-600);

  /* Button colors */
  --jp-accept-color-normal: var(--md-blue-700);
  --jp-accept-color-hover: var(--md-blue-800);
  --jp-accept-color-active: var(--md-blue-900);
  --jp-warn-color-normal: var(--md-red-700);
  --jp-warn-color-hover: var(--md-red-800);
  --jp-warn-color-active: var(--md-red-900);
  --jp-reject-color-normal: var(--md-grey-600);
  --jp-reject-color-hover: var(--md-grey-700);
  --jp-reject-color-active: var(--md-grey-800);

  /* File or activity icons and switch semantic variables */
  --jp-jupyter-icon-color: #f37626;
  --jp-notebook-icon-color: #f37626;
  --jp-json-icon-color: var(--md-orange-700);
  --jp-console-icon-background-color: var(--md-blue-700);
  --jp-console-icon-color: white;
  --jp-terminal-icon-background-color: var(--md-grey-800);
  --jp-terminal-icon-color: var(--md-grey-200);
  --jp-text-editor-icon-color: var(--md-grey-700);
  --jp-inspector-icon-color: var(--md-grey-700);
  --jp-switch-color: var(--md-grey-400);
  --jp-switch-true-position-color: var(--md-orange-900);
}
</style>
<style type="text/css">
/* Force rendering true colors when outputing to pdf */
* {
  -webkit-print-color-adjust: exact;
}

/* Misc */
a.anchor-link {
  display: none;
}

/* Input area styling */
.jp-InputArea {
  overflow: hidden;
}

.jp-InputArea-editor {
  overflow: hidden;
}

.cm-editor.cm-s-jupyter .highlight pre {
/* weird, but --jp-code-padding defined to be 5px but 4px horizontal padding is hardcoded for pre.cm-line */
  padding: var(--jp-code-padding) 4px;
  margin: 0;

  font-family: inherit;
  font-size: inherit;
  line-height: inherit;
  color: inherit;

}

.jp-OutputArea-output pre {
  line-height: inherit;
  font-family: inherit;
}

.jp-RenderedText pre {
  color: var(--jp-content-font-color1);
  font-size: var(--jp-code-font-size);
}

/* Hiding the collapser by default */
.jp-Collapser {
  display: none;
}

@page {
    margin: 0.5in; /* Margin for each printed piece of paper */
}

@media print {
  .jp-Cell-inputWrapper,
  .jp-Cell-outputWrapper {
    display: block;
  }
}
</style>
<!-- Load mathjax -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS_CHTML-full,Safe"> </script>
<!-- MathJax configuration -->
<script type="text/x-mathjax-config">
    init_mathjax = function() {
        if (window.MathJax) {
        // MathJax loaded
            MathJax.Hub.Config({
                TeX: {
                    equationNumbers: {
                    autoNumber: "AMS",
                    useLabelIds: true
                    }
                },
                tex2jax: {
                    inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                    displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
                    processEscapes: true,
                    processEnvironments: true
                },
                displayAlign: 'center',
                CommonHTML: {
                    linebreaks: {
                    automatic: true
                    }
                }
            });

            MathJax.Hub.Queue(["Typeset", MathJax.Hub]);
        }
    }
    init_mathjax();
    </script>
<!-- End of mathjax configuration --><script type="module">
  document.addEventListener("DOMContentLoaded", async () => {
    const diagrams = document.querySelectorAll(".jp-Mermaid > pre.mermaid");
    // do not load mermaidjs if not needed
    if (!diagrams.length) {
      return;
    }
    const mermaid = (await import("https://cdnjs.cloudflare.com/ajax/libs/mermaid/10.5.0/mermaid.esm.min.mjs")).default;
    const parser = new DOMParser();

    mermaid.initialize({
      maxTextSize: 100000,
      startOnLoad: false,
      fontFamily: window
        .getComputedStyle(document.body)
        .getPropertyValue("--jp-ui-font-family"),
      theme: document.querySelector("body[data-jp-theme-light='true']")
        ? "default"
        : "dark",
    });

    let _nextMermaidId = 0;

    function makeMermaidImage(svg) {
      const img = document.createElement("img");
      const doc = parser.parseFromString(svg, "image/svg+xml");
      const svgEl = doc.querySelector("svg");
      const { maxWidth } = svgEl?.style || {};
      const firstTitle = doc.querySelector("title");
      const firstDesc = doc.querySelector("desc");

      img.setAttribute("src", `data:image/svg+xml,${encodeURIComponent(svg)}`);
      if (maxWidth) {
        img.width = parseInt(maxWidth);
      }
      if (firstTitle) {
        img.setAttribute("alt", firstTitle.textContent);
      }
      if (firstDesc) {
        const caption = document.createElement("figcaption");
        caption.className = "sr-only";
        caption.textContent = firstDesc.textContent;
        return [img, caption];
      }
      return [img];
    }

    async function makeMermaidError(text) {
      let errorMessage = "";
      try {
        await mermaid.parse(text);
      } catch (err) {
        errorMessage = `${err}`;
      }

      const result = document.createElement("details");
      result.className = 'jp-RenderedMermaid-Details';
      const summary = document.createElement("summary");
      summary.className = 'jp-RenderedMermaid-Summary';
      const pre = document.createElement("pre");
      const code = document.createElement("code");
      code.innerText = text;
      pre.appendChild(code);
      summary.appendChild(pre);
      result.appendChild(summary);

      const warning = document.createElement("pre");
      warning.innerText = errorMessage;
      result.appendChild(warning);
      return [result];
    }

    async function renderOneMarmaid(src) {
      const id = `jp-mermaid-${_nextMermaidId++}`;
      const parent = src.parentNode;
      let raw = src.textContent.trim();
      const el = document.createElement("div");
      el.style.visibility = "hidden";
      document.body.appendChild(el);
      let results = null;
      let output = null;
      try {
        const { svg } = await mermaid.render(id, raw, el);
        results = makeMermaidImage(svg);
        output = document.createElement("figure");
        results.map(output.appendChild, output);
      } catch (err) {
        parent.classList.add("jp-mod-warning");
        results = await makeMermaidError(raw);
        output = results[0];
      } finally {
        el.remove();
      }
      parent.classList.add("jp-RenderedMermaid");
      parent.appendChild(output);
    }

    void Promise.all([...diagrams].map(renderOneMarmaid));
  });
</script>
<style>
  .jp-Mermaid:not(.jp-RenderedMermaid) {
    display: none;
  }

  .jp-RenderedMermaid {
    overflow: auto;
    display: flex;
  }

  .jp-RenderedMermaid.jp-mod-warning {
    width: auto;
    padding: 0.5em;
    margin-top: 0.5em;
    border: var(--jp-border-width) solid var(--jp-warn-color2);
    border-radius: var(--jp-border-radius);
    color: var(--jp-ui-font-color1);
    font-size: var(--jp-ui-font-size1);
    white-space: pre-wrap;
    word-wrap: break-word;
  }

  .jp-RenderedMermaid figure {
    margin: 0;
    overflow: auto;
    max-width: 100%;
  }

  .jp-RenderedMermaid img {
    max-width: 100%;
  }

  .jp-RenderedMermaid-Details > pre {
    margin-top: 1em;
  }

  .jp-RenderedMermaid-Summary {
    color: var(--jp-warn-color2);
  }

  .jp-RenderedMermaid:not(.jp-mod-warning) pre {
    display: none;
  }

  .jp-RenderedMermaid-Summary > pre {
    display: inline-block;
    white-space: normal;
  }
</style>
<!-- End of mermaid configuration --></head>
<body class="jp-Notebook" data-jp-theme-light="true" data-jp-theme-name="JupyterLab Light">
<main><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torchvision</span>
<span class="kn">import</span> <span class="nn">torchvision.datasets</span>
<span class="kn">import</span> <span class="nn">torchvision.transforms</span>
<span class="kn">import</span> <span class="nn">torch.utils.data</span>
<span class="kn">import</span> <span class="nn">torch.nn</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">from</span> <span class="nn">torchviz</span> <span class="kn">import</span> <span class="n">make_dot</span> <span class="c1"># net visualization</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">tqdm</span> <span class="kn">import</span> <span class="n">tqdm</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">collections</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">SEED</span> <span class="o">=</span> <span class="mi">42</span>
<span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">SEED</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">SEED</span><span class="p">)</span>
<span class="n">torch</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">SEED</span><span class="p">)</span>
<span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">manual_seed_all</span><span class="p">(</span><span class="n">SEED</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="%D0%97%D0%B0%D0%B3%D1%80%D1%83%D0%B7%D0%BA%D0%B0-%D0%B4%D0%B0%D0%BD%D0%BD%D1%8B%D1%85">Загрузка данных<a class="anchor-link" href="#%D0%97%D0%B0%D0%B3%D1%80%D1%83%D0%B7%D0%BA%D0%B0-%D0%B4%D0%B0%D0%BD%D0%BD%D1%8B%D1%85">¶</a></h3>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">dir_name</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">getcwd</span><span class="p">()</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">128</span>

<span class="k">class</span> <span class="nc">DatasetFromSubset</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">subset</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">subset</span> <span class="o">=</span> <span class="n">subset</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">transform</span> <span class="o">=</span> <span class="n">transform</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">class_to_idx</span> <span class="o">=</span> <span class="n">subset</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">class_to_idx</span>


        
    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">):</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">subset</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span>
        
    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">subset</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">transform_to_image</span><span class="p">(</span><span class="n">image</span><span class="p">):</span>
    <span class="c1"># [Normalize] output = (input - mean) / std</span>
    <span class="n">image</span> <span class="o">=</span> <span class="p">(</span><span class="n">image</span> <span class="o">-</span> <span class="p">(</span><span class="o">-</span><span class="n">train_mean</span> <span class="o">/</span> <span class="n">train_std</span><span class="p">))</span> <span class="o">/</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">/</span> <span class="n">train_std</span><span class="p">)</span>
    <span class="n">image</span> <span class="o">=</span> <span class="n">image</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">image</span>

<span class="k">def</span> <span class="nf">show_images</span><span class="p">(</span><span class="n">images</span><span class="p">,</span> <span class="n">title</span><span class="p">):</span>
    <span class="n">num_showed_imgs_x</span> <span class="o">=</span> <span class="mi">3</span>
    <span class="n">num_showed_imgs_y</span> <span class="o">=</span> <span class="mi">3</span>

    <span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">)</span>
    <span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">num_showed_imgs_y</span><span class="p">,</span> <span class="n">num_showed_imgs_x</span><span class="p">,</span> <span class="n">figsize</span> <span class="o">=</span> <span class="n">figsize</span><span class="p">)</span>
    <span class="n">fig</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="n">title</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Images shape: </span><span class="si">{</span><span class="n">images</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">setp</span><span class="p">(</span><span class="n">plt</span><span class="o">.</span><span class="n">gcf</span><span class="p">()</span><span class="o">.</span><span class="n">get_axes</span><span class="p">(),</span> <span class="n">xticks</span> <span class="o">=</span> <span class="p">[],</span> <span class="n">yticks</span> <span class="o">=</span> <span class="p">[])</span>
    <span class="n">classes</span> <span class="o">=</span> <span class="p">{</span><span class="n">val</span> <span class="p">:</span> <span class="n">key</span> <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">images</span><span class="o">.</span><span class="n">class_to_idx</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">ax</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">axes</span><span class="o">.</span><span class="n">flat</span><span class="p">):</span>
        <span class="n">img</span> <span class="o">=</span> <span class="n">images</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="c1">#.squeeze(axis = 2)</span>
        <span class="n">label</span> <span class="o">=</span> <span class="n">classes</span><span class="p">[</span><span class="n">images</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">1</span><span class="p">]]</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="n">label</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">transform_to_image</span><span class="p">(</span><span class="n">img</span><span class="p">))</span>

<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">CIFAR10</span><span class="p">(</span>
    <span class="n">root</span> <span class="o">=</span> <span class="n">dir_name</span><span class="p">,</span> <span class="n">train</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> <span class="n">download</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">transform</span> <span class="o">=</span> <span class="kc">None</span>
<span class="p">)</span>

<span class="n">train_dataset</span><span class="p">,</span> <span class="n">valid_dataset</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">random_split</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span> <span class="p">[</span><span class="mf">0.8</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">],</span> <span class="n">generator</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">Generator</span><span class="p">()</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">))</span>
<span class="n">train_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">train_dataset</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">train_dataset</span><span class="o">.</span><span class="n">indices</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="nb">tuple</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">train_dataset</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">ndim</span><span class="o">-</span><span class="mi">1</span><span class="p">)))</span> <span class="o">/</span> <span class="mi">255</span>
<span class="n">train_std</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">train_dataset</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">train_dataset</span><span class="o">.</span><span class="n">indices</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="nb">tuple</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">train_dataset</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">ndim</span><span class="o">-</span><span class="mi">1</span><span class="p">)))</span> <span class="o">/</span> <span class="mi">255</span>

<span class="n">transform_train</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
    <span class="n">torchvision</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">RandomCrop</span><span class="p">(</span><span class="mi">32</span><span class="p">),</span>
    <span class="n">torchvision</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">RandomHorizontalFlip</span><span class="p">(),</span>
    <span class="n">torchvision</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
    <span class="n">torchvision</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">(</span><span class="n">train_mean</span><span class="o">.</span><span class="n">tolist</span><span class="p">(),</span> <span class="n">train_std</span><span class="o">.</span><span class="n">tolist</span><span class="p">()),</span> <span class="c1"># means and stds</span>
<span class="p">])</span>
<span class="n">transform_test</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
    <span class="n">torchvision</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
    <span class="n">torchvision</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">(</span><span class="n">train_mean</span><span class="o">.</span><span class="n">tolist</span><span class="p">(),</span> <span class="n">train_std</span><span class="o">.</span><span class="n">tolist</span><span class="p">()),</span> <span class="c1"># means and stds</span>
<span class="p">])</span>

<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">DatasetFromSubset</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">transform_train</span><span class="p">)</span>
<span class="n">valid_dataset</span> <span class="o">=</span> <span class="n">DatasetFromSubset</span><span class="p">(</span><span class="n">valid_dataset</span><span class="p">,</span> <span class="n">transform_test</span><span class="p">)</span>
<span class="n">test_dataset</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">CIFAR10</span><span class="p">(</span>
    <span class="n">root</span> <span class="o">=</span> <span class="n">dir_name</span><span class="p">,</span> <span class="n">train</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n">download</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">transform</span> <span class="o">=</span> <span class="n">transform_test</span>
<span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">'Number of train samples: </span><span class="si">{}</span><span class="s1">'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">)))</span>
<span class="n">show_images</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span> <span class="s1">'Train samples'</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">'Number of valid samples: </span><span class="si">{}</span><span class="s1">'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">valid_dataset</span><span class="p">)))</span>
<span class="n">show_images</span><span class="p">(</span><span class="n">valid_dataset</span><span class="p">,</span> <span class="s1">'Valid samples'</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">'Number of test samples: </span><span class="si">{}</span><span class="s1">'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">test_dataset</span><span class="p">)))</span>
<span class="n">show_images</span><span class="p">(</span><span class="n">test_dataset</span><span class="p">,</span> <span class="s1">'Test samples'</span><span class="p">)</span>

<span class="n">train_data_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span>
    <span class="n">train_dataset</span><span class="p">,</span> <span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span> <span class="o">=</span> <span class="kc">True</span>
<span class="p">)</span>
<span class="n">valid_data_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span>
    <span class="n">valid_dataset</span><span class="p">,</span> <span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span> <span class="o">=</span> <span class="kc">False</span>
<span class="p">)</span>
<span class="n">test_data_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span>
    <span class="n">test_dataset</span><span class="p">,</span> <span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span> <span class="o">=</span> <span class="kc">False</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Files already downloaded and verified
Files already downloaded and verified
Number of train samples: 40000
Images shape: (32, 32, 3)
Number of valid samples: 10000
Images shape: (32, 32, 3)
Number of test samples: 10000
Images shape: (32, 32, 3)
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedImage jp-OutputArea-output" tabindex="0">
<img alt="No description has been provided for this image" class="" src="data:image/png;base64,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"/>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedImage jp-OutputArea-output" tabindex="0">
<img alt="No description has been provided for this image" class="" src="data:image/png;base64,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"/>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedImage jp-OutputArea-output" tabindex="0">
<img alt="No description has been provided for this image" class="" src="data:image/png;base64,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"/>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="%D0%A2%D1%80%D0%B5%D0%BD%D0%B8%D1%80%D0%BE%D0%B2%D0%BA%D0%B0-%D0%BC%D0%BE%D0%B4%D0%B5%D0%BB%D0%B8">Тренировка модели<a class="anchor-link" href="#%D0%A2%D1%80%D0%B5%D0%BD%D0%B8%D1%80%D0%BE%D0%B2%D0%BA%D0%B0-%D0%BC%D0%BE%D0%B4%D0%B5%D0%BB%D0%B8">¶</a></h3>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">"cuda:0"</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">"cpu"</span><span class="p">)</span>
<span class="n">device</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[ ]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>device(type='cuda', index=0)</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">get_accuracy</span><span class="p">(</span><span class="n">data_loader</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>
    <span class="n">tp</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">n</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="k">for</span> <span class="n">images</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">data_loader</span><span class="p">:</span>
            <span class="n">labels</span> <span class="o">=</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="n">images</span> <span class="o">=</span> <span class="n">images</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>
            <span class="n">_</span><span class="p">,</span> <span class="n">predicted</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">outputs</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">n</span> <span class="o">+=</span> <span class="n">labels</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">tp</span> <span class="o">+=</span> <span class="p">(</span><span class="n">predicted</span> <span class="o">==</span> <span class="n">labels</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">tp</span> <span class="o">/</span> <span class="n">n</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">model_training</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">model_name</span><span class="p">,</span> <span class="n">num_epochs</span><span class="p">,</span> <span class="n">save_model</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.1</span>
    <span class="n">momentum</span> <span class="o">=</span> <span class="mf">0.9</span>
    <span class="n">weight_decay</span> <span class="o">=</span> <span class="mf">5e-4</span>

    <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">"cuda:0"</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">"cpu"</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">loss_function</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span> <span class="o">=</span> <span class="n">learning_rate</span><span class="p">,</span> <span class="n">momentum</span> <span class="o">=</span> <span class="n">momentum</span><span class="p">,</span> <span class="n">weight_decay</span> <span class="o">=</span> <span class="n">weight_decay</span><span class="p">)</span>
    <span class="n">scheduler</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="o">.</span><span class="n">CosineAnnealingLR</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">T_max</span><span class="o">=</span><span class="n">num_epochs</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="n">pbar</span> <span class="o">=</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">))</span>
    <span class="n">last_epoch_time</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="n">min_valid_loss</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">epochs_valid_loss</span> <span class="o">=</span> <span class="mi">15</span>
    <span class="n">iters_valid_loss</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">best_valid_accuracy</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="nb">print</span><span class="p">(</span><span class="s1">'#############################################################################################'</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'[Training parameters]</span><span class="se">\n\t</span><span class="s1">epochs = </span><span class="si">{</span><span class="n">num_epochs</span><span class="si">}</span><span class="s1">,</span><span class="se">\n\t</span><span class="s1">lr = </span><span class="si">{</span><span class="n">learning_rate</span><span class="si">}</span><span class="s1">,</span><span class="se">\n\t</span><span class="s1">momentum = </span><span class="si">{</span><span class="n">momentum</span><span class="si">}</span><span class="s1">,</span><span class="se">\n\t</span><span class="s1">weight_decay = </span><span class="si">{</span><span class="n">weight_decay</span><span class="si">}</span><span class="s1">,</span><span class="se">\n\t</span><span class="s1">loss = </span><span class="si">{</span><span class="n">loss_function</span><span class="si">}</span><span class="s1">,</span><span class="se">\n\t</span><span class="s1">optimizer = </span><span class="si">{</span><span class="n">optimizer</span><span class="si">}</span><span class="s1">,</span><span class="se">\n\t</span><span class="s1">scheduler = </span><span class="si">{</span><span class="n">scheduler</span><span class="si">}</span><span class="s1">,</span><span class="se">\n\t</span><span class="s1">device = </span><span class="si">{</span><span class="n">device</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">'#############################################################################################'</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="n">pbar</span><span class="p">:</span>
        <span class="n">train_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">images</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">train_data_loader</span><span class="p">):</span>
            <span class="n">images</span> <span class="o">=</span> <span class="n">images</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="n">labels</span> <span class="o">=</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

            <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

            <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
            <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
            <span class="n">train_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
        <span class="n">train_loss</span> <span class="o">=</span> <span class="n">train_loss</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_data_loader</span><span class="p">)</span>
        <span class="n">train_accuracy</span> <span class="o">=</span> <span class="n">get_accuracy</span><span class="p">(</span><span class="n">train_data_loader</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

        <span class="n">valid_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">vimages</span><span class="p">,</span> <span class="n">vlabels</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">valid_data_loader</span><span class="p">):</span>
            <span class="n">vimages</span> <span class="o">=</span> <span class="n">vimages</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="n">vlabels</span> <span class="o">=</span> <span class="n">vlabels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

            <span class="n">voutputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">vimages</span><span class="p">)</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">voutputs</span><span class="p">,</span> <span class="n">vlabels</span><span class="p">)</span>
            <span class="n">valid_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
        <span class="n">valid_loss</span> <span class="o">=</span> <span class="n">valid_loss</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">valid_data_loader</span><span class="p">)</span>
        <span class="n">valid_accuracy</span> <span class="o">=</span> <span class="n">get_accuracy</span><span class="p">(</span><span class="n">valid_data_loader</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
        <span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Epoch[</span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s1">]:'</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'</span><span class="se">\t</span><span class="s1">train_loss = </span><span class="si">{</span><span class="nb">round</span><span class="p">(</span><span class="n">train_loss</span><span class="p">,</span><span class="w"> </span><span class="mi">5</span><span class="p">)</span><span class="si">}</span><span class="s1">, train_accuracy = </span><span class="si">{</span><span class="nb">round</span><span class="p">(</span><span class="n">train_accuracy</span><span class="p">,</span><span class="w"> </span><span class="mi">8</span><span class="p">)</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'</span><span class="se">\t</span><span class="s1">valid_loss = </span><span class="si">{</span><span class="nb">round</span><span class="p">(</span><span class="n">valid_loss</span><span class="p">,</span><span class="w"> </span><span class="mi">5</span><span class="p">)</span><span class="si">}</span><span class="s1">, valid_accuracy = </span><span class="si">{</span><span class="nb">round</span><span class="p">(</span><span class="n">valid_accuracy</span><span class="p">,</span><span class="w"> </span><span class="mi">8</span><span class="p">)</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'</span><span class="se">\t</span><span class="s1">time = </span><span class="si">{</span><span class="nb">round</span><span class="p">(</span><span class="n">pbar</span><span class="o">.</span><span class="n">format_dict</span><span class="p">[</span><span class="s2">"elapsed"</span><span class="p">]</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">last_epoch_time</span><span class="p">,</span><span class="w"> </span><span class="mi">2</span><span class="p">)</span><span class="si">}</span><span class="s1"> s'</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">min_valid_loss</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">min_valid_loss</span> <span class="o">&gt;</span> <span class="n">valid_loss</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Validation loss decreased(</span><span class="si">{</span><span class="kc">None</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="n">min_valid_loss</span><span class="w"> </span><span class="ow">is</span><span class="w"> </span><span class="kc">None</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="nb">round</span><span class="p">(</span><span class="n">min_valid_loss</span><span class="p">,</span><span class="w"> </span><span class="mi">5</span><span class="p">)</span><span class="si">}</span><span class="s1">---&gt;</span><span class="si">{</span><span class="nb">round</span><span class="p">(</span><span class="n">valid_loss</span><span class="p">,</span><span class="w"> </span><span class="mi">5</span><span class="p">)</span><span class="si">}</span><span class="s1">) </span><span class="se">\t</span><span class="s1"> Saving The Model'</span><span class="p">)</span>
            <span class="n">min_valid_loss</span> <span class="o">=</span> <span class="n">valid_loss</span>
            <span class="n">valid_train_loss</span> <span class="o">=</span> <span class="n">train_loss</span> <span class="c1"># relative to valid loss</span>
            <span class="n">valid_train_accuracy</span> <span class="o">=</span> <span class="n">train_accuracy</span> <span class="c1"># relative to valid loss</span>
            <span class="n">best_valid_accuracy</span> <span class="o">=</span> <span class="n">valid_accuracy</span>
            <span class="c1"># Saving State Dict</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="sa">f</span><span class="s1">'</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s1">_model.pth'</span><span class="p">)</span>
            <span class="n">iters_valid_loss</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">iters_valid_loss</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">iters_valid_loss</span> <span class="o">==</span> <span class="n">epochs_valid_loss</span><span class="p">):</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Validation loss didn't decrease for </span><span class="si">{</span><span class="n">epochs_valid_loss</span><span class="si">}</span><span class="s2"> epochs ---&gt; model training stopped"</span><span class="p">)</span>
            <span class="k">break</span>
        <span class="n">last_epoch_time</span> <span class="o">=</span> <span class="n">pbar</span><span class="o">.</span><span class="n">format_dict</span><span class="p">[</span><span class="s2">"elapsed"</span><span class="p">]</span>

    <span class="c1"># log result</span>
    <span class="n">file</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="sa">f</span><span class="s1">'</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s1">_model.log'</span><span class="p">,</span> <span class="s1">'w'</span><span class="p">)</span>
    <span class="n">file</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="sa">f</span><span class="s1">'[</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s1">]</span><span class="se">\n\t</span><span class="si">{</span><span class="n">model</span><span class="si">}</span><span class="se">\n\t</span><span class="s1">valid training loss: </span><span class="si">{</span><span class="nb">round</span><span class="p">(</span><span class="n">valid_train_loss</span><span class="p">,</span><span class="w"> </span><span class="mi">5</span><span class="p">)</span><span class="si">}</span><span class="se">\n\t</span><span class="s1">valid training accuracy </span><span class="si">{</span><span class="nb">round</span><span class="p">(</span><span class="n">valid_train_accuracy</span><span class="p">,</span><span class="w"> </span><span class="mi">8</span><span class="p">)</span><span class="si">}</span><span class="se">\n\t</span><span class="s1">min validation loss: </span><span class="si">{</span><span class="nb">round</span><span class="p">(</span><span class="n">min_valid_loss</span><span class="p">,</span><span class="w"> </span><span class="mi">5</span><span class="p">)</span><span class="si">}</span><span class="s1">,</span><span class="se">\n\t</span><span class="s1">best validation accuracy: </span><span class="si">{</span><span class="nb">round</span><span class="p">(</span><span class="n">best_valid_accuracy</span><span class="p">,</span><span class="w"> </span><span class="mi">8</span><span class="p">)</span><span class="si">}</span><span class="s1">,</span><span class="se">\n\t</span><span class="s1">time: </span><span class="si">{</span><span class="n">pbar</span><span class="o">.</span><span class="n">format_dict</span><span class="p">[</span><span class="s2">"elapsed"</span><span class="p">]</span><span class="si">}</span><span class="s1"> s'</span><span class="p">)</span>
    <span class="n">file</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'[Finished training]</span><span class="se">\n\t</span><span class="s1">valid training loss: </span><span class="si">{</span><span class="nb">round</span><span class="p">(</span><span class="n">valid_train_loss</span><span class="p">,</span><span class="w"> </span><span class="mi">5</span><span class="p">)</span><span class="si">}</span><span class="se">\n\t</span><span class="s1">valid training accuracy </span><span class="si">{</span><span class="nb">round</span><span class="p">(</span><span class="n">valid_train_accuracy</span><span class="p">,</span><span class="w"> </span><span class="mi">8</span><span class="p">)</span><span class="si">}</span><span class="se">\n\t</span><span class="s1">min validation loss: </span><span class="si">{</span><span class="nb">round</span><span class="p">(</span><span class="n">min_valid_loss</span><span class="p">,</span><span class="w"> </span><span class="mi">5</span><span class="p">)</span><span class="si">}</span><span class="s1">,</span><span class="se">\n\t</span><span class="s1">best validation accuracy: </span><span class="si">{</span><span class="nb">round</span><span class="p">(</span><span class="n">best_valid_accuracy</span><span class="p">,</span><span class="w"> </span><span class="mi">8</span><span class="p">)</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span><span class="p">,</span> <span class="n">classification_report</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">roc_auc_score</span>
<span class="kn">from</span> <span class="nn">itertools</span> <span class="kn">import</span> <span class="n">cycle</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>

<span class="k">def</span> <span class="nf">get_metrics</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">'macro'</span><span class="p">):</span>
  <span class="nb">print</span><span class="p">(</span><span class="s2">"Classification Report</span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>
  <span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
  <span class="n">cm</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
  <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">cm</span><span class="p">,</span> <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">'coolwarm'</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s1">'.3g'</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Pred'</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'True'</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Confusion matrix'</span><span class="p">)</span>

  <span class="n">roc_auc</span> <span class="o">=</span> <span class="p">{}</span>
  <span class="n">classes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
  <span class="k">for</span> <span class="n">cl</span> <span class="ow">in</span> <span class="n">classes</span><span class="p">:</span>
    <span class="c1">#creating a list of all the classes except the current class </span>
    <span class="n">other_class</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">classes</span> <span class="k">if</span> <span class="n">x</span> <span class="o">!=</span> <span class="n">cl</span><span class="p">]</span>

    <span class="c1">#marking the current class as 1 and all other classes as 0</span>
    <span class="n">new_actual_class</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span> <span class="k">if</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">other_class</span> <span class="k">else</span> <span class="mi">1</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">y_true</span><span class="p">]</span>
    <span class="n">new_pred_class</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span> <span class="k">if</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">other_class</span> <span class="k">else</span> <span class="mi">1</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">y_pred</span><span class="p">]</span>

    <span class="n">roc_auc</span><span class="p">[</span><span class="n">cl</span><span class="p">]</span> <span class="o">=</span> <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">new_actual_class</span><span class="p">,</span> <span class="n">new_pred_class</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="n">average</span><span class="p">)</span>
  <span class="nb">print</span><span class="p">(</span><span class="s1">'Roc auc scores:'</span><span class="p">)</span>
  <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">roc_auc</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">'</span><span class="se">\t</span><span class="s1">'</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="s1">':'</span><span class="p">,</span> <span class="n">val</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">get_res</span><span class="p">(</span><span class="n">data_loader</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>
    <span class="n">y_true</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="k">for</span> <span class="n">images</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">data_loader</span><span class="p">:</span>
            <span class="n">labels</span> <span class="o">=</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="n">images</span> <span class="o">=</span> <span class="n">images</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>
            <span class="n">_</span><span class="p">,</span> <span class="n">predicted</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">outputs</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">y_true</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
            <span class="n">y_pred</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">predicted</span><span class="p">)</span>
    <span class="n">y_true</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">y_true</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">y_pred</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">copy</span>

<span class="k">def</span> <span class="nf">make_viz</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">model_name</span><span class="p">):</span>
    <span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">'cpu'</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="n">dataiter</span> <span class="o">=</span> <span class="nb">iter</span><span class="p">(</span><span class="n">test_data_loader</span><span class="p">)</span>
    <span class="n">images</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">dataiter</span><span class="p">)</span>
    <span class="n">out</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>
    <span class="n">make_dot</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">())))</span><span class="o">.</span><span class="n">render</span><span class="p">(</span><span class="n">model_name</span><span class="p">,</span> <span class="nb">format</span><span class="o">=</span><span class="s2">"png"</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">make_mod</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">model_name</span><span class="p">):</span>
    <span class="n">model_fc</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">model_fc</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="c1"># for efficient, mobilenet  </span>
    <span class="k">except</span><span class="p">:</span>
        <span class="n">model_fc</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fc</span> <span class="c1"># for regnet, shuffle</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Model[</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s1">] last FC before mod:'</span><span class="p">,</span> <span class="n">model_fc</span><span class="p">)</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">model_fc</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Model[</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s1">] last FC after mod:'</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
    <span class="k">except</span><span class="p">:</span>
        <span class="n">model</span><span class="o">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">model_fc</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Model[</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s1">] last FC after mod:'</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">fc</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">make_freeze</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">model_name</span><span class="p">):</span>
    <span class="n">check</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">'EfficientNet'</span><span class="p">:</span> <span class="s1">'classifier'</span><span class="p">,</span>
        <span class="s1">'RegNet'</span><span class="p">:</span> <span class="s1">'fc'</span><span class="p">,</span>
        <span class="s1">'ShuffleNetV2'</span><span class="p">:</span> <span class="s1">'fc'</span><span class="p">,</span>
        <span class="s1">'MobileNetV3'</span><span class="p">:</span> <span class="s1">'classifier.3'</span>
    <span class="p">}</span>
    <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">():</span>
        <span class="k">if</span> <span class="n">param</span><span class="o">.</span><span class="n">requires_grad</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">name</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="n">check</span><span class="p">[</span><span class="n">model_name</span><span class="p">]):</span>
            <span class="n">param</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">False</span>


<span class="k">def</span> <span class="nf">model_results</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">model_name</span><span class="p">,</span> <span class="n">num_epochs</span><span class="p">,</span> <span class="n">weight_type</span><span class="o">=</span><span class="s1">'model_weights'</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">'================================================================================'</span><span class="p">)</span>
    <span class="n">make_mod</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">model_name</span><span class="p">)</span>
    <span class="n">model_full</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">model</span><span class="p">)</span> <span class="c1"># for full training</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Model[</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s1">] - full training / </span><span class="si">{</span><span class="n">weight_type</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
    <span class="n">make_viz</span><span class="p">(</span><span class="n">model_full</span><span class="p">,</span> <span class="n">model_name</span> <span class="o">+</span> <span class="s1">'_full'</span><span class="p">)</span>
    <span class="n">model_training</span><span class="p">(</span><span class="n">model_full</span><span class="p">,</span> <span class="n">model_name</span> <span class="o">+</span> <span class="s1">'_full'</span><span class="p">,</span> <span class="n">num_epochs</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Model[</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s1">] - partial training (last layer) / </span><span class="si">{</span><span class="n">weight_type</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
    <span class="n">model_partial</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">model</span><span class="p">)</span> <span class="c1"># for partial training</span>
    <span class="n">make_freeze</span><span class="p">(</span><span class="n">model_partial</span><span class="p">,</span> <span class="n">model_name</span><span class="p">)</span>
    <span class="n">make_viz</span><span class="p">(</span><span class="n">model_partial</span><span class="p">,</span> <span class="n">model_name</span> <span class="o">+</span> <span class="s1">'_partial'</span><span class="p">)</span>
    <span class="n">model_training</span><span class="p">(</span><span class="n">model_partial</span><span class="p">,</span> <span class="n">model_name</span> <span class="o">+</span> <span class="s1">'_partial'</span><span class="p">,</span> <span class="n">num_epochs</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">models</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">torchvision</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">get_model</span><span class="p">(</span><span class="s1">'efficientnet_b1'</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="s1">'EfficientNet_B1_Weights.IMAGENET1K_V2'</span><span class="p">),</span>
    <span class="n">torchvision</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">get_model</span><span class="p">(</span><span class="s1">'regnet_y_400mf'</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="s1">'RegNet_Y_400MF_Weights.IMAGENET1K_V2'</span><span class="p">),</span>
    <span class="n">torchvision</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">get_model</span><span class="p">(</span><span class="s1">'shufflenet_v2_x0_5'</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="s1">'ShuffleNet_V2_X0_5_Weights.IMAGENET1K_V1'</span><span class="p">),</span>
    <span class="n">torchvision</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">get_model</span><span class="p">(</span><span class="s1">'mobilenet_v3_small'</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="s1">'MobileNet_V3_Small_Weights.IMAGENET1K_V1'</span><span class="p">)</span>
    <span class="p">]</span>
<span class="k">for</span> <span class="n">model</span> <span class="ow">in</span> <span class="n">models</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>EfficientNet(
  (features): Sequential(
    (0): Conv2dNormActivation(
      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): SiLU(inplace=True)
    )
    (1): Sequential(
      (0): MBConv(
        (block): Sequential(
          (0): Conv2dNormActivation(
            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(inplace=True)
          )
          (1): SqueezeExcitation(
            (avgpool): AdaptiveAvgPool2d(output_size=1)
            (fc1): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(inplace=True)
            (scale_activation): Sigmoid()
          )
          (2): Conv2dNormActivation(
            (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.0, mode=row)
      )
      (1): MBConv(
        (block): Sequential(
          (0): Conv2dNormActivation(
            (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)
            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(inplace=True)
          )
          (1): SqueezeExcitation(
            (avgpool): AdaptiveAvgPool2d(output_size=1)
            (fc1): Conv2d(16, 4, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(4, 16, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(inplace=True)
            (scale_activation): Sigmoid()
          )
          (2): Conv2dNormActivation(
            (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.008695652173913044, mode=row)
      )
    )
    (2): Sequential(
      (0): MBConv(
        (block): Sequential(
          (0): Conv2dNormActivation(
            (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(inplace=True)
          )
          (1): Conv2dNormActivation(
            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(inplace=True)
          )
          (2): SqueezeExcitation(
            (avgpool): AdaptiveAvgPool2d(output_size=1)
            (fc1): Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(4, 96, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(inplace=True)
            (scale_activation): Sigmoid()
          )
          (3): Conv2dNormActivation(
            (0): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.017391304347826087, mode=row)
      )
      (1): MBConv(
        (block): Sequential(
          (0): Conv2dNormActivation(
            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(inplace=True)
          )
          (1): Conv2dNormActivation(
            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)
            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(inplace=True)
          )
          (2): SqueezeExcitation(
            (avgpool): AdaptiveAvgPool2d(output_size=1)
            (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(inplace=True)
            (scale_activation): Sigmoid()
          )
          (3): Conv2dNormActivation(
            (0): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.026086956521739136, mode=row)
      )
      (2): MBConv(
        (block): Sequential(
          (0): Conv2dNormActivation(
            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(inplace=True)
          )
          (1): Conv2dNormActivation(
            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)
            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(inplace=True)
          )
          (2): SqueezeExcitation(
            (avgpool): AdaptiveAvgPool2d(output_size=1)
            (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(inplace=True)
            (scale_activation): Sigmoid()
          )
          (3): Conv2dNormActivation(
            (0): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.034782608695652174, mode=row)
      )
    )
    (3): Sequential(
      (0): MBConv(
        (block): Sequential(
          (0): Conv2dNormActivation(
            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(inplace=True)
          )
          (1): Conv2dNormActivation(
            (0): Conv2d(144, 144, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=144, bias=False)
            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(inplace=True)
          )
          (2): SqueezeExcitation(
            (avgpool): AdaptiveAvgPool2d(output_size=1)
            (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(inplace=True)
            (scale_activation): Sigmoid()
          )
          (3): Conv2dNormActivation(
            (0): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.043478260869565216, mode=row)
      )
      (1): MBConv(
        (block): Sequential(
          (0): Conv2dNormActivation(
            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(inplace=True)
          )
          (1): Conv2dNormActivation(
            (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)
            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(inplace=True)
          )
          (2): SqueezeExcitation(
            (avgpool): AdaptiveAvgPool2d(output_size=1)
            (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(inplace=True)
            (scale_activation): Sigmoid()
          )
          (3): Conv2dNormActivation(
            (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.05217391304347827, mode=row)
      )
      (2): MBConv(
        (block): Sequential(
          (0): Conv2dNormActivation(
            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(inplace=True)
          )
          (1): Conv2dNormActivation(
            (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)
            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(inplace=True)
          )
          (2): SqueezeExcitation(
            (avgpool): AdaptiveAvgPool2d(output_size=1)
            (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(inplace=True)
            (scale_activation): Sigmoid()
          )
          (3): Conv2dNormActivation(
            (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.06086956521739131, mode=row)
      )
    )
    (4): Sequential(
      (0): MBConv(
        (block): Sequential(
          (0): Conv2dNormActivation(
            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(inplace=True)
          )
          (1): Conv2dNormActivation(
            (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)
            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(inplace=True)
          )
          (2): SqueezeExcitation(
            (avgpool): AdaptiveAvgPool2d(output_size=1)
            (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(inplace=True)
            (scale_activation): Sigmoid()
          )
          (3): Conv2dNormActivation(
            (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.06956521739130435, mode=row)
      )
      (1): MBConv(
        (block): Sequential(
          (0): Conv2dNormActivation(
            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(inplace=True)
          )
          (1): Conv2dNormActivation(
            (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)
            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(inplace=True)
          )
          (2): SqueezeExcitation(
            (avgpool): AdaptiveAvgPool2d(output_size=1)
            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(inplace=True)
            (scale_activation): Sigmoid()
          )
          (3): Conv2dNormActivation(
            (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.0782608695652174, mode=row)
      )
      (2): MBConv(
        (block): Sequential(
          (0): Conv2dNormActivation(
            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(inplace=True)
          )
          (1): Conv2dNormActivation(
            (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)
            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(inplace=True)
          )
          (2): SqueezeExcitation(
            (avgpool): AdaptiveAvgPool2d(output_size=1)
            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(inplace=True)
            (scale_activation): Sigmoid()
          )
          (3): Conv2dNormActivation(
            (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.08695652173913043, mode=row)
      )
      (3): MBConv(
        (block): Sequential(
          (0): Conv2dNormActivation(
            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(inplace=True)
          )
          (1): Conv2dNormActivation(
            (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)
            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(inplace=True)
          )
          (2): SqueezeExcitation(
            (avgpool): AdaptiveAvgPool2d(output_size=1)
            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(inplace=True)
            (scale_activation): Sigmoid()
          )
          (3): Conv2dNormActivation(
            (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.09565217391304348, mode=row)
      )
    )
    (5): Sequential(
      (0): MBConv(
        (block): Sequential(
          (0): Conv2dNormActivation(
            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(inplace=True)
          )
          (1): Conv2dNormActivation(
            (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)
            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(inplace=True)
          )
          (2): SqueezeExcitation(
            (avgpool): AdaptiveAvgPool2d(output_size=1)
            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(inplace=True)
            (scale_activation): Sigmoid()
          )
          (3): Conv2dNormActivation(
            (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.10434782608695654, mode=row)
      )
      (1): MBConv(
        (block): Sequential(
          (0): Conv2dNormActivation(
            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(inplace=True)
          )
          (1): Conv2dNormActivation(
            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)
            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(inplace=True)
          )
          (2): SqueezeExcitation(
            (avgpool): AdaptiveAvgPool2d(output_size=1)
            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(inplace=True)
            (scale_activation): Sigmoid()
          )
          (3): Conv2dNormActivation(
            (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.11304347826086956, mode=row)
      )
      (2): MBConv(
        (block): Sequential(
          (0): Conv2dNormActivation(
            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(inplace=True)
          )
          (1): Conv2dNormActivation(
            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)
            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(inplace=True)
          )
          (2): SqueezeExcitation(
            (avgpool): AdaptiveAvgPool2d(output_size=1)
            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(inplace=True)
            (scale_activation): Sigmoid()
          )
          (3): Conv2dNormActivation(
            (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.12173913043478261, mode=row)
      )
      (3): MBConv(
        (block): Sequential(
          (0): Conv2dNormActivation(
            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(inplace=True)
          )
          (1): Conv2dNormActivation(
            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)
            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(inplace=True)
          )
          (2): SqueezeExcitation(
            (avgpool): AdaptiveAvgPool2d(output_size=1)
            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(inplace=True)
            (scale_activation): Sigmoid()
          )
          (3): Conv2dNormActivation(
            (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.13043478260869565, mode=row)
      )
    )
    (6): Sequential(
      (0): MBConv(
        (block): Sequential(
          (0): Conv2dNormActivation(
            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(inplace=True)
          )
          (1): Conv2dNormActivation(
            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)
            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(inplace=True)
          )
          (2): SqueezeExcitation(
            (avgpool): AdaptiveAvgPool2d(output_size=1)
            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(inplace=True)
            (scale_activation): Sigmoid()
          )
          (3): Conv2dNormActivation(
            (0): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1391304347826087, mode=row)
      )
      (1): MBConv(
        (block): Sequential(
          (0): Conv2dNormActivation(
            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(inplace=True)
          )
          (1): Conv2dNormActivation(
            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)
            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(inplace=True)
          )
          (2): SqueezeExcitation(
            (avgpool): AdaptiveAvgPool2d(output_size=1)
            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(inplace=True)
            (scale_activation): Sigmoid()
          )
          (3): Conv2dNormActivation(
            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.14782608695652175, mode=row)
      )
      (2): MBConv(
        (block): Sequential(
          (0): Conv2dNormActivation(
            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(inplace=True)
          )
          (1): Conv2dNormActivation(
            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)
            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(inplace=True)
          )
          (2): SqueezeExcitation(
            (avgpool): AdaptiveAvgPool2d(output_size=1)
            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(inplace=True)
            (scale_activation): Sigmoid()
          )
          (3): Conv2dNormActivation(
            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1565217391304348, mode=row)
      )
      (3): MBConv(
        (block): Sequential(
          (0): Conv2dNormActivation(
            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(inplace=True)
          )
          (1): Conv2dNormActivation(
            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)
            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(inplace=True)
          )
          (2): SqueezeExcitation(
            (avgpool): AdaptiveAvgPool2d(output_size=1)
            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(inplace=True)
            (scale_activation): Sigmoid()
          )
          (3): Conv2dNormActivation(
            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.16521739130434784, mode=row)
      )
      (4): MBConv(
        (block): Sequential(
          (0): Conv2dNormActivation(
            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(inplace=True)
          )
          (1): Conv2dNormActivation(
            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)
            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(inplace=True)
          )
          (2): SqueezeExcitation(
            (avgpool): AdaptiveAvgPool2d(output_size=1)
            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(inplace=True)
            (scale_activation): Sigmoid()
          )
          (3): Conv2dNormActivation(
            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.17391304347826086, mode=row)
      )
    )
    (7): Sequential(
      (0): MBConv(
        (block): Sequential(
          (0): Conv2dNormActivation(
            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(inplace=True)
          )
          (1): Conv2dNormActivation(
            (0): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)
            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(inplace=True)
          )
          (2): SqueezeExcitation(
            (avgpool): AdaptiveAvgPool2d(output_size=1)
            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(inplace=True)
            (scale_activation): Sigmoid()
          )
          (3): Conv2dNormActivation(
            (0): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1826086956521739, mode=row)
      )
      (1): MBConv(
        (block): Sequential(
          (0): Conv2dNormActivation(
            (0): Conv2d(320, 1920, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1920, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(inplace=True)
          )
          (1): Conv2dNormActivation(
            (0): Conv2d(1920, 1920, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1920, bias=False)
            (1): BatchNorm2d(1920, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(inplace=True)
          )
          (2): SqueezeExcitation(
            (avgpool): AdaptiveAvgPool2d(output_size=1)
            (fc1): Conv2d(1920, 80, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(80, 1920, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(inplace=True)
            (scale_activation): Sigmoid()
          )
          (3): Conv2dNormActivation(
            (0): Conv2d(1920, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.19130434782608696, mode=row)
      )
    )
    (8): Conv2dNormActivation(
      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): SiLU(inplace=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(output_size=1)
  (classifier): Sequential(
    (0): Dropout(p=0.2, inplace=True)
    (1): Linear(in_features=1280, out_features=1000, bias=True)
  )
)
RegNet(
  (stem): SimpleStemIN(
    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
  )
  (trunk_output): Sequential(
    (block1): AnyStage(
      (block1-0): ResBottleneckBlock(
        (proj): Conv2dNormActivation(
          (0): Conv2d(32, 48, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (f): BottleneckTransform(
          (a): Conv2dNormActivation(
            (0): Conv2d(32, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (b): Conv2dNormActivation(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=6, bias=False)
            (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (se): SqueezeExcitation(
            (avgpool): AdaptiveAvgPool2d(output_size=1)
            (fc1): Conv2d(48, 8, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(8, 48, kernel_size=(1, 1), stride=(1, 1))
            (activation): ReLU()
            (scale_activation): Sigmoid()
          )
          (c): Conv2dNormActivation(
            (0): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (activation): ReLU(inplace=True)
      )
    )
    (block2): AnyStage(
      (block2-0): ResBottleneckBlock(
        (proj): Conv2dNormActivation(
          (0): Conv2d(48, 104, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (f): BottleneckTransform(
          (a): Conv2dNormActivation(
            (0): Conv2d(48, 104, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (b): Conv2dNormActivation(
            (0): Conv2d(104, 104, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=13, bias=False)
            (1): BatchNorm2d(104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (se): SqueezeExcitation(
            (avgpool): AdaptiveAvgPool2d(output_size=1)
            (fc1): Conv2d(104, 12, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(12, 104, kernel_size=(1, 1), stride=(1, 1))
            (activation): ReLU()
            (scale_activation): Sigmoid()
          )
          (c): Conv2dNormActivation(
            (0): Conv2d(104, 104, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (activation): ReLU(inplace=True)
      )
      (block2-1): ResBottleneckBlock(
        (f): BottleneckTransform(
          (a): Conv2dNormActivation(
            (0): Conv2d(104, 104, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (b): Conv2dNormActivation(
            (0): Conv2d(104, 104, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=13, bias=False)
            (1): BatchNorm2d(104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (se): SqueezeExcitation(
            (avgpool): AdaptiveAvgPool2d(output_size=1)
            (fc1): Conv2d(104, 26, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(26, 104, kernel_size=(1, 1), stride=(1, 1))
            (activation): ReLU()
            (scale_activation): Sigmoid()
          )
          (c): Conv2dNormActivation(
            (0): Conv2d(104, 104, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (activation): ReLU(inplace=True)
      )
      (block2-2): ResBottleneckBlock(
        (f): BottleneckTransform(
          (a): Conv2dNormActivation(
            (0): Conv2d(104, 104, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (b): Conv2dNormActivation(
            (0): Conv2d(104, 104, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=13, bias=False)
            (1): BatchNorm2d(104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (se): SqueezeExcitation(
            (avgpool): AdaptiveAvgPool2d(output_size=1)
            (fc1): Conv2d(104, 26, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(26, 104, kernel_size=(1, 1), stride=(1, 1))
            (activation): ReLU()
            (scale_activation): Sigmoid()
          )
          (c): Conv2dNormActivation(
            (0): Conv2d(104, 104, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (activation): ReLU(inplace=True)
      )
    )
    (block3): AnyStage(
      (block3-0): ResBottleneckBlock(
        (proj): Conv2dNormActivation(
          (0): Conv2d(104, 208, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (f): BottleneckTransform(
          (a): Conv2dNormActivation(
            (0): Conv2d(104, 208, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (b): Conv2dNormActivation(
            (0): Conv2d(208, 208, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=26, bias=False)
            (1): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (se): SqueezeExcitation(
            (avgpool): AdaptiveAvgPool2d(output_size=1)
            (fc1): Conv2d(208, 26, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(26, 208, kernel_size=(1, 1), stride=(1, 1))
            (activation): ReLU()
            (scale_activation): Sigmoid()
          )
          (c): Conv2dNormActivation(
            (0): Conv2d(208, 208, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (activation): ReLU(inplace=True)
      )
      (block3-1): ResBottleneckBlock(
        (f): BottleneckTransform(
          (a): Conv2dNormActivation(
            (0): Conv2d(208, 208, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (b): Conv2dNormActivation(
            (0): Conv2d(208, 208, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=26, bias=False)
            (1): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (se): SqueezeExcitation(
            (avgpool): AdaptiveAvgPool2d(output_size=1)
            (fc1): Conv2d(208, 52, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(52, 208, kernel_size=(1, 1), stride=(1, 1))
            (activation): ReLU()
            (scale_activation): Sigmoid()
          )
          (c): Conv2dNormActivation(
            (0): Conv2d(208, 208, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (activation): ReLU(inplace=True)
      )
      (block3-2): ResBottleneckBlock(
        (f): BottleneckTransform(
          (a): Conv2dNormActivation(
            (0): Conv2d(208, 208, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (b): Conv2dNormActivation(
            (0): Conv2d(208, 208, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=26, bias=False)
            (1): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (se): SqueezeExcitation(
            (avgpool): AdaptiveAvgPool2d(output_size=1)
            (fc1): Conv2d(208, 52, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(52, 208, kernel_size=(1, 1), stride=(1, 1))
            (activation): ReLU()
            (scale_activation): Sigmoid()
          )
          (c): Conv2dNormActivation(
            (0): Conv2d(208, 208, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (activation): ReLU(inplace=True)
      )
      (block3-3): ResBottleneckBlock(
        (f): BottleneckTransform(
          (a): Conv2dNormActivation(
            (0): Conv2d(208, 208, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (b): Conv2dNormActivation(
            (0): Conv2d(208, 208, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=26, bias=False)
            (1): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (se): SqueezeExcitation(
            (avgpool): AdaptiveAvgPool2d(output_size=1)
            (fc1): Conv2d(208, 52, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(52, 208, kernel_size=(1, 1), stride=(1, 1))
            (activation): ReLU()
            (scale_activation): Sigmoid()
          )
          (c): Conv2dNormActivation(
            (0): Conv2d(208, 208, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (activation): ReLU(inplace=True)
      )
      (block3-4): ResBottleneckBlock(
        (f): BottleneckTransform(
          (a): Conv2dNormActivation(
            (0): Conv2d(208, 208, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (b): Conv2dNormActivation(
            (0): Conv2d(208, 208, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=26, bias=False)
            (1): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (se): SqueezeExcitation(
            (avgpool): AdaptiveAvgPool2d(output_size=1)
            (fc1): Conv2d(208, 52, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(52, 208, kernel_size=(1, 1), stride=(1, 1))
            (activation): ReLU()
            (scale_activation): Sigmoid()
          )
          (c): Conv2dNormActivation(
            (0): Conv2d(208, 208, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (activation): ReLU(inplace=True)
      )
      (block3-5): ResBottleneckBlock(
        (f): BottleneckTransform(
          (a): Conv2dNormActivation(
            (0): Conv2d(208, 208, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (b): Conv2dNormActivation(
            (0): Conv2d(208, 208, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=26, bias=False)
            (1): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (se): SqueezeExcitation(
            (avgpool): AdaptiveAvgPool2d(output_size=1)
            (fc1): Conv2d(208, 52, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(52, 208, kernel_size=(1, 1), stride=(1, 1))
            (activation): ReLU()
            (scale_activation): Sigmoid()
          )
          (c): Conv2dNormActivation(
            (0): Conv2d(208, 208, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (activation): ReLU(inplace=True)
      )
    )
    (block4): AnyStage(
      (block4-0): ResBottleneckBlock(
        (proj): Conv2dNormActivation(
          (0): Conv2d(208, 440, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (f): BottleneckTransform(
          (a): Conv2dNormActivation(
            (0): Conv2d(208, 440, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (b): Conv2dNormActivation(
            (0): Conv2d(440, 440, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=55, bias=False)
            (1): BatchNorm2d(440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (se): SqueezeExcitation(
            (avgpool): AdaptiveAvgPool2d(output_size=1)
            (fc1): Conv2d(440, 52, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(52, 440, kernel_size=(1, 1), stride=(1, 1))
            (activation): ReLU()
            (scale_activation): Sigmoid()
          )
          (c): Conv2dNormActivation(
            (0): Conv2d(440, 440, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (activation): ReLU(inplace=True)
      )
      (block4-1): ResBottleneckBlock(
        (f): BottleneckTransform(
          (a): Conv2dNormActivation(
            (0): Conv2d(440, 440, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (b): Conv2dNormActivation(
            (0): Conv2d(440, 440, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=55, bias=False)
            (1): BatchNorm2d(440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (se): SqueezeExcitation(
            (avgpool): AdaptiveAvgPool2d(output_size=1)
            (fc1): Conv2d(440, 110, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(110, 440, kernel_size=(1, 1), stride=(1, 1))
            (activation): ReLU()
            (scale_activation): Sigmoid()
          )
          (c): Conv2dNormActivation(
            (0): Conv2d(440, 440, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (activation): ReLU(inplace=True)
      )
      (block4-2): ResBottleneckBlock(
        (f): BottleneckTransform(
          (a): Conv2dNormActivation(
            (0): Conv2d(440, 440, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (b): Conv2dNormActivation(
            (0): Conv2d(440, 440, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=55, bias=False)
            (1): BatchNorm2d(440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (se): SqueezeExcitation(
            (avgpool): AdaptiveAvgPool2d(output_size=1)
            (fc1): Conv2d(440, 110, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(110, 440, kernel_size=(1, 1), stride=(1, 1))
            (activation): ReLU()
            (scale_activation): Sigmoid()
          )
          (c): Conv2dNormActivation(
            (0): Conv2d(440, 440, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (activation): ReLU(inplace=True)
      )
      (block4-3): ResBottleneckBlock(
        (f): BottleneckTransform(
          (a): Conv2dNormActivation(
            (0): Conv2d(440, 440, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (b): Conv2dNormActivation(
            (0): Conv2d(440, 440, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=55, bias=False)
            (1): BatchNorm2d(440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (se): SqueezeExcitation(
            (avgpool): AdaptiveAvgPool2d(output_size=1)
            (fc1): Conv2d(440, 110, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(110, 440, kernel_size=(1, 1), stride=(1, 1))
            (activation): ReLU()
            (scale_activation): Sigmoid()
          )
          (c): Conv2dNormActivation(
            (0): Conv2d(440, 440, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (activation): ReLU(inplace=True)
      )
      (block4-4): ResBottleneckBlock(
        (f): BottleneckTransform(
          (a): Conv2dNormActivation(
            (0): Conv2d(440, 440, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (b): Conv2dNormActivation(
            (0): Conv2d(440, 440, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=55, bias=False)
            (1): BatchNorm2d(440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (se): SqueezeExcitation(
            (avgpool): AdaptiveAvgPool2d(output_size=1)
            (fc1): Conv2d(440, 110, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(110, 440, kernel_size=(1, 1), stride=(1, 1))
            (activation): ReLU()
            (scale_activation): Sigmoid()
          )
          (c): Conv2dNormActivation(
            (0): Conv2d(440, 440, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (activation): ReLU(inplace=True)
      )
      (block4-5): ResBottleneckBlock(
        (f): BottleneckTransform(
          (a): Conv2dNormActivation(
            (0): Conv2d(440, 440, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (b): Conv2dNormActivation(
            (0): Conv2d(440, 440, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=55, bias=False)
            (1): BatchNorm2d(440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (se): SqueezeExcitation(
            (avgpool): AdaptiveAvgPool2d(output_size=1)
            (fc1): Conv2d(440, 110, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(110, 440, kernel_size=(1, 1), stride=(1, 1))
            (activation): ReLU()
            (scale_activation): Sigmoid()
          )
          (c): Conv2dNormActivation(
            (0): Conv2d(440, 440, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (activation): ReLU(inplace=True)
      )
    )
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (fc): Linear(in_features=440, out_features=1000, bias=True)
)
ShuffleNetV2(
  (conv1): Sequential(
    (0): Conv2d(3, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
  )
  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (stage2): Sequential(
    (0): InvertedResidual(
      (branch1): Sequential(
        (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=24, bias=False)
        (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (4): ReLU(inplace=True)
      )
      (branch2): Sequential(
        (0): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): Conv2d(24, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=24, bias=False)
        (4): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (6): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (7): ReLU(inplace=True)
      )
    )
    (1): InvertedResidual(
      (branch1): Sequential()
      (branch2): Sequential(
        (0): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)
        (4): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (6): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (7): ReLU(inplace=True)
      )
    )
    (2): InvertedResidual(
      (branch1): Sequential()
      (branch2): Sequential(
        (0): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)
        (4): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (6): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (7): ReLU(inplace=True)
      )
    )
    (3): InvertedResidual(
      (branch1): Sequential()
      (branch2): Sequential(
        (0): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)
        (4): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (6): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (7): ReLU(inplace=True)
      )
    )
  )
  (stage3): Sequential(
    (0): InvertedResidual(
      (branch1): Sequential(
        (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=48, bias=False)
        (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (4): ReLU(inplace=True)
      )
      (branch2): Sequential(
        (0): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=48, bias=False)
        (4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (6): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (7): ReLU(inplace=True)
      )
    )
    (1): InvertedResidual(
      (branch1): Sequential()
      (branch2): Sequential(
        (0): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (6): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (7): ReLU(inplace=True)
      )
    )
    (2): InvertedResidual(
      (branch1): Sequential()
      (branch2): Sequential(
        (0): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (6): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (7): ReLU(inplace=True)
      )
    )
    (3): InvertedResidual(
      (branch1): Sequential()
      (branch2): Sequential(
        (0): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (6): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (7): ReLU(inplace=True)
      )
    )
    (4): InvertedResidual(
      (branch1): Sequential()
      (branch2): Sequential(
        (0): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (6): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (7): ReLU(inplace=True)
      )
    )
    (5): InvertedResidual(
      (branch1): Sequential()
      (branch2): Sequential(
        (0): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (6): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (7): ReLU(inplace=True)
      )
    )
    (6): InvertedResidual(
      (branch1): Sequential()
      (branch2): Sequential(
        (0): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (6): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (7): ReLU(inplace=True)
      )
    )
    (7): InvertedResidual(
      (branch1): Sequential()
      (branch2): Sequential(
        (0): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (6): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (7): ReLU(inplace=True)
      )
    )
  )
  (stage4): Sequential(
    (0): InvertedResidual(
      (branch1): Sequential(
        (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)
        (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (4): ReLU(inplace=True)
      )
      (branch2): Sequential(
        (0): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)
        (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (6): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (7): ReLU(inplace=True)
      )
    )
    (1): InvertedResidual(
      (branch1): Sequential()
      (branch2): Sequential(
        (0): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
        (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (6): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (7): ReLU(inplace=True)
      )
    )
    (2): InvertedResidual(
      (branch1): Sequential()
      (branch2): Sequential(
        (0): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
        (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (6): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (7): ReLU(inplace=True)
      )
    )
    (3): InvertedResidual(
      (branch1): Sequential()
      (branch2): Sequential(
        (0): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
        (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (6): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (7): ReLU(inplace=True)
      )
    )
  )
  (conv5): Sequential(
    (0): Conv2d(192, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
  )
  (fc): Linear(in_features=1024, out_features=1000, bias=True)
)
MobileNetV3(
  (features): Sequential(
    (0): Conv2dNormActivation(
      (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (2): Hardswish()
    )
    (1): InvertedResidual(
      (block): Sequential(
        (0): Conv2dNormActivation(
          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=16, bias=False)
          (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
        (1): SqueezeExcitation(
          (avgpool): AdaptiveAvgPool2d(output_size=1)
          (fc1): Conv2d(16, 8, kernel_size=(1, 1), stride=(1, 1))
          (fc2): Conv2d(8, 16, kernel_size=(1, 1), stride=(1, 1))
          (activation): ReLU()
          (scale_activation): Hardsigmoid()
        )
        (2): Conv2dNormActivation(
          (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        )
      )
    )
    (2): InvertedResidual(
      (block): Sequential(
        (0): Conv2dNormActivation(
          (0): Conv2d(16, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
        (1): Conv2dNormActivation(
          (0): Conv2d(72, 72, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=72, bias=False)
          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
        (2): Conv2dNormActivation(
          (0): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        )
      )
    )
    (3): InvertedResidual(
      (block): Sequential(
        (0): Conv2dNormActivation(
          (0): Conv2d(24, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(88, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
        (1): Conv2dNormActivation(
          (0): Conv2d(88, 88, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=88, bias=False)
          (1): BatchNorm2d(88, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
        (2): Conv2dNormActivation(
          (0): Conv2d(88, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        )
      )
    )
    (4): InvertedResidual(
      (block): Sequential(
        (0): Conv2dNormActivation(
          (0): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): Hardswish()
        )
        (1): Conv2dNormActivation(
          (0): Conv2d(96, 96, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=96, bias=False)
          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): Hardswish()
        )
        (2): SqueezeExcitation(
          (avgpool): AdaptiveAvgPool2d(output_size=1)
          (fc1): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1))
          (fc2): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1))
          (activation): ReLU()
          (scale_activation): Hardsigmoid()
        )
        (3): Conv2dNormActivation(
          (0): Conv2d(96, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        )
      )
    )
    (5): InvertedResidual(
      (block): Sequential(
        (0): Conv2dNormActivation(
          (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): Hardswish()
        )
        (1): Conv2dNormActivation(
          (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)
          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): Hardswish()
        )
        (2): SqueezeExcitation(
          (avgpool): AdaptiveAvgPool2d(output_size=1)
          (fc1): Conv2d(240, 64, kernel_size=(1, 1), stride=(1, 1))
          (fc2): Conv2d(64, 240, kernel_size=(1, 1), stride=(1, 1))
          (activation): ReLU()
          (scale_activation): Hardsigmoid()
        )
        (3): Conv2dNormActivation(
          (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        )
      )
    )
    (6): InvertedResidual(
      (block): Sequential(
        (0): Conv2dNormActivation(
          (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): Hardswish()
        )
        (1): Conv2dNormActivation(
          (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)
          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): Hardswish()
        )
        (2): SqueezeExcitation(
          (avgpool): AdaptiveAvgPool2d(output_size=1)
          (fc1): Conv2d(240, 64, kernel_size=(1, 1), stride=(1, 1))
          (fc2): Conv2d(64, 240, kernel_size=(1, 1), stride=(1, 1))
          (activation): ReLU()
          (scale_activation): Hardsigmoid()
        )
        (3): Conv2dNormActivation(
          (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        )
      )
    )
    (7): InvertedResidual(
      (block): Sequential(
        (0): Conv2dNormActivation(
          (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): Hardswish()
        )
        (1): Conv2dNormActivation(
          (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)
          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): Hardswish()
        )
        (2): SqueezeExcitation(
          (avgpool): AdaptiveAvgPool2d(output_size=1)
          (fc1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))
          (fc2): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))
          (activation): ReLU()
          (scale_activation): Hardsigmoid()
        )
        (3): Conv2dNormActivation(
          (0): Conv2d(120, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        )
      )
    )
    (8): InvertedResidual(
      (block): Sequential(
        (0): Conv2dNormActivation(
          (0): Conv2d(48, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(144, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): Hardswish()
        )
        (1): Conv2dNormActivation(
          (0): Conv2d(144, 144, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=144, bias=False)
          (1): BatchNorm2d(144, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): Hardswish()
        )
        (2): SqueezeExcitation(
          (avgpool): AdaptiveAvgPool2d(output_size=1)
          (fc1): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1))
          (fc2): Conv2d(40, 144, kernel_size=(1, 1), stride=(1, 1))
          (activation): ReLU()
          (scale_activation): Hardsigmoid()
        )
        (3): Conv2dNormActivation(
          (0): Conv2d(144, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        )
      )
    )
    (9): InvertedResidual(
      (block): Sequential(
        (0): Conv2dNormActivation(
          (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): Hardswish()
        )
        (1): Conv2dNormActivation(
          (0): Conv2d(288, 288, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=288, bias=False)
          (1): BatchNorm2d(288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): Hardswish()
        )
        (2): SqueezeExcitation(
          (avgpool): AdaptiveAvgPool2d(output_size=1)
          (fc1): Conv2d(288, 72, kernel_size=(1, 1), stride=(1, 1))
          (fc2): Conv2d(72, 288, kernel_size=(1, 1), stride=(1, 1))
          (activation): ReLU()
          (scale_activation): Hardsigmoid()
        )
        (3): Conv2dNormActivation(
          (0): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        )
      )
    )
    (10): InvertedResidual(
      (block): Sequential(
        (0): Conv2dNormActivation(
          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): Hardswish()
        )
        (1): Conv2dNormActivation(
          (0): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)
          (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): Hardswish()
        )
        (2): SqueezeExcitation(
          (avgpool): AdaptiveAvgPool2d(output_size=1)
          (fc1): Conv2d(576, 144, kernel_size=(1, 1), stride=(1, 1))
          (fc2): Conv2d(144, 576, kernel_size=(1, 1), stride=(1, 1))
          (activation): ReLU()
          (scale_activation): Hardsigmoid()
        )
        (3): Conv2dNormActivation(
          (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        )
      )
    )
    (11): InvertedResidual(
      (block): Sequential(
        (0): Conv2dNormActivation(
          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): Hardswish()
        )
        (1): Conv2dNormActivation(
          (0): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)
          (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): Hardswish()
        )
        (2): SqueezeExcitation(
          (avgpool): AdaptiveAvgPool2d(output_size=1)
          (fc1): Conv2d(576, 144, kernel_size=(1, 1), stride=(1, 1))
          (fc2): Conv2d(144, 576, kernel_size=(1, 1), stride=(1, 1))
          (activation): ReLU()
          (scale_activation): Hardsigmoid()
        )
        (3): Conv2dNormActivation(
          (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        )
      )
    )
    (12): Conv2dNormActivation(
      (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (2): Hardswish()
    )
  )
  (avgpool): AdaptiveAvgPool2d(output_size=1)
  (classifier): Sequential(
    (0): Linear(in_features=576, out_features=1024, bias=True)
    (1): Hardswish()
    (2): Dropout(p=0.2, inplace=True)
    (3): Linear(in_features=1024, out_features=1000, bias=True)
  )
)
</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">models</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">torchvision</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">get_model</span><span class="p">(</span><span class="s1">'efficientnet_b1'</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="s1">'EfficientNet_B1_Weights.IMAGENET1K_V2'</span><span class="p">),</span>
    <span class="n">torchvision</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">get_model</span><span class="p">(</span><span class="s1">'regnet_y_400mf'</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="s1">'RegNet_Y_400MF_Weights.IMAGENET1K_V2'</span><span class="p">),</span>
    <span class="n">torchvision</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">get_model</span><span class="p">(</span><span class="s1">'shufflenet_v2_x0_5'</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="s1">'ShuffleNet_V2_X0_5_Weights.IMAGENET1K_V1'</span><span class="p">),</span>
    <span class="n">torchvision</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">get_model</span><span class="p">(</span><span class="s1">'mobilenet_v3_small'</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="s1">'MobileNet_V3_Small_Weights.IMAGENET1K_V1'</span><span class="p">)</span>
    <span class="p">]</span>
<span class="n">model_names</span> <span class="o">=</span> <span class="p">[</span><span class="n">model</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span> <span class="k">for</span> <span class="n">model</span> <span class="ow">in</span> <span class="n">models</span><span class="p">]</span>
<span class="k">for</span> <span class="n">model</span><span class="p">,</span> <span class="n">model_name</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">models</span><span class="p">,</span> <span class="n">model_names</span><span class="p">):</span>
    <span class="n">model_results</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">model_name</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>================================================================================
Model[EfficientNet] last FC before mod: Linear(in_features=1280, out_features=1000, bias=True)
Model[EfficientNet] last FC after mod: Linear(in_features=1280, out_features=10, bias=True)
Model[EfficientNet] - full training / model_weights
Adjusting learning rate of group 0 to 1.0000e-01.
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>  0%|          | 0/100 [00:00&lt;?, ?it/s]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>#############################################################################################
[Training parameters]
	epochs = 100,
	lr = 0.1,
	momentum = 0.9,
	weight_decay = 0.0005,
	loss = CrossEntropyLoss(),
	optimizer = SGD (
Parameter Group 0
    dampening: 0
    differentiable: False
    foreach: None
    initial_lr: 0.1
    lr: 0.1
    maximize: False
    momentum: 0.9
    nesterov: False
    weight_decay: 0.0005
),
	scheduler = &lt;torch.optim.lr_scheduler.CosineAnnealingLR object at 0x0000026820613D60&gt;,
	device = cuda:0
#############################################################################################
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>  1%|          | 1/100 [00:47&lt;1:17:42, 47.09s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.9975e-02.
Epoch[0]:
	train_loss = 1.62188, train_accuracy = 0.550825
	valid_loss = 1.24034, valid_accuracy = 0.54689997
	time = 47.04 s
Validation loss decreased(None---&gt;1.24034) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>  2%|▏         | 2/100 [01:31&lt;1:14:21, 45.53s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.9901e-02.
Epoch[1]:
	train_loss = 1.08278, train_accuracy = 0.68072498
	valid_loss = 0.93042, valid_accuracy = 0.67219996
	time = 44.39 s
Validation loss decreased(1.24034---&gt;0.93042) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>  3%|▎         | 3/100 [02:14&lt;1:11:59, 44.53s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.9778e-02.
Epoch[2]:
	train_loss = 0.88205, train_accuracy = 0.72235
	valid_loss = 0.8342, valid_accuracy = 0.70309997
	time = 43.3 s
Validation loss decreased(0.93042---&gt;0.8342) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>  4%|▍         | 4/100 [02:58&lt;1:10:34, 44.10s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.9606e-02.
Epoch[3]:
	train_loss = 0.77413, train_accuracy = 0.75657499
	valid_loss = 0.7625, valid_accuracy = 0.73969996
	time = 43.41 s
Validation loss decreased(0.8342---&gt;0.7625) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>  5%|▌         | 5/100 [03:42&lt;1:09:44, 44.05s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.9384e-02.
Epoch[4]:
	train_loss = 0.7727, train_accuracy = 0.76317495
	valid_loss = 0.73857, valid_accuracy = 0.74719995
	time = 43.9 s
Validation loss decreased(0.7625---&gt;0.73857) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>  6%|▌         | 6/100 [04:24&lt;1:08:15, 43.57s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.9114e-02.
Epoch[5]:
	train_loss = 0.71413, train_accuracy = 0.75567496
	valid_loss = 0.76065, valid_accuracy = 0.73589998
	time = 42.65 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>  7%|▋         | 7/100 [05:07&lt;1:07:07, 43.31s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.8796e-02.
Epoch[6]:
	train_loss = 0.67811, train_accuracy = 0.76442498
	valid_loss = 0.719, valid_accuracy = 0.74469995
	time = 42.71 s
Validation loss decreased(0.73857---&gt;0.719) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>  8%|▊         | 8/100 [05:50&lt;1:06:03, 43.08s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.8429e-02.
Epoch[7]:
	train_loss = 0.66111, train_accuracy = 0.777125
	valid_loss = 0.69988, valid_accuracy = 0.75389999
	time = 42.56 s
Validation loss decreased(0.719---&gt;0.69988) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>  9%|▉         | 9/100 [06:32&lt;1:05:05, 42.92s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.8015e-02.
Epoch[8]:
	train_loss = 0.66782, train_accuracy = 0.77887499
	valid_loss = 0.70652, valid_accuracy = 0.7568
	time = 42.55 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 10%|█         | 10/100 [07:15&lt;1:04:18, 42.87s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.7553e-02.
Epoch[9]:
	train_loss = 0.67469, train_accuracy = 0.759
	valid_loss = 0.73918, valid_accuracy = 0.73869997
	time = 42.78 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 11%|█         | 11/100 [07:58&lt;1:03:38, 42.90s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.7044e-02.
Epoch[10]:
	train_loss = 0.66986, train_accuracy = 0.75177497
	valid_loss = 0.77331, valid_accuracy = 0.73449999
	time = 42.97 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 12%|█▏        | 12/100 [08:41&lt;1:02:52, 42.87s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.6489e-02.
Epoch[11]:
	train_loss = 0.6734, train_accuracy = 0.78824997
	valid_loss = 0.66506, valid_accuracy = 0.77349997
	time = 42.74 s
Validation loss decreased(0.69988---&gt;0.66506) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 13%|█▎        | 13/100 [09:24&lt;1:02:16, 42.95s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.5888e-02.
Epoch[12]:
	train_loss = 0.67448, train_accuracy = 0.75207496
	valid_loss = 0.73751, valid_accuracy = 0.73199999
	time = 43.13 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 14%|█▍        | 14/100 [10:07&lt;1:01:37, 43.00s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.5241e-02.
Epoch[13]:
	train_loss = 0.67044, train_accuracy = 0.78882498
	valid_loss = 0.66915, valid_accuracy = 0.77029997
	time = 43.11 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 15%|█▌        | 15/100 [10:50&lt;1:00:52, 42.97s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.4550e-02.
Epoch[14]:
	train_loss = 0.6668, train_accuracy = 0.75762498
	valid_loss = 0.7651, valid_accuracy = 0.73399997
	time = 42.9 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 16%|█▌        | 16/100 [11:33&lt;1:00:20, 43.11s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.3815e-02.
Epoch[15]:
	train_loss = 0.6671, train_accuracy = 0.73927498
	valid_loss = 0.83764, valid_accuracy = 0.72359997
	time = 43.43 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 17%|█▋        | 17/100 [12:16&lt;59:33, 43.05s/it]  </pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.3037e-02.
Epoch[16]:
	train_loss = 0.66145, train_accuracy = 0.76854998
	valid_loss = 0.7218, valid_accuracy = 0.74659997
	time = 42.93 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 18%|█▊        | 18/100 [12:59&lt;58:39, 42.92s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.2216e-02.
Epoch[17]:
	train_loss = 0.66202, train_accuracy = 0.76702499
	valid_loss = 0.72927, valid_accuracy = 0.745
	time = 42.61 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 19%|█▉        | 19/100 [13:42&lt;57:54, 42.90s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.1354e-02.
Epoch[18]:
	train_loss = 0.6622, train_accuracy = 0.76362497
	valid_loss = 0.7639, valid_accuracy = 0.7367
	time = 42.84 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 20%|██        | 20/100 [14:26&lt;57:36, 43.20s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.0451e-02.
Epoch[19]:
	train_loss = 0.66608, train_accuracy = 0.729375
	valid_loss = 0.87947, valid_accuracy = 0.70300001
	time = 43.92 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 21%|██        | 21/100 [15:09&lt;57:04, 43.34s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 8.9508e-02.
Epoch[20]:
	train_loss = 0.64884, train_accuracy = 0.79467499
	valid_loss = 0.67362, valid_accuracy = 0.76739997
	time = 43.67 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 22%|██▏       | 22/100 [15:53&lt;56:15, 43.27s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 8.8526e-02.
Epoch[21]:
	train_loss = 0.65247, train_accuracy = 0.79777497
	valid_loss = 0.65734, valid_accuracy = 0.773
	time = 43.04 s
Validation loss decreased(0.66506---&gt;0.65734) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 23%|██▎       | 23/100 [16:35&lt;55:16, 43.07s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 8.7506e-02.
Epoch[22]:
	train_loss = 0.64972, train_accuracy = 0.7834
	valid_loss = 0.70566, valid_accuracy = 0.75959998
	time = 42.6 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 24%|██▍       | 24/100 [17:18&lt;54:31, 43.05s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 8.6448e-02.
Epoch[23]:
	train_loss = 0.63929, train_accuracy = 0.78889996
	valid_loss = 0.6805, valid_accuracy = 0.75949997
	time = 43.01 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 25%|██▌       | 25/100 [18:01&lt;53:55, 43.15s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 8.5355e-02.
Epoch[24]:
	train_loss = 0.63904, train_accuracy = 0.80135
	valid_loss = 0.65545, valid_accuracy = 0.77629995
	time = 43.32 s
Validation loss decreased(0.65734---&gt;0.65545) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 26%|██▌       | 26/100 [18:44&lt;52:59, 42.97s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 8.4227e-02.
Epoch[25]:
	train_loss = 0.62971, train_accuracy = 0.78314996
	valid_loss = 0.7047, valid_accuracy = 0.75909996
	time = 42.55 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 27%|██▋       | 27/100 [19:27&lt;52:21, 43.03s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 8.3066e-02.
Epoch[26]:
	train_loss = 0.62668, train_accuracy = 0.78417498
	valid_loss = 0.70802, valid_accuracy = 0.76229995
	time = 43.19 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 28%|██▊       | 28/100 [20:10&lt;51:36, 43.01s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 8.1871e-02.
Epoch[27]:
	train_loss = 0.61671, train_accuracy = 0.77934998
	valid_loss = 0.7071, valid_accuracy = 0.75129998
	time = 42.96 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 29%|██▉       | 29/100 [20:53&lt;50:49, 42.95s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 8.0645e-02.
Epoch[28]:
	train_loss = 0.61317, train_accuracy = 0.78462499
	valid_loss = 0.69071, valid_accuracy = 0.76249999
	time = 42.79 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 30%|███       | 30/100 [21:36&lt;50:06, 42.95s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 7.9389e-02.
Epoch[29]:
	train_loss = 0.61001, train_accuracy = 0.81002498
	valid_loss = 0.64528, valid_accuracy = 0.7791
	time = 42.92 s
Validation loss decreased(0.65545---&gt;0.64528) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 31%|███       | 31/100 [22:19&lt;49:34, 43.11s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 7.8104e-02.
Epoch[30]:
	train_loss = 0.61473, train_accuracy = 0.78944999
	valid_loss = 0.65777, valid_accuracy = 0.76709998
	time = 43.48 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 32%|███▏      | 32/100 [23:03&lt;48:51, 43.10s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 7.6791e-02.
Epoch[31]:
	train_loss = 0.60456, train_accuracy = 0.77919996
	valid_loss = 0.72694, valid_accuracy = 0.75150001
	time = 43.09 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 33%|███▎      | 33/100 [23:54&lt;51:05, 45.76s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 7.5452e-02.
Epoch[32]:
	train_loss = 0.59884, train_accuracy = 0.79717499
	valid_loss = 0.68488, valid_accuracy = 0.76769996
	time = 51.94 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 34%|███▍      | 34/100 [24:50&lt;53:32, 48.68s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 7.4088e-02.
Epoch[33]:
	train_loss = 0.59231, train_accuracy = 0.782125
	valid_loss = 0.69315, valid_accuracy = 0.75769997
	time = 55.49 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 35%|███▌      | 35/100 [25:44&lt;54:33, 50.36s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 7.2700e-02.
Epoch[34]:
	train_loss = 0.59197, train_accuracy = 0.81332499
	valid_loss = 0.63093, valid_accuracy = 0.78639996
	time = 54.23 s
Validation loss decreased(0.64528---&gt;0.63093) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 36%|███▌      | 36/100 [26:37&lt;54:20, 50.95s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 7.1289e-02.
Epoch[35]:
	train_loss = 0.57215, train_accuracy = 0.81474996
	valid_loss = 0.62699, valid_accuracy = 0.78319997
	time = 52.26 s
Validation loss decreased(0.63093---&gt;0.62699) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 37%|███▋      | 37/100 [27:29&lt;53:50, 51.27s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 6.9857e-02.
Epoch[36]:
	train_loss = 0.57959, train_accuracy = 0.8301
	valid_loss = 0.57708, valid_accuracy = 0.80109996
	time = 51.97 s
Validation loss decreased(0.62699---&gt;0.57708) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 38%|███▊      | 38/100 [28:18&lt;52:30, 50.82s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 6.8406e-02.
Epoch[37]:
	train_loss = 0.56943, train_accuracy = 0.82247496
	valid_loss = 0.59752, valid_accuracy = 0.7931
	time = 49.76 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 39%|███▉      | 39/100 [29:03&lt;49:44, 48.93s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 6.6937e-02.
Epoch[38]:
	train_loss = 0.5675, train_accuracy = 0.79782498
	valid_loss = 0.67157, valid_accuracy = 0.76839995
	time = 44.53 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 40%|████      | 40/100 [29:47&lt;47:36, 47.60s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 6.5451e-02.
Epoch[39]:
	train_loss = 0.55923, train_accuracy = 0.82157499
	valid_loss = 0.60654, valid_accuracy = 0.78969997
	time = 44.5 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 41%|████      | 41/100 [30:31&lt;45:45, 46.53s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 6.3950e-02.
Epoch[40]:
	train_loss = 0.55442, train_accuracy = 0.81847501
	valid_loss = 0.61489, valid_accuracy = 0.78490001
	time = 44.01 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 42%|████▏     | 42/100 [31:16&lt;44:18, 45.84s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 6.2434e-02.
Epoch[41]:
	train_loss = 0.54891, train_accuracy = 0.81584996
	valid_loss = 0.61335, valid_accuracy = 0.78619999
	time = 44.23 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 43%|████▎     | 43/100 [32:00&lt;43:06, 45.38s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 6.0907e-02.
Epoch[42]:
	train_loss = 0.53785, train_accuracy = 0.82674998
	valid_loss = 0.58634, valid_accuracy = 0.7942
	time = 44.31 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 44%|████▍     | 44/100 [32:44&lt;42:03, 45.06s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 5.9369e-02.
Epoch[43]:
	train_loss = 0.54445, train_accuracy = 0.81659997
	valid_loss = 0.61775, valid_accuracy = 0.78579998
	time = 44.3 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 45%|████▌     | 45/100 [33:29&lt;41:06, 44.85s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 5.7822e-02.
Epoch[44]:
	train_loss = 0.53092, train_accuracy = 0.82255
	valid_loss = 0.60888, valid_accuracy = 0.79179996
	time = 44.36 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 46%|████▌     | 46/100 [34:13&lt;40:12, 44.68s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 5.6267e-02.
Epoch[45]:
	train_loss = 0.52849, train_accuracy = 0.82835001
	valid_loss = 0.59471, valid_accuracy = 0.79619998
	time = 44.29 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 47%|████▋     | 47/100 [34:58&lt;39:32, 44.76s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 5.4705e-02.
Epoch[46]:
	train_loss = 0.51563, train_accuracy = 0.82744998
	valid_loss = 0.60452, valid_accuracy = 0.78939998
	time = 44.96 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 48%|████▊     | 48/100 [35:43&lt;38:49, 44.80s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 5.3140e-02.
Epoch[47]:
	train_loss = 0.51159, train_accuracy = 0.83252496
	valid_loss = 0.59414, valid_accuracy = 0.79809999
	time = 44.87 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 49%|████▉     | 49/100 [36:28&lt;38:09, 44.90s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 5.1571e-02.
Epoch[48]:
	train_loss = 0.50556, train_accuracy = 0.83452499
	valid_loss = 0.58509, valid_accuracy = 0.79960001
	time = 45.13 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 50%|█████     | 50/100 [37:14&lt;37:47, 45.34s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 5.0000e-02.
Epoch[49]:
	train_loss = 0.50417, train_accuracy = 0.84157497
	valid_loss = 0.56431, valid_accuracy = 0.8071
	time = 46.32 s
Validation loss decreased(0.57708---&gt;0.56431) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 51%|█████     | 51/100 [38:01&lt;37:29, 45.90s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 4.8429e-02.
Epoch[50]:
	train_loss = 0.49511, train_accuracy = 0.84759998
	valid_loss = 0.55223, valid_accuracy = 0.80860001
	time = 47.15 s
Validation loss decreased(0.56431---&gt;0.55223) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 52%|█████▏    | 52/100 [38:58&lt;39:10, 48.98s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 4.6860e-02.
Epoch[51]:
	train_loss = 0.48817, train_accuracy = 0.83579999
	valid_loss = 0.5918, valid_accuracy = 0.79789996
	time = 56.16 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 53%|█████▎    | 53/100 [40:00&lt;41:24, 52.87s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 4.5295e-02.
Epoch[52]:
	train_loss = 0.48168, train_accuracy = 0.83089995
	valid_loss = 0.60691, valid_accuracy = 0.79209995
	time = 61.93 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 54%|█████▍    | 54/100 [40:45&lt;38:45, 50.56s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 4.3733e-02.
Epoch[53]:
	train_loss = 0.47155, train_accuracy = 0.86272496
	valid_loss = 0.52494, valid_accuracy = 0.82119995
	time = 45.11 s
Validation loss decreased(0.55223---&gt;0.52494) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 55%|█████▌    | 55/100 [41:30&lt;36:39, 48.88s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 4.2178e-02.
Epoch[54]:
	train_loss = 0.46221, train_accuracy = 0.84969997
	valid_loss = 0.5695, valid_accuracy = 0.80849999
	time = 44.96 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 56%|█████▌    | 56/100 [42:15&lt;35:05, 47.85s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 4.0631e-02.
Epoch[55]:
	train_loss = 0.45945, train_accuracy = 0.848575
	valid_loss = 0.56365, valid_accuracy = 0.8021
	time = 45.44 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 57%|█████▋    | 57/100 [43:04&lt;34:24, 48.01s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 3.9093e-02.
Epoch[56]:
	train_loss = 0.45233, train_accuracy = 0.85462499
	valid_loss = 0.54917, valid_accuracy = 0.81110001
	time = 48.4 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 58%|█████▊    | 58/100 [43:53&lt;33:53, 48.41s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 3.7566e-02.
Epoch[57]:
	train_loss = 0.44023, train_accuracy = 0.8563
	valid_loss = 0.55827, valid_accuracy = 0.80729997
	time = 49.33 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 59%|█████▉    | 59/100 [44:41&lt;33:06, 48.45s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 3.6050e-02.
Epoch[58]:
	train_loss = 0.43795, train_accuracy = 0.86794996
	valid_loss = 0.50683, valid_accuracy = 0.8251
	time = 48.49 s
Validation loss decreased(0.52494---&gt;0.50683) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 60%|██████    | 60/100 [45:26&lt;31:34, 47.36s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 3.4549e-02.
Epoch[59]:
	train_loss = 0.43217, train_accuracy = 0.87512499
	valid_loss = 0.50155, valid_accuracy = 0.8272
	time = 44.77 s
Validation loss decreased(0.50683---&gt;0.50155) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 61%|██████    | 61/100 [46:10&lt;30:10, 46.42s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 3.3063e-02.
Epoch[60]:
	train_loss = 0.41977, train_accuracy = 0.85732496
	valid_loss = 0.56064, valid_accuracy = 0.80860001
	time = 44.23 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 62%|██████▏   | 62/100 [46:55&lt;29:03, 45.88s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 3.1594e-02.
Epoch[61]:
	train_loss = 0.40857, train_accuracy = 0.86127496
	valid_loss = 0.56228, valid_accuracy = 0.81079996
	time = 44.62 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 63%|██████▎   | 63/100 [47:41&lt;28:15, 45.81s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 3.0143e-02.
Epoch[62]:
	train_loss = 0.40013, train_accuracy = 0.87572497
	valid_loss = 0.52242, valid_accuracy = 0.82339996
	time = 45.66 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 64%|██████▍   | 64/100 [48:27&lt;27:29, 45.83s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 2.8711e-02.
Epoch[63]:
	train_loss = 0.39339, train_accuracy = 0.88017499
	valid_loss = 0.49088, valid_accuracy = 0.82909995
	time = 45.8 s
Validation loss decreased(0.50155---&gt;0.49088) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 65%|██████▌   | 65/100 [49:12&lt;26:39, 45.69s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 2.7300e-02.
Epoch[64]:
	train_loss = 0.38436, train_accuracy = 0.88664997
	valid_loss = 0.47992, valid_accuracy = 0.83499998
	time = 45.34 s
Validation loss decreased(0.49088---&gt;0.47992) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 66%|██████▌   | 66/100 [49:58&lt;25:56, 45.77s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 2.5912e-02.
Epoch[65]:
	train_loss = 0.37417, train_accuracy = 0.88264996
	valid_loss = 0.49566, valid_accuracy = 0.83069998
	time = 45.94 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 67%|██████▋   | 67/100 [50:43&lt;25:05, 45.61s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 2.4548e-02.
Epoch[66]:
	train_loss = 0.37086, train_accuracy = 0.87954998
	valid_loss = 0.5186, valid_accuracy = 0.82179999
	time = 45.23 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 68%|██████▊   | 68/100 [51:29&lt;24:21, 45.67s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 2.3209e-02.
Epoch[67]:
	train_loss = 0.35559, train_accuracy = 0.891325
	valid_loss = 0.48795, valid_accuracy = 0.83209997
	time = 45.81 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 69%|██████▉   | 69/100 [52:16&lt;23:50, 46.15s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 2.1896e-02.
Epoch[68]:
	train_loss = 0.35038, train_accuracy = 0.896375
	valid_loss = 0.47441, valid_accuracy = 0.8398
	time = 47.23 s
Validation loss decreased(0.47992---&gt;0.47441) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 70%|███████   | 70/100 [53:04&lt;23:21, 46.73s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 2.0611e-02.
Epoch[69]:
	train_loss = 0.33884, train_accuracy = 0.90314996
	valid_loss = 0.48143, valid_accuracy = 0.83669996
	time = 48.09 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 71%|███████   | 71/100 [53:53&lt;22:54, 47.39s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 1.9355e-02.
Epoch[70]:
	train_loss = 0.32795, train_accuracy = 0.90429997
	valid_loss = 0.47559, valid_accuracy = 0.84129995
	time = 48.91 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 72%|███████▏  | 72/100 [54:41&lt;22:12, 47.60s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 1.8129e-02.
Epoch[71]:
	train_loss = 0.32358, train_accuracy = 0.90477496
	valid_loss = 0.47753, valid_accuracy = 0.83629996
	time = 48.09 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 73%|███████▎  | 73/100 [55:27&lt;21:07, 46.94s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 1.6934e-02.
Epoch[72]:
	train_loss = 0.30881, train_accuracy = 0.91684997
	valid_loss = 0.45122, valid_accuracy = 0.84209996
	time = 45.35 s
Validation loss decreased(0.47441---&gt;0.45122) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 74%|███████▍  | 74/100 [56:15&lt;20:29, 47.29s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 1.5773e-02.
Epoch[73]:
	train_loss = 0.29596, train_accuracy = 0.91052496
	valid_loss = 0.48263, valid_accuracy = 0.83709997
	time = 48.11 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 75%|███████▌  | 75/100 [56:59&lt;19:19, 46.36s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 1.4645e-02.
Epoch[74]:
	train_loss = 0.28699, train_accuracy = 0.92095
	valid_loss = 0.43962, valid_accuracy = 0.84859997
	time = 44.15 s
Validation loss decreased(0.45122---&gt;0.43962) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 76%|███████▌  | 76/100 [57:42&lt;18:08, 45.34s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 1.3552e-02.
Epoch[75]:
	train_loss = 0.2746, train_accuracy = 0.91872495
	valid_loss = 0.46702, valid_accuracy = 0.84679997
	time = 42.96 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 77%|███████▋  | 77/100 [58:25&lt;17:08, 44.72s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 1.2494e-02.
Epoch[76]:
	train_loss = 0.26294, train_accuracy = 0.93254995
	valid_loss = 0.43192, valid_accuracy = 0.85359997
	time = 43.22 s
Validation loss decreased(0.43962---&gt;0.43192) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 78%|███████▊  | 78/100 [59:09&lt;16:17, 44.43s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 1.1474e-02.
Epoch[77]:
	train_loss = 0.2561, train_accuracy = 0.93304998
	valid_loss = 0.44362, valid_accuracy = 0.85229999
	time = 43.75 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 79%|███████▉  | 79/100 [59:53&lt;15:32, 44.38s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 1.0492e-02.
Epoch[78]:
	train_loss = 0.23781, train_accuracy = 0.9411
	valid_loss = 0.43426, valid_accuracy = 0.85579997
	time = 44.27 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 80%|████████  | 80/100 [1:00:37&lt;14:43, 44.15s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.5492e-03.
Epoch[79]:
	train_loss = 0.22595, train_accuracy = 0.93672496
	valid_loss = 0.45123, valid_accuracy = 0.84939998
	time = 43.61 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 81%|████████  | 81/100 [1:01:21&lt;14:00, 44.23s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 8.6460e-03.
Epoch[80]:
	train_loss = 0.21833, train_accuracy = 0.94707495
	valid_loss = 0.44036, valid_accuracy = 0.85429996
	time = 44.43 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 82%|████████▏ | 82/100 [1:02:05&lt;13:11, 43.98s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 7.7836e-03.
Epoch[81]:
	train_loss = 0.20584, train_accuracy = 0.94755
	valid_loss = 0.44097, valid_accuracy = 0.85600001
	time = 43.37 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 83%|████████▎ | 83/100 [1:02:49&lt;12:27, 43.95s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 6.9629e-03.
Epoch[82]:
	train_loss = 0.19043, train_accuracy = 0.95642495
	valid_loss = 0.43709, valid_accuracy = 0.85600001
	time = 43.88 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 84%|████████▍ | 84/100 [1:03:33&lt;11:46, 44.13s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 6.1847e-03.
Epoch[83]:
	train_loss = 0.17956, train_accuracy = 0.95999998
	valid_loss = 0.42898, valid_accuracy = 0.86109996
	time = 44.49 s
Validation loss decreased(0.43192---&gt;0.42898) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 85%|████████▌ | 85/100 [1:04:17&lt;10:59, 43.96s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 5.4497e-03.
Epoch[84]:
	train_loss = 0.16746, train_accuracy = 0.964625
	valid_loss = 0.42307, valid_accuracy = 0.8642
	time = 43.51 s
Validation loss decreased(0.42898---&gt;0.42307) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 86%|████████▌ | 86/100 [1:05:00&lt;10:12, 43.75s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 4.7586e-03.
Epoch[85]:
	train_loss = 0.15605, train_accuracy = 0.969675
	valid_loss = 0.42982, valid_accuracy = 0.86609995
	time = 43.26 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 87%|████████▋ | 87/100 [1:05:43&lt;09:27, 43.68s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 4.1123e-03.
Epoch[86]:
	train_loss = 0.14795, train_accuracy = 0.97509998
	valid_loss = 0.43056, valid_accuracy = 0.86379999
	time = 43.52 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 88%|████████▊ | 88/100 [1:06:28&lt;08:46, 43.84s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 3.5112e-03.
Epoch[87]:
	train_loss = 0.13057, train_accuracy = 0.97789997
	valid_loss = 0.43339, valid_accuracy = 0.86609995
	time = 44.2 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 89%|████████▉ | 89/100 [1:07:11&lt;08:00, 43.72s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 2.9560e-03.
Epoch[88]:
	train_loss = 0.12369, train_accuracy = 0.98025
	valid_loss = 0.43179, valid_accuracy = 0.86799997
	time = 43.46 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 90%|█████████ | 90/100 [1:07:59&lt;07:29, 44.92s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 2.4472e-03.
Epoch[89]:
	train_loss = 0.11219, train_accuracy = 0.98357499
	valid_loss = 0.43678, valid_accuracy = 0.87
	time = 47.72 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 91%|█████████ | 91/100 [1:08:45&lt;06:47, 45.23s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 1.9853e-03.
Epoch[90]:
	train_loss = 0.10538, train_accuracy = 0.98627496
	valid_loss = 0.43542, valid_accuracy = 0.86739999
	time = 45.94 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 92%|█████████▏| 92/100 [1:09:33&lt;06:10, 46.27s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 1.5708e-03.
Epoch[91]:
	train_loss = 0.10003, train_accuracy = 0.98677498
	valid_loss = 0.43498, valid_accuracy = 0.86809999
	time = 48.71 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 93%|█████████▎| 93/100 [1:10:27&lt;05:39, 48.54s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 1.2042e-03.
Epoch[92]:
	train_loss = 0.09421, train_accuracy = 0.98954999
	valid_loss = 0.44329, valid_accuracy = 0.86729997
	time = 53.84 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 94%|█████████▍| 94/100 [1:11:14&lt;04:48, 48.12s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 8.8564e-04.
Epoch[93]:
	train_loss = 0.08901, train_accuracy = 0.98989999
	valid_loss = 0.44572, valid_accuracy = 0.86879998
	time = 47.15 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 95%|█████████▌| 95/100 [1:12:00&lt;03:57, 47.45s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 6.1558e-04.
Epoch[94]:
	train_loss = 0.08263, train_accuracy = 0.99175
	valid_loss = 0.4404, valid_accuracy = 0.87029999
	time = 45.88 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 96%|█████████▌| 96/100 [1:12:46&lt;03:07, 46.81s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 3.9426e-04.
Epoch[95]:
	train_loss = 0.07783, train_accuracy = 0.99267495
	valid_loss = 0.43668, valid_accuracy = 0.87019998
	time = 45.32 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 97%|█████████▋| 97/100 [1:13:32&lt;02:19, 46.53s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 2.2190e-04.
Epoch[96]:
	train_loss = 0.07358, train_accuracy = 0.99219996
	valid_loss = 0.44238, valid_accuracy = 0.8682
	time = 45.87 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 98%|█████████▊| 98/100 [1:14:16&lt;01:31, 45.99s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.8664e-05.
Epoch[97]:
	train_loss = 0.0736, train_accuracy = 0.99309999
	valid_loss = 0.44042, valid_accuracy = 0.87019998
	time = 44.74 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 99%|█████████▉| 99/100 [1:15:00&lt;00:45, 45.17s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 2.4672e-05.
Epoch[98]:
	train_loss = 0.07111, train_accuracy = 0.99282497
	valid_loss = 0.44471, valid_accuracy = 0.86989999
	time = 43.24 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 99%|█████████▉| 99/100 [1:15:43&lt;00:45, 45.89s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 0.0000e+00.
Epoch[99]:
	train_loss = 0.07279, train_accuracy = 0.99312496
	valid_loss = 0.44638, valid_accuracy = 0.86909997
	time = 43.48 s
Validation loss didn't decrease for 15 epochs ---&gt; model training stopped
[Finished training]
	valid training loss: 0.16746
	valid training accuracy 0.964625
	min validation loss: 0.42307,
	best validation accuracy: 0.8642
Model[EfficientNet] - partial training (last layer) / model_weights
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>
<span class="ansi-red-intense-fg ansi-bold">---------------------------------------------------------------------------</span>
<span class="ansi-red-intense-fg ansi-bold">TypeError</span>                                 Traceback (most recent call last)
<span class="ansi-green-intense-fg ansi-bold">c:\Users\marem\dev\projects\unn\deep-learning\lab2\unn_year_2_deeplearning_lab_2.ipynb Cell 12</span> line <span class="ansi-cyan-fg">9
</span><span class="ansi-green-fg">      &lt;a href='vscode-notebook-cell:/c%3A/Users/marem/dev/projects/unn/deep-learning/lab2/unn_year_2_deeplearning_lab_2.ipynb#X14sZmlsZQ%3D%3D?line=6'&gt;7&lt;/a&gt;</span> model_names = [model.__class__.__name__ for model in models]
<span class="ansi-green-fg">      &lt;a href='vscode-notebook-cell:/c%3A/Users/marem/dev/projects/unn/deep-learning/lab2/unn_year_2_deeplearning_lab_2.ipynb#X14sZmlsZQ%3D%3D?line=7'&gt;8&lt;/a&gt;</span> for model, model_name in zip(models, model_names):
<span class="ansi-green-intense-fg ansi-bold">----&gt; &lt;a href='vscode-notebook-cell:/c%3A/Users/marem/dev/projects/unn/deep-learning/lab2/unn_year_2_deeplearning_lab_2.ipynb#X14sZmlsZQ%3D%3D?line=8'&gt;9&lt;/a&gt;</span>     model_results(model, model_name, 100)

<span class="ansi-green-intense-fg ansi-bold">c:\Users\marem\dev\projects\unn\deep-learning\lab2\unn_year_2_deeplearning_lab_2.ipynb Cell 12</span> line <span class="ansi-cyan-fg">4
</span><span class="ansi-green-fg">     &lt;a href='vscode-notebook-cell:/c%3A/Users/marem/dev/projects/unn/deep-learning/lab2/unn_year_2_deeplearning_lab_2.ipynb#X14sZmlsZQ%3D%3D?line=45'&gt;46&lt;/a&gt;</span> print(f'Model[{model_name}] - partial training (last layer) / {weight_type}')
<span class="ansi-green-fg">     &lt;a href='vscode-notebook-cell:/c%3A/Users/marem/dev/projects/unn/deep-learning/lab2/unn_year_2_deeplearning_lab_2.ipynb#X14sZmlsZQ%3D%3D?line=46'&gt;47&lt;/a&gt;</span> model_partial = copy.deepcopy(model) # for partial training
<span class="ansi-green-intense-fg ansi-bold">---&gt; &lt;a href='vscode-notebook-cell:/c%3A/Users/marem/dev/projects/unn/deep-learning/lab2/unn_year_2_deeplearning_lab_2.ipynb#X14sZmlsZQ%3D%3D?line=47'&gt;48&lt;/a&gt;</span> make_freeze(model_partial)
<span class="ansi-green-fg">     &lt;a href='vscode-notebook-cell:/c%3A/Users/marem/dev/projects/unn/deep-learning/lab2/unn_year_2_deeplearning_lab_2.ipynb#X14sZmlsZQ%3D%3D?line=48'&gt;49&lt;/a&gt;</span> make_viz(model_partial, model_name + '_partial')
<span class="ansi-green-fg">     &lt;a href='vscode-notebook-cell:/c%3A/Users/marem/dev/projects/unn/deep-learning/lab2/unn_year_2_deeplearning_lab_2.ipynb#X14sZmlsZQ%3D%3D?line=49'&gt;50&lt;/a&gt;</span> model_training(model_partial, model_name + '_partial', num_epochs, True)

<span class="ansi-red-intense-fg ansi-bold">TypeError</span>: make_freeze() missing 1 required positional argument: 'model_name'</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>================================================================================
Model[EfficientNet] last FC before mod: Linear(in_features=1280, out_features=1000, bias=True)
Model[EfficientNet] last FC after mod: Linear(in_features=1280, out_features=10, bias=True)
Model[EfficientNet] - full training / model_weights
Adjusting learning rate of group 0 to 1.0000e-01.
0%|          | 0/100 [00:00&lt;?, ?it/s]
#############################################################################################
[Training parameters]
epochs = 100,
lr = 0.1,
momentum = 0.9,
weight_decay = 0.0005,
loss = CrossEntropyLoss(),
optimizer = SGD (
Parameter Group 0
dampening: 0
differentiable: False
foreach: None
initial_lr: 0.1
lr: 0.1
maximize: False
momentum: 0.9
nesterov: False
weight_decay: 0.0005
),
scheduler = &lt;torch.optim.lr_scheduler.CosineAnnealingLR object at 0x0000026820613D60&gt;,
device = cuda:0
#############################################################################################
1%|          | 1/100 [00:47&lt;1:17:42, 47.09s/it]
Adjusting learning rate of group 0 to 9.9975e-02.
Epoch[0]:
train_loss = 1.62188, train_accuracy = 0.550825
valid_loss = 1.24034, valid_accuracy = 0.54689997
time = 47.04 s
Validation loss decreased(None---&gt;1.24034) 	 Saving The Model
2%|▏         | 2/100 [01:31&lt;1:14:21, 45.53s/it]
Adjusting learning rate of group 0 to 9.9901e-02.
Epoch[1]:
train_loss = 1.08278, train_accuracy = 0.68072498
valid_loss = 0.93042, valid_accuracy = 0.67219996
time = 44.39 s
Validation loss decreased(1.24034---&gt;0.93042) 	 Saving The Model
3%|▎         | 3/100 [02:14&lt;1:11:59, 44.53s/it]
Adjusting learning rate of group 0 to 9.9778e-02.
Epoch[2]:
train_loss = 0.88205, train_accuracy = 0.72235
valid_loss = 0.8342, valid_accuracy = 0.70309997
time = 43.3 s
Validation loss decreased(0.93042---&gt;0.8342) 	 Saving The Model
4%|▍         | 4/100 [02:58&lt;1:10:34, 44.10s/it]
Adjusting learning rate of group 0 to 9.9606e-02.
Epoch[3]:
train_loss = 0.77413, train_accuracy = 0.75657499
valid_loss = 0.7625, valid_accuracy = 0.73969996
time = 43.41 s
Validation loss decreased(0.8342---&gt;0.7625) 	 Saving The Model
5%|▌         | 5/100 [03:42&lt;1:09:44, 44.05s/it]
Adjusting learning rate of group 0 to 9.9384e-02.
Epoch[4]:
train_loss = 0.7727, train_accuracy = 0.76317495
valid_loss = 0.73857, valid_accuracy = 0.74719995
time = 43.9 s
Validation loss decreased(0.7625---&gt;0.73857) 	 Saving The Model
6%|▌         | 6/100 [04:24&lt;1:08:15, 43.57s/it]
Adjusting learning rate of group 0 to 9.9114e-02.
Epoch[5]:
train_loss = 0.71413, train_accuracy = 0.75567496
valid_loss = 0.76065, valid_accuracy = 0.73589998
time = 42.65 s
7%|▋         | 7/100 [05:07&lt;1:07:07, 43.31s/it]
Adjusting learning rate of group 0 to 9.8796e-02.
Epoch[6]:
train_loss = 0.67811, train_accuracy = 0.76442498
valid_loss = 0.719, valid_accuracy = 0.74469995
time = 42.71 s
Validation loss decreased(0.73857---&gt;0.719) 	 Saving The Model
8%|▊         | 8/100 [05:50&lt;1:06:03, 43.08s/it]
Adjusting learning rate of group 0 to 9.8429e-02.
Epoch[7]:
train_loss = 0.66111, train_accuracy = 0.777125
valid_loss = 0.69988, valid_accuracy = 0.75389999
time = 42.56 s
Validation loss decreased(0.719---&gt;0.69988) 	 Saving The Model
9%|▉         | 9/100 [06:32&lt;1:05:05, 42.92s/it]
Adjusting learning rate of group 0 to 9.8015e-02.
Epoch[8]:
train_loss = 0.66782, train_accuracy = 0.77887499
valid_loss = 0.70652, valid_accuracy = 0.7568
time = 42.55 s
10%|█         | 10/100 [07:15&lt;1:04:18, 42.87s/it]
Adjusting learning rate of group 0 to 9.7553e-02.
Epoch[9]:
train_loss = 0.67469, train_accuracy = 0.759
valid_loss = 0.73918, valid_accuracy = 0.73869997
time = 42.78 s
11%|█         | 11/100 [07:58&lt;1:03:38, 42.90s/it]
Adjusting learning rate of group 0 to 9.7044e-02.
Epoch[10]:
train_loss = 0.66986, train_accuracy = 0.75177497
valid_loss = 0.77331, valid_accuracy = 0.73449999
time = 42.97 s
12%|█▏        | 12/100 [08:41&lt;1:02:52, 42.87s/it]
Adjusting learning rate of group 0 to 9.6489e-02.
Epoch[11]:
train_loss = 0.6734, train_accuracy = 0.78824997
valid_loss = 0.66506, valid_accuracy = 0.77349997
time = 42.74 s
Validation loss decreased(0.69988---&gt;0.66506) 	 Saving The Model
13%|█▎        | 13/100 [09:24&lt;1:02:16, 42.95s/it]
Adjusting learning rate of group 0 to 9.5888e-02.
Epoch[12]:
train_loss = 0.67448, train_accuracy = 0.75207496
valid_loss = 0.73751, valid_accuracy = 0.73199999
time = 43.13 s
14%|█▍        | 14/100 [10:07&lt;1:01:37, 43.00s/it]
Adjusting learning rate of group 0 to 9.5241e-02.
Epoch[13]:
train_loss = 0.67044, train_accuracy = 0.78882498
valid_loss = 0.66915, valid_accuracy = 0.77029997
time = 43.11 s
15%|█▌        | 15/100 [10:50&lt;1:00:52, 42.97s/it]
Adjusting learning rate of group 0 to 9.4550e-02.
Epoch[14]:
train_loss = 0.6668, train_accuracy = 0.75762498
valid_loss = 0.7651, valid_accuracy = 0.73399997
time = 42.9 s
16%|█▌        | 16/100 [11:33&lt;1:00:20, 43.11s/it]
Adjusting learning rate of group 0 to 9.3815e-02.
Epoch[15]:
train_loss = 0.6671, train_accuracy = 0.73927498
valid_loss = 0.83764, valid_accuracy = 0.72359997
time = 43.43 s
17%|█▋        | 17/100 [12:16&lt;59:33, 43.05s/it]<br/>
Adjusting learning rate of group 0 to 9.3037e-02.
Epoch[16]:
train_loss = 0.66145, train_accuracy = 0.76854998
valid_loss = 0.7218, valid_accuracy = 0.74659997
time = 42.93 s
18%|█▊        | 18/100 [12:59&lt;58:39, 42.92s/it]
Adjusting learning rate of group 0 to 9.2216e-02.
Epoch[17]:
train_loss = 0.66202, train_accuracy = 0.76702499
valid_loss = 0.72927, valid_accuracy = 0.745
time = 42.61 s
19%|█▉        | 19/100 [13:42&lt;57:54, 42.90s/it]
Adjusting learning rate of group 0 to 9.1354e-02.
Epoch[18]:
train_loss = 0.6622, train_accuracy = 0.76362497
valid_loss = 0.7639, valid_accuracy = 0.7367
time = 42.84 s
20%|██        | 20/100 [14:26&lt;57:36, 43.20s/it]
Adjusting learning rate of group 0 to 9.0451e-02.
Epoch[19]:
train_loss = 0.66608, train_accuracy = 0.729375
valid_loss = 0.87947, valid_accuracy = 0.70300001
time = 43.92 s
21%|██        | 21/100 [15:09&lt;57:04, 43.34s/it]
Adjusting learning rate of group 0 to 8.9508e-02.
Epoch[20]:
train_loss = 0.64884, train_accuracy = 0.79467499
valid_loss = 0.67362, valid_accuracy = 0.76739997
time = 43.67 s
22%|██▏       | 22/100 [15:53&lt;56:15, 43.27s/it]
Adjusting learning rate of group 0 to 8.8526e-02.
Epoch[21]:
train_loss = 0.65247, train_accuracy = 0.79777497
valid_loss = 0.65734, valid_accuracy = 0.773
time = 43.04 s
Validation loss decreased(0.66506---&gt;0.65734) 	 Saving The Model
23%|██▎       | 23/100 [16:35&lt;55:16, 43.07s/it]
Adjusting learning rate of group 0 to 8.7506e-02.
Epoch[22]:
train_loss = 0.64972, train_accuracy = 0.7834
valid_loss = 0.70566, valid_accuracy = 0.75959998
time = 42.6 s
24%|██▍       | 24/100 [17:18&lt;54:31, 43.05s/it]
Adjusting learning rate of group 0 to 8.6448e-02.
Epoch[23]:
train_loss = 0.63929, train_accuracy = 0.78889996
valid_loss = 0.6805, valid_accuracy = 0.75949997
time = 43.01 s
25%|██▌       | 25/100 [18:01&lt;53:55, 43.15s/it]
Adjusting learning rate of group 0 to 8.5355e-02.
Epoch[24]:
train_loss = 0.63904, train_accuracy = 0.80135
valid_loss = 0.65545, valid_accuracy = 0.77629995
time = 43.32 s
Validation loss decreased(0.65734---&gt;0.65545) 	 Saving The Model
26%|██▌       | 26/100 [18:44&lt;52:59, 42.97s/it]
Adjusting learning rate of group 0 to 8.4227e-02.
Epoch[25]:
train_loss = 0.62971, train_accuracy = 0.78314996
valid_loss = 0.7047, valid_accuracy = 0.75909996
time = 42.55 s
27%|██▋       | 27/100 [19:27&lt;52:21, 43.03s/it]
Adjusting learning rate of group 0 to 8.3066e-02.
Epoch[26]:
train_loss = 0.62668, train_accuracy = 0.78417498
valid_loss = 0.70802, valid_accuracy = 0.76229995
time = 43.19 s
28%|██▊       | 28/100 [20:10&lt;51:36, 43.01s/it]
Adjusting learning rate of group 0 to 8.1871e-02.
Epoch[27]:
train_loss = 0.61671, train_accuracy = 0.77934998
valid_loss = 0.7071, valid_accuracy = 0.75129998
time = 42.96 s
29%|██▉       | 29/100 [20:53&lt;50:49, 42.95s/it]
Adjusting learning rate of group 0 to 8.0645e-02.
Epoch[28]:
train_loss = 0.61317, train_accuracy = 0.78462499
valid_loss = 0.69071, valid_accuracy = 0.76249999
time = 42.79 s
30%|███       | 30/100 [21:36&lt;50:06, 42.95s/it]
Adjusting learning rate of group 0 to 7.9389e-02.
Epoch[29]:
train_loss = 0.61001, train_accuracy = 0.81002498
valid_loss = 0.64528, valid_accuracy = 0.7791
time = 42.92 s
Validation loss decreased(0.65545---&gt;0.64528) 	 Saving The Model
31%|███       | 31/100 [22:19&lt;49:34, 43.11s/it]
Adjusting learning rate of group 0 to 7.8104e-02.
Epoch[30]:
train_loss = 0.61473, train_accuracy = 0.78944999
valid_loss = 0.65777, valid_accuracy = 0.76709998
time = 43.48 s
32%|███▏      | 32/100 [23:03&lt;48:51, 43.10s/it]
Adjusting learning rate of group 0 to 7.6791e-02.
Epoch[31]:
train_loss = 0.60456, train_accuracy = 0.77919996
valid_loss = 0.72694, valid_accuracy = 0.75150001
time = 43.09 s
33%|███▎      | 33/100 [23:54&lt;51:05, 45.76s/it]
Adjusting learning rate of group 0 to 7.5452e-02.
Epoch[32]:
train_loss = 0.59884, train_accuracy = 0.79717499
valid_loss = 0.68488, valid_accuracy = 0.76769996
time = 51.94 s
34%|███▍      | 34/100 [24:50&lt;53:32, 48.68s/it]
Adjusting learning rate of group 0 to 7.4088e-02.
Epoch[33]:
train_loss = 0.59231, train_accuracy = 0.782125
valid_loss = 0.69315, valid_accuracy = 0.75769997
time = 55.49 s
35%|███▌      | 35/100 [25:44&lt;54:33, 50.36s/it]
Adjusting learning rate of group 0 to 7.2700e-02.
Epoch[34]:
train_loss = 0.59197, train_accuracy = 0.81332499
valid_loss = 0.63093, valid_accuracy = 0.78639996
time = 54.23 s
Validation loss decreased(0.64528---&gt;0.63093) 	 Saving The Model
36%|███▌      | 36/100 [26:37&lt;54:20, 50.95s/it]
Adjusting learning rate of group 0 to 7.1289e-02.
Epoch[35]:
train_loss = 0.57215, train_accuracy = 0.81474996
valid_loss = 0.62699, valid_accuracy = 0.78319997
time = 52.26 s
Validation loss decreased(0.63093---&gt;0.62699) 	 Saving The Model
37%|███▋      | 37/100 [27:29&lt;53:50, 51.27s/it]
Adjusting learning rate of group 0 to 6.9857e-02.
Epoch[36]:
train_loss = 0.57959, train_accuracy = 0.8301
valid_loss = 0.57708, valid_accuracy = 0.80109996
time = 51.97 s
Validation loss decreased(0.62699---&gt;0.57708) 	 Saving The Model
38%|███▊      | 38/100 [28:18&lt;52:30, 50.82s/it]
Adjusting learning rate of group 0 to 6.8406e-02.
Epoch[37]:
train_loss = 0.56943, train_accuracy = 0.82247496
valid_loss = 0.59752, valid_accuracy = 0.7931
time = 49.76 s
39%|███▉      | 39/100 [29:03&lt;49:44, 48.93s/it]
Adjusting learning rate of group 0 to 6.6937e-02.
Epoch[38]:
train_loss = 0.5675, train_accuracy = 0.79782498
valid_loss = 0.67157, valid_accuracy = 0.76839995
time = 44.53 s
40%|████      | 40/100 [29:47&lt;47:36, 47.60s/it]
Adjusting learning rate of group 0 to 6.5451e-02.
Epoch[39]:
train_loss = 0.55923, train_accuracy = 0.82157499
valid_loss = 0.60654, valid_accuracy = 0.78969997
time = 44.5 s
41%|████      | 41/100 [30:31&lt;45:45, 46.53s/it]
Adjusting learning rate of group 0 to 6.3950e-02.
Epoch[40]:
train_loss = 0.55442, train_accuracy = 0.81847501
valid_loss = 0.61489, valid_accuracy = 0.78490001
time = 44.01 s
42%|████▏     | 42/100 [31:16&lt;44:18, 45.84s/it]
Adjusting learning rate of group 0 to 6.2434e-02.
Epoch[41]:
train_loss = 0.54891, train_accuracy = 0.81584996
valid_loss = 0.61335, valid_accuracy = 0.78619999
time = 44.23 s
43%|████▎     | 43/100 [32:00&lt;43:06, 45.38s/it]
Adjusting learning rate of group 0 to 6.0907e-02.
Epoch[42]:
train_loss = 0.53785, train_accuracy = 0.82674998
valid_loss = 0.58634, valid_accuracy = 0.7942
time = 44.31 s
44%|████▍     | 44/100 [32:44&lt;42:03, 45.06s/it]
Adjusting learning rate of group 0 to 5.9369e-02.
Epoch[43]:
train_loss = 0.54445, train_accuracy = 0.81659997
valid_loss = 0.61775, valid_accuracy = 0.78579998
time = 44.3 s
45%|████▌     | 45/100 [33:29&lt;41:06, 44.85s/it]
Adjusting learning rate of group 0 to 5.7822e-02.
Epoch[44]:
train_loss = 0.53092, train_accuracy = 0.82255
valid_loss = 0.60888, valid_accuracy = 0.79179996
time = 44.36 s
46%|████▌     | 46/100 [34:13&lt;40:12, 44.68s/it]
Adjusting learning rate of group 0 to 5.6267e-02.
Epoch[45]:
train_loss = 0.52849, train_accuracy = 0.82835001
valid_loss = 0.59471, valid_accuracy = 0.79619998
time = 44.29 s
47%|████▋     | 47/100 [34:58&lt;39:32, 44.76s/it]
Adjusting learning rate of group 0 to 5.4705e-02.
Epoch[46]:
train_loss = 0.51563, train_accuracy = 0.82744998
valid_loss = 0.60452, valid_accuracy = 0.78939998
time = 44.96 s
48%|████▊     | 48/100 [35:43&lt;38:49, 44.80s/it]
Adjusting learning rate of group 0 to 5.3140e-02.
Epoch[47]:
train_loss = 0.51159, train_accuracy = 0.83252496
valid_loss = 0.59414, valid_accuracy = 0.79809999
time = 44.87 s
49%|████▉     | 49/100 [36:28&lt;38:09, 44.90s/it]
Adjusting learning rate of group 0 to 5.1571e-02.
Epoch[48]:
train_loss = 0.50556, train_accuracy = 0.83452499
valid_loss = 0.58509, valid_accuracy = 0.79960001
time = 45.13 s
50%|█████     | 50/100 [37:14&lt;37:47, 45.34s/it]
Adjusting learning rate of group 0 to 5.0000e-02.
Epoch[49]:
train_loss = 0.50417, train_accuracy = 0.84157497
valid_loss = 0.56431, valid_accuracy = 0.8071
time = 46.32 s
Validation loss decreased(0.57708---&gt;0.56431) 	 Saving The Model
51%|█████     | 51/100 [38:01&lt;37:29, 45.90s/it]
Adjusting learning rate of group 0 to 4.8429e-02.
Epoch[50]:
train_loss = 0.49511, train_accuracy = 0.84759998
valid_loss = 0.55223, valid_accuracy = 0.80860001
time = 47.15 s
Validation loss decreased(0.56431---&gt;0.55223) 	 Saving The Model
52%|█████▏    | 52/100 [38:58&lt;39:10, 48.98s/it]
Adjusting learning rate of group 0 to 4.6860e-02.
Epoch[51]:
train_loss = 0.48817, train_accuracy = 0.83579999
valid_loss = 0.5918, valid_accuracy = 0.79789996
time = 56.16 s
53%|█████▎    | 53/100 [40:00&lt;41:24, 52.87s/it]
Adjusting learning rate of group 0 to 4.5295e-02.
Epoch[52]:
train_loss = 0.48168, train_accuracy = 0.83089995
valid_loss = 0.60691, valid_accuracy = 0.79209995
time = 61.93 s
54%|█████▍    | 54/100 [40:45&lt;38:45, 50.56s/it]
Adjusting learning rate of group 0 to 4.3733e-02.
Epoch[53]:
train_loss = 0.47155, train_accuracy = 0.86272496
valid_loss = 0.52494, valid_accuracy = 0.82119995
time = 45.11 s
Validation loss decreased(0.55223---&gt;0.52494) 	 Saving The Model
55%|█████▌    | 55/100 [41:30&lt;36:39, 48.88s/it]
Adjusting learning rate of group 0 to 4.2178e-02.
Epoch[54]:
train_loss = 0.46221, train_accuracy = 0.84969997
valid_loss = 0.5695, valid_accuracy = 0.80849999
time = 44.96 s
56%|█████▌    | 56/100 [42:15&lt;35:05, 47.85s/it]
Adjusting learning rate of group 0 to 4.0631e-02.
Epoch[55]:
train_loss = 0.45945, train_accuracy = 0.848575
valid_loss = 0.56365, valid_accuracy = 0.8021
time = 45.44 s
57%|█████▋    | 57/100 [43:04&lt;34:24, 48.01s/it]
Adjusting learning rate of group 0 to 3.9093e-02.
Epoch[56]:
train_loss = 0.45233, train_accuracy = 0.85462499
valid_loss = 0.54917, valid_accuracy = 0.81110001
time = 48.4 s
58%|█████▊    | 58/100 [43:53&lt;33:53, 48.41s/it]
Adjusting learning rate of group 0 to 3.7566e-02.
Epoch[57]:
train_loss = 0.44023, train_accuracy = 0.8563
valid_loss = 0.55827, valid_accuracy = 0.80729997
time = 49.33 s
59%|█████▉    | 59/100 [44:41&lt;33:06, 48.45s/it]
Adjusting learning rate of group 0 to 3.6050e-02.
Epoch[58]:
train_loss = 0.43795, train_accuracy = 0.86794996
valid_loss = 0.50683, valid_accuracy = 0.8251
time = 48.49 s
Validation loss decreased(0.52494---&gt;0.50683) 	 Saving The Model
60%|██████    | 60/100 [45:26&lt;31:34, 47.36s/it]
Adjusting learning rate of group 0 to 3.4549e-02.
Epoch[59]:
train_loss = 0.43217, train_accuracy = 0.87512499
valid_loss = 0.50155, valid_accuracy = 0.8272
time = 44.77 s
Validation loss decreased(0.50683---&gt;0.50155) 	 Saving The Model
61%|██████    | 61/100 [46:10&lt;30:10, 46.42s/it]
Adjusting learning rate of group 0 to 3.3063e-02.
Epoch[60]:
train_loss = 0.41977, train_accuracy = 0.85732496
valid_loss = 0.56064, valid_accuracy = 0.80860001
time = 44.23 s
62%|██████▏   | 62/100 [46:55&lt;29:03, 45.88s/it]
Adjusting learning rate of group 0 to 3.1594e-02.
Epoch[61]:
train_loss = 0.40857, train_accuracy = 0.86127496
valid_loss = 0.56228, valid_accuracy = 0.81079996
time = 44.62 s
63%|██████▎   | 63/100 [47:41&lt;28:15, 45.81s/it]
Adjusting learning rate of group 0 to 3.0143e-02.
Epoch[62]:
train_loss = 0.40013, train_accuracy = 0.87572497
valid_loss = 0.52242, valid_accuracy = 0.82339996
time = 45.66 s
64%|██████▍   | 64/100 [48:27&lt;27:29, 45.83s/it]
Adjusting learning rate of group 0 to 2.8711e-02.
Epoch[63]:
train_loss = 0.39339, train_accuracy = 0.88017499
valid_loss = 0.49088, valid_accuracy = 0.82909995
time = 45.8 s
Validation loss decreased(0.50155---&gt;0.49088) 	 Saving The Model
65%|██████▌   | 65/100 [49:12&lt;26:39, 45.69s/it]
Adjusting learning rate of group 0 to 2.7300e-02.
Epoch[64]:
train_loss = 0.38436, train_accuracy = 0.88664997
valid_loss = 0.47992, valid_accuracy = 0.83499998
time = 45.34 s
Validation loss decreased(0.49088---&gt;0.47992) 	 Saving The Model
66%|██████▌   | 66/100 [49:58&lt;25:56, 45.77s/it]
Adjusting learning rate of group 0 to 2.5912e-02.
Epoch[65]:
train_loss = 0.37417, train_accuracy = 0.88264996
valid_loss = 0.49566, valid_accuracy = 0.83069998
time = 45.94 s
67%|██████▋   | 67/100 [50:43&lt;25:05, 45.61s/it]
Adjusting learning rate of group 0 to 2.4548e-02.
Epoch[66]:
train_loss = 0.37086, train_accuracy = 0.87954998
valid_loss = 0.5186, valid_accuracy = 0.82179999
time = 45.23 s
68%|██████▊   | 68/100 [51:29&lt;24:21, 45.67s/it]
Adjusting learning rate of group 0 to 2.3209e-02.
Epoch[67]:
train_loss = 0.35559, train_accuracy = 0.891325
valid_loss = 0.48795, valid_accuracy = 0.83209997
time = 45.81 s
69%|██████▉   | 69/100 [52:16&lt;23:50, 46.15s/it]
Adjusting learning rate of group 0 to 2.1896e-02.
Epoch[68]:
train_loss = 0.35038, train_accuracy = 0.896375
valid_loss = 0.47441, valid_accuracy = 0.8398
time = 47.23 s
Validation loss decreased(0.47992---&gt;0.47441) 	 Saving The Model
70%|███████   | 70/100 [53:04&lt;23:21, 46.73s/it]
Adjusting learning rate of group 0 to 2.0611e-02.
Epoch[69]:
train_loss = 0.33884, train_accuracy = 0.90314996
valid_loss = 0.48143, valid_accuracy = 0.83669996
time = 48.09 s
71%|███████   | 71/100 [53:53&lt;22:54, 47.39s/it]
Adjusting learning rate of group 0 to 1.9355e-02.
Epoch[70]:
train_loss = 0.32795, train_accuracy = 0.90429997
valid_loss = 0.47559, valid_accuracy = 0.84129995
time = 48.91 s
72%|███████▏  | 72/100 [54:41&lt;22:12, 47.60s/it]
Adjusting learning rate of group 0 to 1.8129e-02.
Epoch[71]:
train_loss = 0.32358, train_accuracy = 0.90477496
valid_loss = 0.47753, valid_accuracy = 0.83629996
time = 48.09 s
73%|███████▎  | 73/100 [55:27&lt;21:07, 46.94s/it]
Adjusting learning rate of group 0 to 1.6934e-02.
Epoch[72]:
train_loss = 0.30881, train_accuracy = 0.91684997
valid_loss = 0.45122, valid_accuracy = 0.84209996
time = 45.35 s
Validation loss decreased(0.47441---&gt;0.45122) 	 Saving The Model
74%|███████▍  | 74/100 [56:15&lt;20:29, 47.29s/it]
Adjusting learning rate of group 0 to 1.5773e-02.
Epoch[73]:
train_loss = 0.29596, train_accuracy = 0.91052496
valid_loss = 0.48263, valid_accuracy = 0.83709997
time = 48.11 s
75%|███████▌  | 75/100 [56:59&lt;19:19, 46.36s/it]
Adjusting learning rate of group 0 to 1.4645e-02.
Epoch[74]:
train_loss = 0.28699, train_accuracy = 0.92095
valid_loss = 0.43962, valid_accuracy = 0.84859997
time = 44.15 s
Validation loss decreased(0.45122---&gt;0.43962) 	 Saving The Model
76%|███████▌  | 76/100 [57:42&lt;18:08, 45.34s/it]
Adjusting learning rate of group 0 to 1.3552e-02.
Epoch[75]:
train_loss = 0.2746, train_accuracy = 0.91872495
valid_loss = 0.46702, valid_accuracy = 0.84679997
time = 42.96 s
77%|███████▋  | 77/100 [58:25&lt;17:08, 44.72s/it]
Adjusting learning rate of group 0 to 1.2494e-02.
Epoch[76]:
train_loss = 0.26294, train_accuracy = 0.93254995
valid_loss = 0.43192, valid_accuracy = 0.85359997
time = 43.22 s
Validation loss decreased(0.43962---&gt;0.43192) 	 Saving The Model
78%|███████▊  | 78/100 [59:09&lt;16:17, 44.43s/it]
Adjusting learning rate of group 0 to 1.1474e-02.
Epoch[77]:
train_loss = 0.2561, train_accuracy = 0.93304998
valid_loss = 0.44362, valid_accuracy = 0.85229999
time = 43.75 s
79%|███████▉  | 79/100 [59:53&lt;15:32, 44.38s/it]
Adjusting learning rate of group 0 to 1.0492e-02.
Epoch[78]:
train_loss = 0.23781, train_accuracy = 0.9411
valid_loss = 0.43426, valid_accuracy = 0.85579997
time = 44.27 s
80%|████████  | 80/100 [1:00:37&lt;14:43, 44.15s/it]
Adjusting learning rate of group 0 to 9.5492e-03.
Epoch[79]:
train_loss = 0.22595, train_accuracy = 0.93672496
valid_loss = 0.45123, valid_accuracy = 0.84939998
time = 43.61 s
81%|████████  | 81/100 [1:01:21&lt;14:00, 44.23s/it]
Adjusting learning rate of group 0 to 8.6460e-03.
Epoch[80]:
train_loss = 0.21833, train_accuracy = 0.94707495
valid_loss = 0.44036, valid_accuracy = 0.85429996
time = 44.43 s
82%|████████▏ | 82/100 [1:02:05&lt;13:11, 43.98s/it]
Adjusting learning rate of group 0 to 7.7836e-03.
Epoch[81]:
train_loss = 0.20584, train_accuracy = 0.94755
valid_loss = 0.44097, valid_accuracy = 0.85600001
time = 43.37 s
83%|████████▎ | 83/100 [1:02:49&lt;12:27, 43.95s/it]
Adjusting learning rate of group 0 to 6.9629e-03.
Epoch[82]:
train_loss = 0.19043, train_accuracy = 0.95642495
valid_loss = 0.43709, valid_accuracy = 0.85600001
time = 43.88 s
84%|████████▍ | 84/100 [1:03:33&lt;11:46, 44.13s/it]
Adjusting learning rate of group 0 to 6.1847e-03.
Epoch[83]:
train_loss = 0.17956, train_accuracy = 0.95999998
valid_loss = 0.42898, valid_accuracy = 0.86109996
time = 44.49 s
Validation loss decreased(0.43192---&gt;0.42898) 	 Saving The Model
85%|████████▌ | 85/100 [1:04:17&lt;10:59, 43.96s/it]
Adjusting learning rate of group 0 to 5.4497e-03.
Epoch[84]:
train_loss = 0.16746, train_accuracy = 0.964625
valid_loss = 0.42307, valid_accuracy = 0.8642
time = 43.51 s
Validation loss decreased(0.42898---&gt;0.42307) 	 Saving The Model
86%|████████▌ | 86/100 [1:05:00&lt;10:12, 43.75s/it]
Adjusting learning rate of group 0 to 4.7586e-03.
Epoch[85]:
train_loss = 0.15605, train_accuracy = 0.969675
valid_loss = 0.42982, valid_accuracy = 0.86609995
time = 43.26 s
87%|████████▋ | 87/100 [1:05:43&lt;09:27, 43.68s/it]
Adjusting learning rate of group 0 to 4.1123e-03.
Epoch[86]:
train_loss = 0.14795, train_accuracy = 0.97509998
valid_loss = 0.43056, valid_accuracy = 0.86379999
time = 43.52 s
88%|████████▊ | 88/100 [1:06:28&lt;08:46, 43.84s/it]
Adjusting learning rate of group 0 to 3.5112e-03.
Epoch[87]:
train_loss = 0.13057, train_accuracy = 0.97789997
valid_loss = 0.43339, valid_accuracy = 0.86609995
time = 44.2 s
89%|████████▉ | 89/100 [1:07:11&lt;08:00, 43.72s/it]
Adjusting learning rate of group 0 to 2.9560e-03.
Epoch[88]:
train_loss = 0.12369, train_accuracy = 0.98025
valid_loss = 0.43179, valid_accuracy = 0.86799997
time = 43.46 s
90%|█████████ | 90/100 [1:07:59&lt;07:29, 44.92s/it]
Adjusting learning rate of group 0 to 2.4472e-03.
Epoch[89]:
train_loss = 0.11219, train_accuracy = 0.98357499
valid_loss = 0.43678, valid_accuracy = 0.87
time = 47.72 s
91%|█████████ | 91/100 [1:08:45&lt;06:47, 45.23s/it]
Adjusting learning rate of group 0 to 1.9853e-03.
Epoch[90]:
train_loss = 0.10538, train_accuracy = 0.98627496
valid_loss = 0.43542, valid_accuracy = 0.86739999
time = 45.94 s
92%|█████████▏| 92/100 [1:09:33&lt;06:10, 46.27s/it]
Adjusting learning rate of group 0 to 1.5708e-03.
Epoch[91]:
train_loss = 0.10003, train_accuracy = 0.98677498
valid_loss = 0.43498, valid_accuracy = 0.86809999
time = 48.71 s
93%|█████████▎| 93/100 [1:10:27&lt;05:39, 48.54s/it]
Adjusting learning rate of group 0 to 1.2042e-03.
Epoch[92]:
train_loss = 0.09421, train_accuracy = 0.98954999
valid_loss = 0.44329, valid_accuracy = 0.86729997
time = 53.84 s
94%|█████████▍| 94/100 [1:11:14&lt;04:48, 48.12s/it]
Adjusting learning rate of group 0 to 8.8564e-04.
Epoch[93]:
train_loss = 0.08901, train_accuracy = 0.98989999
valid_loss = 0.44572, valid_accuracy = 0.86879998
time = 47.15 s
95%|█████████▌| 95/100 [1:12:00&lt;03:57, 47.45s/it]
Adjusting learning rate of group 0 to 6.1558e-04.
Epoch[94]:
train_loss = 0.08263, train_accuracy = 0.99175
valid_loss = 0.4404, valid_accuracy = 0.87029999
time = 45.88 s
96%|█████████▌| 96/100 [1:12:46&lt;03:07, 46.81s/it]
Adjusting learning rate of group 0 to 3.9426e-04.
Epoch[95]:
train_loss = 0.07783, train_accuracy = 0.99267495
valid_loss = 0.43668, valid_accuracy = 0.87019998
time = 45.32 s
97%|█████████▋| 97/100 [1:13:32&lt;02:19, 46.53s/it]
Adjusting learning rate of group 0 to 2.2190e-04.
Epoch[96]:
train_loss = 0.07358, train_accuracy = 0.99219996
valid_loss = 0.44238, valid_accuracy = 0.8682
time = 45.87 s
98%|█████████▊| 98/100 [1:14:16&lt;01:31, 45.99s/it]
Adjusting learning rate of group 0 to 9.8664e-05.
Epoch[97]:
train_loss = 0.0736, train_accuracy = 0.99309999
valid_loss = 0.44042, valid_accuracy = 0.87019998
time = 44.74 s
99%|█████████▉| 99/100 [1:15:00&lt;00:45, 45.17s/it]
Adjusting learning rate of group 0 to 2.4672e-05.
Epoch[98]:
train_loss = 0.07111, train_accuracy = 0.99282497
valid_loss = 0.44471, valid_accuracy = 0.86989999
time = 43.24 s
99%|█████████▉| 99/100 [1:15:43&lt;00:45, 45.89s/it]
Adjusting learning rate of group 0 to 0.0000e+00.
Epoch[99]:
train_loss = 0.07279, train_accuracy = 0.99312496
valid_loss = 0.44638, valid_accuracy = 0.86909997
time = 43.48 s
Validation loss didn't decrease for 15 epochs ---&gt; model training stopped
[Finished training]
valid training loss: 0.16746
valid training accuracy 0.964625
min validation loss: 0.42307,
best validation accuracy: 0.8642
Model[EfficientNet] - partial training (last layer) / model_weights</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">models</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">torchvision</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">get_model</span><span class="p">(</span><span class="s1">'efficientnet_b1'</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="s1">'EfficientNet_B1_Weights.IMAGENET1K_V2'</span><span class="p">),</span>
    <span class="n">torchvision</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">get_model</span><span class="p">(</span><span class="s1">'regnet_y_400mf'</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="s1">'RegNet_Y_400MF_Weights.IMAGENET1K_V2'</span><span class="p">),</span>
    <span class="n">torchvision</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">get_model</span><span class="p">(</span><span class="s1">'shufflenet_v2_x0_5'</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="s1">'ShuffleNet_V2_X0_5_Weights.IMAGENET1K_V1'</span><span class="p">),</span>
    <span class="n">torchvision</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">get_model</span><span class="p">(</span><span class="s1">'mobilenet_v3_small'</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="s1">'MobileNet_V3_Small_Weights.IMAGENET1K_V1'</span><span class="p">)</span>
    <span class="p">]</span>
<span class="n">model_names</span> <span class="o">=</span> <span class="p">[</span><span class="n">model</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span> <span class="k">for</span> <span class="n">model</span> <span class="ow">in</span> <span class="n">models</span><span class="p">]</span>
<span class="k">for</span> <span class="n">model</span><span class="p">,</span> <span class="n">model_name</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">models</span><span class="p">,</span> <span class="n">model_names</span><span class="p">):</span>
    <span class="n">model_results</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">model_name</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>================================================================================
Model[EfficientNet] last FC before mod: Linear(in_features=1280, out_features=1000, bias=True)
Model[EfficientNet] last FC after mod: Linear(in_features=1280, out_features=10, bias=True)
Model[EfficientNet] - partial training (last layer) / model_weights
Adjusting learning rate of group 0 to 1.0000e-01.
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>  0%|          | 0/100 [00:00&lt;?, ?it/s]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>#############################################################################################
[Training parameters]
	epochs = 100,
	lr = 0.1,
	momentum = 0.9,
	weight_decay = 0.0005,
	loss = CrossEntropyLoss(),
	optimizer = SGD (
Parameter Group 0
    dampening: 0
    differentiable: False
    foreach: None
    initial_lr: 0.1
    lr: 0.1
    maximize: False
    momentum: 0.9
    nesterov: False
    weight_decay: 0.0005
),
	scheduler = &lt;torch.optim.lr_scheduler.CosineAnnealingLR object at 0x00000268205FD990&gt;,
	device = cuda:0
#############################################################################################
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>  1%|          | 1/100 [00:22&lt;37:18, 22.61s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.9975e-02.
Epoch[0]:
	train_loss = 2.93203, train_accuracy = 0.35685
	valid_loss = 2.5239, valid_accuracy = 0.34079999
	time = 22.56 s
Validation loss decreased(None---&gt;2.5239) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>  2%|▏         | 2/100 [00:45&lt;37:34, 23.00s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.9901e-02.
Epoch[1]:
	train_loss = 3.15848, train_accuracy = 0.34869999
	valid_loss = 2.54035, valid_accuracy = 0.34379998
	time = 23.28 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>  3%|▎         | 3/100 [01:08&lt;36:46, 22.75s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.9778e-02.
Epoch[2]:
	train_loss = 3.00871, train_accuracy = 0.35249999
	valid_loss = 2.66724, valid_accuracy = 0.3351
	time = 22.44 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>  4%|▍         | 4/100 [01:30&lt;36:08, 22.59s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.9606e-02.
Epoch[3]:
	train_loss = 3.12241, train_accuracy = 0.36759999
	valid_loss = 2.62627, valid_accuracy = 0.35839999
	time = 22.34 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>  5%|▌         | 5/100 [01:54&lt;36:19, 22.94s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.9384e-02.
Epoch[4]:
	train_loss = 3.06807, train_accuracy = 0.37252498
	valid_loss = 2.37035, valid_accuracy = 0.36489999
	time = 23.53 s
Validation loss decreased(2.5239---&gt;2.37035) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>  6%|▌         | 6/100 [02:17&lt;35:53, 22.90s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.9114e-02.
Epoch[5]:
	train_loss = 3.08106, train_accuracy = 0.36205
	valid_loss = 2.42848, valid_accuracy = 0.35279998
	time = 22.83 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>  7%|▋         | 7/100 [02:39&lt;35:20, 22.80s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.8796e-02.
Epoch[6]:
	train_loss = 3.12369, train_accuracy = 0.366575
	valid_loss = 2.41003, valid_accuracy = 0.3583
	time = 22.58 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>  8%|▊         | 8/100 [03:01&lt;34:40, 22.61s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.8429e-02.
Epoch[7]:
	train_loss = 3.1109, train_accuracy = 0.352025
	valid_loss = 2.74935, valid_accuracy = 0.3382
	time = 22.22 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>  9%|▉         | 9/100 [03:24&lt;34:07, 22.50s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.8015e-02.
Epoch[8]:
	train_loss = 3.03223, train_accuracy = 0.36399999
	valid_loss = 2.37579, valid_accuracy = 0.35510001
	time = 22.24 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 10%|█         | 10/100 [03:45&lt;33:21, 22.24s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.7553e-02.
Epoch[9]:
	train_loss = 3.01516, train_accuracy = 0.36964998
	valid_loss = 2.42259, valid_accuracy = 0.35499999
	time = 21.67 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 11%|█         | 11/100 [04:08&lt;33:03, 22.28s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.7044e-02.
Epoch[10]:
	train_loss = 3.07504, train_accuracy = 0.35332498
	valid_loss = 2.39444, valid_accuracy = 0.34239998
	time = 22.37 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 12%|█▏        | 12/100 [04:31&lt;33:02, 22.53s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.6489e-02.
Epoch[11]:
	train_loss = 3.04755, train_accuracy = 0.36449999
	valid_loss = 2.43446, valid_accuracy = 0.35319999
	time = 23.09 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 13%|█▎        | 13/100 [04:54&lt;32:53, 22.69s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.5888e-02.
Epoch[12]:
	train_loss = 3.01807, train_accuracy = 0.3653
	valid_loss = 2.38297, valid_accuracy = 0.35169998
	time = 23.06 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 14%|█▍        | 14/100 [05:17&lt;32:44, 22.84s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.5241e-02.
Epoch[13]:
	train_loss = 3.02955, train_accuracy = 0.361875
	valid_loss = 2.50132, valid_accuracy = 0.3547
	time = 23.2 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 15%|█▌        | 15/100 [05:40&lt;32:20, 22.83s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.4550e-02.
Epoch[14]:
	train_loss = 3.04791, train_accuracy = 0.36249998
	valid_loss = 2.35516, valid_accuracy = 0.34869999
	time = 22.73 s
Validation loss decreased(2.37035---&gt;2.35516) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 16%|█▌        | 16/100 [06:02&lt;31:31, 22.52s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.3815e-02.
Epoch[15]:
	train_loss = 3.00953, train_accuracy = 0.35782498
	valid_loss = 2.38918, valid_accuracy = 0.35259998
	time = 21.81 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 17%|█▋        | 17/100 [06:23&lt;30:46, 22.25s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.3037e-02.
Epoch[16]:
	train_loss = 2.95933, train_accuracy = 0.35767499
	valid_loss = 2.50931, valid_accuracy = 0.35659999
	time = 21.62 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 18%|█▊        | 18/100 [06:45&lt;30:18, 22.18s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.2216e-02.
Epoch[17]:
	train_loss = 2.97642, train_accuracy = 0.365125
	valid_loss = 2.33659, valid_accuracy = 0.3608
	time = 21.96 s
Validation loss decreased(2.35516---&gt;2.33659) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 19%|█▉        | 19/100 [07:07&lt;29:46, 22.05s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.1354e-02.
Epoch[18]:
	train_loss = 2.95215, train_accuracy = 0.35824999
	valid_loss = 2.42544, valid_accuracy = 0.34729999
	time = 21.75 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 20%|██        | 20/100 [07:28&lt;29:09, 21.86s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.0451e-02.
Epoch[19]:
	train_loss = 3.02241, train_accuracy = 0.37097499
	valid_loss = 2.33852, valid_accuracy = 0.35119998
	time = 21.42 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 21%|██        | 21/100 [07:50&lt;28:40, 21.78s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 8.9508e-02.
Epoch[20]:
	train_loss = 2.90062, train_accuracy = 0.37594998
	valid_loss = 2.27325, valid_accuracy = 0.359
	time = 21.54 s
Validation loss decreased(2.33659---&gt;2.27325) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 22%|██▏       | 22/100 [08:12&lt;28:14, 21.72s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 8.8526e-02.
Epoch[21]:
	train_loss = 2.88752, train_accuracy = 0.36462498
	valid_loss = 2.457, valid_accuracy = 0.35729998
	time = 21.6 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 23%|██▎       | 23/100 [08:34&lt;28:05, 21.88s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 8.7506e-02.
Epoch[22]:
	train_loss = 2.93807, train_accuracy = 0.36229998
	valid_loss = 2.38242, valid_accuracy = 0.35119998
	time = 22.26 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 24%|██▍       | 24/100 [08:56&lt;27:46, 21.92s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 8.6448e-02.
Epoch[23]:
	train_loss = 2.91356, train_accuracy = 0.36112499
	valid_loss = 2.27033, valid_accuracy = 0.35229999
	time = 21.98 s
Validation loss decreased(2.27325---&gt;2.27033) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 25%|██▌       | 25/100 [09:17&lt;27:14, 21.79s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 8.5355e-02.
Epoch[24]:
	train_loss = 2.89196, train_accuracy = 0.36609998
	valid_loss = 2.34219, valid_accuracy = 0.35439998
	time = 21.47 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 26%|██▌       | 26/100 [09:39&lt;26:50, 21.77s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 8.4227e-02.
Epoch[25]:
	train_loss = 2.80807, train_accuracy = 0.36675
	valid_loss = 2.57044, valid_accuracy = 0.34869999
	time = 21.71 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 27%|██▋       | 27/100 [10:01&lt;26:25, 21.72s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 8.3066e-02.
Epoch[26]:
	train_loss = 2.77641, train_accuracy = 0.364425
	valid_loss = 2.20487, valid_accuracy = 0.35749999
	time = 21.56 s
Validation loss decreased(2.27033---&gt;2.20487) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 28%|██▊       | 28/100 [10:22&lt;26:01, 21.68s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 8.1871e-02.
Epoch[27]:
	train_loss = 2.75955, train_accuracy = 0.36205
	valid_loss = 2.27724, valid_accuracy = 0.3529
	time = 21.59 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 29%|██▉       | 29/100 [10:44&lt;25:41, 21.71s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 8.0645e-02.
Epoch[28]:
	train_loss = 2.71626, train_accuracy = 0.37735
	valid_loss = 2.34212, valid_accuracy = 0.35779998
	time = 21.78 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 30%|███       | 30/100 [11:06&lt;25:22, 21.75s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 7.9389e-02.
Epoch[29]:
	train_loss = 2.77822, train_accuracy = 0.36109999
	valid_loss = 2.28184, valid_accuracy = 0.34899998
	time = 21.82 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 31%|███       | 31/100 [11:28&lt;25:06, 21.83s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 7.8104e-02.
Epoch[30]:
	train_loss = 2.69808, train_accuracy = 0.3768
	valid_loss = 2.19161, valid_accuracy = 0.3662
	time = 21.97 s
Validation loss decreased(2.20487---&gt;2.19161) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 32%|███▏      | 32/100 [11:50&lt;24:40, 21.78s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 7.6791e-02.
Epoch[31]:
	train_loss = 2.71589, train_accuracy = 0.37527499
	valid_loss = 2.11868, valid_accuracy = 0.35420001
	time = 21.62 s
Validation loss decreased(2.19161---&gt;2.11868) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 33%|███▎      | 33/100 [12:11&lt;24:10, 21.66s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 7.5452e-02.
Epoch[32]:
	train_loss = 2.75228, train_accuracy = 0.382025
	valid_loss = 2.1476, valid_accuracy = 0.3635
	time = 21.37 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 34%|███▍      | 34/100 [12:33&lt;23:56, 21.76s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 7.4088e-02.
Epoch[33]:
	train_loss = 2.70502, train_accuracy = 0.38082498
	valid_loss = 2.21326, valid_accuracy = 0.36589998
	time = 22.01 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 35%|███▌      | 35/100 [12:55&lt;23:37, 21.81s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 7.2700e-02.
Epoch[34]:
	train_loss = 2.68035, train_accuracy = 0.371425
	valid_loss = 2.09357, valid_accuracy = 0.35879999
	time = 21.87 s
Validation loss decreased(2.11868---&gt;2.09357) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 36%|███▌      | 36/100 [13:16&lt;23:08, 21.70s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 7.1289e-02.
Epoch[35]:
	train_loss = 2.64111, train_accuracy = 0.36289999
	valid_loss = 2.14002, valid_accuracy = 0.35339999
	time = 21.44 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 37%|███▋      | 37/100 [13:38&lt;22:49, 21.74s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 6.9857e-02.
Epoch[36]:
	train_loss = 2.56424, train_accuracy = 0.373925
	valid_loss = 2.14293, valid_accuracy = 0.3664
	time = 21.83 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 38%|███▊      | 38/100 [14:00&lt;22:25, 21.70s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 6.8406e-02.
Epoch[37]:
	train_loss = 2.56409, train_accuracy = 0.366575
	valid_loss = 2.15126, valid_accuracy = 0.35299999
	time = 21.6 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 39%|███▉      | 39/100 [14:21&lt;22:00, 21.65s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 6.6937e-02.
Epoch[38]:
	train_loss = 2.55823, train_accuracy = 0.39017498
	valid_loss = 2.14052, valid_accuracy = 0.38139999
	time = 21.53 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 40%|████      | 40/100 [14:43&lt;21:42, 21.71s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 6.5451e-02.
Epoch[39]:
	train_loss = 2.49004, train_accuracy = 0.36862499
	valid_loss = 2.17556, valid_accuracy = 0.36449999
	time = 21.85 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 41%|████      | 41/100 [15:05&lt;21:20, 21.70s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 6.3950e-02.
Epoch[40]:
	train_loss = 2.49798, train_accuracy = 0.38317499
	valid_loss = 2.09877, valid_accuracy = 0.37379998
	time = 21.68 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 42%|████▏     | 42/100 [15:27&lt;21:00, 21.73s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 6.2434e-02.
Epoch[41]:
	train_loss = 2.49788, train_accuracy = 0.38374999
	valid_loss = 2.12098, valid_accuracy = 0.36839998
	time = 21.81 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 43%|████▎     | 43/100 [15:48&lt;20:37, 21.70s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 6.0907e-02.
Epoch[42]:
	train_loss = 2.43938, train_accuracy = 0.37667498
	valid_loss = 2.29352, valid_accuracy = 0.35869998
	time = 21.64 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 44%|████▍     | 44/100 [16:10&lt;20:22, 21.84s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 5.9369e-02.
Epoch[43]:
	train_loss = 2.41863, train_accuracy = 0.38582498
	valid_loss = 2.01335, valid_accuracy = 0.36629999
	time = 22.1 s
Validation loss decreased(2.09357---&gt;2.01335) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 45%|████▌     | 45/100 [16:33&lt;20:19, 22.16s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 5.7822e-02.
Epoch[44]:
	train_loss = 2.41907, train_accuracy = 0.37965
	valid_loss = 2.11993, valid_accuracy = 0.37
	time = 22.93 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 46%|████▌     | 46/100 [16:55&lt;19:53, 22.11s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 5.6267e-02.
Epoch[45]:
	train_loss = 2.37403, train_accuracy = 0.39197499
	valid_loss = 1.97159, valid_accuracy = 0.38159999
	time = 21.94 s
Validation loss decreased(2.01335---&gt;1.97159) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 47%|████▋     | 47/100 [17:17&lt;19:33, 22.13s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 5.4705e-02.
Epoch[46]:
	train_loss = 2.36433, train_accuracy = 0.39572498
	valid_loss = 1.9678, valid_accuracy = 0.3829
	time = 22.14 s
Validation loss decreased(1.97159---&gt;1.9678) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 48%|████▊     | 48/100 [17:39&lt;19:06, 22.04s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 5.3140e-02.
Epoch[47]:
	train_loss = 2.35168, train_accuracy = 0.39334998
	valid_loss = 1.94791, valid_accuracy = 0.38139999
	time = 21.77 s
Validation loss decreased(1.9678---&gt;1.94791) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 49%|████▉     | 49/100 [18:01&lt;18:34, 21.85s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 5.1571e-02.
Epoch[48]:
	train_loss = 2.32353, train_accuracy = 0.39039999
	valid_loss = 1.96033, valid_accuracy = 0.37869999
	time = 21.41 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 50%|█████     | 50/100 [18:22&lt;18:05, 21.70s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 5.0000e-02.
Epoch[49]:
	train_loss = 2.33353, train_accuracy = 0.38049999
	valid_loss = 1.9444, valid_accuracy = 0.3827
	time = 21.31 s
Validation loss decreased(1.94791---&gt;1.9444) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 51%|█████     | 51/100 [18:44&lt;17:45, 21.75s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 4.8429e-02.
Epoch[50]:
	train_loss = 2.25986, train_accuracy = 0.40054998
	valid_loss = 1.87041, valid_accuracy = 0.38909999
	time = 21.8 s
Validation loss decreased(1.9444---&gt;1.87041) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 52%|█████▏    | 52/100 [19:06&lt;17:34, 21.96s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 4.6860e-02.
Epoch[51]:
	train_loss = 2.25321, train_accuracy = 0.39534998
	valid_loss = 1.95355, valid_accuracy = 0.37989998
	time = 22.46 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 53%|█████▎    | 53/100 [19:29&lt;17:16, 22.05s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 4.5295e-02.
Epoch[52]:
	train_loss = 2.2285, train_accuracy = 0.41029999
	valid_loss = 1.8161, valid_accuracy = 0.39789999
	time = 22.21 s
Validation loss decreased(1.87041---&gt;1.8161) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 54%|█████▍    | 54/100 [19:50&lt;16:50, 21.97s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 4.3733e-02.
Epoch[53]:
	train_loss = 2.22173, train_accuracy = 0.40154999
	valid_loss = 1.91252, valid_accuracy = 0.37889999
	time = 21.79 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 55%|█████▌    | 55/100 [20:12&lt;16:26, 21.92s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 4.2178e-02.
Epoch[54]:
	train_loss = 2.2267, train_accuracy = 0.40099999
	valid_loss = 1.82606, valid_accuracy = 0.38959998
	time = 21.79 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 56%|█████▌    | 56/100 [20:35&lt;16:13, 22.13s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 4.0631e-02.
Epoch[55]:
	train_loss = 2.19139, train_accuracy = 0.405875
	valid_loss = 1.81241, valid_accuracy = 0.38769999
	time = 22.58 s
Validation loss decreased(1.8161---&gt;1.81241) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 57%|█████▋    | 57/100 [20:59&lt;16:18, 22.76s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 3.9093e-02.
Epoch[56]:
	train_loss = 2.14536, train_accuracy = 0.400125
	valid_loss = 1.83043, valid_accuracy = 0.3937
	time = 24.22 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 58%|█████▊    | 58/100 [21:23&lt;16:07, 23.04s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 3.7566e-02.
Epoch[57]:
	train_loss = 2.15717, train_accuracy = 0.411075
	valid_loss = 1.85764, valid_accuracy = 0.39139998
	time = 23.71 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 59%|█████▉    | 59/100 [21:47&lt;16:01, 23.46s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 3.6050e-02.
Epoch[58]:
	train_loss = 2.10782, train_accuracy = 0.41059998
	valid_loss = 1.83202, valid_accuracy = 0.3969
	time = 24.45 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 60%|██████    | 60/100 [22:11&lt;15:45, 23.63s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 3.4549e-02.
Epoch[59]:
	train_loss = 2.10164, train_accuracy = 0.4041
	valid_loss = 1.87846, valid_accuracy = 0.3933
	time = 24.03 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 61%|██████    | 61/100 [22:35&lt;15:28, 23.81s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 3.3063e-02.
Epoch[60]:
	train_loss = 2.0866, train_accuracy = 0.42182499
	valid_loss = 1.708, valid_accuracy = 0.41569999
	time = 24.18 s
Validation loss decreased(1.81241---&gt;1.708) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 62%|██████▏   | 62/100 [23:00&lt;15:07, 23.89s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 3.1594e-02.
Epoch[61]:
	train_loss = 2.0582, train_accuracy = 0.41727498
	valid_loss = 1.74015, valid_accuracy = 0.39649999
	time = 24.08 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 63%|██████▎   | 63/100 [23:23&lt;14:42, 23.84s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 3.0143e-02.
Epoch[62]:
	train_loss = 2.03969, train_accuracy = 0.41817498
	valid_loss = 1.76677, valid_accuracy = 0.40739998
	time = 23.71 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 64%|██████▍   | 64/100 [23:46&lt;14:11, 23.66s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 2.8711e-02.
Epoch[63]:
	train_loss = 2.04129, train_accuracy = 0.417025
	valid_loss = 1.75411, valid_accuracy = 0.40309998
	time = 23.24 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 65%|██████▌   | 65/100 [24:10&lt;13:42, 23.50s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 2.7300e-02.
Epoch[64]:
	train_loss = 2.00991, train_accuracy = 0.42427498
	valid_loss = 1.76546, valid_accuracy = 0.4086
	time = 23.14 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 66%|██████▌   | 66/100 [24:33&lt;13:20, 23.54s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 2.5912e-02.
Epoch[65]:
	train_loss = 1.98008, train_accuracy = 0.42995
	valid_loss = 1.69952, valid_accuracy = 0.40759999
	time = 23.58 s
Validation loss decreased(1.708---&gt;1.69952) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 67%|██████▋   | 67/100 [24:57&lt;12:57, 23.57s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 2.4548e-02.
Epoch[66]:
	train_loss = 1.96689, train_accuracy = 0.42784998
	valid_loss = 1.697, valid_accuracy = 0.41499999
	time = 23.57 s
Validation loss decreased(1.69952---&gt;1.697) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 68%|██████▊   | 68/100 [25:20&lt;12:33, 23.54s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 2.3209e-02.
Epoch[67]:
	train_loss = 1.95454, train_accuracy = 0.436225
	valid_loss = 1.6935, valid_accuracy = 0.41339999
	time = 23.44 s
Validation loss decreased(1.697---&gt;1.6935) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 69%|██████▉   | 69/100 [25:44&lt;12:06, 23.43s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 2.1896e-02.
Epoch[68]:
	train_loss = 1.95137, train_accuracy = 0.43335
	valid_loss = 1.71116, valid_accuracy = 0.41399997
	time = 23.17 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 70%|███████   | 70/100 [26:07&lt;11:40, 23.34s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 2.0611e-02.
Epoch[69]:
	train_loss = 1.92284, train_accuracy = 0.42537498
	valid_loss = 1.71883, valid_accuracy = 0.41419998
	time = 23.12 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 71%|███████   | 71/100 [26:30&lt;11:14, 23.26s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 1.9355e-02.
Epoch[70]:
	train_loss = 1.91315, train_accuracy = 0.43204999
	valid_loss = 1.69544, valid_accuracy = 0.4208
	time = 23.07 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 72%|███████▏  | 72/100 [26:53&lt;10:54, 23.36s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 1.8129e-02.
Epoch[71]:
	train_loss = 1.9003, train_accuracy = 0.436225
	valid_loss = 1.71809, valid_accuracy = 0.42209998
	time = 23.59 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 73%|███████▎  | 73/100 [27:17&lt;10:31, 23.40s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 1.6934e-02.
Epoch[72]:
	train_loss = 1.89719, train_accuracy = 0.44372499
	valid_loss = 1.67417, valid_accuracy = 0.42769998
	time = 23.44 s
Validation loss decreased(1.6935---&gt;1.67417) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 74%|███████▍  | 74/100 [27:40&lt;10:07, 23.35s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 1.5773e-02.
Epoch[73]:
	train_loss = 1.88165, train_accuracy = 0.44344997
	valid_loss = 1.67265, valid_accuracy = 0.42589998
	time = 23.18 s
Validation loss decreased(1.67417---&gt;1.67265) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 75%|███████▌  | 75/100 [28:03&lt;09:43, 23.35s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 1.4645e-02.
Epoch[74]:
	train_loss = 1.87362, train_accuracy = 0.44712499
	valid_loss = 1.65068, valid_accuracy = 0.43009999
	time = 23.31 s
Validation loss decreased(1.67265---&gt;1.65068) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 76%|███████▌  | 76/100 [28:27&lt;09:24, 23.53s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 1.3552e-02.
Epoch[75]:
	train_loss = 1.85745, train_accuracy = 0.44219998
	valid_loss = 1.68614, valid_accuracy = 0.42389998
	time = 23.93 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 77%|███████▋  | 77/100 [28:51&lt;09:00, 23.51s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 1.2494e-02.
Epoch[76]:
	train_loss = 1.84161, train_accuracy = 0.44279999
	valid_loss = 1.66431, valid_accuracy = 0.42879999
	time = 23.47 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 78%|███████▊  | 78/100 [29:14&lt;08:35, 23.43s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 1.1474e-02.
Epoch[77]:
	train_loss = 1.83004, train_accuracy = 0.45432499
	valid_loss = 1.64812, valid_accuracy = 0.43349999
	time = 23.21 s
Validation loss decreased(1.65068---&gt;1.64812) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 79%|███████▉  | 79/100 [29:37&lt;08:10, 23.36s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 1.0492e-02.
Epoch[78]:
	train_loss = 1.8092, train_accuracy = 0.44464999
	valid_loss = 1.63931, valid_accuracy = 0.4373
	time = 23.14 s
Validation loss decreased(1.64812---&gt;1.63931) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 80%|████████  | 80/100 [30:00&lt;07:43, 23.20s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.5492e-03.
Epoch[79]:
	train_loss = 1.81546, train_accuracy = 0.4585
	valid_loss = 1.63546, valid_accuracy = 0.4411
	time = 22.78 s
Validation loss decreased(1.63931---&gt;1.63546) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 81%|████████  | 81/100 [30:23&lt;07:17, 23.03s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 8.6460e-03.
Epoch[80]:
	train_loss = 1.8104, train_accuracy = 0.46527499
	valid_loss = 1.6052, valid_accuracy = 0.4481
	time = 22.59 s
Validation loss decreased(1.63546---&gt;1.6052) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 82%|████████▏ | 82/100 [30:45&lt;06:52, 22.91s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 7.7836e-03.
Epoch[81]:
	train_loss = 1.78908, train_accuracy = 0.46794999
	valid_loss = 1.6001, valid_accuracy = 0.4472
	time = 22.58 s
Validation loss decreased(1.6052---&gt;1.6001) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 83%|████████▎ | 83/100 [31:08&lt;06:27, 22.82s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 6.9629e-03.
Epoch[82]:
	train_loss = 1.78762, train_accuracy = 0.46439999
	valid_loss = 1.6133, valid_accuracy = 0.44949999
	time = 22.6 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 84%|████████▍ | 84/100 [31:31&lt;06:04, 22.78s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 6.1847e-03.
Epoch[83]:
	train_loss = 1.80312, train_accuracy = 0.4632
	valid_loss = 1.61616, valid_accuracy = 0.4456
	time = 22.7 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 85%|████████▌ | 85/100 [31:54&lt;05:42, 22.83s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 5.4497e-03.
Epoch[84]:
	train_loss = 1.7792, train_accuracy = 0.46765
	valid_loss = 1.5912, valid_accuracy = 0.4481
	time = 22.9 s
Validation loss decreased(1.6001---&gt;1.5912) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 86%|████████▌ | 86/100 [32:17&lt;05:20, 22.89s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 4.7586e-03.
Epoch[85]:
	train_loss = 1.76883, train_accuracy = 0.464425
	valid_loss = 1.61865, valid_accuracy = 0.44149998
	time = 23.04 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 87%|████████▋ | 87/100 [32:40&lt;04:59, 23.06s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 4.1123e-03.
Epoch[86]:
	train_loss = 1.76609, train_accuracy = 0.47087499
	valid_loss = 1.5958, valid_accuracy = 0.44659999
	time = 23.45 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 88%|████████▊ | 88/100 [33:03&lt;04:37, 23.08s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 3.5112e-03.
Epoch[87]:
	train_loss = 1.75778, train_accuracy = 0.47082499
	valid_loss = 1.60657, valid_accuracy = 0.4513
	time = 23.14 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 89%|████████▉ | 89/100 [33:26&lt;04:13, 23.04s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 2.9560e-03.
Epoch[88]:
	train_loss = 1.76036, train_accuracy = 0.47684997
	valid_loss = 1.58264, valid_accuracy = 0.4531
	time = 22.88 s
Validation loss decreased(1.5912---&gt;1.58264) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 90%|█████████ | 90/100 [33:49&lt;03:50, 23.04s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 2.4472e-03.
Epoch[89]:
	train_loss = 1.75308, train_accuracy = 0.47619998
	valid_loss = 1.58681, valid_accuracy = 0.45649999
	time = 23.05 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 91%|█████████ | 91/100 [34:12&lt;03:27, 23.06s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 1.9853e-03.
Epoch[90]:
	train_loss = 1.74113, train_accuracy = 0.476625
	valid_loss = 1.58529, valid_accuracy = 0.46159998
	time = 23.08 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 92%|█████████▏| 92/100 [34:35&lt;03:04, 23.05s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 1.5708e-03.
Epoch[91]:
	train_loss = 1.74242, train_accuracy = 0.47867498
	valid_loss = 1.60305, valid_accuracy = 0.45989999
	time = 23.03 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 93%|█████████▎| 93/100 [34:57&lt;02:39, 22.74s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 1.2042e-03.
Epoch[92]:
	train_loss = 1.74199, train_accuracy = 0.47562498
	valid_loss = 1.59031, valid_accuracy = 0.45629999
	time = 22.01 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 94%|█████████▍| 94/100 [35:19&lt;02:14, 22.44s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 8.8564e-04.
Epoch[93]:
	train_loss = 1.72687, train_accuracy = 0.47944999
	valid_loss = 1.58546, valid_accuracy = 0.46019998
	time = 21.75 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 95%|█████████▌| 95/100 [35:41&lt;01:50, 22.16s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 6.1558e-04.
Epoch[94]:
	train_loss = 1.72957, train_accuracy = 0.47477499
	valid_loss = 1.58763, valid_accuracy = 0.45919999
	time = 21.49 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 96%|█████████▌| 96/100 [36:02&lt;01:27, 21.95s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 3.9426e-04.
Epoch[95]:
	train_loss = 1.73202, train_accuracy = 0.48342499
	valid_loss = 1.55952, valid_accuracy = 0.4646
	time = 21.42 s
Validation loss decreased(1.58264---&gt;1.55952) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 97%|█████████▋| 97/100 [36:24&lt;01:05, 21.86s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 2.2190e-04.
Epoch[96]:
	train_loss = 1.72411, train_accuracy = 0.47404999
	valid_loss = 1.57793, valid_accuracy = 0.46329999
	time = 21.66 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 98%|█████████▊| 98/100 [36:46&lt;00:43, 21.97s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.8664e-05.
Epoch[97]:
	train_loss = 1.72545, train_accuracy = 0.479
	valid_loss = 1.58194, valid_accuracy = 0.46499997
	time = 22.22 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 99%|█████████▉| 99/100 [37:07&lt;00:21, 21.82s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 2.4672e-05.
Epoch[98]:
	train_loss = 1.72017, train_accuracy = 0.47564998
	valid_loss = 1.58394, valid_accuracy = 0.46089998
	time = 21.49 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>100%|██████████| 100/100 [37:29&lt;00:00, 22.50s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 0.0000e+00.
Epoch[99]:
	train_loss = 1.73222, train_accuracy = 0.478975
	valid_loss = 1.59088, valid_accuracy = 0.4542
	time = 21.68 s
[Finished training]
	valid training loss: 1.73202
	valid training accuracy 0.48342499
	min validation loss: 1.55952,
	best validation accuracy: 0.4646
================================================================================
Model[RegNet] last FC before mod: Linear(in_features=440, out_features=1000, bias=True)
Model[RegNet] last FC after mod: Linear(in_features=440, out_features=10, bias=True)
Model[RegNet] - full training / model_weights
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 1.0000e-01.
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>  0%|          | 0/100 [00:00&lt;?, ?it/s]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>#############################################################################################
[Training parameters]
	epochs = 100,
	lr = 0.1,
	momentum = 0.9,
	weight_decay = 0.0005,
	loss = CrossEntropyLoss(),
	optimizer = SGD (
Parameter Group 0
    dampening: 0
    differentiable: False
    foreach: None
    initial_lr: 0.1
    lr: 0.1
    maximize: False
    momentum: 0.9
    nesterov: False
    weight_decay: 0.0005
),
	scheduler = &lt;torch.optim.lr_scheduler.CosineAnnealingLR object at 0x00000268207F6470&gt;,
	device = cuda:0
#############################################################################################
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>  1%|          | 1/100 [00:28&lt;46:20, 28.09s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.9975e-02.
Epoch[0]:
	train_loss = 1.87621, train_accuracy = 0.39587498
	valid_loss = 1.63915, valid_accuracy = 0.3987
	time = 28.06 s
Validation loss decreased(None---&gt;1.63915) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>  2%|▏         | 2/100 [00:55&lt;45:13, 27.69s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.9901e-02.
Epoch[1]:
	train_loss = 1.57047, train_accuracy = 0.4472
	valid_loss = 1.51937, valid_accuracy = 0.44579998
	time = 27.38 s
Validation loss decreased(1.63915---&gt;1.51937) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>  3%|▎         | 3/100 [01:23&lt;44:48, 27.72s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.9778e-02.
Epoch[2]:
	train_loss = 1.44425, train_accuracy = 0.4903
	valid_loss = 1.43225, valid_accuracy = 0.47919998
	time = 27.73 s
Validation loss decreased(1.51937---&gt;1.43225) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>  4%|▍         | 4/100 [01:51&lt;44:22, 27.74s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.9606e-02.
Epoch[3]:
	train_loss = 1.37212, train_accuracy = 0.524575
	valid_loss = 1.37392, valid_accuracy = 0.50729996
	time = 27.73 s
Validation loss decreased(1.43225---&gt;1.37392) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>  5%|▌         | 5/100 [02:18&lt;43:45, 27.64s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.9384e-02.
Epoch[4]:
	train_loss = 1.29722, train_accuracy = 0.57734996
	valid_loss = 1.23914, valid_accuracy = 0.55979997
	time = 27.44 s
Validation loss decreased(1.37392---&gt;1.23914) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>  6%|▌         | 6/100 [02:46&lt;43:14, 27.60s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.9114e-02.
Epoch[5]:
	train_loss = 1.23109, train_accuracy = 0.55937499
	valid_loss = 1.33026, valid_accuracy = 0.55079997
	time = 27.51 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>  7%|▋         | 7/100 [03:14&lt;43:05, 27.80s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.8796e-02.
Epoch[6]:
	train_loss = 1.18443, train_accuracy = 0.6045
	valid_loss = 1.16358, valid_accuracy = 0.58469999
	time = 28.19 s
Validation loss decreased(1.23914---&gt;1.16358) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>  8%|▊         | 8/100 [03:41&lt;42:25, 27.67s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.8429e-02.
Epoch[7]:
	train_loss = 1.09812, train_accuracy = 0.60514998
	valid_loss = 1.17014, valid_accuracy = 0.59240001
	time = 27.4 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>  9%|▉         | 9/100 [04:09&lt;41:50, 27.59s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.8015e-02.
Epoch[8]:
	train_loss = 1.1073, train_accuracy = 0.57412499
	valid_loss = 1.36237, valid_accuracy = 0.55879998
	time = 27.41 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 10%|█         | 10/100 [04:36&lt;41:21, 27.58s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.7553e-02.
Epoch[9]:
	train_loss = 1.06879, train_accuracy = 0.64609998
	valid_loss = 1.04691, valid_accuracy = 0.62470001
	time = 27.51 s
Validation loss decreased(1.16358---&gt;1.04691) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 11%|█         | 11/100 [05:04&lt;40:54, 27.58s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.7044e-02.
Epoch[10]:
	train_loss = 0.98421, train_accuracy = 0.64587498
	valid_loss = 1.10742, valid_accuracy = 0.61849999
	time = 27.58 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 12%|█▏        | 12/100 [05:34&lt;41:38, 28.39s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.6489e-02.
Epoch[11]:
	train_loss = 0.93693, train_accuracy = 0.67374998
	valid_loss = 1.00022, valid_accuracy = 0.64770001
	time = 30.22 s
Validation loss decreased(1.04691---&gt;1.00022) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 13%|█▎        | 13/100 [06:02&lt;41:12, 28.42s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.5888e-02.
Epoch[12]:
	train_loss = 0.89635, train_accuracy = 0.65227497
	valid_loss = 1.06634, valid_accuracy = 0.62659997
	time = 28.46 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 14%|█▍        | 14/100 [06:34&lt;42:16, 29.49s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.5241e-02.
Epoch[13]:
	train_loss = 0.87125, train_accuracy = 0.65482497
	valid_loss = 1.06605, valid_accuracy = 0.63139999
	time = 31.98 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 15%|█▌        | 15/100 [07:05&lt;42:16, 29.84s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.4550e-02.
Epoch[14]:
	train_loss = 0.82651, train_accuracy = 0.721775
	valid_loss = 0.88971, valid_accuracy = 0.68729997
	time = 30.63 s
Validation loss decreased(1.00022---&gt;0.88971) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 16%|█▌        | 16/100 [07:35&lt;41:40, 29.77s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.3815e-02.
Epoch[15]:
	train_loss = 0.80637, train_accuracy = 0.69942498
	valid_loss = 0.95311, valid_accuracy = 0.66909999
	time = 29.58 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 17%|█▋        | 17/100 [08:04&lt;41:11, 29.77s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.3037e-02.
Epoch[16]:
	train_loss = 0.78983, train_accuracy = 0.70875001
	valid_loss = 0.92226, valid_accuracy = 0.67629999
	time = 29.79 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 18%|█▊        | 18/100 [08:34&lt;40:25, 29.57s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.2216e-02.
Epoch[17]:
	train_loss = 0.7665, train_accuracy = 0.71512496
	valid_loss = 0.91812, valid_accuracy = 0.6796
	time = 29.11 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 19%|█▉        | 19/100 [09:03&lt;39:49, 29.50s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.1354e-02.
Epoch[18]:
	train_loss = 0.75434, train_accuracy = 0.72240001
	valid_loss = 0.92255, valid_accuracy = 0.68430001
	time = 29.32 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 20%|██        | 20/100 [09:33&lt;39:33, 29.67s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.0451e-02.
Epoch[19]:
	train_loss = 0.7342, train_accuracy = 0.76934999
	valid_loss = 0.78285, valid_accuracy = 0.7256
	time = 30.05 s
Validation loss decreased(0.88971---&gt;0.78285) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 21%|██        | 21/100 [10:03&lt;39:10, 29.76s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 8.9508e-02.
Epoch[20]:
	train_loss = 0.71993, train_accuracy = 0.72964996
	valid_loss = 0.89812, valid_accuracy = 0.69239998
	time = 29.95 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 22%|██▏       | 22/100 [10:34&lt;39:03, 30.05s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 8.8526e-02.
Epoch[21]:
	train_loss = 0.69979, train_accuracy = 0.75830001
	valid_loss = 0.81357, valid_accuracy = 0.71880001
	time = 30.73 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 23%|██▎       | 23/100 [11:04&lt;38:41, 30.15s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 8.7506e-02.
Epoch[22]:
	train_loss = 0.69527, train_accuracy = 0.71915001
	valid_loss = 0.96964, valid_accuracy = 0.67869997
	time = 30.39 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 24%|██▍       | 24/100 [11:34&lt;38:00, 30.00s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 8.6448e-02.
Epoch[23]:
	train_loss = 0.68489, train_accuracy = 0.77492499
	valid_loss = 0.77746, valid_accuracy = 0.7317
	time = 29.62 s
Validation loss decreased(0.78285---&gt;0.77746) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 25%|██▌       | 25/100 [12:03&lt;37:25, 29.93s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 8.5355e-02.
Epoch[24]:
	train_loss = 0.67221, train_accuracy = 0.76169997
	valid_loss = 0.81463, valid_accuracy = 0.71539998
	time = 29.78 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 26%|██▌       | 26/100 [12:33&lt;36:49, 29.86s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 8.4227e-02.
Epoch[25]:
	train_loss = 0.65668, train_accuracy = 0.74495
	valid_loss = 0.86388, valid_accuracy = 0.7001
	time = 29.7 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 27%|██▋       | 27/100 [13:03&lt;36:22, 29.90s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 8.3066e-02.
Epoch[26]:
	train_loss = 0.64725, train_accuracy = 0.77024996
	valid_loss = 0.79108, valid_accuracy = 0.72709996
	time = 29.97 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 28%|██▊       | 28/100 [13:33&lt;35:43, 29.77s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 8.1871e-02.
Epoch[27]:
	train_loss = 0.63881, train_accuracy = 0.768875
	valid_loss = 0.81416, valid_accuracy = 0.71469998
	time = 29.48 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 29%|██▉       | 29/100 [14:02&lt;35:13, 29.76s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 8.0645e-02.
Epoch[28]:
	train_loss = 0.62674, train_accuracy = 0.759
	valid_loss = 0.82269, valid_accuracy = 0.71219999
	time = 29.75 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 30%|███       | 30/100 [14:33&lt;34:56, 29.95s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 7.9389e-02.
Epoch[29]:
	train_loss = 0.61682, train_accuracy = 0.76909995
	valid_loss = 0.82129, valid_accuracy = 0.72279996
	time = 30.37 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 31%|███       | 31/100 [15:03&lt;34:40, 30.15s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 7.8104e-02.
Epoch[30]:
	train_loss = 0.60565, train_accuracy = 0.767075
	valid_loss = 0.81168, valid_accuracy = 0.72009999
	time = 30.62 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 32%|███▏      | 32/100 [15:33&lt;34:06, 30.10s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 7.6791e-02.
Epoch[31]:
	train_loss = 0.60065, train_accuracy = 0.78829998
	valid_loss = 0.771, valid_accuracy = 0.73509997
	time = 29.95 s
Validation loss decreased(0.77746---&gt;0.771) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 33%|███▎      | 33/100 [16:03&lt;33:23, 29.91s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 7.5452e-02.
Epoch[32]:
	train_loss = 0.59207, train_accuracy = 0.76475
	valid_loss = 0.86179, valid_accuracy = 0.70899999
	time = 29.46 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 34%|███▍      | 34/100 [16:32&lt;32:47, 29.81s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 7.4088e-02.
Epoch[33]:
	train_loss = 0.57581, train_accuracy = 0.7913
	valid_loss = 0.78293, valid_accuracy = 0.73710001
	time = 29.58 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 35%|███▌      | 35/100 [17:02&lt;32:10, 29.70s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 7.2700e-02.
Epoch[34]:
	train_loss = 0.56758, train_accuracy = 0.803675
	valid_loss = 0.7283, valid_accuracy = 0.74989998
	time = 29.4 s
Validation loss decreased(0.771---&gt;0.7283) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 36%|███▌      | 36/100 [17:31&lt;31:33, 29.59s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 7.1289e-02.
Epoch[35]:
	train_loss = 0.56089, train_accuracy = 0.809075
	valid_loss = 0.74761, valid_accuracy = 0.7482
	time = 29.34 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 37%|███▋      | 37/100 [18:00&lt;30:57, 29.49s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 6.9857e-02.
Epoch[36]:
	train_loss = 0.55337, train_accuracy = 0.8071
	valid_loss = 0.74723, valid_accuracy = 0.74549997
	time = 29.26 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 38%|███▊      | 38/100 [18:30&lt;30:38, 29.66s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 6.8406e-02.
Epoch[37]:
	train_loss = 0.54095, train_accuracy = 0.81194997
	valid_loss = 0.72011, valid_accuracy = 0.75269997
	time = 30.0 s
Validation loss decreased(0.7283---&gt;0.72011) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 39%|███▉      | 39/100 [19:01&lt;30:18, 29.81s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 6.6937e-02.
Epoch[38]:
	train_loss = 0.52262, train_accuracy = 0.82947499
	valid_loss = 0.69132, valid_accuracy = 0.76370001
	time = 30.14 s
Validation loss decreased(0.72011---&gt;0.69132) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 40%|████      | 40/100 [19:30&lt;29:45, 29.75s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 6.5451e-02.
Epoch[39]:
	train_loss = 0.51931, train_accuracy = 0.79622495
	valid_loss = 0.78226, valid_accuracy = 0.73589998
	time = 29.62 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 41%|████      | 41/100 [19:59&lt;29:03, 29.55s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 6.3950e-02.
Epoch[40]:
	train_loss = 0.51821, train_accuracy = 0.80917495
	valid_loss = 0.75193, valid_accuracy = 0.74809998
	time = 29.08 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 42%|████▏     | 42/100 [20:28&lt;28:24, 29.38s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 6.2434e-02.
Epoch[41]:
	train_loss = 0.49678, train_accuracy = 0.82767498
	valid_loss = 0.71174, valid_accuracy = 0.7536
	time = 29.0 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 43%|████▎     | 43/100 [20:57&lt;27:43, 29.18s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 6.0907e-02.
Epoch[42]:
	train_loss = 0.4984, train_accuracy = 0.83064997
	valid_loss = 0.71413, valid_accuracy = 0.75519997
	time = 28.72 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 44%|████▍     | 44/100 [21:25&lt;26:49, 28.75s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 5.9369e-02.
Epoch[43]:
	train_loss = 0.48455, train_accuracy = 0.83074999
	valid_loss = 0.71303, valid_accuracy = 0.759
	time = 27.73 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 45%|████▌     | 45/100 [21:53&lt;26:06, 28.47s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 5.7822e-02.
Epoch[44]:
	train_loss = 0.4773, train_accuracy = 0.80785
	valid_loss = 0.77292, valid_accuracy = 0.7414
	time = 27.83 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 46%|████▌     | 46/100 [22:21&lt;25:31, 28.37s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 5.6267e-02.
Epoch[45]:
	train_loss = 0.46978, train_accuracy = 0.85104996
	valid_loss = 0.66495, valid_accuracy = 0.77139997
	time = 28.08 s
Validation loss decreased(0.69132---&gt;0.66495) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 47%|████▋     | 47/100 [22:49&lt;24:56, 28.24s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 5.4705e-02.
Epoch[46]:
	train_loss = 0.45732, train_accuracy = 0.852925
	valid_loss = 0.6616, valid_accuracy = 0.77359998
	time = 27.92 s
Validation loss decreased(0.66495---&gt;0.6616) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 48%|████▊     | 48/100 [23:17&lt;24:26, 28.21s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 5.3140e-02.
Epoch[47]:
	train_loss = 0.44423, train_accuracy = 0.85469997
	valid_loss = 0.68881, valid_accuracy = 0.76429999
	time = 28.14 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 49%|████▉     | 49/100 [23:44&lt;23:46, 27.96s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 5.1571e-02.
Epoch[48]:
	train_loss = 0.4364, train_accuracy = 0.84762496
	valid_loss = 0.7141, valid_accuracy = 0.7658
	time = 27.39 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 50%|█████     | 50/100 [24:12&lt;23:16, 27.92s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 5.0000e-02.
Epoch[49]:
	train_loss = 0.42343, train_accuracy = 0.84877497
	valid_loss = 0.70199, valid_accuracy = 0.76319999
	time = 27.82 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 51%|█████     | 51/100 [24:40&lt;22:52, 28.00s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 4.8429e-02.
Epoch[50]:
	train_loss = 0.41925, train_accuracy = 0.86002499
	valid_loss = 0.70572, valid_accuracy = 0.7687
	time = 28.19 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 52%|█████▏    | 52/100 [25:08&lt;22:25, 28.03s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 4.6860e-02.
Epoch[51]:
	train_loss = 0.40605, train_accuracy = 0.87274998
	valid_loss = 0.66085, valid_accuracy = 0.77759999
	time = 28.05 s
Validation loss decreased(0.6616---&gt;0.66085) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 53%|█████▎    | 53/100 [25:36&lt;21:55, 27.99s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 4.5295e-02.
Epoch[52]:
	train_loss = 0.38985, train_accuracy = 0.88347501
	valid_loss = 0.65802, valid_accuracy = 0.78319997
	time = 27.85 s
Validation loss decreased(0.66085---&gt;0.65802) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 54%|█████▍    | 54/100 [26:04&lt;21:20, 27.84s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 4.3733e-02.
Epoch[53]:
	train_loss = 0.38696, train_accuracy = 0.87442499
	valid_loss = 0.66854, valid_accuracy = 0.77160001
	time = 27.51 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 55%|█████▌    | 55/100 [26:31&lt;20:50, 27.79s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 4.2178e-02.
Epoch[54]:
	train_loss = 0.36862, train_accuracy = 0.88942498
	valid_loss = 0.63704, valid_accuracy = 0.7895
	time = 27.64 s
Validation loss decreased(0.65802---&gt;0.63704) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 56%|█████▌    | 56/100 [26:59&lt;20:21, 27.75s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 4.0631e-02.
Epoch[55]:
	train_loss = 0.35705, train_accuracy = 0.87449998
	valid_loss = 0.69445, valid_accuracy = 0.77579999
	time = 27.66 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 57%|█████▋    | 57/100 [27:27&lt;19:53, 27.75s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 3.9093e-02.
Epoch[56]:
	train_loss = 0.34836, train_accuracy = 0.87935001
	valid_loss = 0.69658, valid_accuracy = 0.76909995
	time = 27.76 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 58%|█████▊    | 58/100 [27:54&lt;19:20, 27.64s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 3.7566e-02.
Epoch[57]:
	train_loss = 0.33177, train_accuracy = 0.90007496
	valid_loss = 0.64647, valid_accuracy = 0.78569996
	time = 27.37 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 59%|█████▉    | 59/100 [28:21&lt;18:49, 27.56s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 3.6050e-02.
Epoch[58]:
	train_loss = 0.31935, train_accuracy = 0.89934999
	valid_loss = 0.66863, valid_accuracy = 0.78669995
	time = 27.37 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 60%|██████    | 60/100 [28:49&lt;18:18, 27.47s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 3.4549e-02.
Epoch[59]:
	train_loss = 0.31079, train_accuracy = 0.91564995
	valid_loss = 0.61799, valid_accuracy = 0.79659998
	time = 27.22 s
Validation loss decreased(0.63704---&gt;0.61799) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 61%|██████    | 61/100 [29:16&lt;17:54, 27.55s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 3.3063e-02.
Epoch[60]:
	train_loss = 0.29231, train_accuracy = 0.90154999
	valid_loss = 0.68429, valid_accuracy = 0.78509998
	time = 27.74 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 62%|██████▏   | 62/100 [29:44&lt;17:28, 27.60s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 3.1594e-02.
Epoch[61]:
	train_loss = 0.28235, train_accuracy = 0.91527498
	valid_loss = 0.67253, valid_accuracy = 0.78889996
	time = 27.72 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 63%|██████▎   | 63/100 [30:12&lt;16:58, 27.52s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 3.0143e-02.
Epoch[62]:
	train_loss = 0.27336, train_accuracy = 0.90609998
	valid_loss = 0.69924, valid_accuracy = 0.77869999
	time = 27.32 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 64%|██████▍   | 64/100 [30:39&lt;16:30, 27.52s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 2.8711e-02.
Epoch[63]:
	train_loss = 0.26266, train_accuracy = 0.92245001
	valid_loss = 0.66273, valid_accuracy = 0.79139996
	time = 27.53 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 65%|██████▌   | 65/100 [31:07&lt;16:07, 27.65s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 2.7300e-02.
Epoch[64]:
	train_loss = 0.24306, train_accuracy = 0.92859995
	valid_loss = 0.66525, valid_accuracy = 0.79399997
	time = 27.96 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 66%|██████▌   | 66/100 [31:35&lt;15:40, 27.67s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 2.5912e-02.
Epoch[65]:
	train_loss = 0.22279, train_accuracy = 0.93314999
	valid_loss = 0.7082, valid_accuracy = 0.79069996
	time = 27.72 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 67%|██████▋   | 67/100 [32:02&lt;15:09, 27.57s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 2.4548e-02.
Epoch[66]:
	train_loss = 0.2106, train_accuracy = 0.91769999
	valid_loss = 0.75424, valid_accuracy = 0.77639997
	time = 27.32 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 68%|██████▊   | 68/100 [32:29&lt;14:40, 27.53s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 2.3209e-02.
Epoch[67]:
	train_loss = 0.19714, train_accuracy = 0.93959999
	valid_loss = 0.71467, valid_accuracy = 0.7902
	time = 27.44 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 69%|██████▉   | 69/100 [32:57&lt;14:14, 27.57s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 2.1896e-02.
Epoch[68]:
	train_loss = 0.18564, train_accuracy = 0.95119995
	valid_loss = 0.69794, valid_accuracy = 0.79929996
	time = 27.68 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 70%|███████   | 70/100 [33:25&lt;13:50, 27.67s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 2.0611e-02.
Epoch[69]:
	train_loss = 0.16525, train_accuracy = 0.93102497
	valid_loss = 0.77667, valid_accuracy = 0.7816
	time = 27.89 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 71%|███████   | 71/100 [33:53&lt;13:21, 27.65s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 1.9355e-02.
Epoch[70]:
	train_loss = 0.16059, train_accuracy = 0.95819998
	valid_loss = 0.72401, valid_accuracy = 0.79229999
	time = 27.6 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 72%|███████▏  | 72/100 [34:20&lt;12:52, 27.57s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 1.8129e-02.
Epoch[71]:
	train_loss = 0.13343, train_accuracy = 0.96609998
	valid_loss = 0.73286, valid_accuracy = 0.80409998
	time = 27.4 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 73%|███████▎  | 73/100 [34:48&lt;12:23, 27.54s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 1.6934e-02.
Epoch[72]:
	train_loss = 0.1236, train_accuracy = 0.96702498
	valid_loss = 0.73965, valid_accuracy = 0.80140001
	time = 27.48 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 74%|███████▍  | 74/100 [35:16&lt;12:02, 27.79s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 1.5773e-02.
Epoch[73]:
	train_loss = 0.1111, train_accuracy = 0.97247499
	valid_loss = 0.75573, valid_accuracy = 0.8028
	time = 28.37 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 74%|███████▍  | 74/100 [35:44&lt;12:33, 28.97s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 1.4645e-02.
Epoch[74]:
	train_loss = 0.09276, train_accuracy = 0.97849995
	valid_loss = 0.77665, valid_accuracy = 0.81009996
	time = 27.66 s
Validation loss didn't decrease for 15 epochs ---&gt; model training stopped
[Finished training]
	valid training loss: 0.31079
	valid training accuracy 0.91564995
	min validation loss: 0.61799,
	best validation accuracy: 0.79659998
Model[RegNet] - partial training (last layer) / model_weights
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 1.0000e-01.
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>  0%|          | 0/100 [00:00&lt;?, ?it/s]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>#############################################################################################
[Training parameters]
	epochs = 100,
	lr = 0.1,
	momentum = 0.9,
	weight_decay = 0.0005,
	loss = CrossEntropyLoss(),
	optimizer = SGD (
Parameter Group 0
    dampening: 0
    differentiable: False
    foreach: None
    initial_lr: 0.1
    lr: 0.1
    maximize: False
    momentum: 0.9
    nesterov: False
    weight_decay: 0.0005
),
	scheduler = &lt;torch.optim.lr_scheduler.CosineAnnealingLR object at 0x0000026A386C3F40&gt;,
	device = cuda:0
#############################################################################################
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>  1%|          | 1/100 [00:20&lt;33:00, 20.01s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.9975e-02.
Epoch[0]:
	train_loss = 4.16603, train_accuracy = 0.23217499
	valid_loss = 4.49328, valid_accuracy = 0.22809999
	time = 19.97 s
Validation loss decreased(None---&gt;4.49328) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>  2%|▏         | 2/100 [00:39&lt;32:19, 19.79s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.9901e-02.
Epoch[1]:
	train_loss = 4.42499, train_accuracy = 0.230675
	valid_loss = 4.36251, valid_accuracy = 0.22939999
	time = 19.61 s
Validation loss decreased(4.49328---&gt;4.36251) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>  3%|▎         | 3/100 [00:59&lt;31:52, 19.72s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.9778e-02.
Epoch[2]:
	train_loss = 4.37994, train_accuracy = 0.241175
	valid_loss = 4.2857, valid_accuracy = 0.23879999
	time = 19.51 s
Validation loss decreased(4.36251---&gt;4.2857) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>  4%|▍         | 4/100 [01:18&lt;31:29, 19.69s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.9606e-02.
Epoch[3]:
	train_loss = 4.48169, train_accuracy = 0.23674999
	valid_loss = 4.47288, valid_accuracy = 0.2261
	time = 19.64 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>  5%|▌         | 5/100 [01:38&lt;31:21, 19.81s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.9384e-02.
Epoch[4]:
	train_loss = 4.44311, train_accuracy = 0.24274999
	valid_loss = 4.43329, valid_accuracy = 0.2454
	time = 20.02 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>  6%|▌         | 6/100 [01:59&lt;31:10, 19.89s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.9114e-02.
Epoch[5]:
	train_loss = 4.46664, train_accuracy = 0.23185
	valid_loss = 4.48544, valid_accuracy = 0.2218
	time = 20.06 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>  7%|▋         | 7/100 [02:18&lt;30:51, 19.91s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.8796e-02.
Epoch[6]:
	train_loss = 4.38824, train_accuracy = 0.23864999
	valid_loss = 4.56713, valid_accuracy = 0.23879999
	time = 19.94 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>  8%|▊         | 8/100 [02:38&lt;30:31, 19.91s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.8429e-02.
Epoch[7]:
	train_loss = 4.36588, train_accuracy = 0.24394999
	valid_loss = 4.28614, valid_accuracy = 0.23779999
	time = 19.92 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>  9%|▉         | 9/100 [02:58&lt;30:11, 19.90s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.8015e-02.
Epoch[8]:
	train_loss = 4.38582, train_accuracy = 0.243975
	valid_loss = 4.48745, valid_accuracy = 0.23959999
	time = 19.89 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 10%|█         | 10/100 [03:18&lt;29:42, 19.81s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.7553e-02.
Epoch[9]:
	train_loss = 4.41938, train_accuracy = 0.240125
	valid_loss = 4.56307, valid_accuracy = 0.2351
	time = 19.6 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 11%|█         | 11/100 [03:38&lt;29:28, 19.88s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.7044e-02.
Epoch[10]:
	train_loss = 4.24585, train_accuracy = 0.24482499
	valid_loss = 4.01044, valid_accuracy = 0.24579999
	time = 19.99 s
Validation loss decreased(4.2857---&gt;4.01044) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 12%|█▏        | 12/100 [03:58&lt;29:25, 20.06s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.6489e-02.
Epoch[11]:
	train_loss = 4.40159, train_accuracy = 0.235275
	valid_loss = 4.46103, valid_accuracy = 0.2251
	time = 20.49 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 13%|█▎        | 13/100 [04:18&lt;29:05, 20.06s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.5888e-02.
Epoch[12]:
	train_loss = 4.41824, train_accuracy = 0.24412499
	valid_loss = 4.24201, valid_accuracy = 0.25
	time = 20.07 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 14%|█▍        | 14/100 [04:38&lt;28:39, 20.00s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.5241e-02.
Epoch[13]:
	train_loss = 4.32617, train_accuracy = 0.234
	valid_loss = 4.36911, valid_accuracy = 0.228
	time = 19.84 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 15%|█▌        | 15/100 [04:58&lt;28:21, 20.02s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.4550e-02.
Epoch[14]:
	train_loss = 4.29365, train_accuracy = 0.24769999
	valid_loss = 4.32305, valid_accuracy = 0.24249999
	time = 20.08 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 16%|█▌        | 16/100 [05:18&lt;28:01, 20.02s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.3815e-02.
Epoch[15]:
	train_loss = 4.13532, train_accuracy = 0.24874999
	valid_loss = 3.93366, valid_accuracy = 0.2385
	time = 19.99 s
Validation loss decreased(4.01044---&gt;3.93366) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 17%|█▋        | 17/100 [05:39&lt;27:49, 20.12s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.3037e-02.
Epoch[16]:
	train_loss = 4.22316, train_accuracy = 0.24484999
	valid_loss = 4.35048, valid_accuracy = 0.23869999
	time = 20.34 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 18%|█▊        | 18/100 [05:59&lt;27:32, 20.15s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.2216e-02.
Epoch[17]:
	train_loss = 4.18611, train_accuracy = 0.23002499
	valid_loss = 4.56635, valid_accuracy = 0.22909999
	time = 20.24 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 19%|█▉        | 19/100 [06:19&lt;27:14, 20.18s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.1354e-02.
Epoch[18]:
	train_loss = 4.18194, train_accuracy = 0.23547499
	valid_loss = 4.27277, valid_accuracy = 0.2332
	time = 20.24 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 20%|██        | 20/100 [06:40&lt;27:04, 20.30s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.0451e-02.
Epoch[19]:
	train_loss = 4.12868, train_accuracy = 0.2392
	valid_loss = 4.51055, valid_accuracy = 0.23359999
	time = 20.59 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 21%|██        | 21/100 [07:01&lt;27:09, 20.62s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 8.9508e-02.
Epoch[20]:
	train_loss = 4.08997, train_accuracy = 0.246925
	valid_loss = 3.82835, valid_accuracy = 0.24479999
	time = 21.33 s
Validation loss decreased(3.93366---&gt;3.82835) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 22%|██▏       | 22/100 [07:21&lt;26:38, 20.50s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 8.8526e-02.
Epoch[21]:
	train_loss = 4.01168, train_accuracy = 0.233025
	valid_loss = 4.36618, valid_accuracy = 0.234
	time = 20.2 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 23%|██▎       | 23/100 [07:41&lt;26:08, 20.36s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 8.7506e-02.
Epoch[22]:
	train_loss = 4.05126, train_accuracy = 0.24687499
	valid_loss = 4.15405, valid_accuracy = 0.24329999
	time = 20.06 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 24%|██▍       | 24/100 [08:02&lt;25:48, 20.38s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 8.6448e-02.
Epoch[23]:
	train_loss = 3.96302, train_accuracy = 0.24627499
	valid_loss = 4.07553, valid_accuracy = 0.24069999
	time = 20.41 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 25%|██▌       | 25/100 [08:22&lt;25:14, 20.20s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 8.5355e-02.
Epoch[24]:
	train_loss = 4.03471, train_accuracy = 0.240375
	valid_loss = 3.95712, valid_accuracy = 0.2403
	time = 19.77 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 26%|██▌       | 26/100 [08:42&lt;24:48, 20.11s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 8.4227e-02.
Epoch[25]:
	train_loss = 3.95583, train_accuracy = 0.23355
	valid_loss = 4.25984, valid_accuracy = 0.2313
	time = 19.92 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 27%|██▋       | 27/100 [09:01&lt;24:21, 20.02s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 8.3066e-02.
Epoch[26]:
	train_loss = 3.85024, train_accuracy = 0.245675
	valid_loss = 3.81213, valid_accuracy = 0.236
	time = 19.78 s
Validation loss decreased(3.82835---&gt;3.81213) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 28%|██▊       | 28/100 [09:21&lt;24:02, 20.04s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 8.1871e-02.
Epoch[27]:
	train_loss = 3.84294, train_accuracy = 0.24637499
	valid_loss = 3.7951, valid_accuracy = 0.24169999
	time = 20.03 s
Validation loss decreased(3.81213---&gt;3.7951) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 29%|██▉       | 29/100 [09:41&lt;23:43, 20.04s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 8.0645e-02.
Epoch[28]:
	train_loss = 3.78715, train_accuracy = 0.24107499
	valid_loss = 3.8587, valid_accuracy = 0.233
	time = 20.05 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 30%|███       | 30/100 [10:02&lt;23:30, 20.15s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 7.9389e-02.
Epoch[29]:
	train_loss = 3.69284, train_accuracy = 0.25722501
	valid_loss = 3.81879, valid_accuracy = 0.24749999
	time = 20.39 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 31%|███       | 31/100 [10:22&lt;23:14, 20.21s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 7.8104e-02.
Epoch[30]:
	train_loss = 3.7188, train_accuracy = 0.247475
	valid_loss = 3.54973, valid_accuracy = 0.2358
	time = 20.33 s
Validation loss decreased(3.7951---&gt;3.54973) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 32%|███▏      | 32/100 [10:45&lt;23:39, 20.87s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 7.6791e-02.
Epoch[31]:
	train_loss = 3.6376, train_accuracy = 0.24969999
	valid_loss = 3.75787, valid_accuracy = 0.2472
	time = 22.41 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 33%|███▎      | 33/100 [11:06&lt;23:27, 21.01s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 7.5452e-02.
Epoch[32]:
	train_loss = 3.64004, train_accuracy = 0.249725
	valid_loss = 3.80296, valid_accuracy = 0.24489999
	time = 21.33 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 34%|███▍      | 34/100 [11:27&lt;23:14, 21.13s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 7.4088e-02.
Epoch[33]:
	train_loss = 3.55331, train_accuracy = 0.25529999
	valid_loss = 3.53644, valid_accuracy = 0.2471
	time = 21.36 s
Validation loss decreased(3.54973---&gt;3.53644) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 35%|███▌      | 35/100 [11:47&lt;22:29, 20.76s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 7.2700e-02.
Epoch[34]:
	train_loss = 3.61376, train_accuracy = 0.240825
	valid_loss = 3.66893, valid_accuracy = 0.24259999
	time = 19.92 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 36%|███▌      | 36/100 [12:08&lt;22:04, 20.70s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 7.1289e-02.
Epoch[35]:
	train_loss = 3.58066, train_accuracy = 0.243775
	valid_loss = 3.77873, valid_accuracy = 0.241
	time = 20.55 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 37%|███▋      | 37/100 [12:29&lt;21:46, 20.74s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 6.9857e-02.
Epoch[36]:
	train_loss = 3.49723, train_accuracy = 0.24855
	valid_loss = 3.55237, valid_accuracy = 0.243
	time = 20.85 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 38%|███▊      | 38/100 [12:50&lt;21:38, 20.94s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 6.8406e-02.
Epoch[37]:
	train_loss = 3.39298, train_accuracy = 0.24609999
	valid_loss = 3.54454, valid_accuracy = 0.2401
	time = 21.39 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 39%|███▉      | 39/100 [13:12&lt;21:29, 21.14s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 6.6937e-02.
Epoch[38]:
	train_loss = 3.35862, train_accuracy = 0.24572499
	valid_loss = 3.43486, valid_accuracy = 0.23909999
	time = 21.57 s
Validation loss decreased(3.53644---&gt;3.43486) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 40%|████      | 40/100 [13:32&lt;20:51, 20.86s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 6.5451e-02.
Epoch[39]:
	train_loss = 3.29803, train_accuracy = 0.23602499
	valid_loss = 3.82491, valid_accuracy = 0.23449999
	time = 20.2 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 41%|████      | 41/100 [13:52&lt;20:16, 20.62s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 6.3950e-02.
Epoch[40]:
	train_loss = 3.25823, train_accuracy = 0.25165001
	valid_loss = 3.48243, valid_accuracy = 0.24489999
	time = 20.07 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 42%|████▏     | 42/100 [14:12&lt;19:46, 20.46s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 6.2434e-02.
Epoch[41]:
	train_loss = 3.22204, train_accuracy = 0.25292498
	valid_loss = 3.19013, valid_accuracy = 0.24259999
	time = 20.05 s
Validation loss decreased(3.43486---&gt;3.19013) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 43%|████▎     | 43/100 [14:32&lt;19:10, 20.19s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 6.0907e-02.
Epoch[42]:
	train_loss = 3.14716, train_accuracy = 0.2656
	valid_loss = 3.21173, valid_accuracy = 0.25779998
	time = 19.56 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 44%|████▍     | 44/100 [14:52&lt;18:47, 20.14s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 5.9369e-02.
Epoch[43]:
	train_loss = 3.16178, train_accuracy = 0.255
	valid_loss = 3.31514, valid_accuracy = 0.25029999
	time = 20.03 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 45%|████▌     | 45/100 [15:12&lt;18:29, 20.18s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 5.7822e-02.
Epoch[44]:
	train_loss = 3.07957, train_accuracy = 0.25220001
	valid_loss = 3.11581, valid_accuracy = 0.25139999
	time = 20.23 s
Validation loss decreased(3.19013---&gt;3.11581) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 46%|████▌     | 46/100 [15:32&lt;18:13, 20.24s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 5.6267e-02.
Epoch[45]:
	train_loss = 3.02682, train_accuracy = 0.256675
	valid_loss = 3.05527, valid_accuracy = 0.25189999
	time = 20.37 s
Validation loss decreased(3.11581---&gt;3.05527) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 47%|████▋     | 47/100 [15:52&lt;17:43, 20.07s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 5.4705e-02.
Epoch[46]:
	train_loss = 2.9493, train_accuracy = 0.24955
	valid_loss = 3.13585, valid_accuracy = 0.2429
	time = 19.67 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 48%|████▊     | 48/100 [16:12&lt;17:22, 20.04s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 5.3140e-02.
Epoch[47]:
	train_loss = 2.91045, train_accuracy = 0.251625
	valid_loss = 2.92683, valid_accuracy = 0.25329998
	time = 19.94 s
Validation loss decreased(3.05527---&gt;2.92683) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 49%|████▉     | 49/100 [16:32&lt;16:59, 19.99s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 5.1571e-02.
Epoch[48]:
	train_loss = 2.89749, train_accuracy = 0.25075001
	valid_loss = 2.94314, valid_accuracy = 0.2464
	time = 19.87 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 50%|█████     | 50/100 [16:51&lt;16:34, 19.89s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 5.0000e-02.
Epoch[49]:
	train_loss = 2.85549, train_accuracy = 0.26467499
	valid_loss = 2.80001, valid_accuracy = 0.2586
	time = 19.64 s
Validation loss decreased(2.92683---&gt;2.80001) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 51%|█████     | 51/100 [17:11&lt;16:08, 19.77s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 4.8429e-02.
Epoch[50]:
	train_loss = 2.80979, train_accuracy = 0.261475
	valid_loss = 2.8474, valid_accuracy = 0.25310001
	time = 19.48 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 52%|█████▏    | 52/100 [17:31&lt;15:50, 19.81s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 4.6860e-02.
Epoch[51]:
	train_loss = 2.81255, train_accuracy = 0.243975
	valid_loss = 3.20039, valid_accuracy = 0.24139999
	time = 19.9 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 53%|█████▎    | 53/100 [17:51&lt;15:31, 19.82s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 4.5295e-02.
Epoch[52]:
	train_loss = 2.74155, train_accuracy = 0.27702498
	valid_loss = 2.64636, valid_accuracy = 0.26809999
	time = 19.8 s
Validation loss decreased(2.80001---&gt;2.64636) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 54%|█████▍    | 54/100 [18:11&lt;15:13, 19.86s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 4.3733e-02.
Epoch[53]:
	train_loss = 2.6432, train_accuracy = 0.26440001
	valid_loss = 2.65182, valid_accuracy = 0.25419998
	time = 19.97 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 55%|█████▌    | 55/100 [18:30&lt;14:53, 19.85s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 4.2178e-02.
Epoch[54]:
	train_loss = 2.62833, train_accuracy = 0.25579998
	valid_loss = 2.73838, valid_accuracy = 0.25279999
	time = 19.83 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 56%|█████▌    | 56/100 [18:51&lt;14:39, 19.99s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 4.0631e-02.
Epoch[55]:
	train_loss = 2.60601, train_accuracy = 0.27562499
	valid_loss = 2.56997, valid_accuracy = 0.26929998
	time = 20.27 s
Validation loss decreased(2.64636---&gt;2.56997) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 57%|█████▋    | 57/100 [19:11&lt;14:21, 20.03s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 3.9093e-02.
Epoch[56]:
	train_loss = 2.56206, train_accuracy = 0.273875
	valid_loss = 2.52386, valid_accuracy = 0.26190001
	time = 20.11 s
Validation loss decreased(2.56997---&gt;2.52386) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 58%|█████▊    | 58/100 [19:31&lt;14:03, 20.08s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 3.7566e-02.
Epoch[57]:
	train_loss = 2.54173, train_accuracy = 0.268325
	valid_loss = 2.5369, valid_accuracy = 0.2633
	time = 20.19 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 59%|█████▉    | 59/100 [19:51&lt;13:42, 20.06s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 3.6050e-02.
Epoch[58]:
	train_loss = 2.51333, train_accuracy = 0.27109998
	valid_loss = 2.50259, valid_accuracy = 0.26530001
	time = 19.98 s
Validation loss decreased(2.52386---&gt;2.50259) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 60%|██████    | 60/100 [20:11&lt;13:18, 19.95s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 3.4549e-02.
Epoch[59]:
	train_loss = 2.4543, train_accuracy = 0.26955
	valid_loss = 2.51377, valid_accuracy = 0.27019998
	time = 19.7 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 61%|██████    | 61/100 [20:31&lt;12:56, 19.91s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 3.3063e-02.
Epoch[60]:
	train_loss = 2.4385, train_accuracy = 0.27222499
	valid_loss = 2.3668, valid_accuracy = 0.271
	time = 19.79 s
Validation loss decreased(2.50259---&gt;2.3668) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 62%|██████▏   | 62/100 [20:50&lt;12:33, 19.83s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 3.1594e-02.
Epoch[61]:
	train_loss = 2.39039, train_accuracy = 0.28755
	valid_loss = 2.3245, valid_accuracy = 0.26989999
	time = 19.61 s
Validation loss decreased(2.3668---&gt;2.3245) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 63%|██████▎   | 63/100 [21:11&lt;12:20, 20.02s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 3.0143e-02.
Epoch[62]:
	train_loss = 2.37033, train_accuracy = 0.2814
	valid_loss = 2.39874, valid_accuracy = 0.2802
	time = 20.45 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 64%|██████▍   | 64/100 [21:31&lt;11:58, 19.96s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 2.8711e-02.
Epoch[63]:
	train_loss = 2.34091, train_accuracy = 0.28187498
	valid_loss = 2.30265, valid_accuracy = 0.27559999
	time = 19.8 s
Validation loss decreased(2.3245---&gt;2.30265) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 65%|██████▌   | 65/100 [21:50&lt;11:37, 19.94s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 2.7300e-02.
Epoch[64]:
	train_loss = 2.30209, train_accuracy = 0.28474998
	valid_loss = 2.36872, valid_accuracy = 0.27399999
	time = 19.9 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 66%|██████▌   | 66/100 [22:11&lt;11:20, 20.02s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 2.5912e-02.
Epoch[65]:
	train_loss = 2.27045, train_accuracy = 0.29299998
	valid_loss = 2.23288, valid_accuracy = 0.28619999
	time = 20.17 s
Validation loss decreased(2.30265---&gt;2.23288) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 67%|██████▋   | 67/100 [22:31&lt;11:02, 20.08s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 2.4548e-02.
Epoch[66]:
	train_loss = 2.24347, train_accuracy = 0.29260001
	valid_loss = 2.24947, valid_accuracy = 0.28219998
	time = 20.21 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 68%|██████▊   | 68/100 [22:51&lt;10:40, 20.02s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 2.3209e-02.
Epoch[67]:
	train_loss = 2.20751, train_accuracy = 0.29179999
	valid_loss = 2.25989, valid_accuracy = 0.28979999
	time = 19.88 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 69%|██████▉   | 69/100 [23:11&lt;10:19, 19.99s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 2.1896e-02.
Epoch[68]:
	train_loss = 2.19819, train_accuracy = 0.29314998
	valid_loss = 2.20318, valid_accuracy = 0.28659999
	time = 19.89 s
Validation loss decreased(2.23288---&gt;2.20318) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 70%|███████   | 70/100 [23:31&lt;10:01, 20.06s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 2.0611e-02.
Epoch[69]:
	train_loss = 2.17893, train_accuracy = 0.286825
	valid_loss = 2.19743, valid_accuracy = 0.28279999
	time = 20.19 s
Validation loss decreased(2.20318---&gt;2.19743) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 71%|███████   | 71/100 [23:51&lt;09:42, 20.08s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 1.9355e-02.
Epoch[70]:
	train_loss = 2.14055, train_accuracy = 0.29214999
	valid_loss = 2.12973, valid_accuracy = 0.2902
	time = 20.09 s
Validation loss decreased(2.19743---&gt;2.12973) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 72%|███████▏  | 72/100 [24:11&lt;09:19, 19.98s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 1.8129e-02.
Epoch[71]:
	train_loss = 2.12032, train_accuracy = 0.30217499
	valid_loss = 2.15952, valid_accuracy = 0.2985
	time = 19.74 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 73%|███████▎  | 73/100 [24:32&lt;09:06, 20.26s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 1.6934e-02.
Epoch[72]:
	train_loss = 2.1189, train_accuracy = 0.30204999
	valid_loss = 2.14208, valid_accuracy = 0.29170001
	time = 20.91 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 74%|███████▍  | 74/100 [24:52&lt;08:45, 20.21s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 1.5773e-02.
Epoch[73]:
	train_loss = 2.05884, train_accuracy = 0.30884999
	valid_loss = 2.05046, valid_accuracy = 0.30339998
	time = 20.08 s
Validation loss decreased(2.12973---&gt;2.05046) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 75%|███████▌  | 75/100 [25:12&lt;08:24, 20.20s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 1.4645e-02.
Epoch[74]:
	train_loss = 2.05801, train_accuracy = 0.30840001
	valid_loss = 2.01912, valid_accuracy = 0.2942
	time = 20.12 s
Validation loss decreased(2.05046---&gt;2.01912) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 76%|███████▌  | 76/100 [25:32&lt;08:03, 20.15s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 1.3552e-02.
Epoch[75]:
	train_loss = 2.04939, train_accuracy = 0.31555
	valid_loss = 2.00933, valid_accuracy = 0.30449998
	time = 20.0 s
Validation loss decreased(2.01912---&gt;2.00933) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 77%|███████▋  | 77/100 [25:52&lt;07:42, 20.09s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 1.2494e-02.
Epoch[76]:
	train_loss = 2.02121, train_accuracy = 0.31709999
	valid_loss = 1.98402, valid_accuracy = 0.3127
	time = 19.95 s
Validation loss decreased(2.00933---&gt;1.98402) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 78%|███████▊  | 78/100 [26:12&lt;07:19, 19.99s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 1.1474e-02.
Epoch[77]:
	train_loss = 2.00663, train_accuracy = 0.31747499
	valid_loss = 2.01924, valid_accuracy = 0.30579999
	time = 19.75 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 79%|███████▉  | 79/100 [26:31&lt;06:57, 19.89s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 1.0492e-02.
Epoch[78]:
	train_loss = 1.99248, train_accuracy = 0.32170001
	valid_loss = 2.0042, valid_accuracy = 0.30789998
	time = 19.64 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 80%|████████  | 80/100 [26:51&lt;06:37, 19.85s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.5492e-03.
Epoch[79]:
	train_loss = 1.97787, train_accuracy = 0.32479998
	valid_loss = 1.98609, valid_accuracy = 0.3154
	time = 19.77 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 81%|████████  | 81/100 [27:11&lt;06:20, 20.00s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 8.6460e-03.
Epoch[80]:
	train_loss = 1.96397, train_accuracy = 0.33177498
	valid_loss = 1.94905, valid_accuracy = 0.32099998
	time = 20.34 s
Validation loss decreased(1.98402---&gt;1.94905) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 82%|████████▏ | 82/100 [27:32&lt;06:01, 20.10s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 7.7836e-03.
Epoch[81]:
	train_loss = 1.94471, train_accuracy = 0.32657498
	valid_loss = 1.95027, valid_accuracy = 0.3197
	time = 20.32 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 83%|████████▎ | 83/100 [27:52&lt;05:40, 20.02s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 6.9629e-03.
Epoch[82]:
	train_loss = 1.93341, train_accuracy = 0.33499998
	valid_loss = 1.9151, valid_accuracy = 0.3301
	time = 19.8 s
Validation loss decreased(1.94905---&gt;1.9151) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 84%|████████▍ | 84/100 [28:12&lt;05:19, 19.99s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 6.1847e-03.
Epoch[83]:
	train_loss = 1.93243, train_accuracy = 0.34047499
	valid_loss = 1.90841, valid_accuracy = 0.3265
	time = 19.9 s
Validation loss decreased(1.9151---&gt;1.90841) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 85%|████████▌ | 85/100 [28:31&lt;04:58, 19.91s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 5.4497e-03.
Epoch[84]:
	train_loss = 1.91701, train_accuracy = 0.33335
	valid_loss = 1.94698, valid_accuracy = 0.32839999
	time = 19.72 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 86%|████████▌ | 86/100 [28:51&lt;04:37, 19.83s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 4.7586e-03.
Epoch[85]:
	train_loss = 1.90292, train_accuracy = 0.34254998
	valid_loss = 1.89704, valid_accuracy = 0.3364
	time = 19.59 s
Validation loss decreased(1.90841---&gt;1.89704) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 87%|████████▋ | 87/100 [29:11&lt;04:17, 19.77s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 4.1123e-03.
Epoch[86]:
	train_loss = 1.904, train_accuracy = 0.34709999
	valid_loss = 1.8945, valid_accuracy = 0.33829999
	time = 19.6 s
Validation loss decreased(1.89704---&gt;1.8945) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 88%|████████▊ | 88/100 [29:30&lt;03:56, 19.74s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 3.5112e-03.
Epoch[87]:
	train_loss = 1.88496, train_accuracy = 0.35152498
	valid_loss = 1.87896, valid_accuracy = 0.3371
	time = 19.65 s
Validation loss decreased(1.8945---&gt;1.87896) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 89%|████████▉ | 89/100 [29:50&lt;03:38, 19.86s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 2.9560e-03.
Epoch[88]:
	train_loss = 1.87896, train_accuracy = 0.34722498
	valid_loss = 1.88271, valid_accuracy = 0.3344
	time = 20.14 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 90%|█████████ | 90/100 [30:10&lt;03:18, 19.86s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 2.4472e-03.
Epoch[89]:
	train_loss = 1.87629, train_accuracy = 0.35527501
	valid_loss = 1.87349, valid_accuracy = 0.33499998
	time = 19.81 s
Validation loss decreased(1.87896---&gt;1.87349) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 91%|█████████ | 91/100 [30:30&lt;02:59, 19.91s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 1.9853e-03.
Epoch[90]:
	train_loss = 1.86171, train_accuracy = 0.35505
	valid_loss = 1.85406, valid_accuracy = 0.34649998
	time = 20.0 s
Validation loss decreased(1.87349---&gt;1.85406) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 92%|█████████▏| 92/100 [30:50&lt;02:39, 19.91s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 1.5708e-03.
Epoch[91]:
	train_loss = 1.85498, train_accuracy = 0.35157499
	valid_loss = 1.88937, valid_accuracy = 0.33969998
	time = 19.91 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 93%|█████████▎| 93/100 [31:10&lt;02:19, 19.88s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 1.2042e-03.
Epoch[92]:
	train_loss = 1.85984, train_accuracy = 0.35705
	valid_loss = 1.87852, valid_accuracy = 0.3488
	time = 19.81 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 94%|█████████▍| 94/100 [31:30&lt;02:00, 20.07s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 8.8564e-04.
Epoch[93]:
	train_loss = 1.84729, train_accuracy = 0.35734999
	valid_loss = 1.85434, valid_accuracy = 0.34559998
	time = 20.53 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 95%|█████████▌| 95/100 [31:51&lt;01:40, 20.12s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 6.1558e-04.
Epoch[94]:
	train_loss = 1.84991, train_accuracy = 0.35862499
	valid_loss = 1.84526, valid_accuracy = 0.3486
	time = 20.18 s
Validation loss decreased(1.85406---&gt;1.84526) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 96%|█████████▌| 96/100 [32:10&lt;01:20, 20.01s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 3.9426e-04.
Epoch[95]:
	train_loss = 1.84239, train_accuracy = 0.36184999
	valid_loss = 1.84213, valid_accuracy = 0.35389999
	time = 19.75 s
Validation loss decreased(1.84526---&gt;1.84213) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 97%|█████████▋| 97/100 [32:30&lt;00:59, 19.93s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 2.2190e-04.
Epoch[96]:
	train_loss = 1.84443, train_accuracy = 0.36307499
	valid_loss = 1.84001, valid_accuracy = 0.34899998
	time = 19.7 s
Validation loss decreased(1.84213---&gt;1.84001) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 98%|█████████▊| 98/100 [32:50&lt;00:39, 19.82s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.8664e-05.
Epoch[97]:
	train_loss = 1.8395, train_accuracy = 0.36199999
	valid_loss = 1.84326, valid_accuracy = 0.3524
	time = 19.57 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 99%|█████████▉| 99/100 [33:09&lt;00:19, 19.72s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 2.4672e-05.
Epoch[98]:
	train_loss = 1.83626, train_accuracy = 0.36217499
	valid_loss = 1.87207, valid_accuracy = 0.35079998
	time = 19.49 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>100%|██████████| 100/100 [33:29&lt;00:00, 20.09s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 0.0000e+00.
Epoch[99]:
	train_loss = 1.83114, train_accuracy = 0.36472499
	valid_loss = 1.85614, valid_accuracy = 0.35499999
	time = 19.63 s
[Finished training]
	valid training loss: 1.84443
	valid training accuracy 0.36307499
	min validation loss: 1.84001,
	best validation accuracy: 0.34899998
================================================================================
Model[ShuffleNetV2] last FC before mod: Linear(in_features=1024, out_features=1000, bias=True)
Model[ShuffleNetV2] last FC after mod: Linear(in_features=1024, out_features=10, bias=True)
Model[ShuffleNetV2] - full training / model_weights
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 1.0000e-01.
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>  0%|          | 0/100 [00:00&lt;?, ?it/s]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>#############################################################################################
[Training parameters]
	epochs = 100,
	lr = 0.1,
	momentum = 0.9,
	weight_decay = 0.0005,
	loss = CrossEntropyLoss(),
	optimizer = SGD (
Parameter Group 0
    dampening: 0
    differentiable: False
    foreach: None
    initial_lr: 0.1
    lr: 0.1
    maximize: False
    momentum: 0.9
    nesterov: False
    weight_decay: 0.0005
),
	scheduler = &lt;torch.optim.lr_scheduler.CosineAnnealingLR object at 0x0000026820C72440&gt;,
	device = cuda:0
#############################################################################################
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>  1%|          | 1/100 [00:22&lt;37:15, 22.58s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.9975e-02.
Epoch[0]:
	train_loss = 1.35325, train_accuracy = 0.565925
	valid_loss = 1.25774, valid_accuracy = 0.55469996
	time = 22.56 s
Validation loss decreased(None---&gt;1.25774) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>  2%|▏         | 2/100 [00:44&lt;36:30, 22.35s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.9901e-02.
Epoch[1]:
	train_loss = 1.06867, train_accuracy = 0.62352496
	valid_loss = 1.11629, valid_accuracy = 0.60079998
	time = 22.17 s
Validation loss decreased(1.25774---&gt;1.11629) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>  3%|▎         | 3/100 [01:06&lt;35:38, 22.04s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.9778e-02.
Epoch[2]:
	train_loss = 1.02104, train_accuracy = 0.63752496
	valid_loss = 1.06543, valid_accuracy = 0.62339997
	time = 21.65 s
Validation loss decreased(1.11629---&gt;1.06543) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>  4%|▍         | 4/100 [01:27&lt;34:38, 21.66s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.9606e-02.
Epoch[3]:
	train_loss = 1.00417, train_accuracy = 0.64384997
	valid_loss = 1.065, valid_accuracy = 0.62329996
	time = 21.04 s
Validation loss decreased(1.06543---&gt;1.065) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>  5%|▌         | 5/100 [01:49&lt;34:41, 21.91s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.9384e-02.
Epoch[4]:
	train_loss = 0.99149, train_accuracy = 0.637025
	valid_loss = 1.06436, valid_accuracy = 0.61879998
	time = 22.35 s
Validation loss decreased(1.065---&gt;1.06436) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>  6%|▌         | 6/100 [02:12&lt;34:26, 21.99s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.9114e-02.
Epoch[5]:
	train_loss = 0.97243, train_accuracy = 0.58687496
	valid_loss = 1.21723, valid_accuracy = 0.57359999
	time = 22.13 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>  7%|▋         | 7/100 [02:33&lt;34:03, 21.98s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.8796e-02.
Epoch[6]:
	train_loss = 0.96443, train_accuracy = 0.60589999
	valid_loss = 1.17154, valid_accuracy = 0.5966
	time = 21.95 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>  8%|▊         | 8/100 [02:56&lt;33:46, 22.02s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.8429e-02.
Epoch[7]:
	train_loss = 0.95751, train_accuracy = 0.58222497
	valid_loss = 1.24501, valid_accuracy = 0.55619997
	time = 22.13 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>  9%|▉         | 9/100 [03:17&lt;32:56, 21.72s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.8015e-02.
Epoch[8]:
	train_loss = 0.9454, train_accuracy = 0.61649996
	valid_loss = 1.13765, valid_accuracy = 0.59799999
	time = 21.04 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 10%|█         | 10/100 [03:38&lt;32:30, 21.67s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.7553e-02.
Epoch[9]:
	train_loss = 0.94053, train_accuracy = 0.65027499
	valid_loss = 1.0405, valid_accuracy = 0.63059998
	time = 21.54 s
Validation loss decreased(1.06436---&gt;1.0405) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 11%|█         | 11/100 [04:00&lt;32:20, 21.80s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.7044e-02.
Epoch[10]:
	train_loss = 0.93863, train_accuracy = 0.66552496
	valid_loss = 1.00572, valid_accuracy = 0.65309995
	time = 22.09 s
Validation loss decreased(1.0405---&gt;1.00572) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 12%|█▏        | 12/100 [04:22&lt;32:07, 21.90s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.6489e-02.
Epoch[11]:
	train_loss = 0.93619, train_accuracy = 0.63592499
	valid_loss = 1.1065, valid_accuracy = 0.6135
	time = 22.12 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 13%|█▎        | 13/100 [04:44&lt;31:47, 21.92s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.5888e-02.
Epoch[12]:
	train_loss = 0.9462, train_accuracy = 0.65867496
	valid_loss = 1.0383, valid_accuracy = 0.63999999
	time = 21.97 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 14%|█▍        | 14/100 [05:06&lt;31:23, 21.90s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.5241e-02.
Epoch[13]:
	train_loss = 0.92862, train_accuracy = 0.67925
	valid_loss = 0.97171, valid_accuracy = 0.65639997
	time = 21.83 s
Validation loss decreased(1.00572---&gt;0.97171) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 15%|█▌        | 15/100 [05:27&lt;30:37, 21.61s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.4550e-02.
Epoch[14]:
	train_loss = 0.92468, train_accuracy = 0.67147499
	valid_loss = 1.00352, valid_accuracy = 0.6473
	time = 20.96 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 16%|█▌        | 16/100 [05:49&lt;30:31, 21.80s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.3815e-02.
Epoch[15]:
	train_loss = 0.92644, train_accuracy = 0.63482499
	valid_loss = 1.07546, valid_accuracy = 0.62
	time = 22.24 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 17%|█▋        | 17/100 [06:11&lt;30:15, 21.87s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.3037e-02.
Epoch[16]:
	train_loss = 0.92411, train_accuracy = 0.66670001
	valid_loss = 1.01585, valid_accuracy = 0.6444
	time = 22.03 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 18%|█▊        | 18/100 [06:34&lt;30:01, 21.97s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.2216e-02.
Epoch[17]:
	train_loss = 0.91562, train_accuracy = 0.61724997
	valid_loss = 1.1488, valid_accuracy = 0.5984
	time = 22.19 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 19%|█▉        | 19/100 [06:56&lt;29:40, 21.98s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.1354e-02.
Epoch[18]:
	train_loss = 0.91165, train_accuracy = 0.66639996
	valid_loss = 1.00379, valid_accuracy = 0.64660001
	time = 22.01 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 20%|██        | 20/100 [07:17&lt;28:58, 21.74s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.0451e-02.
Epoch[19]:
	train_loss = 0.9106, train_accuracy = 0.67057496
	valid_loss = 1.01363, valid_accuracy = 0.65149999
	time = 21.17 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 21%|██        | 21/100 [07:38&lt;28:29, 21.64s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 8.9508e-02.
Epoch[20]:
	train_loss = 0.902, train_accuracy = 0.66834998
	valid_loss = 1.00294, valid_accuracy = 0.65219998
	time = 21.43 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 22%|██▏       | 22/100 [08:00&lt;28:16, 21.75s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 8.8526e-02.
Epoch[21]:
	train_loss = 0.90195, train_accuracy = 0.64029998
	valid_loss = 1.10413, valid_accuracy = 0.62360001
	time = 22.0 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 23%|██▎       | 23/100 [08:22&lt;27:51, 21.71s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 8.7506e-02.
Epoch[22]:
	train_loss = 0.88943, train_accuracy = 0.69059998
	valid_loss = 0.92674, valid_accuracy = 0.66979998
	time = 21.58 s
Validation loss decreased(0.97171---&gt;0.92674) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 24%|██▍       | 24/100 [08:44&lt;27:35, 21.78s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 8.6448e-02.
Epoch[23]:
	train_loss = 0.8861, train_accuracy = 0.66532499
	valid_loss = 0.9972, valid_accuracy = 0.64910001
	time = 21.95 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 25%|██▌       | 25/100 [09:06&lt;27:21, 21.89s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 8.5355e-02.
Epoch[24]:
	train_loss = 0.88186, train_accuracy = 0.66209996
	valid_loss = 1.01697, valid_accuracy = 0.64269996
	time = 22.13 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 26%|██▌       | 26/100 [09:27&lt;26:39, 21.62s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 8.4227e-02.
Epoch[25]:
	train_loss = 0.88164, train_accuracy = 0.66602498
	valid_loss = 1.00792, valid_accuracy = 0.64669997
	time = 21.0 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 27%|██▋       | 27/100 [09:49&lt;26:33, 21.83s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 8.3066e-02.
Epoch[26]:
	train_loss = 0.87221, train_accuracy = 0.65082496
	valid_loss = 1.06831, valid_accuracy = 0.62869996
	time = 22.33 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 28%|██▊       | 28/100 [10:11&lt;26:09, 21.79s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 8.1871e-02.
Epoch[27]:
	train_loss = 0.86488, train_accuracy = 0.68009996
	valid_loss = 0.96021, valid_accuracy = 0.65669996
	time = 21.7 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 29%|██▉       | 29/100 [10:33&lt;25:42, 21.73s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 8.0645e-02.
Epoch[28]:
	train_loss = 0.86354, train_accuracy = 0.68852496
	valid_loss = 0.9524, valid_accuracy = 0.66439998
	time = 21.57 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 30%|███       | 30/100 [10:54&lt;25:21, 21.74s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 7.9389e-02.
Epoch[29]:
	train_loss = 0.86445, train_accuracy = 0.66472501
	valid_loss = 1.01137, valid_accuracy = 0.64679998
	time = 21.77 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 31%|███       | 31/100 [11:16&lt;24:52, 21.62s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 7.8104e-02.
Epoch[30]:
	train_loss = 0.85894, train_accuracy = 0.68274999
	valid_loss = 0.96998, valid_accuracy = 0.65429997
	time = 21.35 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 32%|███▏      | 32/100 [11:37&lt;24:24, 21.54s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 7.6791e-02.
Epoch[31]:
	train_loss = 0.85045, train_accuracy = 0.67127496
	valid_loss = 0.98742, valid_accuracy = 0.65549999
	time = 21.35 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 33%|███▎      | 33/100 [11:59&lt;24:08, 21.62s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 7.5452e-02.
Epoch[32]:
	train_loss = 0.84971, train_accuracy = 0.68577498
	valid_loss = 0.96153, valid_accuracy = 0.662
	time = 21.82 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 34%|███▍      | 34/100 [12:20&lt;23:45, 21.60s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 7.4088e-02.
Epoch[33]:
	train_loss = 0.84174, train_accuracy = 0.70550001
	valid_loss = 0.91519, valid_accuracy = 0.68159997
	time = 21.54 s
Validation loss decreased(0.92674---&gt;0.91519) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 35%|███▌      | 35/100 [12:42&lt;23:30, 21.70s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 7.2700e-02.
Epoch[34]:
	train_loss = 0.84236, train_accuracy = 0.69537497
	valid_loss = 0.93073, valid_accuracy = 0.67439997
	time = 21.93 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 36%|███▌      | 36/100 [13:04&lt;23:13, 21.78s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 7.1289e-02.
Epoch[35]:
	train_loss = 0.83731, train_accuracy = 0.69809997
	valid_loss = 0.9415, valid_accuracy = 0.67259997
	time = 21.95 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 37%|███▋      | 37/100 [13:26&lt;22:42, 21.63s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 6.9857e-02.
Epoch[36]:
	train_loss = 0.84752, train_accuracy = 0.67887497
	valid_loss = 0.94834, valid_accuracy = 0.65849996
	time = 21.29 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 38%|███▊      | 38/100 [13:48&lt;22:32, 21.82s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 6.8406e-02.
Epoch[37]:
	train_loss = 0.8501, train_accuracy = 0.70314997
	valid_loss = 0.8919, valid_accuracy = 0.68759996
	time = 22.24 s
Validation loss decreased(0.91519---&gt;0.8919) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 39%|███▉      | 39/100 [14:10&lt;22:12, 21.84s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 6.6937e-02.
Epoch[38]:
	train_loss = 0.84168, train_accuracy = 0.69817495
	valid_loss = 0.92608, valid_accuracy = 0.67019999
	time = 21.89 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 40%|████      | 40/100 [14:31&lt;21:48, 21.81s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 6.5451e-02.
Epoch[39]:
	train_loss = 0.83024, train_accuracy = 0.69547498
	valid_loss = 0.93008, valid_accuracy = 0.67329997
	time = 21.73 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 41%|████      | 41/100 [14:53&lt;21:24, 21.77s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 6.3950e-02.
Epoch[40]:
	train_loss = 0.82979, train_accuracy = 0.67897499
	valid_loss = 0.99478, valid_accuracy = 0.65880001
	time = 21.7 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 42%|████▏     | 42/100 [15:14&lt;20:55, 21.65s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 6.2434e-02.
Epoch[41]:
	train_loss = 0.81652, train_accuracy = 0.66272497
	valid_loss = 1.0441, valid_accuracy = 0.63809997
	time = 21.36 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 43%|████▎     | 43/100 [15:36&lt;20:27, 21.53s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 6.0907e-02.
Epoch[42]:
	train_loss = 0.81058, train_accuracy = 0.69304997
	valid_loss = 0.95085, valid_accuracy = 0.67189997
	time = 21.24 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 44%|████▍     | 44/100 [15:58&lt;20:13, 21.68s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 5.9369e-02.
Epoch[43]:
	train_loss = 0.80612, train_accuracy = 0.72272497
	valid_loss = 0.87843, valid_accuracy = 0.69119996
	time = 22.01 s
Validation loss decreased(0.8919---&gt;0.87843) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 45%|████▌     | 45/100 [16:19&lt;19:49, 21.62s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 5.7822e-02.
Epoch[44]:
	train_loss = 0.79985, train_accuracy = 0.70192498
	valid_loss = 0.91893, valid_accuracy = 0.67930001
	time = 21.48 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 46%|████▌     | 46/100 [16:41&lt;19:31, 21.69s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 5.6267e-02.
Epoch[45]:
	train_loss = 0.80149, train_accuracy = 0.709225
	valid_loss = 0.92915, valid_accuracy = 0.67609996
	time = 21.87 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 47%|████▋     | 47/100 [17:03&lt;19:14, 21.79s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 5.4705e-02.
Epoch[46]:
	train_loss = 0.78505, train_accuracy = 0.72284997
	valid_loss = 0.86165, valid_accuracy = 0.6979
	time = 21.99 s
Validation loss decreased(0.87843---&gt;0.86165) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 48%|████▊     | 48/100 [17:26&lt;19:14, 22.21s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 5.3140e-02.
Epoch[47]:
	train_loss = 0.79138, train_accuracy = 0.72415
	valid_loss = 0.86013, valid_accuracy = 0.70059997
	time = 23.15 s
Validation loss decreased(0.86165---&gt;0.86013) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 49%|████▉     | 49/100 [17:49&lt;18:54, 22.25s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 5.1571e-02.
Epoch[48]:
	train_loss = 0.7774, train_accuracy = 0.72372496
	valid_loss = 0.87619, valid_accuracy = 0.69599998
	time = 22.36 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 50%|█████     | 50/100 [18:10&lt;18:23, 22.08s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 5.0000e-02.
Epoch[49]:
	train_loss = 0.7756, train_accuracy = 0.72529995
	valid_loss = 0.87373, valid_accuracy = 0.68949997
	time = 21.67 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 51%|█████     | 51/100 [18:32&lt;17:57, 21.99s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 4.8429e-02.
Epoch[50]:
	train_loss = 0.77488, train_accuracy = 0.69867498
	valid_loss = 0.92608, valid_accuracy = 0.67249995
	time = 21.78 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 52%|█████▏    | 52/100 [18:54&lt;17:33, 21.94s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 4.6860e-02.
Epoch[51]:
	train_loss = 0.76238, train_accuracy = 0.70397496
	valid_loss = 0.9205, valid_accuracy = 0.67719996
	time = 21.82 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 53%|█████▎    | 53/100 [19:15&lt;16:56, 21.62s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 4.5295e-02.
Epoch[52]:
	train_loss = 0.76455, train_accuracy = 0.74437499
	valid_loss = 0.8234, valid_accuracy = 0.70910001
	time = 20.87 s
Validation loss decreased(0.86013---&gt;0.8234) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 54%|█████▍    | 54/100 [19:36&lt;16:26, 21.44s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 4.3733e-02.
Epoch[53]:
	train_loss = 0.75516, train_accuracy = 0.73197496
	valid_loss = 0.86523, valid_accuracy = 0.69489998
	time = 21.03 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 55%|█████▌    | 55/100 [19:58&lt;16:11, 21.60s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 4.2178e-02.
Epoch[54]:
	train_loss = 0.75606, train_accuracy = 0.75229996
	valid_loss = 0.79876, valid_accuracy = 0.71810001
	time = 21.93 s
Validation loss decreased(0.8234---&gt;0.79876) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 56%|█████▌    | 56/100 [20:20&lt;15:55, 21.72s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 4.0631e-02.
Epoch[55]:
	train_loss = 0.7415, train_accuracy = 0.740125
	valid_loss = 0.84692, valid_accuracy = 0.70279998
	time = 22.01 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 57%|█████▋    | 57/100 [20:42&lt;15:37, 21.80s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 3.9093e-02.
Epoch[56]:
	train_loss = 0.7345, train_accuracy = 0.74259996
	valid_loss = 0.83794, valid_accuracy = 0.71039999
	time = 22.0 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 58%|█████▊    | 58/100 [21:04&lt;15:17, 21.85s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 3.7566e-02.
Epoch[57]:
	train_loss = 0.72601, train_accuracy = 0.73882496
	valid_loss = 0.85335, valid_accuracy = 0.69889998
	time = 21.95 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 59%|█████▉    | 59/100 [21:25&lt;14:43, 21.56s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 3.6050e-02.
Epoch[58]:
	train_loss = 0.72859, train_accuracy = 0.746975
	valid_loss = 0.83144, valid_accuracy = 0.70669997
	time = 20.88 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 60%|██████    | 60/100 [21:47&lt;14:28, 21.72s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 3.4549e-02.
Epoch[59]:
	train_loss = 0.71716, train_accuracy = 0.74917495
	valid_loss = 0.82412, valid_accuracy = 0.70559996
	time = 22.1 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 61%|██████    | 61/100 [22:09&lt;14:10, 21.80s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 3.3063e-02.
Epoch[60]:
	train_loss = 0.70356, train_accuracy = 0.76199996
	valid_loss = 0.78943, valid_accuracy = 0.71759999
	time = 21.98 s
Validation loss decreased(0.79876---&gt;0.78943) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 62%|██████▏   | 62/100 [22:30&lt;13:47, 21.79s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 3.1594e-02.
Epoch[61]:
	train_loss = 0.69501, train_accuracy = 0.75797498
	valid_loss = 0.80724, valid_accuracy = 0.71929997
	time = 21.76 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 63%|██████▎   | 63/100 [22:52&lt;13:25, 21.77s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 3.0143e-02.
Epoch[62]:
	train_loss = 0.69019, train_accuracy = 0.76644999
	valid_loss = 0.79363, valid_accuracy = 0.72310001
	time = 21.74 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 64%|██████▍   | 64/100 [23:14&lt;12:59, 21.64s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 2.8711e-02.
Epoch[63]:
	train_loss = 0.68022, train_accuracy = 0.7543
	valid_loss = 0.82605, valid_accuracy = 0.70789999
	time = 21.34 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 65%|██████▌   | 65/100 [23:35&lt;12:32, 21.51s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 2.7300e-02.
Epoch[64]:
	train_loss = 0.68007, train_accuracy = 0.77142501
	valid_loss = 0.78768, valid_accuracy = 0.72209996
	time = 21.16 s
Validation loss decreased(0.78943---&gt;0.78768) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 66%|██████▌   | 66/100 [23:57&lt;12:18, 21.72s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 2.5912e-02.
Epoch[65]:
	train_loss = 0.66532, train_accuracy = 0.757375
	valid_loss = 0.81788, valid_accuracy = 0.71599996
	time = 22.22 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 67%|██████▋   | 67/100 [24:19&lt;12:03, 21.91s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 2.4548e-02.
Epoch[66]:
	train_loss = 0.6626, train_accuracy = 0.78029996
	valid_loss = 0.77355, valid_accuracy = 0.73009998
	time = 22.34 s
Validation loss decreased(0.78768---&gt;0.77355) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 68%|██████▊   | 68/100 [24:41&lt;11:42, 21.96s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 2.3209e-02.
Epoch[67]:
	train_loss = 0.65572, train_accuracy = 0.77950001
	valid_loss = 0.78109, valid_accuracy = 0.72569996
	time = 22.05 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 69%|██████▉   | 69/100 [25:03&lt;11:19, 21.93s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 2.1896e-02.
Epoch[68]:
	train_loss = 0.64654, train_accuracy = 0.78867495
	valid_loss = 0.74926, valid_accuracy = 0.7349
	time = 21.86 s
Validation loss decreased(0.77355---&gt;0.74926) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 70%|███████   | 70/100 [25:25&lt;10:52, 21.74s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 2.0611e-02.
Epoch[69]:
	train_loss = 0.638, train_accuracy = 0.7895
	valid_loss = 0.75404, valid_accuracy = 0.7317
	time = 21.3 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 71%|███████   | 71/100 [25:47&lt;10:35, 21.93s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 1.9355e-02.
Epoch[70]:
	train_loss = 0.62587, train_accuracy = 0.79939997
	valid_loss = 0.73514, valid_accuracy = 0.74019998
	time = 22.33 s
Validation loss decreased(0.74926---&gt;0.73514) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 72%|███████▏  | 72/100 [26:09&lt;10:13, 21.91s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 1.8129e-02.
Epoch[71]:
	train_loss = 0.62102, train_accuracy = 0.78492498
	valid_loss = 0.78105, valid_accuracy = 0.7288
	time = 21.87 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 73%|███████▎  | 73/100 [26:30&lt;09:47, 21.76s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 1.6934e-02.
Epoch[72]:
	train_loss = 0.61056, train_accuracy = 0.79949999
	valid_loss = 0.73905, valid_accuracy = 0.74180001
	time = 21.4 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 74%|███████▍  | 74/100 [26:52&lt;09:25, 21.75s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 1.5773e-02.
Epoch[73]:
	train_loss = 0.6019, train_accuracy = 0.81219995
	valid_loss = 0.72752, valid_accuracy = 0.73829997
	time = 21.72 s
Validation loss decreased(0.73514---&gt;0.72752) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 75%|███████▌  | 75/100 [27:13&lt;09:01, 21.67s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 1.4645e-02.
Epoch[74]:
	train_loss = 0.59227, train_accuracy = 0.81532496
	valid_loss = 0.72654, valid_accuracy = 0.7432
	time = 21.46 s
Validation loss decreased(0.72752---&gt;0.72654) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 76%|███████▌  | 76/100 [27:35&lt;08:38, 21.60s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 1.3552e-02.
Epoch[75]:
	train_loss = 0.5783, train_accuracy = 0.81614995
	valid_loss = 0.71827, valid_accuracy = 0.74809998
	time = 21.41 s
Validation loss decreased(0.72654---&gt;0.71827) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 77%|███████▋  | 77/100 [27:57&lt;08:17, 21.63s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 1.2494e-02.
Epoch[76]:
	train_loss = 0.56646, train_accuracy = 0.82432497
	valid_loss = 0.71859, valid_accuracy = 0.74579996
	time = 21.69 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 78%|███████▊  | 78/100 [28:19&lt;07:59, 21.80s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 1.1474e-02.
Epoch[77]:
	train_loss = 0.55609, train_accuracy = 0.81834996
	valid_loss = 0.73282, valid_accuracy = 0.74449998
	time = 22.22 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 79%|███████▉  | 79/100 [28:41&lt;07:39, 21.86s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 1.0492e-02.
Epoch[78]:
	train_loss = 0.54573, train_accuracy = 0.82835001
	valid_loss = 0.71403, valid_accuracy = 0.75319999
	time = 21.99 s
Validation loss decreased(0.71827---&gt;0.71403) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 80%|████████  | 80/100 [29:03&lt;07:16, 21.84s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.5492e-03.
Epoch[79]:
	train_loss = 0.53347, train_accuracy = 0.83194995
	valid_loss = 0.71508, valid_accuracy = 0.75150001
	time = 21.77 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 81%|████████  | 81/100 [29:23&lt;06:49, 21.56s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 8.6460e-03.
Epoch[80]:
	train_loss = 0.51717, train_accuracy = 0.83177495
	valid_loss = 0.72623, valid_accuracy = 0.74829996
	time = 20.91 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 82%|████████▏ | 82/100 [29:45&lt;06:30, 21.69s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 7.7836e-03.
Epoch[81]:
	train_loss = 0.50675, train_accuracy = 0.83724999
	valid_loss = 0.72751, valid_accuracy = 0.75019997
	time = 21.98 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 83%|████████▎ | 83/100 [30:08&lt;06:11, 21.84s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 6.9629e-03.
Epoch[82]:
	train_loss = 0.49813, train_accuracy = 0.84662497
	valid_loss = 0.72092, valid_accuracy = 0.75129998
	time = 22.21 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 84%|████████▍ | 84/100 [30:30&lt;05:49, 21.85s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 6.1847e-03.
Epoch[83]:
	train_loss = 0.48483, train_accuracy = 0.85299999
	valid_loss = 0.70845, valid_accuracy = 0.75729996
	time = 21.86 s
Validation loss decreased(0.71403---&gt;0.70845) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 85%|████████▌ | 85/100 [30:51&lt;05:28, 21.89s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 5.4497e-03.
Epoch[84]:
	train_loss = 0.47435, train_accuracy = 0.85644996
	valid_loss = 0.71768, valid_accuracy = 0.75599998
	time = 21.96 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 86%|████████▌ | 86/100 [31:13&lt;05:05, 21.82s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 4.7586e-03.
Epoch[85]:
	train_loss = 0.45751, train_accuracy = 0.86044997
	valid_loss = 0.7241, valid_accuracy = 0.75449997
	time = 21.65 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 87%|████████▋ | 87/100 [31:35&lt;04:42, 21.73s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 4.1123e-03.
Epoch[86]:
	train_loss = 0.44318, train_accuracy = 0.86785001
	valid_loss = 0.71513, valid_accuracy = 0.75989997
	time = 21.53 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 88%|████████▊ | 88/100 [31:56&lt;04:21, 21.77s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 3.5112e-03.
Epoch[87]:
	train_loss = 0.42846, train_accuracy = 0.87404996
	valid_loss = 0.71325, valid_accuracy = 0.7568
	time = 21.85 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 89%|████████▉ | 89/100 [32:18&lt;04:00, 21.83s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 2.9560e-03.
Epoch[88]:
	train_loss = 0.4159, train_accuracy = 0.88
	valid_loss = 0.71907, valid_accuracy = 0.75830001
	time = 21.99 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 90%|█████████ | 90/100 [32:40&lt;03:38, 21.81s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 2.4472e-03.
Epoch[89]:
	train_loss = 0.39906, train_accuracy = 0.88639998
	valid_loss = 0.71464, valid_accuracy = 0.7604
	time = 21.76 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 91%|█████████ | 91/100 [33:02&lt;03:15, 21.73s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 1.9853e-03.
Epoch[90]:
	train_loss = 0.38682, train_accuracy = 0.88729995
	valid_loss = 0.7248, valid_accuracy = 0.75760001
	time = 21.53 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 92%|█████████▏| 92/100 [33:23&lt;02:52, 21.52s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 1.5708e-03.
Epoch[91]:
	train_loss = 0.37684, train_accuracy = 0.89489996
	valid_loss = 0.72307, valid_accuracy = 0.76119995
	time = 21.05 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 93%|█████████▎| 93/100 [33:45&lt;02:31, 21.65s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 1.2042e-03.
Epoch[92]:
	train_loss = 0.36111, train_accuracy = 0.89859998
	valid_loss = 0.73216, valid_accuracy = 0.75869995
	time = 21.95 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 94%|█████████▍| 94/100 [34:07&lt;02:11, 21.87s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 8.8564e-04.
Epoch[93]:
	train_loss = 0.35298, train_accuracy = 0.90344995
	valid_loss = 0.73237, valid_accuracy = 0.76139998
	time = 22.38 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 95%|█████████▌| 95/100 [34:29&lt;01:49, 21.97s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 6.1558e-04.
Epoch[94]:
	train_loss = 0.34553, train_accuracy = 0.90744996
	valid_loss = 0.73586, valid_accuracy = 0.76119995
	time = 22.22 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 96%|█████████▌| 96/100 [34:51&lt;01:27, 21.90s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 3.9426e-04.
Epoch[95]:
	train_loss = 0.33442, train_accuracy = 0.90964997
	valid_loss = 0.73349, valid_accuracy = 0.76299995
	time = 21.71 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 97%|█████████▋| 97/100 [35:13&lt;01:05, 21.76s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 2.2190e-04.
Epoch[96]:
	train_loss = 0.32876, train_accuracy = 0.90952498
	valid_loss = 0.74137, valid_accuracy = 0.76309997
	time = 21.43 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 98%|█████████▊| 98/100 [35:34&lt;00:43, 21.60s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.8664e-05.
Epoch[97]:
	train_loss = 0.32343, train_accuracy = 0.912175
	valid_loss = 0.74138, valid_accuracy = 0.76319999
	time = 21.25 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 98%|█████████▊| 98/100 [35:56&lt;00:44, 22.00s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 2.4672e-05.
Epoch[98]:
	train_loss = 0.32177, train_accuracy = 0.91207498
	valid_loss = 0.74096, valid_accuracy = 0.76389998
	time = 21.86 s
Validation loss didn't decrease for 15 epochs ---&gt; model training stopped
[Finished training]
	valid training loss: 0.48483
	valid training accuracy 0.85299999
	min validation loss: 0.70845,
	best validation accuracy: 0.75729996
Model[ShuffleNetV2] - partial training (last layer) / model_weights
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 1.0000e-01.
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>  0%|          | 0/100 [00:00&lt;?, ?it/s]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>#############################################################################################
[Training parameters]
	epochs = 100,
	lr = 0.1,
	momentum = 0.9,
	weight_decay = 0.0005,
	loss = CrossEntropyLoss(),
	optimizer = SGD (
Parameter Group 0
    dampening: 0
    differentiable: False
    foreach: None
    initial_lr: 0.1
    lr: 0.1
    maximize: False
    momentum: 0.9
    nesterov: False
    weight_decay: 0.0005
),
	scheduler = &lt;torch.optim.lr_scheduler.CosineAnnealingLR object at 0x0000026820C72440&gt;,
	device = cuda:0
#############################################################################################
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>  1%|          | 1/100 [00:19&lt;32:36, 19.77s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.9975e-02.
Epoch[0]:
	train_loss = 1.85673, train_accuracy = 0.45232499
	valid_loss = 1.69, valid_accuracy = 0.43649998
	time = 19.73 s
Validation loss decreased(None---&gt;1.69) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>  2%|▏         | 2/100 [00:39&lt;31:46, 19.45s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.9901e-02.
Epoch[1]:
	train_loss = 1.63991, train_accuracy = 0.46724999
	valid_loss = 1.61024, valid_accuracy = 0.45559999
	time = 19.21 s
Validation loss decreased(1.69---&gt;1.61024) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>  3%|▎         | 3/100 [00:58&lt;31:15, 19.33s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.9778e-02.
Epoch[2]:
	train_loss = 1.58876, train_accuracy = 0.47992498
	valid_loss = 1.57511, valid_accuracy = 0.46609998
	time = 19.17 s
Validation loss decreased(1.61024---&gt;1.57511) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>  4%|▍         | 4/100 [01:16&lt;30:31, 19.07s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.9606e-02.
Epoch[3]:
	train_loss = 1.56647, train_accuracy = 0.48692498
	valid_loss = 1.56679, valid_accuracy = 0.4682
	time = 18.66 s
Validation loss decreased(1.57511---&gt;1.56679) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>  5%|▌         | 5/100 [01:36&lt;30:18, 19.14s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.9384e-02.
Epoch[4]:
	train_loss = 1.55156, train_accuracy = 0.48712498
	valid_loss = 1.5586, valid_accuracy = 0.47239998
	time = 19.25 s
Validation loss decreased(1.56679---&gt;1.5586) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>  6%|▌         | 6/100 [01:55&lt;30:05, 19.21s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.9114e-02.
Epoch[5]:
	train_loss = 1.54466, train_accuracy = 0.492975
	valid_loss = 1.54701, valid_accuracy = 0.47349998
	time = 19.31 s
Validation loss decreased(1.5586---&gt;1.54701) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>  7%|▋         | 7/100 [02:14&lt;29:50, 19.25s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.8796e-02.
Epoch[6]:
	train_loss = 1.53831, train_accuracy = 0.49242499
	valid_loss = 1.54438, valid_accuracy = 0.47379997
	time = 19.32 s
Validation loss decreased(1.54701---&gt;1.54438) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>  8%|▊         | 8/100 [02:34&lt;29:33, 19.28s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.8429e-02.
Epoch[7]:
	train_loss = 1.5342, train_accuracy = 0.4964
	valid_loss = 1.54256, valid_accuracy = 0.47349998
	time = 19.33 s
Validation loss decreased(1.54438---&gt;1.54256) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>  9%|▉         | 9/100 [02:53&lt;29:06, 19.19s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.8015e-02.
Epoch[8]:
	train_loss = 1.5298, train_accuracy = 0.49884999
	valid_loss = 1.54542, valid_accuracy = 0.47559997
	time = 18.99 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 10%|█         | 10/100 [03:11&lt;28:33, 19.04s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.7553e-02.
Epoch[9]:
	train_loss = 1.52649, train_accuracy = 0.49637499
	valid_loss = 1.54159, valid_accuracy = 0.47099999
	time = 18.69 s
Validation loss decreased(1.54256---&gt;1.54159) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 11%|█         | 11/100 [03:30&lt;28:06, 18.95s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.7044e-02.
Epoch[10]:
	train_loss = 1.52418, train_accuracy = 0.49777499
	valid_loss = 1.53813, valid_accuracy = 0.4763
	time = 18.74 s
Validation loss decreased(1.54159---&gt;1.53813) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 12%|█▏        | 12/100 [03:49&lt;27:51, 18.99s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.6489e-02.
Epoch[11]:
	train_loss = 1.52239, train_accuracy = 0.499075
	valid_loss = 1.5384, valid_accuracy = 0.4804
	time = 19.08 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 13%|█▎        | 13/100 [04:09&lt;27:42, 19.10s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.5888e-02.
Epoch[12]:
	train_loss = 1.52451, train_accuracy = 0.49647498
	valid_loss = 1.54228, valid_accuracy = 0.47669998
	time = 19.36 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 14%|█▍        | 14/100 [04:28&lt;27:34, 19.24s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.5241e-02.
Epoch[13]:
	train_loss = 1.52561, train_accuracy = 0.49859998
	valid_loss = 1.53391, valid_accuracy = 0.47649997
	time = 19.52 s
Validation loss decreased(1.53813---&gt;1.53391) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 15%|█▌        | 15/100 [04:47&lt;27:07, 19.14s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.4550e-02.
Epoch[14]:
	train_loss = 1.52273, train_accuracy = 0.49812499
	valid_loss = 1.53731, valid_accuracy = 0.4779
	time = 18.92 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 16%|█▌        | 16/100 [05:06&lt;26:43, 19.08s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.3815e-02.
Epoch[15]:
	train_loss = 1.5249, train_accuracy = 0.49804997
	valid_loss = 1.53968, valid_accuracy = 0.4772
	time = 18.95 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 17%|█▋        | 17/100 [05:25&lt;26:15, 18.98s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.3037e-02.
Epoch[16]:
	train_loss = 1.5247, train_accuracy = 0.49629998
	valid_loss = 1.53228, valid_accuracy = 0.47689998
	time = 18.73 s
Validation loss decreased(1.53391---&gt;1.53228) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 18%|█▊        | 18/100 [05:44&lt;26:03, 19.07s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.2216e-02.
Epoch[17]:
	train_loss = 1.52254, train_accuracy = 0.49842498
	valid_loss = 1.5419, valid_accuracy = 0.47739998
	time = 19.28 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 19%|█▉        | 19/100 [06:03&lt;25:52, 19.17s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.1354e-02.
Epoch[18]:
	train_loss = 1.52483, train_accuracy = 0.49864998
	valid_loss = 1.5423, valid_accuracy = 0.47639999
	time = 19.4 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 20%|██        | 20/100 [06:22&lt;25:29, 19.12s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.0451e-02.
Epoch[19]:
	train_loss = 1.51707, train_accuracy = 0.49642497
	valid_loss = 1.53557, valid_accuracy = 0.47939998
	time = 19.01 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 21%|██        | 21/100 [06:41&lt;25:09, 19.10s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 8.9508e-02.
Epoch[20]:
	train_loss = 1.52349, train_accuracy = 0.49612498
	valid_loss = 1.5347, valid_accuracy = 0.47889999
	time = 19.06 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 22%|██▏       | 22/100 [07:01&lt;24:53, 19.15s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 8.8526e-02.
Epoch[21]:
	train_loss = 1.51894, train_accuracy = 0.49649999
	valid_loss = 1.53303, valid_accuracy = 0.47889999
	time = 19.25 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 23%|██▎       | 23/100 [07:20&lt;24:30, 19.10s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 8.7506e-02.
Epoch[22]:
	train_loss = 1.52044, train_accuracy = 0.49542499
	valid_loss = 1.53781, valid_accuracy = 0.47319999
	time = 18.97 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 24%|██▍       | 24/100 [07:39&lt;24:10, 19.09s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 8.6448e-02.
Epoch[23]:
	train_loss = 1.52206, train_accuracy = 0.49834999
	valid_loss = 1.53718, valid_accuracy = 0.479
	time = 19.06 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 25%|██▌       | 25/100 [07:58&lt;23:56, 19.16s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 8.5355e-02.
Epoch[24]:
	train_loss = 1.51924, train_accuracy = 0.49344999
	valid_loss = 1.53981, valid_accuracy = 0.47569999
	time = 19.32 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 26%|██▌       | 26/100 [08:17&lt;23:34, 19.12s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 8.4227e-02.
Epoch[25]:
	train_loss = 1.52108, train_accuracy = 0.50040001
	valid_loss = 1.53307, valid_accuracy = 0.47829998
	time = 19.03 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 27%|██▋       | 27/100 [08:36&lt;23:15, 19.12s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 8.3066e-02.
Epoch[26]:
	train_loss = 1.52072, train_accuracy = 0.49947497
	valid_loss = 1.53399, valid_accuracy = 0.47579998
	time = 19.11 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 28%|██▊       | 28/100 [08:55&lt;22:52, 19.07s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 8.1871e-02.
Epoch[27]:
	train_loss = 1.52029, train_accuracy = 0.49977499
	valid_loss = 1.53603, valid_accuracy = 0.47799999
	time = 18.96 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 29%|██▉       | 29/100 [09:14&lt;22:38, 19.13s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 8.0645e-02.
Epoch[28]:
	train_loss = 1.51966, train_accuracy = 0.49894997
	valid_loss = 1.53482, valid_accuracy = 0.47849998
	time = 19.26 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 30%|███       | 30/100 [09:33&lt;22:11, 19.03s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 7.9389e-02.
Epoch[29]:
	train_loss = 1.51943, train_accuracy = 0.50199997
	valid_loss = 1.53105, valid_accuracy = 0.479
	time = 18.78 s
Validation loss decreased(1.53228---&gt;1.53105) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 31%|███       | 31/100 [09:53&lt;22:02, 19.17s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 7.8104e-02.
Epoch[30]:
	train_loss = 1.5195, train_accuracy = 0.49759999
	valid_loss = 1.54179, valid_accuracy = 0.47649997
	time = 19.49 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 32%|███▏      | 32/100 [10:12&lt;21:44, 19.18s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 7.6791e-02.
Epoch[31]:
	train_loss = 1.52067, train_accuracy = 0.50059998
	valid_loss = 1.52855, valid_accuracy = 0.47689998
	time = 19.2 s
Validation loss decreased(1.53105---&gt;1.52855) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 33%|███▎      | 33/100 [10:31&lt;21:21, 19.12s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 7.5452e-02.
Epoch[32]:
	train_loss = 1.51914, train_accuracy = 0.4964
	valid_loss = 1.53174, valid_accuracy = 0.47459999
	time = 18.98 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 34%|███▍      | 34/100 [10:50&lt;21:01, 19.12s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 7.4088e-02.
Epoch[33]:
	train_loss = 1.52005, train_accuracy = 0.49632499
	valid_loss = 1.53338, valid_accuracy = 0.47669998
	time = 19.11 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 35%|███▌      | 35/100 [11:09&lt;20:40, 19.08s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 7.2700e-02.
Epoch[34]:
	train_loss = 1.51754, train_accuracy = 0.49977499
	valid_loss = 1.53347, valid_accuracy = 0.4754
	time = 18.99 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 36%|███▌      | 36/100 [11:28&lt;20:18, 19.05s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 7.1289e-02.
Epoch[35]:
	train_loss = 1.52038, train_accuracy = 0.50217497
	valid_loss = 1.53391, valid_accuracy = 0.47569999
	time = 18.97 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 37%|███▋      | 37/100 [11:47&lt;20:00, 19.05s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 6.9857e-02.
Epoch[36]:
	train_loss = 1.5235, train_accuracy = 0.50234997
	valid_loss = 1.53424, valid_accuracy = 0.47829998
	time = 19.06 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 38%|███▊      | 38/100 [12:06&lt;19:45, 19.13s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 6.8406e-02.
Epoch[37]:
	train_loss = 1.52231, train_accuracy = 0.49785
	valid_loss = 1.5395, valid_accuracy = 0.47679999
	time = 19.31 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 39%|███▉      | 39/100 [12:25&lt;19:26, 19.13s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 6.6937e-02.
Epoch[38]:
	train_loss = 1.52127, train_accuracy = 0.49495
	valid_loss = 1.54312, valid_accuracy = 0.47229999
	time = 19.13 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 40%|████      | 40/100 [12:45&lt;19:06, 19.11s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 6.5451e-02.
Epoch[39]:
	train_loss = 1.52017, train_accuracy = 0.50297499
	valid_loss = 1.54135, valid_accuracy = 0.477
	time = 19.08 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 41%|████      | 41/100 [13:04&lt;18:45, 19.08s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 6.3950e-02.
Epoch[40]:
	train_loss = 1.51832, train_accuracy = 0.49627498
	valid_loss = 1.54071, valid_accuracy = 0.4736
	time = 19.01 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 42%|████▏     | 42/100 [13:22&lt;18:20, 18.98s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 6.2434e-02.
Epoch[41]:
	train_loss = 1.52207, train_accuracy = 0.50174999
	valid_loss = 1.53704, valid_accuracy = 0.4772
	time = 18.75 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 43%|████▎     | 43/100 [13:41&lt;18:01, 18.98s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 6.0907e-02.
Epoch[42]:
	train_loss = 1.51988, train_accuracy = 0.499825
	valid_loss = 1.53444, valid_accuracy = 0.4795
	time = 18.96 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 44%|████▍     | 44/100 [14:00&lt;17:46, 19.04s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 5.9369e-02.
Epoch[43]:
	train_loss = 1.51549, train_accuracy = 0.50242501
	valid_loss = 1.53006, valid_accuracy = 0.47709998
	time = 19.18 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 45%|████▌     | 45/100 [14:20&lt;17:28, 19.06s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 5.7822e-02.
Epoch[44]:
	train_loss = 1.51806, train_accuracy = 0.49515
	valid_loss = 1.53735, valid_accuracy = 0.47709998
	time = 19.1 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 46%|████▌     | 46/100 [14:39&lt;17:08, 19.04s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 5.6267e-02.
Epoch[45]:
	train_loss = 1.5199, train_accuracy = 0.499975
	valid_loss = 1.53446, valid_accuracy = 0.47749999
	time = 19.0 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 46%|████▌     | 46/100 [14:57&lt;17:34, 19.52s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 5.4705e-02.
Epoch[46]:
	train_loss = 1.52117, train_accuracy = 0.49902499
	valid_loss = 1.53744, valid_accuracy = 0.47679999
	time = 18.91 s
Validation loss didn't decrease for 15 epochs ---&gt; model training stopped
[Finished training]
	valid training loss: 1.52067
	valid training accuracy 0.50059998
	min validation loss: 1.52855,
	best validation accuracy: 0.47689998
================================================================================
Model[MobileNetV3] last FC before mod: Linear(in_features=1024, out_features=1000, bias=True)
Model[MobileNetV3] last FC after mod: Linear(in_features=1024, out_features=10, bias=True)
Model[MobileNetV3] - full training / model_weights
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 1.0000e-01.
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>  0%|          | 0/100 [00:00&lt;?, ?it/s]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>#############################################################################################
[Training parameters]
	epochs = 100,
	lr = 0.1,
	momentum = 0.9,
	weight_decay = 0.0005,
	loss = CrossEntropyLoss(),
	optimizer = SGD (
Parameter Group 0
    dampening: 0
    differentiable: False
    foreach: None
    initial_lr: 0.1
    lr: 0.1
    maximize: False
    momentum: 0.9
    nesterov: False
    weight_decay: 0.0005
),
	scheduler = &lt;torch.optim.lr_scheduler.CosineAnnealingLR object at 0x0000026A38B684F0&gt;,
	device = cuda:0
#############################################################################################
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>  1%|          | 1/100 [00:21&lt;35:05, 21.26s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.9975e-02.
Epoch[0]:
	train_loss = 3.29472, train_accuracy = 0.15764999
	valid_loss = 2.22732, valid_accuracy = 0.15889999
	time = 21.25 s
Validation loss decreased(None---&gt;2.22732) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>  2%|▏         | 2/100 [00:42&lt;34:40, 21.22s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.9901e-02.
Epoch[1]:
	train_loss = 1.8782, train_accuracy = 0.17054999
	valid_loss = 2.22112, valid_accuracy = 0.17549999
	time = 21.18 s
Validation loss decreased(2.22732---&gt;2.22112) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>  3%|▎         | 3/100 [01:03&lt;34:27, 21.32s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.9778e-02.
Epoch[2]:
	train_loss = 1.68402, train_accuracy = 0.23819999
	valid_loss = 2.05779, valid_accuracy = 0.23179999
	time = 21.41 s
Validation loss decreased(2.22112---&gt;2.05779) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>  4%|▍         | 4/100 [01:25&lt;34:32, 21.59s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.9606e-02.
Epoch[3]:
	train_loss = 1.57438, train_accuracy = 0.21162499
	valid_loss = 2.1324, valid_accuracy = 0.2084
	time = 22.02 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>  5%|▌         | 5/100 [01:47&lt;34:06, 21.54s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.9384e-02.
Epoch[4]:
	train_loss = 1.48867, train_accuracy = 0.20379999
	valid_loss = 2.17148, valid_accuracy = 0.1973
	time = 21.44 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>  6%|▌         | 6/100 [02:08&lt;33:35, 21.44s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.9114e-02.
Epoch[5]:
	train_loss = 1.43804, train_accuracy = 0.2113
	valid_loss = 2.099, valid_accuracy = 0.213
	time = 21.26 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>  7%|▋         | 7/100 [02:29&lt;33:02, 21.32s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.8796e-02.
Epoch[6]:
	train_loss = 1.40021, train_accuracy = 0.29359999
	valid_loss = 1.95629, valid_accuracy = 0.29409999
	time = 21.04 s
Validation loss decreased(2.05779---&gt;1.95629) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>  8%|▊         | 8/100 [02:52&lt;33:29, 21.84s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.8429e-02.
Epoch[7]:
	train_loss = 1.35053, train_accuracy = 0.37529999
	valid_loss = 1.72991, valid_accuracy = 0.37979999
	time = 22.93 s
Validation loss decreased(1.95629---&gt;1.72991) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>  9%|▉         | 9/100 [03:14&lt;33:08, 21.85s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.8015e-02.
Epoch[8]:
	train_loss = 1.33492, train_accuracy = 0.43945
	valid_loss = 1.62463, valid_accuracy = 0.43629998
	time = 21.86 s
Validation loss decreased(1.72991---&gt;1.62463) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 10%|█         | 10/100 [03:36&lt;32:49, 21.88s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.7553e-02.
Epoch[9]:
	train_loss = 1.30784, train_accuracy = 0.47367498
	valid_loss = 1.47736, valid_accuracy = 0.46919999
	time = 21.93 s
Validation loss decreased(1.62463---&gt;1.47736) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 11%|█         | 11/100 [03:57&lt;32:14, 21.73s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.7044e-02.
Epoch[10]:
	train_loss = 1.28704, train_accuracy = 0.46474999
	valid_loss = 1.48814, valid_accuracy = 0.4666
	time = 21.41 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 12%|█▏        | 12/100 [04:19&lt;31:38, 21.57s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.6489e-02.
Epoch[11]:
	train_loss = 1.23046, train_accuracy = 0.48104998
	valid_loss = 1.50254, valid_accuracy = 0.47409999
	time = 21.2 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 13%|█▎        | 13/100 [04:40&lt;31:11, 21.51s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.5888e-02.
Epoch[12]:
	train_loss = 1.18352, train_accuracy = 0.49184999
	valid_loss = 1.44727, valid_accuracy = 0.49049997
	time = 21.33 s
Validation loss decreased(1.47736---&gt;1.44727) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 14%|█▍        | 14/100 [05:01&lt;30:51, 21.53s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.5241e-02.
Epoch[13]:
	train_loss = 1.16437, train_accuracy = 0.543625
	valid_loss = 1.28774, valid_accuracy = 0.53859997
	time = 21.56 s
Validation loss decreased(1.44727---&gt;1.28774) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 15%|█▌        | 15/100 [05:23&lt;30:30, 21.53s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.4550e-02.
Epoch[14]:
	train_loss = 1.15064, train_accuracy = 0.57212496
	valid_loss = 1.20923, valid_accuracy = 0.57019997
	time = 21.51 s
Validation loss decreased(1.28774---&gt;1.20923) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 16%|█▌        | 16/100 [05:44&lt;29:59, 21.42s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.3815e-02.
Epoch[15]:
	train_loss = 1.13509, train_accuracy = 0.57292497
	valid_loss = 1.25189, valid_accuracy = 0.55779999
	time = 21.15 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 17%|█▋        | 17/100 [06:05&lt;29:28, 21.31s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.3037e-02.
Epoch[16]:
	train_loss = 1.12608, train_accuracy = 0.49744999
	valid_loss = 1.41085, valid_accuracy = 0.49419999
	time = 21.06 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 18%|█▊        | 18/100 [06:26&lt;28:55, 21.17s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.2216e-02.
Epoch[17]:
	train_loss = 1.10974, train_accuracy = 0.55624998
	valid_loss = 1.27918, valid_accuracy = 0.54109997
	time = 20.85 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 19%|█▉        | 19/100 [06:48&lt;28:56, 21.44s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.1354e-02.
Epoch[18]:
	train_loss = 1.08324, train_accuracy = 0.46447498
	valid_loss = 1.62831, valid_accuracy = 0.46069998
	time = 22.08 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 20%|██        | 20/100 [07:10&lt;28:39, 21.49s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.0451e-02.
Epoch[19]:
	train_loss = 1.07303, train_accuracy = 0.57277501
	valid_loss = 1.25361, valid_accuracy = 0.56169999
	time = 21.6 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 21%|██        | 21/100 [07:32&lt;28:30, 21.65s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 8.9508e-02.
Epoch[20]:
	train_loss = 1.05486, train_accuracy = 0.57162499
	valid_loss = 1.21827, valid_accuracy = 0.55930001
	time = 22.02 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 22%|██▏       | 22/100 [07:54&lt;28:12, 21.70s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 8.8526e-02.
Epoch[21]:
	train_loss = 1.0432, train_accuracy = 0.60302496
	valid_loss = 1.14626, valid_accuracy = 0.59630001
	time = 21.8 s
Validation loss decreased(1.20923---&gt;1.14626) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 23%|██▎       | 23/100 [08:15&lt;27:39, 21.55s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 8.7506e-02.
Epoch[22]:
	train_loss = 1.03358, train_accuracy = 0.47292498
	valid_loss = 1.58114, valid_accuracy = 0.4619
	time = 21.21 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 24%|██▍       | 24/100 [08:36&lt;27:13, 21.49s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 8.6448e-02.
Epoch[23]:
	train_loss = 1.01803, train_accuracy = 0.59842497
	valid_loss = 1.16988, valid_accuracy = 0.58379996
	time = 21.35 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 25%|██▌       | 25/100 [08:58&lt;26:54, 21.53s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 8.5355e-02.
Epoch[24]:
	train_loss = 1.0094, train_accuracy = 0.58787501
	valid_loss = 1.21046, valid_accuracy = 0.56919998
	time = 21.61 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 26%|██▌       | 26/100 [09:20&lt;26:41, 21.64s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 8.4227e-02.
Epoch[25]:
	train_loss = 0.99087, train_accuracy = 0.53455001
	valid_loss = 1.42741, valid_accuracy = 0.52560002
	time = 21.92 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 27%|██▋       | 27/100 [09:41&lt;26:17, 21.61s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 8.3066e-02.
Epoch[26]:
	train_loss = 0.97882, train_accuracy = 0.50264996
	valid_loss = 1.55892, valid_accuracy = 0.4885
	time = 21.53 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 28%|██▊       | 28/100 [10:03&lt;25:50, 21.54s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 8.1871e-02.
Epoch[27]:
	train_loss = 0.9793, train_accuracy = 0.61202496
	valid_loss = 1.16854, valid_accuracy = 0.60369998
	time = 21.37 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 29%|██▉       | 29/100 [10:24&lt;25:19, 21.40s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 8.0645e-02.
Epoch[28]:
	train_loss = 0.96722, train_accuracy = 0.488325
	valid_loss = 1.64014, valid_accuracy = 0.4869
	time = 21.09 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 30%|███       | 30/100 [10:45&lt;25:07, 21.53s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 7.9389e-02.
Epoch[29]:
	train_loss = 0.95649, train_accuracy = 0.58884996
	valid_loss = 1.19567, valid_accuracy = 0.57099998
	time = 21.82 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 31%|███       | 31/100 [11:07&lt;24:49, 21.59s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 7.8104e-02.
Epoch[30]:
	train_loss = 0.94755, train_accuracy = 0.58187497
	valid_loss = 1.20907, valid_accuracy = 0.57499999
	time = 21.74 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 32%|███▏      | 32/100 [11:29&lt;24:21, 21.50s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 7.6791e-02.
Epoch[31]:
	train_loss = 0.93831, train_accuracy = 0.55479997
	valid_loss = 1.27569, valid_accuracy = 0.54469997
	time = 21.27 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 33%|███▎      | 33/100 [11:50&lt;24:05, 21.58s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 7.5452e-02.
Epoch[32]:
	train_loss = 0.93134, train_accuracy = 0.511325
	valid_loss = 1.48517, valid_accuracy = 0.50510001
	time = 21.76 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 34%|███▍      | 34/100 [12:12&lt;23:40, 21.53s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 7.4088e-02.
Epoch[33]:
	train_loss = 0.92456, train_accuracy = 0.61172497
	valid_loss = 1.13428, valid_accuracy = 0.60209996
	time = 21.4 s
Validation loss decreased(1.14626---&gt;1.13428) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 35%|███▌      | 35/100 [12:33&lt;23:16, 21.49s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 7.2700e-02.
Epoch[34]:
	train_loss = 0.91363, train_accuracy = 0.62992501
	valid_loss = 1.11646, valid_accuracy = 0.61409998
	time = 21.37 s
Validation loss decreased(1.13428---&gt;1.11646) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 36%|███▌      | 36/100 [12:55&lt;23:01, 21.59s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 7.1289e-02.
Epoch[35]:
	train_loss = 0.91139, train_accuracy = 0.64802498
	valid_loss = 1.05428, valid_accuracy = 0.63389999
	time = 21.81 s
Validation loss decreased(1.11646---&gt;1.05428) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 37%|███▋      | 37/100 [13:17&lt;22:43, 21.64s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 6.9857e-02.
Epoch[36]:
	train_loss = 0.89909, train_accuracy = 0.59419996
	valid_loss = 1.18996, valid_accuracy = 0.5765
	time = 21.76 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 38%|███▊      | 38/100 [13:38&lt;22:24, 21.68s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 6.8406e-02.
Epoch[37]:
	train_loss = 0.90715, train_accuracy = 0.59657496
	valid_loss = 1.15987, valid_accuracy = 0.5819
	time = 21.77 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 39%|███▉      | 39/100 [14:00&lt;21:58, 21.62s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 6.6937e-02.
Epoch[38]:
	train_loss = 0.89848, train_accuracy = 0.65789998
	valid_loss = 1.01529, valid_accuracy = 0.64209998
	time = 21.46 s
Validation loss decreased(1.05428---&gt;1.01529) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 40%|████      | 40/100 [14:21&lt;21:22, 21.38s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 6.5451e-02.
Epoch[39]:
	train_loss = 0.88118, train_accuracy = 0.56624997
	valid_loss = 1.33278, valid_accuracy = 0.54879999
	time = 20.82 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 41%|████      | 41/100 [14:42&lt;21:06, 21.46s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 6.3950e-02.
Epoch[40]:
	train_loss = 0.88083, train_accuracy = 0.62357497
	valid_loss = 1.15659, valid_accuracy = 0.6031
	time = 21.64 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 42%|████▏     | 42/100 [15:04&lt;20:48, 21.53s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 6.2434e-02.
Epoch[41]:
	train_loss = 0.87802, train_accuracy = 0.67322499
	valid_loss = 0.98501, valid_accuracy = 0.65259999
	time = 21.68 s
Validation loss decreased(1.01529---&gt;0.98501) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 43%|████▎     | 43/100 [15:25&lt;20:24, 21.48s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 6.0907e-02.
Epoch[42]:
	train_loss = 0.86709, train_accuracy = 0.58924997
	valid_loss = 1.22712, valid_accuracy = 0.56760001
	time = 21.36 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 44%|████▍     | 44/100 [15:47&lt;20:02, 21.47s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 5.9369e-02.
Epoch[43]:
	train_loss = 0.85656, train_accuracy = 0.67144996
	valid_loss = 1.00258, valid_accuracy = 0.65139997
	time = 21.43 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 45%|████▌     | 45/100 [16:08&lt;19:40, 21.47s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 5.7822e-02.
Epoch[44]:
	train_loss = 0.85553, train_accuracy = 0.69132501
	valid_loss = 0.92358, valid_accuracy = 0.67289996
	time = 21.47 s
Validation loss decreased(0.98501---&gt;0.92358) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 46%|████▌     | 46/100 [16:30&lt;19:18, 21.45s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 5.6267e-02.
Epoch[45]:
	train_loss = 0.84931, train_accuracy = 0.66369998
	valid_loss = 1.03336, valid_accuracy = 0.64219999
	time = 21.39 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 47%|████▋     | 47/100 [16:51&lt;18:56, 21.44s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 5.4705e-02.
Epoch[46]:
	train_loss = 0.84693, train_accuracy = 0.65332496
	valid_loss = 1.03536, valid_accuracy = 0.63239998
	time = 21.41 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 48%|████▊     | 48/100 [17:13&lt;18:40, 21.56s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 5.3140e-02.
Epoch[47]:
	train_loss = 0.84052, train_accuracy = 0.676
	valid_loss = 0.97695, valid_accuracy = 0.6577
	time = 21.83 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 49%|████▉     | 49/100 [17:35&lt;18:18, 21.54s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 5.1571e-02.
Epoch[48]:
	train_loss = 0.83418, train_accuracy = 0.51482499
	valid_loss = 1.57746, valid_accuracy = 0.50659996
	time = 21.51 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 50%|█████     | 50/100 [17:56&lt;17:54, 21.49s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 5.0000e-02.
Epoch[49]:
	train_loss = 0.82776, train_accuracy = 0.65372497
	valid_loss = 1.06318, valid_accuracy = 0.63629997
	time = 21.36 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 51%|█████     | 51/100 [18:17&lt;17:22, 21.28s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 4.8429e-02.
Epoch[50]:
	train_loss = 0.82567, train_accuracy = 0.67397499
	valid_loss = 0.99111, valid_accuracy = 0.64469999
	time = 20.8 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 52%|█████▏    | 52/100 [18:38&lt;16:59, 21.23s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 4.6860e-02.
Epoch[51]:
	train_loss = 0.82087, train_accuracy = 0.70007497
	valid_loss = 0.92019, valid_accuracy = 0.66850001
	time = 21.1 s
Validation loss decreased(0.92358---&gt;0.92019) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 53%|█████▎    | 53/100 [18:59&lt;16:40, 21.30s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 4.5295e-02.
Epoch[52]:
	train_loss = 0.80797, train_accuracy = 0.61344999
	valid_loss = 1.15819, valid_accuracy = 0.5923
	time = 21.44 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 54%|█████▍    | 54/100 [19:21&lt;16:20, 21.32s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 4.3733e-02.
Epoch[53]:
	train_loss = 0.80057, train_accuracy = 0.67597497
	valid_loss = 1.01268, valid_accuracy = 0.65499997
	time = 21.38 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 55%|█████▌    | 55/100 [19:42&lt;15:56, 21.26s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 4.2178e-02.
Epoch[54]:
	train_loss = 0.79492, train_accuracy = 0.63822496
	valid_loss = 1.10191, valid_accuracy = 0.6164
	time = 21.11 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 56%|█████▌    | 56/100 [20:03&lt;15:31, 21.18s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 4.0631e-02.
Epoch[55]:
	train_loss = 0.79644, train_accuracy = 0.69479996
	valid_loss = 0.93096, valid_accuracy = 0.67159998
	time = 20.99 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 57%|█████▋    | 57/100 [20:23&lt;15:05, 21.06s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 3.9093e-02.
Epoch[56]:
	train_loss = 0.78497, train_accuracy = 0.71187496
	valid_loss = 0.89797, valid_accuracy = 0.67839998
	time = 20.77 s
Validation loss decreased(0.92019---&gt;0.89797) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 58%|█████▊    | 58/100 [20:45&lt;14:44, 21.07s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 3.7566e-02.
Epoch[57]:
	train_loss = 0.78148, train_accuracy = 0.70217496
	valid_loss = 0.93182, valid_accuracy = 0.67259997
	time = 21.1 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 59%|█████▉    | 59/100 [21:06&lt;14:25, 21.11s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 3.6050e-02.
Epoch[58]:
	train_loss = 0.78342, train_accuracy = 0.72122496
	valid_loss = 0.86601, valid_accuracy = 0.69669998
	time = 21.17 s
Validation loss decreased(0.89797---&gt;0.86601) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 60%|██████    | 60/100 [21:27&lt;14:05, 21.14s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 3.4549e-02.
Epoch[59]:
	train_loss = 0.77163, train_accuracy = 0.70934999
	valid_loss = 0.90115, valid_accuracy = 0.67829996
	time = 21.21 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 61%|██████    | 61/100 [21:48&lt;13:46, 21.20s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 3.3063e-02.
Epoch[60]:
	train_loss = 0.76143, train_accuracy = 0.70484996
	valid_loss = 0.92383, valid_accuracy = 0.67049998
	time = 21.35 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 62%|██████▏   | 62/100 [22:09&lt;13:22, 21.12s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 3.1594e-02.
Epoch[61]:
	train_loss = 0.75435, train_accuracy = 0.68642497
	valid_loss = 0.96801, valid_accuracy = 0.6609
	time = 20.92 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 63%|██████▎   | 63/100 [22:30&lt;12:58, 21.03s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 3.0143e-02.
Epoch[62]:
	train_loss = 0.74805, train_accuracy = 0.69337499
	valid_loss = 0.94825, valid_accuracy = 0.66439998
	time = 20.83 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 64%|██████▍   | 64/100 [22:51&lt;12:40, 21.11s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 2.8711e-02.
Epoch[63]:
	train_loss = 0.74775, train_accuracy = 0.728275
	valid_loss = 0.873, valid_accuracy = 0.68879998
	time = 21.31 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 65%|██████▌   | 65/100 [23:13&lt;12:24, 21.26s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 2.7300e-02.
Epoch[64]:
	train_loss = 0.7342, train_accuracy = 0.73324996
	valid_loss = 0.85445, valid_accuracy = 0.69949996
	time = 21.58 s
Validation loss decreased(0.86601---&gt;0.85445) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 66%|██████▌   | 66/100 [23:34&lt;12:02, 21.26s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 2.5912e-02.
Epoch[65]:
	train_loss = 0.72719, train_accuracy = 0.73019999
	valid_loss = 0.86396, valid_accuracy = 0.6929
	time = 21.27 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 67%|██████▋   | 67/100 [23:56&lt;11:42, 21.28s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 2.4548e-02.
Epoch[66]:
	train_loss = 0.72398, train_accuracy = 0.70622498
	valid_loss = 0.92338, valid_accuracy = 0.67579997
	time = 21.31 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 68%|██████▊   | 68/100 [24:17&lt;11:20, 21.27s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 2.3209e-02.
Epoch[67]:
	train_loss = 0.71595, train_accuracy = 0.70384997
	valid_loss = 0.94588, valid_accuracy = 0.67479998
	time = 21.26 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 69%|██████▉   | 69/100 [24:38&lt;10:56, 21.19s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 2.1896e-02.
Epoch[68]:
	train_loss = 0.71118, train_accuracy = 0.73772496
	valid_loss = 0.8477, valid_accuracy = 0.70129997
	time = 20.97 s
Validation loss decreased(0.85445---&gt;0.8477) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 70%|███████   | 70/100 [24:59&lt;10:37, 21.25s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 2.0611e-02.
Epoch[69]:
	train_loss = 0.70302, train_accuracy = 0.71754998
	valid_loss = 0.91972, valid_accuracy = 0.67739999
	time = 21.38 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 71%|███████   | 71/100 [25:21&lt;10:17, 21.28s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 1.9355e-02.
Epoch[70]:
	train_loss = 0.68993, train_accuracy = 0.71402496
	valid_loss = 0.93437, valid_accuracy = 0.68189996
	time = 21.38 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 72%|███████▏  | 72/100 [25:42&lt;09:55, 21.27s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 1.8129e-02.
Epoch[71]:
	train_loss = 0.68971, train_accuracy = 0.75672495
	valid_loss = 0.80782, valid_accuracy = 0.71849996
	time = 21.23 s
Validation loss decreased(0.8477---&gt;0.80782) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 73%|███████▎  | 73/100 [26:03&lt;09:32, 21.21s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 1.6934e-02.
Epoch[72]:
	train_loss = 0.67996, train_accuracy = 0.764
	valid_loss = 0.79024, valid_accuracy = 0.7198
	time = 21.03 s
Validation loss decreased(0.80782---&gt;0.79024) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 74%|███████▍  | 74/100 [26:24&lt;09:07, 21.05s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 1.5773e-02.
Epoch[73]:
	train_loss = 0.66977, train_accuracy = 0.76529998
	valid_loss = 0.7894, valid_accuracy = 0.72209996
	time = 20.67 s
Validation loss decreased(0.79024---&gt;0.7894) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 75%|███████▌  | 75/100 [26:45&lt;08:47, 21.09s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 1.4645e-02.
Epoch[74]:
	train_loss = 0.66768, train_accuracy = 0.76257497
	valid_loss = 0.79337, valid_accuracy = 0.72009999
	time = 21.17 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 76%|███████▌  | 76/100 [27:06&lt;08:30, 21.29s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 1.3552e-02.
Epoch[75]:
	train_loss = 0.65762, train_accuracy = 0.74457496
	valid_loss = 0.84156, valid_accuracy = 0.70229995
	time = 21.75 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 77%|███████▋  | 77/100 [27:28&lt;08:09, 21.28s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 1.2494e-02.
Epoch[76]:
	train_loss = 0.64416, train_accuracy = 0.7773
	valid_loss = 0.77998, valid_accuracy = 0.72869998
	time = 21.24 s
Validation loss decreased(0.7894---&gt;0.77998) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 78%|███████▊  | 78/100 [27:49&lt;07:51, 21.41s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 1.1474e-02.
Epoch[77]:
	train_loss = 0.63285, train_accuracy = 0.77939999
	valid_loss = 0.75763, valid_accuracy = 0.73769999
	time = 21.71 s
Validation loss decreased(0.77998---&gt;0.75763) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 79%|███████▉  | 79/100 [28:12&lt;07:35, 21.67s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 1.0492e-02.
Epoch[78]:
	train_loss = 0.63271, train_accuracy = 0.78077495
	valid_loss = 0.76657, valid_accuracy = 0.72670001
	time = 22.27 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 80%|████████  | 80/100 [28:34&lt;07:16, 21.80s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.5492e-03.
Epoch[79]:
	train_loss = 0.6252, train_accuracy = 0.79017496
	valid_loss = 0.74735, valid_accuracy = 0.741
	time = 22.09 s
Validation loss decreased(0.75763---&gt;0.74735) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 81%|████████  | 81/100 [28:56&lt;06:58, 22.00s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 8.6460e-03.
Epoch[80]:
	train_loss = 0.61541, train_accuracy = 0.77382499
	valid_loss = 0.78587, valid_accuracy = 0.72219998
	time = 22.47 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 82%|████████▏ | 82/100 [29:18&lt;06:33, 21.87s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 7.7836e-03.
Epoch[81]:
	train_loss = 0.60814, train_accuracy = 0.773
	valid_loss = 0.79134, valid_accuracy = 0.72139996
	time = 21.57 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 83%|████████▎ | 83/100 [29:39&lt;06:10, 21.77s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 6.9629e-03.
Epoch[82]:
	train_loss = 0.60028, train_accuracy = 0.79974997
	valid_loss = 0.73721, valid_accuracy = 0.74289995
	time = 21.51 s
Validation loss decreased(0.74735---&gt;0.73721) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 84%|████████▍ | 84/100 [30:00&lt;05:44, 21.54s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 6.1847e-03.
Epoch[83]:
	train_loss = 0.58807, train_accuracy = 0.787
	valid_loss = 0.77878, valid_accuracy = 0.72839999
	time = 21.02 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 85%|████████▌ | 85/100 [30:21&lt;05:20, 21.36s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 5.4497e-03.
Epoch[84]:
	train_loss = 0.57793, train_accuracy = 0.79819995
	valid_loss = 0.74594, valid_accuracy = 0.74189997
	time = 20.93 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 86%|████████▌ | 86/100 [30:43&lt;04:59, 21.40s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 4.7586e-03.
Epoch[85]:
	train_loss = 0.57145, train_accuracy = 0.81062496
	valid_loss = 0.72517, valid_accuracy = 0.74879998
	time = 21.46 s
Validation loss decreased(0.73721---&gt;0.72517) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 87%|████████▋ | 87/100 [31:05&lt;04:39, 21.50s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 4.1123e-03.
Epoch[86]:
	train_loss = 0.5639, train_accuracy = 0.81474996
	valid_loss = 0.71895, valid_accuracy = 0.74909997
	time = 21.74 s
Validation loss decreased(0.72517---&gt;0.71895) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 88%|████████▊ | 88/100 [31:26&lt;04:16, 21.39s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 3.5112e-03.
Epoch[87]:
	train_loss = 0.55134, train_accuracy = 0.81919998
	valid_loss = 0.71795, valid_accuracy = 0.74860001
	time = 21.1 s
Validation loss decreased(0.71895---&gt;0.71795) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 89%|████████▉ | 89/100 [31:47&lt;03:55, 21.42s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 2.9560e-03.
Epoch[88]:
	train_loss = 0.55036, train_accuracy = 0.80774999
	valid_loss = 0.74203, valid_accuracy = 0.741
	time = 21.49 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 90%|█████████ | 90/100 [32:08&lt;03:33, 21.36s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 2.4472e-03.
Epoch[89]:
	train_loss = 0.53944, train_accuracy = 0.82054996
	valid_loss = 0.71778, valid_accuracy = 0.75099999
	time = 21.22 s
Validation loss decreased(0.71795---&gt;0.71778) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 91%|█████████ | 91/100 [32:29&lt;03:11, 21.23s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 1.9853e-03.
Epoch[90]:
	train_loss = 0.53276, train_accuracy = 0.82677495
	valid_loss = 0.7094, valid_accuracy = 0.75459999
	time = 20.9 s
Validation loss decreased(0.71778---&gt;0.7094) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 92%|█████████▏| 92/100 [32:51&lt;02:49, 21.23s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 1.5708e-03.
Epoch[91]:
	train_loss = 0.52753, train_accuracy = 0.83032501
	valid_loss = 0.70812, valid_accuracy = 0.75239998
	time = 21.21 s
Validation loss decreased(0.7094---&gt;0.70812) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 93%|█████████▎| 93/100 [33:12&lt;02:29, 21.32s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 1.2042e-03.
Epoch[92]:
	train_loss = 0.52279, train_accuracy = 0.83515
	valid_loss = 0.70218, valid_accuracy = 0.75599998
	time = 21.53 s
Validation loss decreased(0.70812---&gt;0.70218) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 94%|█████████▍| 94/100 [33:34&lt;02:08, 21.36s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 8.8564e-04.
Epoch[93]:
	train_loss = 0.51135, train_accuracy = 0.83515
	valid_loss = 0.70061, valid_accuracy = 0.75699997
	time = 21.43 s
Validation loss decreased(0.70218---&gt;0.70061) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 95%|█████████▌| 95/100 [33:55&lt;01:46, 21.33s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 6.1558e-04.
Epoch[94]:
	train_loss = 0.50525, train_accuracy = 0.83797497
	valid_loss = 0.70357, valid_accuracy = 0.75559998
	time = 21.27 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 96%|█████████▌| 96/100 [34:16&lt;01:24, 21.19s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 3.9426e-04.
Epoch[95]:
	train_loss = 0.50333, train_accuracy = 0.8391
	valid_loss = 0.70296, valid_accuracy = 0.75669998
	time = 20.87 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 97%|█████████▋| 97/100 [34:37&lt;01:03, 21.12s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 2.2190e-04.
Epoch[96]:
	train_loss = 0.49785, train_accuracy = 0.84139997
	valid_loss = 0.70105, valid_accuracy = 0.75739998
	time = 20.95 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 98%|█████████▊| 98/100 [34:58&lt;00:42, 21.16s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.8664e-05.
Epoch[97]:
	train_loss = 0.49682, train_accuracy = 0.84059995
	valid_loss = 0.69977, valid_accuracy = 0.75689995
	time = 21.24 s
Validation loss decreased(0.70061---&gt;0.69977) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 99%|█████████▉| 99/100 [35:19&lt;00:21, 21.21s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 2.4672e-05.
Epoch[98]:
	train_loss = 0.49451, train_accuracy = 0.83894998
	valid_loss = 0.69977, valid_accuracy = 0.75639999
	time = 21.32 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>100%|██████████| 100/100 [35:40&lt;00:00, 21.41s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 0.0000e+00.
Epoch[99]:
	train_loss = 0.49422, train_accuracy = 0.83974999
	valid_loss = 0.70044, valid_accuracy = 0.75639999
	time = 21.16 s
[Finished training]
	valid training loss: 0.49682
	valid training accuracy 0.84059995
	min validation loss: 0.69977,
	best validation accuracy: 0.75689995
Model[MobileNetV3] - partial training (last layer) / model_weights
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 1.0000e-01.
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>  0%|          | 0/100 [00:00&lt;?, ?it/s]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>#############################################################################################
[Training parameters]
	epochs = 100,
	lr = 0.1,
	momentum = 0.9,
	weight_decay = 0.0005,
	loss = CrossEntropyLoss(),
	optimizer = SGD (
Parameter Group 0
    dampening: 0
    differentiable: False
    foreach: None
    initial_lr: 0.1
    lr: 0.1
    maximize: False
    momentum: 0.9
    nesterov: False
    weight_decay: 0.0005
),
	scheduler = &lt;torch.optim.lr_scheduler.CosineAnnealingLR object at 0x0000026A38B6AD70&gt;,
	device = cuda:0
#############################################################################################
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>  1%|          | 1/100 [00:17&lt;29:17, 17.76s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.9975e-02.
Epoch[0]:
	train_loss = 31.81251, train_accuracy = 0.22472499
	valid_loss = 24.72053, valid_accuracy = 0.21949999
	time = 17.74 s
Validation loss decreased(None---&gt;24.72053) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>  2%|▏         | 2/100 [00:35&lt;28:51, 17.66s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.9901e-02.
Epoch[1]:
	train_loss = 30.6439, train_accuracy = 0.2138
	valid_loss = 27.69101, valid_accuracy = 0.2105
	time = 17.6 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>  3%|▎         | 3/100 [00:53&lt;28:34, 17.68s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.9778e-02.
Epoch[2]:
	train_loss = 30.50365, train_accuracy = 0.231325
	valid_loss = 25.14971, valid_accuracy = 0.2148
	time = 17.69 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>  4%|▍         | 4/100 [01:10&lt;28:21, 17.72s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.9606e-02.
Epoch[3]:
	train_loss = 30.52812, train_accuracy = 0.22944999
	valid_loss = 27.98627, valid_accuracy = 0.2174
	time = 17.79 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>  5%|▌         | 5/100 [01:28&lt;28:10, 17.80s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.9384e-02.
Epoch[4]:
	train_loss = 31.18436, train_accuracy = 0.20999999
	valid_loss = 28.97241, valid_accuracy = 0.2078
	time = 17.94 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>  6%|▌         | 6/100 [01:46&lt;28:06, 17.94s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.9114e-02.
Epoch[5]:
	train_loss = 29.92517, train_accuracy = 0.22482499
	valid_loss = 25.11535, valid_accuracy = 0.21439999
	time = 18.22 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>  7%|▋         | 7/100 [02:04&lt;27:41, 17.86s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.8796e-02.
Epoch[6]:
	train_loss = 30.94302, train_accuracy = 0.22149999
	valid_loss = 28.02813, valid_accuracy = 0.21439999
	time = 17.7 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>  8%|▊         | 8/100 [02:22&lt;27:17, 17.79s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.8429e-02.
Epoch[7]:
	train_loss = 29.89, train_accuracy = 0.22724999
	valid_loss = 27.42237, valid_accuracy = 0.2235
	time = 17.65 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>  9%|▉         | 9/100 [02:39&lt;26:50, 17.70s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.8015e-02.
Epoch[8]:
	train_loss = 30.50035, train_accuracy = 0.232575
	valid_loss = 25.44352, valid_accuracy = 0.22479999
	time = 17.49 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 10%|█         | 10/100 [02:57&lt;26:37, 17.75s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.7553e-02.
Epoch[9]:
	train_loss = 30.0153, train_accuracy = 0.226
	valid_loss = 25.48822, valid_accuracy = 0.2219
	time = 17.85 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 11%|█         | 11/100 [03:15&lt;26:23, 17.79s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.7044e-02.
Epoch[10]:
	train_loss = 29.97809, train_accuracy = 0.22385
	valid_loss = 26.51126, valid_accuracy = 0.2129
	time = 17.88 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 12%|█▏        | 12/100 [03:33&lt;26:17, 17.93s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.6489e-02.
Epoch[11]:
	train_loss = 30.07529, train_accuracy = 0.20407499
	valid_loss = 31.06548, valid_accuracy = 0.20119999
	time = 18.25 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 13%|█▎        | 13/100 [03:51&lt;25:58, 17.92s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.5888e-02.
Epoch[12]:
	train_loss = 29.73823, train_accuracy = 0.22819999
	valid_loss = 23.98723, valid_accuracy = 0.22139999
	time = 17.88 s
Validation loss decreased(24.72053---&gt;23.98723) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 14%|█▍        | 14/100 [04:09&lt;25:43, 17.94s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.5241e-02.
Epoch[13]:
	train_loss = 29.81153, train_accuracy = 0.21924999
	valid_loss = 26.38218, valid_accuracy = 0.2131
	time = 18.0 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 15%|█▌        | 15/100 [04:27&lt;25:20, 17.88s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.4550e-02.
Epoch[14]:
	train_loss = 29.65341, train_accuracy = 0.20025
	valid_loss = 31.39033, valid_accuracy = 0.1919
	time = 17.75 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 16%|█▌        | 16/100 [04:45&lt;24:56, 17.81s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.3815e-02.
Epoch[15]:
	train_loss = 28.32487, train_accuracy = 0.20844999
	valid_loss = 29.75284, valid_accuracy = 0.19659999
	time = 17.64 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 17%|█▋        | 17/100 [05:02&lt;24:39, 17.82s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.3037e-02.
Epoch[16]:
	train_loss = 28.93674, train_accuracy = 0.22742499
	valid_loss = 23.19029, valid_accuracy = 0.2269
	time = 17.82 s
Validation loss decreased(23.98723---&gt;23.19029) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 18%|█▊        | 18/100 [05:21&lt;24:27, 17.90s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.2216e-02.
Epoch[17]:
	train_loss = 28.54156, train_accuracy = 0.21097499
	valid_loss = 28.98857, valid_accuracy = 0.20039999
	time = 18.09 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 19%|█▉        | 19/100 [05:39&lt;24:14, 17.96s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.1354e-02.
Epoch[18]:
	train_loss = 28.0518, train_accuracy = 0.22067499
	valid_loss = 25.22226, valid_accuracy = 0.21529999
	time = 18.09 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 20%|██        | 20/100 [05:57&lt;23:55, 17.95s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.0451e-02.
Epoch[19]:
	train_loss = 27.82314, train_accuracy = 0.21077499
	valid_loss = 26.68024, valid_accuracy = 0.2031
	time = 17.93 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 21%|██        | 21/100 [06:14&lt;23:37, 17.94s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 8.9508e-02.
Epoch[20]:
	train_loss = 27.79745, train_accuracy = 0.2243
	valid_loss = 26.32576, valid_accuracy = 0.22369999
	time = 17.93 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 22%|██▏       | 22/100 [06:32&lt;23:19, 17.95s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 8.8526e-02.
Epoch[21]:
	train_loss = 27.66476, train_accuracy = 0.22542499
	valid_loss = 22.54724, valid_accuracy = 0.21529999
	time = 17.93 s
Validation loss decreased(23.19029---&gt;22.54724) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 23%|██▎       | 23/100 [06:51&lt;23:04, 17.98s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 8.7506e-02.
Epoch[22]:
	train_loss = 27.20833, train_accuracy = 0.22192499
	valid_loss = 26.07078, valid_accuracy = 0.2121
	time = 18.07 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 24%|██▍       | 24/100 [07:09&lt;22:48, 18.01s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 8.6448e-02.
Epoch[23]:
	train_loss = 26.68957, train_accuracy = 0.22549999
	valid_loss = 21.81386, valid_accuracy = 0.22019999
	time = 18.05 s
Validation loss decreased(22.54724---&gt;21.81386) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 25%|██▌       | 25/100 [07:27&lt;22:31, 18.02s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 8.5355e-02.
Epoch[24]:
	train_loss = 26.6723, train_accuracy = 0.23134999
	valid_loss = 22.93265, valid_accuracy = 0.2191
	time = 18.06 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 26%|██▌       | 26/100 [07:45&lt;22:14, 18.04s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 8.4227e-02.
Epoch[25]:
	train_loss = 26.56734, train_accuracy = 0.231775
	valid_loss = 21.21615, valid_accuracy = 0.21769999
	time = 18.05 s
Validation loss decreased(21.81386---&gt;21.21615) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 27%|██▋       | 27/100 [08:03&lt;21:52, 17.98s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 8.3066e-02.
Epoch[26]:
	train_loss = 25.93758, train_accuracy = 0.195675
	valid_loss = 26.82688, valid_accuracy = 0.1934
	time = 17.83 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 28%|██▊       | 28/100 [08:22&lt;21:59, 18.33s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 8.1871e-02.
Epoch[27]:
	train_loss = 25.81116, train_accuracy = 0.225225
	valid_loss = 21.2324, valid_accuracy = 0.21609999
	time = 19.16 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 29%|██▉       | 29/100 [08:41&lt;21:55, 18.53s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 8.0645e-02.
Epoch[28]:
	train_loss = 24.78435, train_accuracy = 0.20265
	valid_loss = 24.55746, valid_accuracy = 0.1952
	time = 18.99 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 30%|███       | 30/100 [08:59&lt;21:32, 18.46s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 7.9389e-02.
Epoch[29]:
	train_loss = 25.22114, train_accuracy = 0.2076
	valid_loss = 24.04906, valid_accuracy = 0.20559999
	time = 18.3 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 31%|███       | 31/100 [09:17&lt;21:08, 18.38s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 7.8104e-02.
Epoch[30]:
	train_loss = 25.05756, train_accuracy = 0.21589999
	valid_loss = 22.19297, valid_accuracy = 0.2147
	time = 18.2 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 32%|███▏      | 32/100 [09:36&lt;20:54, 18.46s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 7.6791e-02.
Epoch[31]:
	train_loss = 24.11391, train_accuracy = 0.22714999
	valid_loss = 21.17506, valid_accuracy = 0.21879999
	time = 18.6 s
Validation loss decreased(21.21615---&gt;21.17506) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 33%|███▎      | 33/100 [09:54&lt;20:31, 18.38s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 7.5452e-02.
Epoch[32]:
	train_loss = 23.17956, train_accuracy = 0.208775
	valid_loss = 20.5591, valid_accuracy = 0.19999999
	time = 18.18 s
Validation loss decreased(21.17506---&gt;20.5591) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 34%|███▍      | 34/100 [10:13&lt;20:17, 18.45s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 7.4088e-02.
Epoch[33]:
	train_loss = 23.78794, train_accuracy = 0.21075
	valid_loss = 21.64814, valid_accuracy = 0.21179999
	time = 18.63 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 35%|███▌      | 35/100 [10:31&lt;20:00, 18.47s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 7.2700e-02.
Epoch[34]:
	train_loss = 23.0771, train_accuracy = 0.216125
	valid_loss = 20.52101, valid_accuracy = 0.211
	time = 18.48 s
Validation loss decreased(20.5591---&gt;20.52101) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 36%|███▌      | 36/100 [10:50&lt;19:41, 18.46s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 7.1289e-02.
Epoch[35]:
	train_loss = 22.50588, train_accuracy = 0.218275
	valid_loss = 19.46956, valid_accuracy = 0.2129
	time = 18.44 s
Validation loss decreased(20.52101---&gt;19.46956) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 37%|███▋      | 37/100 [11:08&lt;19:25, 18.50s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 6.9857e-02.
Epoch[36]:
	train_loss = 21.60931, train_accuracy = 0.22667499
	valid_loss = 17.4326, valid_accuracy = 0.2295
	time = 18.56 s
Validation loss decreased(19.46956---&gt;17.4326) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 38%|███▊      | 38/100 [11:27&lt;19:16, 18.66s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 6.8406e-02.
Epoch[37]:
	train_loss = 21.78446, train_accuracy = 0.228875
	valid_loss = 17.84242, valid_accuracy = 0.22219999
	time = 19.01 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 39%|███▉      | 39/100 [11:46&lt;18:57, 18.65s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 6.6937e-02.
Epoch[38]:
	train_loss = 21.85394, train_accuracy = 0.2474
	valid_loss = 17.27314, valid_accuracy = 0.2394
	time = 18.61 s
Validation loss decreased(17.4326---&gt;17.27314) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 40%|████      | 40/100 [12:05&lt;18:46, 18.78s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 6.5451e-02.
Epoch[39]:
	train_loss = 20.27575, train_accuracy = 0.228
	valid_loss = 19.44918, valid_accuracy = 0.2146
	time = 19.07 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 41%|████      | 41/100 [12:23&lt;18:22, 18.68s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 6.3950e-02.
Epoch[40]:
	train_loss = 19.75771, train_accuracy = 0.21994999
	valid_loss = 21.32681, valid_accuracy = 0.2156
	time = 18.47 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 42%|████▏     | 42/100 [12:42&lt;18:10, 18.79s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 6.2434e-02.
Epoch[41]:
	train_loss = 20.12877, train_accuracy = 0.223775
	valid_loss = 18.39458, valid_accuracy = 0.2209
	time = 19.05 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 43%|████▎     | 43/100 [13:02&lt;18:01, 18.97s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 6.0907e-02.
Epoch[42]:
	train_loss = 19.61039, train_accuracy = 0.208575
	valid_loss = 18.41669, valid_accuracy = 0.20269999
	time = 19.36 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 44%|████▍     | 44/100 [13:21&lt;17:43, 19.00s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 5.9369e-02.
Epoch[43]:
	train_loss = 18.87728, train_accuracy = 0.2052
	valid_loss = 17.8669, valid_accuracy = 0.19919999
	time = 19.08 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 45%|████▌     | 45/100 [13:40&lt;17:27, 19.04s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 5.7822e-02.
Epoch[44]:
	train_loss = 18.15233, train_accuracy = 0.210825
	valid_loss = 17.49295, valid_accuracy = 0.20439999
	time = 19.13 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 46%|████▌     | 46/100 [13:59&lt;17:05, 19.00s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 5.6267e-02.
Epoch[45]:
	train_loss = 17.45495, train_accuracy = 0.23339999
	valid_loss = 15.86726, valid_accuracy = 0.22369999
	time = 18.89 s
Validation loss decreased(17.27314---&gt;15.86726) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 47%|████▋     | 47/100 [14:18&lt;16:49, 19.05s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 5.4705e-02.
Epoch[46]:
	train_loss = 17.03386, train_accuracy = 0.22697499
	valid_loss = 14.14242, valid_accuracy = 0.22299999
	time = 19.16 s
Validation loss decreased(15.86726---&gt;14.14242) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 48%|████▊     | 48/100 [14:37&lt;16:24, 18.94s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 5.3140e-02.
Epoch[47]:
	train_loss = 16.97643, train_accuracy = 0.23304999
	valid_loss = 13.58901, valid_accuracy = 0.2243
	time = 18.66 s
Validation loss decreased(14.14242---&gt;13.58901) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 49%|████▉     | 49/100 [14:56&lt;16:08, 18.99s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 5.1571e-02.
Epoch[48]:
	train_loss = 16.33317, train_accuracy = 0.22389999
	valid_loss = 13.07383, valid_accuracy = 0.2201
	time = 19.07 s
Validation loss decreased(13.58901---&gt;13.07383) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 50%|█████     | 50/100 [15:15&lt;15:49, 19.00s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 5.0000e-02.
Epoch[49]:
	train_loss = 16.04551, train_accuracy = 0.22282499
	valid_loss = 13.24382, valid_accuracy = 0.22029999
	time = 19.02 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 51%|█████     | 51/100 [15:34&lt;15:35, 19.08s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 4.8429e-02.
Epoch[50]:
	train_loss = 15.2955, train_accuracy = 0.22379999
	valid_loss = 14.34536, valid_accuracy = 0.2269
	time = 19.28 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 52%|█████▏    | 52/100 [15:53&lt;15:13, 19.03s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 4.6860e-02.
Epoch[51]:
	train_loss = 14.89067, train_accuracy = 0.233725
	valid_loss = 12.40994, valid_accuracy = 0.2278
	time = 18.88 s
Validation loss decreased(13.07383---&gt;12.40994) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 53%|█████▎    | 53/100 [16:12&lt;14:55, 19.06s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 4.5295e-02.
Epoch[52]:
	train_loss = 13.88654, train_accuracy = 0.23384999
	valid_loss = 11.19797, valid_accuracy = 0.2305
	time = 19.1 s
Validation loss decreased(12.40994---&gt;11.19797) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 54%|█████▍    | 54/100 [16:32&lt;14:41, 19.17s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 4.3733e-02.
Epoch[53]:
	train_loss = 13.70242, train_accuracy = 0.21967499
	valid_loss = 11.38, valid_accuracy = 0.2137
	time = 19.45 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 55%|█████▌    | 55/100 [16:51&lt;14:20, 19.12s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 4.2178e-02.
Epoch[54]:
	train_loss = 13.28849, train_accuracy = 0.21579999
	valid_loss = 12.54732, valid_accuracy = 0.2085
	time = 18.99 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 56%|█████▌    | 56/100 [17:10&lt;13:58, 19.06s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 4.0631e-02.
Epoch[55]:
	train_loss = 12.48864, train_accuracy = 0.235175
	valid_loss = 10.82072, valid_accuracy = 0.23199999
	time = 18.92 s
Validation loss decreased(11.19797---&gt;10.82072) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 57%|█████▋    | 57/100 [17:29&lt;13:38, 19.04s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 3.9093e-02.
Epoch[56]:
	train_loss = 12.51795, train_accuracy = 0.2191
	valid_loss = 10.97316, valid_accuracy = 0.21429999
	time = 18.97 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 58%|█████▊    | 58/100 [17:50&lt;13:44, 19.62s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 3.7566e-02.
Epoch[57]:
	train_loss = 11.87826, train_accuracy = 0.226025
	valid_loss = 9.91683, valid_accuracy = 0.2094
	time = 20.97 s
Validation loss decreased(10.82072---&gt;9.91683) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 59%|█████▉    | 59/100 [18:08&lt;13:11, 19.31s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 3.6050e-02.
Epoch[58]:
	train_loss = 11.50127, train_accuracy = 0.239375
	valid_loss = 10.28736, valid_accuracy = 0.23689999
	time = 18.59 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 60%|██████    | 60/100 [18:28&lt;13:03, 19.58s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 3.4549e-02.
Epoch[59]:
	train_loss = 11.22407, train_accuracy = 0.20709999
	valid_loss = 10.6605, valid_accuracy = 0.19939999
	time = 20.19 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 61%|██████    | 61/100 [18:48&lt;12:46, 19.64s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 3.3063e-02.
Epoch[60]:
	train_loss = 10.48025, train_accuracy = 0.18987499
	valid_loss = 10.95908, valid_accuracy = 0.19159999
	time = 19.8 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 62%|██████▏   | 62/100 [19:07&lt;12:15, 19.34s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 3.1594e-02.
Epoch[61]:
	train_loss = 10.20857, train_accuracy = 0.219725
	valid_loss = 8.9872, valid_accuracy = 0.214
	time = 18.63 s
Validation loss decreased(9.91683---&gt;8.9872) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 63%|██████▎   | 63/100 [19:26&lt;11:51, 19.23s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 3.0143e-02.
Epoch[62]:
	train_loss = 9.48482, train_accuracy = 0.22982499
	valid_loss = 7.68416, valid_accuracy = 0.22219999
	time = 18.93 s
Validation loss decreased(8.9872---&gt;7.68416) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 64%|██████▍   | 64/100 [19:45&lt;11:35, 19.33s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 2.8711e-02.
Epoch[63]:
	train_loss = 8.98814, train_accuracy = 0.19777499
	valid_loss = 9.26339, valid_accuracy = 0.1927
	time = 19.57 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 65%|██████▌   | 65/100 [20:05&lt;11:19, 19.41s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 2.7300e-02.
Epoch[64]:
	train_loss = 8.5651, train_accuracy = 0.23195
	valid_loss = 7.00048, valid_accuracy = 0.22909999
	time = 19.58 s
Validation loss decreased(7.68416---&gt;7.00048) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 66%|██████▌   | 66/100 [20:24&lt;10:58, 19.36s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 2.5912e-02.
Epoch[65]:
	train_loss = 8.26106, train_accuracy = 0.223225
	valid_loss = 7.35339, valid_accuracy = 0.2105
	time = 19.24 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 67%|██████▋   | 67/100 [20:44&lt;10:41, 19.43s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 2.4548e-02.
Epoch[66]:
	train_loss = 7.54832, train_accuracy = 0.20962499
	valid_loss = 7.75917, valid_accuracy = 0.21269999
	time = 19.59 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 68%|██████▊   | 68/100 [21:03&lt;10:23, 19.50s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 2.3209e-02.
Epoch[67]:
	train_loss = 7.47338, train_accuracy = 0.22929999
	valid_loss = 7.01617, valid_accuracy = 0.2305
	time = 19.66 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 69%|██████▉   | 69/100 [21:22&lt;10:00, 19.36s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 2.1896e-02.
Epoch[68]:
	train_loss = 6.87651, train_accuracy = 0.22655
	valid_loss = 6.03864, valid_accuracy = 0.2182
	time = 19.03 s
Validation loss decreased(7.00048---&gt;6.03864) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 70%|███████   | 70/100 [21:41&lt;09:34, 19.15s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 2.0611e-02.
Epoch[69]:
	train_loss = 6.4732, train_accuracy = 0.22964999
	valid_loss = 5.67093, valid_accuracy = 0.2199
	time = 18.65 s
Validation loss decreased(6.03864---&gt;5.67093) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 71%|███████   | 71/100 [22:00&lt;09:11, 19.03s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 1.9355e-02.
Epoch[70]:
	train_loss = 6.17948, train_accuracy = 0.210925
	valid_loss = 5.77953, valid_accuracy = 0.20549999
	time = 18.73 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 72%|███████▏  | 72/100 [22:18&lt;08:48, 18.89s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 1.8129e-02.
Epoch[71]:
	train_loss = 5.9213, train_accuracy = 0.22405
	valid_loss = 5.67821, valid_accuracy = 0.2173
	time = 18.56 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 73%|███████▎  | 73/100 [22:38&lt;08:35, 19.08s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 1.6934e-02.
Epoch[72]:
	train_loss = 5.46641, train_accuracy = 0.24212499
	valid_loss = 5.18819, valid_accuracy = 0.23449999
	time = 19.52 s
Validation loss decreased(5.67093---&gt;5.18819) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 74%|███████▍  | 74/100 [22:57&lt;08:17, 19.14s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 1.5773e-02.
Epoch[73]:
	train_loss = 5.00194, train_accuracy = 0.23905
	valid_loss = 4.52378, valid_accuracy = 0.23559999
	time = 19.26 s
Validation loss decreased(5.18819---&gt;4.52378) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 75%|███████▌  | 75/100 [23:16&lt;07:59, 19.17s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 1.4645e-02.
Epoch[74]:
	train_loss = 4.81932, train_accuracy = 0.2421
	valid_loss = 4.13573, valid_accuracy = 0.2296
	time = 19.22 s
Validation loss decreased(4.52378---&gt;4.13573) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 76%|███████▌  | 76/100 [23:35&lt;07:35, 19.00s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 1.3552e-02.
Epoch[75]:
	train_loss = 4.64027, train_accuracy = 0.24495
	valid_loss = 4.00461, valid_accuracy = 0.2429
	time = 18.58 s
Validation loss decreased(4.13573---&gt;4.00461) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 77%|███████▋  | 77/100 [23:54&lt;07:15, 18.95s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 1.2494e-02.
Epoch[76]:
	train_loss = 4.27436, train_accuracy = 0.23414999
	valid_loss = 3.90838, valid_accuracy = 0.2253
	time = 18.81 s
Validation loss decreased(4.00461---&gt;3.90838) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 78%|███████▊  | 78/100 [24:12&lt;06:53, 18.82s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 1.1474e-02.
Epoch[77]:
	train_loss = 4.00876, train_accuracy = 0.23494999
	valid_loss = 3.56948, valid_accuracy = 0.23189999
	time = 18.48 s
Validation loss decreased(3.90838---&gt;3.56948) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 79%|███████▉  | 79/100 [24:31&lt;06:34, 18.78s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 1.0492e-02.
Epoch[78]:
	train_loss = 3.74239, train_accuracy = 0.242725
	valid_loss = 3.45241, valid_accuracy = 0.2376
	time = 18.69 s
Validation loss decreased(3.56948---&gt;3.45241) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 80%|████████  | 80/100 [24:50&lt;06:15, 18.77s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.5492e-03.
Epoch[79]:
	train_loss = 3.5106, train_accuracy = 0.24834999
	valid_loss = 3.23006, valid_accuracy = 0.24089999
	time = 18.72 s
Validation loss decreased(3.45241---&gt;3.23006) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 81%|████████  | 81/100 [25:08&lt;05:55, 18.70s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 8.6460e-03.
Epoch[80]:
	train_loss = 3.28755, train_accuracy = 0.24699999
	valid_loss = 2.94752, valid_accuracy = 0.2376
	time = 18.51 s
Validation loss decreased(3.23006---&gt;2.94752) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 82%|████████▏ | 82/100 [25:27&lt;05:36, 18.69s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 7.7836e-03.
Epoch[81]:
	train_loss = 3.149, train_accuracy = 0.23622499
	valid_loss = 2.98384, valid_accuracy = 0.22149999
	time = 18.68 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 83%|████████▎ | 83/100 [25:46&lt;05:19, 18.79s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 6.9629e-03.
Epoch[82]:
	train_loss = 2.94771, train_accuracy = 0.257025
	valid_loss = 2.62671, valid_accuracy = 0.25299999
	time = 19.0 s
Validation loss decreased(2.94752---&gt;2.62671) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 84%|████████▍ | 84/100 [26:05&lt;05:01, 18.85s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 6.1847e-03.
Epoch[83]:
	train_loss = 2.77392, train_accuracy = 0.26682499
	valid_loss = 2.5303, valid_accuracy = 0.2586
	time = 18.98 s
Validation loss decreased(2.62671---&gt;2.5303) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 85%|████████▌ | 85/100 [26:24&lt;04:42, 18.83s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 5.4497e-03.
Epoch[84]:
	train_loss = 2.65367, train_accuracy = 0.25797498
	valid_loss = 2.45319, valid_accuracy = 0.25049999
	time = 18.73 s
Validation loss decreased(2.5303---&gt;2.45319) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 86%|████████▌ | 86/100 [26:42&lt;04:22, 18.73s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 4.7586e-03.
Epoch[85]:
	train_loss = 2.51608, train_accuracy = 0.27412498
	valid_loss = 2.35197, valid_accuracy = 0.264
	time = 18.49 s
Validation loss decreased(2.45319---&gt;2.35197) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 87%|████████▋ | 87/100 [27:01&lt;04:03, 18.76s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 4.1123e-03.
Epoch[86]:
	train_loss = 2.4401, train_accuracy = 0.27842498
	valid_loss = 2.25352, valid_accuracy = 0.26659998
	time = 18.82 s
Validation loss decreased(2.35197---&gt;2.25352) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 88%|████████▊ | 88/100 [27:20&lt;03:46, 18.86s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 3.5112e-03.
Epoch[87]:
	train_loss = 2.35865, train_accuracy = 0.27884999
	valid_loss = 2.22852, valid_accuracy = 0.26879999
	time = 19.06 s
Validation loss decreased(2.25352---&gt;2.22852) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 89%|████████▉ | 89/100 [27:39&lt;03:26, 18.78s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 2.9560e-03.
Epoch[88]:
	train_loss = 2.2682, train_accuracy = 0.28562498
	valid_loss = 2.15441, valid_accuracy = 0.26949999
	time = 18.57 s
Validation loss decreased(2.22852---&gt;2.15441) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 90%|█████████ | 90/100 [27:57&lt;03:07, 18.73s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 2.4472e-03.
Epoch[89]:
	train_loss = 2.20539, train_accuracy = 0.28332499
	valid_loss = 2.12906, valid_accuracy = 0.27649999
	time = 18.62 s
Validation loss decreased(2.15441---&gt;2.12906) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 91%|█████████ | 91/100 [28:16&lt;02:48, 18.77s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 1.9853e-03.
Epoch[90]:
	train_loss = 2.13804, train_accuracy = 0.31277499
	valid_loss = 2.01154, valid_accuracy = 0.29639998
	time = 18.83 s
Validation loss decreased(2.12906---&gt;2.01154) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 92%|█████████▏| 92/100 [28:35&lt;02:30, 18.76s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 1.5708e-03.
Epoch[91]:
	train_loss = 2.08403, train_accuracy = 0.301375
	valid_loss = 2.02522, valid_accuracy = 0.2897
	time = 18.73 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 93%|█████████▎| 93/100 [28:53&lt;02:10, 18.64s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 1.2042e-03.
Epoch[92]:
	train_loss = 2.04404, train_accuracy = 0.317875
	valid_loss = 1.96986, valid_accuracy = 0.30930001
	time = 18.34 s
Validation loss decreased(2.01154---&gt;1.96986) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 94%|█████████▍| 94/100 [29:12&lt;01:51, 18.56s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 8.8564e-04.
Epoch[93]:
	train_loss = 2.00438, train_accuracy = 0.32295001
	valid_loss = 1.93713, valid_accuracy = 0.31200001
	time = 18.35 s
Validation loss decreased(1.96986---&gt;1.93713) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 95%|█████████▌| 95/100 [29:31&lt;01:33, 18.69s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 6.1558e-04.
Epoch[94]:
	train_loss = 1.97462, train_accuracy = 0.33655
	valid_loss = 1.91996, valid_accuracy = 0.32119998
	time = 18.99 s
Validation loss decreased(1.93713---&gt;1.91996) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 96%|█████████▌| 96/100 [29:50&lt;01:15, 18.76s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 3.9426e-04.
Epoch[95]:
	train_loss = 1.95584, train_accuracy = 0.3362
	valid_loss = 1.89625, valid_accuracy = 0.3251
	time = 18.9 s
Validation loss decreased(1.91996---&gt;1.89625) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 97%|█████████▋| 97/100 [30:09&lt;00:56, 18.84s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 2.2190e-04.
Epoch[96]:
	train_loss = 1.93473, train_accuracy = 0.34147498
	valid_loss = 1.88247, valid_accuracy = 0.33179998
	time = 19.01 s
Validation loss decreased(1.89625---&gt;1.88247) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 98%|█████████▊| 98/100 [30:27&lt;00:37, 18.76s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 9.8664e-05.
Epoch[97]:
	train_loss = 1.91905, train_accuracy = 0.34762499
	valid_loss = 1.88404, valid_accuracy = 0.32979998
	time = 18.57 s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 99%|█████████▉| 99/100 [30:46&lt;00:18, 18.70s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 2.4672e-05.
Epoch[98]:
	train_loss = 1.91165, train_accuracy = 0.34779999
	valid_loss = 1.87671, valid_accuracy = 0.33149999
	time = 18.52 s
Validation loss decreased(1.88247---&gt;1.87671) 	 Saving The Model
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>100%|██████████| 100/100 [31:05&lt;00:00, 18.66s/it]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Adjusting learning rate of group 0 to 0.0000e+00.
Epoch[99]:
	train_loss = 1.90352, train_accuracy = 0.34942499
	valid_loss = 1.87257, valid_accuracy = 0.3339
	time = 19.5 s
Validation loss decreased(1.87671---&gt;1.87257) 	 Saving The Model
[Finished training]
	valid training loss: 1.90352
	valid training accuracy 0.34942499
	min validation loss: 1.87257,
	best validation accuracy: 0.3339
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>
</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">models</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">torchvision</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">get_model</span><span class="p">(</span><span class="s1">'efficientnet_b1'</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="s1">'EfficientNet_B1_Weights.IMAGENET1K_V2'</span><span class="p">),</span>
    <span class="n">torchvision</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">get_model</span><span class="p">(</span><span class="s1">'regnet_y_400mf'</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="s1">'RegNet_Y_400MF_Weights.IMAGENET1K_V2'</span><span class="p">),</span>
    <span class="n">torchvision</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">get_model</span><span class="p">(</span><span class="s1">'shufflenet_v2_x0_5'</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="s1">'ShuffleNet_V2_X0_5_Weights.IMAGENET1K_V1'</span><span class="p">),</span>
    <span class="n">torchvision</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">get_model</span><span class="p">(</span><span class="s1">'mobilenet_v3_small'</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="s1">'MobileNet_V3_Small_Weights.IMAGENET1K_V1'</span><span class="p">)</span>
    <span class="p">]</span>
<span class="n">model_names</span> <span class="o">=</span> <span class="p">[</span><span class="n">model</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span> <span class="k">for</span> <span class="n">model</span> <span class="ow">in</span> <span class="n">models</span><span class="p">]</span>
<span class="p">[</span><span class="n">make_mod</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">model_name</span><span class="p">)</span> <span class="k">for</span> <span class="n">model</span><span class="p">,</span> <span class="n">model_name</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">models</span><span class="p">,</span> <span class="n">model_names</span><span class="p">)]</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Model[EfficientNet] last FC before mod: Linear(in_features=1280, out_features=1000, bias=True)
Model[EfficientNet] last FC after mod: Linear(in_features=1280, out_features=10, bias=True)
Model[RegNet] last FC before mod: Linear(in_features=440, out_features=1000, bias=True)
Model[RegNet] last FC after mod: Linear(in_features=440, out_features=10, bias=True)
Model[ShuffleNetV2] last FC before mod: Linear(in_features=1024, out_features=1000, bias=True)
Model[ShuffleNetV2] last FC after mod: Linear(in_features=1024, out_features=10, bias=True)
Model[MobileNetV3] last FC before mod: Linear(in_features=1024, out_features=1000, bias=True)
Model[MobileNetV3] last FC after mod: Linear(in_features=1024, out_features=10, bias=True)
</pre>
</div>
</div>
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[ ]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>[None, None, None, None]</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">features</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">collections</span><span class="o">.</span><span class="n">OrderedDict</span><span class="p">([</span>
            <span class="c1"># 3 x 32 x 32</span>
          <span class="p">(</span><span class="s1">'conv1'</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span>
            <span class="n">in_channels</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">out_channels</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span>
            <span class="p">)),</span>
            <span class="c1"># 16 x ((32-3+2)/1+1) x ((32-3+2)/1+1) = 16 x 32 x 32</span>
          <span class="p">(</span><span class="s1">'relu1'</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()),</span>
          <span class="p">(</span><span class="s1">'conv2'</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span>
            <span class="n">in_channels</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">out_channels</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span>
            <span class="p">)),</span>
            <span class="c1"># 32 x 32 x 32</span>
          <span class="p">(</span><span class="s1">'batchNorm1'</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="mi">32</span><span class="p">)),</span>
          <span class="p">(</span><span class="s1">'relu2'</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()),</span>
          <span class="p">(</span><span class="s1">'pool1'</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span> <span class="n">stride</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">)),</span>
            <span class="c1"># 32 x ((32-3+2) / 2 + 1) x ((32-3+2) / 2 + 1) = 32 x 16 x 16</span>
          <span class="p">(</span><span class="s1">'conv3'</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span>
            <span class="n">in_channels</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">out_channels</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span>
            <span class="p">)),</span>
            <span class="c1"># 64 x 16 x 16</span>
          <span class="p">(</span><span class="s1">'batchNorm2'</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="mi">64</span><span class="p">)),</span>
          <span class="p">(</span><span class="s1">'relu3'</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()),</span>
          <span class="p">(</span><span class="s1">'pool2'</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span> <span class="n">stride</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">)),</span>
            <span class="c1"># 64 x ((16-3+2) / 2 + 1) x ((16-3+2) / 2 + 1) = 64 x 8 x 8</span>
          <span class="p">(</span><span class="s1">'conv4'</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span>
            <span class="n">in_channels</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">out_channels</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span>
            <span class="p">)),</span>
            <span class="c1"># 128 x 8 x 8</span>
          <span class="p">(</span><span class="s1">'relu4'</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()),</span>
          <span class="p">(</span><span class="s1">'conv5'</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span>
            <span class="n">in_channels</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">out_channels</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span>
            <span class="p">)),</span>
            <span class="c1"># 256 x 8 x 8</span>
          <span class="p">(</span><span class="s1">'batchNorm3'</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="mi">256</span><span class="p">)),</span>
          <span class="p">(</span><span class="s1">'relu5'</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()),</span>
        <span class="p">]))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">collections</span><span class="o">.</span><span class="n">OrderedDict</span><span class="p">([</span>
          <span class="p">(</span><span class="s1">'dropout'</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.2</span><span class="p">)),</span>
          <span class="p">(</span><span class="s1">'fc'</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">256</span> <span class="o">*</span> <span class="mi">8</span> <span class="o">*</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
            <span class="c1"># (softmax включается в вычисление кросс-энтропии)</span>
        <span class="p">]))</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">features</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="c1"># Изменение формата хранения тензора из (B, C, W, H) в (B, C*W*H)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">out</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">out</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">res</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">model</span><span class="p">,</span> <span class="n">model_name</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">models</span><span class="p">,</span> <span class="n">model_names</span><span class="p">):</span>
    <span class="n">res</span><span class="p">[</span><span class="n">model_name</span><span class="p">]</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">mode</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">'full'</span><span class="p">,</span> <span class="s1">'partial'</span><span class="p">]:</span>
        <span class="n">res</span><span class="p">[</span><span class="n">model_name</span><span class="p">][</span><span class="n">mode</span><span class="p">]</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="sa">f</span><span class="s1">'</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s1">_</span><span class="si">{</span><span class="n">mode</span><span class="si">}</span><span class="s1">_model.pth'</span><span class="p">))</span>
        <span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">res</span><span class="p">[</span><span class="n">model_name</span><span class="p">][</span><span class="n">mode</span><span class="p">][</span><span class="s1">'acc'</span><span class="p">]</span> <span class="o">=</span> <span class="n">get_accuracy</span><span class="p">(</span><span class="n">test_data_loader</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
        <span class="n">res</span><span class="p">[</span><span class="n">model_name</span><span class="p">][</span><span class="n">mode</span><span class="p">][</span><span class="s1">'true'</span><span class="p">],</span> <span class="n">res</span><span class="p">[</span><span class="n">model_name</span><span class="p">][</span><span class="n">mode</span><span class="p">][</span><span class="s1">'pred'</span><span class="p">]</span> <span class="o">=</span> <span class="n">get_res</span><span class="p">(</span><span class="n">test_data_loader</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">'../lab1/Net_10_model.pth'</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">res_own_acc</span> <span class="o">=</span> <span class="n">get_accuracy</span><span class="p">(</span><span class="n">test_data_loader</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
<span class="n">res_own_true</span><span class="p">,</span> <span class="n">res_own_pred</span> <span class="o">=</span> <span class="n">get_res</span><span class="p">(</span><span class="n">test_data_loader</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># horizontal bar chart for better readability</span>
<span class="n">bar_vals</span> <span class="o">=</span> <span class="p">[</span><span class="n">res_own_acc</span><span class="p">]</span>
<span class="n">bar_labels</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'OWN'</span><span class="p">]</span>
<span class="k">for</span> <span class="n">model_name</span> <span class="ow">in</span> <span class="n">model_names</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">mode</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">'full'</span><span class="p">,</span> <span class="s1">'partial'</span><span class="p">]:</span>
        <span class="n">bar_vals</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">res</span><span class="p">[</span><span class="n">model_name</span><span class="p">][</span><span class="n">mode</span><span class="p">][</span><span class="s1">'acc'</span><span class="p">])</span>
        <span class="n">bar_labels</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">model_name</span> <span class="o">+</span> <span class="s1">'_'</span> <span class="o">+</span> <span class="n">mode</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">barh</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">models</span><span class="p">)</span><span class="o">*</span><span class="mi">2</span><span class="o">+</span><span class="mi">1</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">bar_vals</span><span class="p">)</span> <span class="o">*</span> <span class="mi">100</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">'mediumseagreen'</span><span class="p">,</span> <span class="n">ec</span><span class="o">=</span><span class="s1">'k'</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">models</span><span class="p">)</span><span class="o">*</span><span class="mi">2</span><span class="o">+</span><span class="mi">1</span><span class="p">),</span> <span class="n">labels</span><span class="o">=</span><span class="n">bar_labels</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Accuracy'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Models'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Models accuracy'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">101</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[ ]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>(0.0, 101.0)</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedImage jp-OutputArea-output" tabindex="0">
<img alt="No description has been provided for this image" class="" src="data:image/png;base64,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"/>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">for</span> <span class="n">model_name</span><span class="p">,</span> <span class="n">acc</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">bar_labels</span><span class="p">,</span> <span class="n">bar_vals</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">model_name</span><span class="o">+</span><span class="s1">':'</span><span class="p">,</span> <span class="n">acc</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>OWN: 0.8431999683380127
EfficientNet_full: 0.8554999828338623
EfficientNet_partial: 0.45989999175071716
RegNet_full: 0.7888999581336975
RegNet_partial: 0.35259997844696045
ShuffleNetV2_full: 0.755899965763092
ShuffleNetV2_partial: 0.4756999909877777
MobileNetV3_full: 0.755899965763092
MobileNetV3_partial: 0.33719998598098755
</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">'Model name:'</span><span class="p">,</span> <span class="n">bar_labels</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">bar_vals</span><span class="p">)]</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">'_'</span><span class="p">)[</span><span class="mi">0</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'</span><span class="se">\t</span><span class="s1">Mode:'</span><span class="p">,</span> <span class="n">bar_labels</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">bar_vals</span><span class="p">)]</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">'_'</span><span class="p">)[</span><span class="mi">1</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'</span><span class="se">\t</span><span class="s1">Weights: model_weights'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'</span><span class="se">\t</span><span class="s1">Params:'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'</span><span class="se">\t\t</span><span class="s1">epochs = 100,</span><span class="se">\n\t\t</span><span class="s1">lr = 0.1,</span><span class="se">\n\t\t</span><span class="s1">momentum = 0.9,</span><span class="se">\n\t\t</span><span class="s1">weight_decay = 5e-4,</span><span class="se">\n\t\t</span><span class="s1">loss = CrossEntropyLoss,</span><span class="se">\n\t\t</span><span class="s1">optimizer = SGD,</span><span class="se">\n\t\t</span><span class="s1">scheduler = CosineAnnealingLR,</span><span class="se">\n\t\t</span><span class="s1">device = cuda'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'</span><span class="se">\t</span><span class="s1">Accuracy:'</span><span class="p">,</span> <span class="nb">max</span><span class="p">(</span><span class="n">bar_vals</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Model name: EfficientNet
	Mode: full
	Weights: model_weights
	Params:
		epochs = 100,
		lr = 0.1,
		momentum = 0.9,
		weight_decay = 5e-4,
		loss = CrossEntropyLoss,
		optimizer = SGD,
		scheduler = CosineAnnealingLR,
		device = cuda
	Accuracy: 0.8554999828338623
</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">get_metrics</span><span class="p">(</span><span class="n">res</span><span class="p">[</span><span class="s1">'EfficientNet'</span><span class="p">][</span><span class="s1">'full'</span><span class="p">][</span><span class="s1">'true'</span><span class="p">],</span> <span class="n">res</span><span class="p">[</span><span class="s1">'EfficientNet'</span><span class="p">][</span><span class="s1">'full'</span><span class="p">][</span><span class="s1">'pred'</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Classification Report

              precision    recall  f1-score   support

           0       0.84      0.86      0.85      1000
           1       0.91      0.93      0.92      1000
           2       0.85      0.78      0.81      1000
           3       0.75      0.70      0.73      1000
           4       0.83      0.86      0.85      1000
           5       0.77      0.81      0.79      1000
           6       0.87      0.91      0.89      1000
           7       0.89      0.89      0.89      1000
           8       0.93      0.90      0.92      1000
           9       0.91      0.90      0.91      1000

    accuracy                           0.86     10000
   macro avg       0.86      0.86      0.86     10000
weighted avg       0.86      0.86      0.86     10000

Roc auc scores:
	 0 : 0.9220555555555556
	 1 : 0.9595
	 2 : 0.8842222222222222
	 3 : 0.8388888888888889
	 4 : 0.9227222222222222
	 5 : 0.8925000000000001
	 6 : 0.9469444444444445
	 7 : 0.9371111111111112
	 8 : 0.9481666666666666
	 9 : 0.945111111111111
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedImage jp-OutputArea-output" tabindex="0">
<img alt="No description has been provided for this image" class="" src="data:image/png;base64,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"/>
</div>
</div>
</div>
</div>
</div>
</main>
</body>
</html>

digraph {
	graph [size="221.25,221.25"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	2655240243536 [label="
 (128, 10)" fillcolor=darkolivegreen1]
	2646243288800 [label=AddmmBackward0]
	2646243286016 -> 2646243288800
	2646239193872 [label="fc.bias
 (10)" fillcolor=lightblue]
	2646239193872 -> 2646243286016
	2646243286016 [label=AccumulateGrad]
	2646243285824 -> 2646243288800
	2646243285824 [label=ViewBackward0]
	2646243284432 -> 2646243285824
	2646243284432 [label=MeanBackward1]
	2646243288224 -> 2646243284432
	2646243288224 [label=ReluBackward0]
	2646243288752 -> 2646243288224
	2646243288752 [label=AddBackward0]
	2646243288176 -> 2646243288752
	2646243288176 [label=ReluBackward0]
	2646243288704 -> 2646243288176
	2646243288704 [label=AddBackward0]
	2646243288896 -> 2646243288704
	2646243288896 [label=ReluBackward0]
	2646243289040 -> 2646243288896
	2646243289040 [label=AddBackward0]
	2646243289280 -> 2646243289040
	2646243289280 [label=ReluBackward0]
	2646243289424 -> 2646243289280
	2646243289424 [label=AddBackward0]
	2646243289520 -> 2646243289424
	2646243289520 [label=ReluBackward0]
	2646243289664 -> 2646243289520
	2646243289664 [label=AddBackward0]
	2646243289760 -> 2646243289664
	2646243289760 [label=ReluBackward0]
	2646243289904 -> 2646243289760
	2646243289904 [label=AddBackward0]
	2646243290000 -> 2646243289904
	2646243290000 [label=NativeBatchNormBackward0]
	2646243290144 -> 2646243290000
	2646243290144 [label=ConvolutionBackward0]
	2646243290336 -> 2646243290144
	2646243290336 [label=ReluBackward0]
	2646243290480 -> 2646243290336
	2646243290480 [label=AddBackward0]
	2646243290576 -> 2646243290480
	2646243290576 [label=ReluBackward0]
	2646243290720 -> 2646243290576
	2646243290720 [label=AddBackward0]
	2646243290816 -> 2646243290720
	2646243290816 [label=ReluBackward0]
	2646243290960 -> 2646243290816
	2646243290960 [label=AddBackward0]
	2646243291056 -> 2646243290960
	2646243291056 [label=ReluBackward0]
	2646243291200 -> 2646243291056
	2646243291200 [label=AddBackward0]
	2646243291296 -> 2646243291200
	2646243291296 [label=ReluBackward0]
	2646243291440 -> 2646243291296
	2646243291440 [label=AddBackward0]
	2646243291536 -> 2646243291440
	2646243291536 [label=ReluBackward0]
	2646243291680 -> 2646243291536
	2646243291680 [label=AddBackward0]
	2646243291776 -> 2646243291680
	2646243291776 [label=NativeBatchNormBackward0]
	2646243291920 -> 2646243291776
	2646243291920 [label=ConvolutionBackward0]
	2646243292112 -> 2646243291920
	2646243292112 [label=ReluBackward0]
	2646243292256 -> 2646243292112
	2646243292256 [label=AddBackward0]
	2646243292352 -> 2646243292256
	2646243292352 [label=ReluBackward0]
	2646243292544 -> 2646243292352
	2646243292544 [label=AddBackward0]
	2646243292640 -> 2646243292544
	2646243292640 [label=ReluBackward0]
	2646243292784 -> 2646243292640
	2646243292784 [label=AddBackward0]
	2646243292880 -> 2646243292784
	2646243292880 [label=NativeBatchNormBackward0]
	2646243293024 -> 2646243292880
	2646243293024 [label=ConvolutionBackward0]
	2646243293216 -> 2646243293024
	2646243293216 [label=ReluBackward0]
	2646243293360 -> 2646243293216
	2646243293360 [label=AddBackward0]
	2646243293456 -> 2646243293360
	2646243293456 [label=NativeBatchNormBackward0]
	2646243293600 -> 2646243293456
	2646243293600 [label=ConvolutionBackward0]
	2646243293792 -> 2646243293600
	2646243293792 [label=ReluBackward0]
	2646243293936 -> 2646243293792
	2646243293936 [label=NativeBatchNormBackward0]
	2646243294032 -> 2646243293936
	2646243294032 [label=ConvolutionBackward0]
	2646243294224 -> 2646243294032
	2646239274032 [label="stem.0.weight
 (32, 3, 3, 3)" fillcolor=lightblue]
	2646239274032 -> 2646243294224
	2646243294224 [label=AccumulateGrad]
	2646243293984 -> 2646243293936
	2646239278112 [label="stem.1.weight
 (32)" fillcolor=lightblue]
	2646239278112 -> 2646243293984
	2646243293984 [label=AccumulateGrad]
	2646243293840 -> 2646243293936
	2646239267152 [label="stem.1.bias
 (32)" fillcolor=lightblue]
	2646239267152 -> 2646243293840
	2646243293840 [label=AccumulateGrad]
	2646243293744 -> 2646243293600
	2646239016128 [label="trunk_output.block1.block1-0.proj.0.weight
 (48, 32, 1, 1)" fillcolor=lightblue]
	2646239016128 -> 2646243293744
	2646243293744 [label=AccumulateGrad]
	2646243293552 -> 2646243293456
	2655237271968 [label="trunk_output.block1.block1-0.proj.1.weight
 (48)" fillcolor=lightblue]
	2655237271968 -> 2646243293552
	2646243293552 [label=AccumulateGrad]
	2646243293504 -> 2646243293456
	2646239003008 [label="trunk_output.block1.block1-0.proj.1.bias
 (48)" fillcolor=lightblue]
	2646239003008 -> 2646243293504
	2646243293504 [label=AccumulateGrad]
	2646243293408 -> 2646243293360
	2646243293408 [label=NativeBatchNormBackward0]
	2646243294176 -> 2646243293408
	2646243294176 [label=ConvolutionBackward0]
	2646243294272 -> 2646243294176
	2646243294272 [label=MulBackward0]
	2646243294416 -> 2646243294272
	2646243294416 [label=SigmoidBackward0]
	2646243294560 -> 2646243294416
	2646243294560 [label=ConvolutionBackward0]
	2646243294656 -> 2646243294560
	2646243294656 [label=ReluBackward0]
	2646243294848 -> 2646243294656
	2646243294848 [label=ConvolutionBackward0]
	2646243294944 -> 2646243294848
	2646243294944 [label=MeanBackward1]
	2646243294368 -> 2646243294944
	2646243294368 [label=ReluBackward0]
	2646243295184 -> 2646243294368
	2646243295184 [label=NativeBatchNormBackward0]
	2646243295088 -> 2646243295184
	2646243295088 [label=ConvolutionBackward0]
	2655240945968 -> 2646243295088
	2655240945968 [label=ReluBackward0]
	2655240946112 -> 2655240945968
	2655240946112 [label=NativeBatchNormBackward0]
	2655240946208 -> 2655240946112
	2655240946208 [label=ConvolutionBackward0]
	2646243293792 -> 2655240946208
	2655240946400 -> 2655240946208
	2646237499920 [label="trunk_output.block1.block1-0.f.a.0.weight
 (48, 32, 1, 1)" fillcolor=lightblue]
	2646237499920 -> 2655240946400
	2655240946400 [label=AccumulateGrad]
	2655240946160 -> 2655240946112
	2646237920880 [label="trunk_output.block1.block1-0.f.a.1.weight
 (48)" fillcolor=lightblue]
	2646237920880 -> 2655240946160
	2655240946160 [label=AccumulateGrad]
	2655240946016 -> 2655240946112
	2646237909200 [label="trunk_output.block1.block1-0.f.a.1.bias
 (48)" fillcolor=lightblue]
	2646237909200 -> 2655240946016
	2655240946016 [label=AccumulateGrad]
	2655240945920 -> 2646243295088
	2646237918880 [label="trunk_output.block1.block1-0.f.b.0.weight
 (48, 8, 3, 3)" fillcolor=lightblue]
	2646237918880 -> 2655240945920
	2655240945920 [label=AccumulateGrad]
	2655240945776 -> 2646243295184
	2646237916480 [label="trunk_output.block1.block1-0.f.b.1.weight
 (48)" fillcolor=lightblue]
	2646237916480 -> 2655240945776
	2655240945776 [label=AccumulateGrad]
	2655240945728 -> 2646243295184
	2646237911120 [label="trunk_output.block1.block1-0.f.b.1.bias
 (48)" fillcolor=lightblue]
	2646237911120 -> 2655240945728
	2655240945728 [label=AccumulateGrad]
	2646243294896 -> 2646243294848
	2646237905760 [label="trunk_output.block1.block1-0.f.se.fc1.weight
 (8, 48, 1, 1)" fillcolor=lightblue]
	2646237905760 -> 2646243294896
	2646243294896 [label=AccumulateGrad]
	2646243294752 -> 2646243294848
	2646237916960 [label="trunk_output.block1.block1-0.f.se.fc1.bias
 (8)" fillcolor=lightblue]
	2646237916960 -> 2646243294752
	2646243294752 [label=AccumulateGrad]
	2646243294608 -> 2646243294560
	2646237906080 [label="trunk_output.block1.block1-0.f.se.fc2.weight
 (48, 8, 1, 1)" fillcolor=lightblue]
	2646237906080 -> 2646243294608
	2646243294608 [label=AccumulateGrad]
	2646243294464 -> 2646243294560
	2646237905600 [label="trunk_output.block1.block1-0.f.se.fc2.bias
 (48)" fillcolor=lightblue]
	2646237905600 -> 2646243294464
	2646243294464 [label=AccumulateGrad]
	2646243294368 -> 2646243294272
	2646243294320 -> 2646243294176
	2646237906400 [label="trunk_output.block1.block1-0.f.c.0.weight
 (48, 48, 1, 1)" fillcolor=lightblue]
	2646237906400 -> 2646243294320
	2646243294320 [label=AccumulateGrad]
	2646243293696 -> 2646243293408
	2646237905680 [label="trunk_output.block1.block1-0.f.c.1.weight
 (48)" fillcolor=lightblue]
	2646237905680 -> 2646243293696
	2646243293696 [label=AccumulateGrad]
	2646243293648 -> 2646243293408
	2646237908080 [label="trunk_output.block1.block1-0.f.c.1.bias
 (48)" fillcolor=lightblue]
	2646237908080 -> 2646243293648
	2646243293648 [label=AccumulateGrad]
	2646243293168 -> 2646243293024
	2646237502080 [label="trunk_output.block2.block2-0.proj.0.weight
 (104, 48, 1, 1)" fillcolor=lightblue]
	2646237502080 -> 2646243293168
	2646243293168 [label=AccumulateGrad]
	2646243292976 -> 2646243292880
	2646239011648 [label="trunk_output.block2.block2-0.proj.1.weight
 (104)" fillcolor=lightblue]
	2646239011648 -> 2646243292976
	2646243292976 [label=AccumulateGrad]
	2646243292928 -> 2646243292880
	2646239016848 [label="trunk_output.block2.block2-0.proj.1.bias
 (104)" fillcolor=lightblue]
	2646239016848 -> 2646243292928
	2646243292928 [label=AccumulateGrad]
	2646243292832 -> 2646243292784
	2646243292832 [label=NativeBatchNormBackward0]
	2646243294080 -> 2646243292832
	2646243294080 [label=ConvolutionBackward0]
	2646243294704 -> 2646243294080
	2646243294704 [label=MulBackward0]
	2646243294800 -> 2646243294704
	2646243294800 [label=SigmoidBackward0]
	2646243295040 -> 2646243294800
	2646243295040 [label=ConvolutionBackward0]
	2646243294992 -> 2646243295040
	2646243294992 [label=ReluBackward0]
	2655240946496 -> 2646243294992
	2655240946496 [label=ConvolutionBackward0]
	2655240946304 -> 2655240946496
	2655240946304 [label=MeanBackward1]
	2646243294128 -> 2655240946304
	2646243294128 [label=ReluBackward0]
	2655240946736 -> 2646243294128
	2655240946736 [label=NativeBatchNormBackward0]
	2655240946832 -> 2655240946736
	2655240946832 [label=ConvolutionBackward0]
	2655240947024 -> 2655240946832
	2655240947024 [label=ReluBackward0]
	2655240947168 -> 2655240947024
	2655240947168 [label=NativeBatchNormBackward0]
	2655240947264 -> 2655240947168
	2655240947264 [label=ConvolutionBackward0]
	2646243293216 -> 2655240947264
	2655240947456 -> 2655240947264
	2646237915280 [label="trunk_output.block2.block2-0.f.a.0.weight
 (104, 48, 1, 1)" fillcolor=lightblue]
	2646237915280 -> 2655240947456
	2655240947456 [label=AccumulateGrad]
	2655240947216 -> 2655240947168
	2646237915760 [label="trunk_output.block2.block2-0.f.a.1.weight
 (104)" fillcolor=lightblue]
	2646237915760 -> 2655240947216
	2655240947216 [label=AccumulateGrad]
	2655240947072 -> 2655240947168
	2646237915840 [label="trunk_output.block2.block2-0.f.a.1.bias
 (104)" fillcolor=lightblue]
	2646237915840 -> 2655240947072
	2655240947072 [label=AccumulateGrad]
	2655240946976 -> 2655240946832
	2646237917280 [label="trunk_output.block2.block2-0.f.b.0.weight
 (104, 8, 3, 3)" fillcolor=lightblue]
	2646237917280 -> 2655240946976
	2655240946976 [label=AccumulateGrad]
	2655240946784 -> 2655240946736
	2646237918080 [label="trunk_output.block2.block2-0.f.b.1.weight
 (104)" fillcolor=lightblue]
	2646237918080 -> 2655240946784
	2655240946784 [label=AccumulateGrad]
	2655240946640 -> 2655240946736
	2646237912480 [label="trunk_output.block2.block2-0.f.b.1.bias
 (104)" fillcolor=lightblue]
	2646237912480 -> 2655240946640
	2655240946640 [label=AccumulateGrad]
	2655240946448 -> 2655240946496
	2646237920560 [label="trunk_output.block2.block2-0.f.se.fc1.weight
 (12, 104, 1, 1)" fillcolor=lightblue]
	2646237920560 -> 2655240946448
	2655240946448 [label=AccumulateGrad]
	2655240946256 -> 2655240946496
	2646237908720 [label="trunk_output.block2.block2-0.f.se.fc1.bias
 (12)" fillcolor=lightblue]
	2646237908720 -> 2655240946256
	2655240946256 [label=AccumulateGrad]
	2655240945872 -> 2646243295040
	2646237907120 [label="trunk_output.block2.block2-0.f.se.fc2.weight
 (104, 12, 1, 1)" fillcolor=lightblue]
	2646237907120 -> 2655240945872
	2655240945872 [label=AccumulateGrad]
	2655240945824 -> 2646243295040
	2646237914480 [label="trunk_output.block2.block2-0.f.se.fc2.bias
 (104)" fillcolor=lightblue]
	2646237914480 -> 2655240945824
	2655240945824 [label=AccumulateGrad]
	2646243294128 -> 2646243294704
	2646243293888 -> 2646243294080
	2646237908240 [label="trunk_output.block2.block2-0.f.c.0.weight
 (104, 104, 1, 1)" fillcolor=lightblue]
	2646237908240 -> 2646243293888
	2646243293888 [label=AccumulateGrad]
	2646243293120 -> 2646243292832
	2646237905040 [label="trunk_output.block2.block2-0.f.c.1.weight
 (104)" fillcolor=lightblue]
	2646237905040 -> 2646243293120
	2646243293120 [label=AccumulateGrad]
	2646243293072 -> 2646243292832
	2646237906640 [label="trunk_output.block2.block2-0.f.c.1.bias
 (104)" fillcolor=lightblue]
	2646237906640 -> 2646243293072
	2646243293072 [label=AccumulateGrad]
	2646243292592 -> 2646243292544
	2646243292592 [label=NativeBatchNormBackward0]
	2646243293264 -> 2646243292592
	2646243293264 [label=ConvolutionBackward0]
	2646243294512 -> 2646243293264
	2646243294512 [label=MulBackward0]
	2655240946688 -> 2646243294512
	2655240946688 [label=SigmoidBackward0]
	2655240946928 -> 2655240946688
	2655240946928 [label=ConvolutionBackward0]
	2655240947312 -> 2655240946928
	2655240947312 [label=ReluBackward0]
	2655240947360 -> 2655240947312
	2655240947360 [label=ConvolutionBackward0]
	2655240947648 -> 2655240947360
	2655240947648 [label=MeanBackward1]
	2655240946544 -> 2655240947648
	2655240946544 [label=ReluBackward0]
	2655240947888 -> 2655240946544
	2655240947888 [label=NativeBatchNormBackward0]
	2655240947984 -> 2655240947888
	2655240947984 [label=ConvolutionBackward0]
	2655240948176 -> 2655240947984
	2655240948176 [label=ReluBackward0]
	2655240948320 -> 2655240948176
	2655240948320 [label=NativeBatchNormBackward0]
	2655240948416 -> 2655240948320
	2655240948416 [label=ConvolutionBackward0]
	2646243292640 -> 2655240948416
	2655240948608 -> 2655240948416
	2646237920400 [label="trunk_output.block2.block2-1.f.a.0.weight
 (104, 104, 1, 1)" fillcolor=lightblue]
	2646237920400 -> 2655240948608
	2655240948608 [label=AccumulateGrad]
	2655240948368 -> 2655240948320
	2646237912160 [label="trunk_output.block2.block2-1.f.a.1.weight
 (104)" fillcolor=lightblue]
	2646237912160 -> 2655240948368
	2655240948368 [label=AccumulateGrad]
	2655240948224 -> 2655240948320
	2646237904960 [label="trunk_output.block2.block2-1.f.a.1.bias
 (104)" fillcolor=lightblue]
	2646237904960 -> 2655240948224
	2655240948224 [label=AccumulateGrad]
	2655240948128 -> 2655240947984
	2646237911520 [label="trunk_output.block2.block2-1.f.b.0.weight
 (104, 8, 3, 3)" fillcolor=lightblue]
	2646237911520 -> 2655240948128
	2655240948128 [label=AccumulateGrad]
	2655240947936 -> 2655240947888
	2646237916640 [label="trunk_output.block2.block2-1.f.b.1.weight
 (104)" fillcolor=lightblue]
	2646237916640 -> 2655240947936
	2655240947936 [label=AccumulateGrad]
	2655240947792 -> 2655240947888
	2646237913360 [label="trunk_output.block2.block2-1.f.b.1.bias
 (104)" fillcolor=lightblue]
	2646237913360 -> 2655240947792
	2655240947792 [label=AccumulateGrad]
	2655240947600 -> 2655240947360
	2646237921040 [label="trunk_output.block2.block2-1.f.se.fc1.weight
 (26, 104, 1, 1)" fillcolor=lightblue]
	2646237921040 -> 2655240947600
	2655240947600 [label=AccumulateGrad]
	2655240947552 -> 2655240947360
	2646237914720 [label="trunk_output.block2.block2-1.f.se.fc1.bias
 (26)" fillcolor=lightblue]
	2646237914720 -> 2655240947552
	2655240947552 [label=AccumulateGrad]
	2655240947408 -> 2655240946928
	2646237919440 [label="trunk_output.block2.block2-1.f.se.fc2.weight
 (104, 26, 1, 1)" fillcolor=lightblue]
	2646237919440 -> 2655240947408
	2655240947408 [label=AccumulateGrad]
	2655240946592 -> 2655240946928
	2646237907040 [label="trunk_output.block2.block2-1.f.se.fc2.bias
 (104)" fillcolor=lightblue]
	2646237907040 -> 2655240946592
	2655240946592 [label=AccumulateGrad]
	2655240946544 -> 2646243294512
	2646243295136 -> 2646243293264
	2646237921120 [label="trunk_output.block2.block2-1.f.c.0.weight
 (104, 104, 1, 1)" fillcolor=lightblue]
	2646237921120 -> 2646243295136
	2646243295136 [label=AccumulateGrad]
	2646243292688 -> 2646243292592
	2646237911200 [label="trunk_output.block2.block2-1.f.c.1.weight
 (104)" fillcolor=lightblue]
	2646237911200 -> 2646243292688
	2646243292688 [label=AccumulateGrad]
	2646243292736 -> 2646243292592
	2646237919600 [label="trunk_output.block2.block2-1.f.c.1.bias
 (104)" fillcolor=lightblue]
	2646237919600 -> 2646243292736
	2646243292736 [label=AccumulateGrad]
	2646243292304 -> 2646243292256
	2646243292304 [label=NativeBatchNormBackward0]
	2646243293312 -> 2646243292304
	2646243293312 [label=ConvolutionBackward0]
	2655240946064 -> 2646243293312
	2655240946064 [label=MulBackward0]
	2655240947840 -> 2655240946064
	2655240947840 [label=SigmoidBackward0]
	2655240948080 -> 2655240947840
	2655240948080 [label=ConvolutionBackward0]
	2655240948464 -> 2655240948080
	2655240948464 [label=ReluBackward0]
	2655240948512 -> 2655240948464
	2655240948512 [label=ConvolutionBackward0]
	2655240948800 -> 2655240948512
	2655240948800 [label=MeanBackward1]
	2655240947696 -> 2655240948800
	2655240947696 [label=ReluBackward0]
	2655240949040 -> 2655240947696
	2655240949040 [label=NativeBatchNormBackward0]
	2655240949136 -> 2655240949040
	2655240949136 [label=ConvolutionBackward0]
	2655240949328 -> 2655240949136
	2655240949328 [label=ReluBackward0]
	2655240949472 -> 2655240949328
	2655240949472 [label=NativeBatchNormBackward0]
	2655240949568 -> 2655240949472
	2655240949568 [label=ConvolutionBackward0]
	2646243292352 -> 2655240949568
	2655240949760 -> 2655240949568
	2646237905280 [label="trunk_output.block2.block2-2.f.a.0.weight
 (104, 104, 1, 1)" fillcolor=lightblue]
	2646237905280 -> 2655240949760
	2655240949760 [label=AccumulateGrad]
	2655240949520 -> 2655240949472
	2646237909920 [label="trunk_output.block2.block2-2.f.a.1.weight
 (104)" fillcolor=lightblue]
	2646237909920 -> 2655240949520
	2655240949520 [label=AccumulateGrad]
	2655240949376 -> 2655240949472
	2646237914400 [label="trunk_output.block2.block2-2.f.a.1.bias
 (104)" fillcolor=lightblue]
	2646237914400 -> 2655240949376
	2655240949376 [label=AccumulateGrad]
	2655240949280 -> 2655240949136
	2646237919200 [label="trunk_output.block2.block2-2.f.b.0.weight
 (104, 8, 3, 3)" fillcolor=lightblue]
	2646237919200 -> 2655240949280
	2655240949280 [label=AccumulateGrad]
	2655240949088 -> 2655240949040
	2646237907360 [label="trunk_output.block2.block2-2.f.b.1.weight
 (104)" fillcolor=lightblue]
	2646237907360 -> 2655240949088
	2655240949088 [label=AccumulateGrad]
	2655240948944 -> 2655240949040
	2646237907520 [label="trunk_output.block2.block2-2.f.b.1.bias
 (104)" fillcolor=lightblue]
	2646237907520 -> 2655240948944
	2655240948944 [label=AccumulateGrad]
	2655240948752 -> 2655240948512
	2646237910640 [label="trunk_output.block2.block2-2.f.se.fc1.weight
 (26, 104, 1, 1)" fillcolor=lightblue]
	2646237910640 -> 2655240948752
	2655240948752 [label=AccumulateGrad]
	2655240948704 -> 2655240948512
	2655238718624 [label="trunk_output.block2.block2-2.f.se.fc1.bias
 (26)" fillcolor=lightblue]
	2655238718624 -> 2655240948704
	2655240948704 [label=AccumulateGrad]
	2655240948560 -> 2655240948080
	2646237916000 [label="trunk_output.block2.block2-2.f.se.fc2.weight
 (104, 26, 1, 1)" fillcolor=lightblue]
	2646237916000 -> 2655240948560
	2655240948560 [label=AccumulateGrad]
	2655240947744 -> 2655240948080
	2655238730464 [label="trunk_output.block2.block2-2.f.se.fc2.bias
 (104)" fillcolor=lightblue]
	2655238730464 -> 2655240947744
	2655240947744 [label=AccumulateGrad]
	2655240947696 -> 2655240946064
	2655240946880 -> 2646243293312
	2655238731024 [label="trunk_output.block2.block2-2.f.c.0.weight
 (104, 104, 1, 1)" fillcolor=lightblue]
	2655238731024 -> 2655240946880
	2655240946880 [label=AccumulateGrad]
	2646243292448 -> 2646243292304
	2655238732224 [label="trunk_output.block2.block2-2.f.c.1.weight
 (104)" fillcolor=lightblue]
	2655238732224 -> 2646243292448
	2646243292448 [label=AccumulateGrad]
	2646243292496 -> 2646243292304
	2655238723984 [label="trunk_output.block2.block2-2.f.c.1.bias
 (104)" fillcolor=lightblue]
	2655238723984 -> 2646243292496
	2646243292496 [label=AccumulateGrad]
	2646243292064 -> 2646243291920
	2646237914880 [label="trunk_output.block3.block3-0.proj.0.weight
 (208, 104, 1, 1)" fillcolor=lightblue]
	2646237914880 -> 2646243292064
	2646243292064 [label=AccumulateGrad]
	2646243291872 -> 2646243291776
	2646237911280 [label="trunk_output.block3.block3-0.proj.1.weight
 (208)" fillcolor=lightblue]
	2646237911280 -> 2646243291872
	2646243291872 [label=AccumulateGrad]
	2646243291824 -> 2646243291776
	2646237920000 [label="trunk_output.block3.block3-0.proj.1.bias
 (208)" fillcolor=lightblue]
	2646237920000 -> 2646243291824
	2646243291824 [label=AccumulateGrad]
	2646243291728 -> 2646243291680
	2646243291728 [label=NativeBatchNormBackward0]
	2646243292160 -> 2646243291728
	2646243292160 [label=ConvolutionBackward0]
	2655240948272 -> 2646243292160
	2655240948272 [label=MulBackward0]
	2655240948656 -> 2655240948272
	2655240948656 [label=SigmoidBackward0]
	2655240948896 -> 2655240948656
	2655240948896 [label=ConvolutionBackward0]
	2655240949232 -> 2655240948896
	2655240949232 [label=ReluBackward0]
	2655240949856 -> 2655240949232
	2655240949856 [label=ConvolutionBackward0]
	2655240949664 -> 2655240949856
	2655240949664 [label=MeanBackward1]
	2655240947504 -> 2655240949664
	2655240947504 [label=ReluBackward0]
	2655240950096 -> 2655240947504
	2655240950096 [label=NativeBatchNormBackward0]
	2655240950192 -> 2655240950096
	2655240950192 [label=ConvolutionBackward0]
	2655240950384 -> 2655240950192
	2655240950384 [label=ReluBackward0]
	2655240950528 -> 2655240950384
	2655240950528 [label=NativeBatchNormBackward0]
	2655240950624 -> 2655240950528
	2655240950624 [label=ConvolutionBackward0]
	2646243292112 -> 2655240950624
	2655240950816 -> 2655240950624
	2655238725104 [label="trunk_output.block3.block3-0.f.a.0.weight
 (208, 104, 1, 1)" fillcolor=lightblue]
	2655238725104 -> 2655240950816
	2655240950816 [label=AccumulateGrad]
	2655240950576 -> 2655240950528
	2655238722464 [label="trunk_output.block3.block3-0.f.a.1.weight
 (208)" fillcolor=lightblue]
	2655238722464 -> 2655240950576
	2655240950576 [label=AccumulateGrad]
	2655240950432 -> 2655240950528
	2655238718784 [label="trunk_output.block3.block3-0.f.a.1.bias
 (208)" fillcolor=lightblue]
	2655238718784 -> 2655240950432
	2655240950432 [label=AccumulateGrad]
	2655240950336 -> 2655240950192
	2655238732704 [label="trunk_output.block3.block3-0.f.b.0.weight
 (208, 8, 3, 3)" fillcolor=lightblue]
	2655238732704 -> 2655240950336
	2655240950336 [label=AccumulateGrad]
	2655240950144 -> 2655240950096
	2655240253216 [label="trunk_output.block3.block3-0.f.b.1.weight
 (208)" fillcolor=lightblue]
	2655240253216 -> 2655240950144
	2655240950144 [label=AccumulateGrad]
	2655240950000 -> 2655240950096
	2655240245776 [label="trunk_output.block3.block3-0.f.b.1.bias
 (208)" fillcolor=lightblue]
	2655240245776 -> 2655240950000
	2655240950000 [label=AccumulateGrad]
	2655240949808 -> 2655240949856
	2655238717824 [label="trunk_output.block3.block3-0.f.se.fc1.weight
 (26, 208, 1, 1)" fillcolor=lightblue]
	2655238717824 -> 2655240949808
	2655240949808 [label=AccumulateGrad]
	2655240949616 -> 2655240949856
	2646238741744 [label="trunk_output.block3.block3-0.f.se.fc1.bias
 (26)" fillcolor=lightblue]
	2646238741744 -> 2655240949616
	2655240949616 [label=AccumulateGrad]
	2655240949184 -> 2655240948896
	2646238746144 [label="trunk_output.block3.block3-0.f.se.fc2.weight
 (208, 26, 1, 1)" fillcolor=lightblue]
	2646238746144 -> 2655240949184
	2655240949184 [label=AccumulateGrad]
	2655240948848 -> 2655240948896
	2646238745744 [label="trunk_output.block3.block3-0.f.se.fc2.bias
 (208)" fillcolor=lightblue]
	2646238745744 -> 2655240948848
	2655240948848 [label=AccumulateGrad]
	2655240947504 -> 2655240948272
	2655240947120 -> 2646243292160
	2646238743984 [label="trunk_output.block3.block3-0.f.c.0.weight
 (208, 208, 1, 1)" fillcolor=lightblue]
	2646238743984 -> 2655240947120
	2655240947120 [label=AccumulateGrad]
	2646243292016 -> 2646243291728
	2646238751104 [label="trunk_output.block3.block3-0.f.c.1.weight
 (208)" fillcolor=lightblue]
	2646238751104 -> 2646243292016
	2646243292016 [label=AccumulateGrad]
	2646243291968 -> 2646243291728
	2646238743424 [label="trunk_output.block3.block3-0.f.c.1.bias
 (208)" fillcolor=lightblue]
	2646238743424 -> 2646243291968
	2646243291968 [label=AccumulateGrad]
	2646243291488 -> 2646243291440
	2646243291488 [label=NativeBatchNormBackward0]
	2646243292208 -> 2646243291488
	2646243292208 [label=ConvolutionBackward0]
	2655240948032 -> 2646243292208
	2655240948032 [label=MulBackward0]
	2655240950048 -> 2655240948032
	2655240950048 [label=SigmoidBackward0]
	2655240950288 -> 2655240950048
	2655240950288 [label=ConvolutionBackward0]
	2655240950672 -> 2655240950288
	2655240950672 [label=ReluBackward0]
	2655240950720 -> 2655240950672
	2655240950720 [label=ConvolutionBackward0]
	2655240951008 -> 2655240950720
	2655240951008 [label=MeanBackward1]
	2655240949904 -> 2655240951008
	2655240949904 [label=ReluBackward0]
	2655240951248 -> 2655240949904
	2655240951248 [label=NativeBatchNormBackward0]
	2655240951344 -> 2655240951248
	2655240951344 [label=ConvolutionBackward0]
	2655240951536 -> 2655240951344
	2655240951536 [label=ReluBackward0]
	2655240951680 -> 2655240951536
	2655240951680 [label=NativeBatchNormBackward0]
	2655240951776 -> 2655240951680
	2655240951776 [label=ConvolutionBackward0]
	2646243291536 -> 2655240951776
	2655240951968 -> 2655240951776
	2646238746304 [label="trunk_output.block3.block3-1.f.a.0.weight
 (208, 208, 1, 1)" fillcolor=lightblue]
	2646238746304 -> 2655240951968
	2655240951968 [label=AccumulateGrad]
	2655240951728 -> 2655240951680
	2646238747824 [label="trunk_output.block3.block3-1.f.a.1.weight
 (208)" fillcolor=lightblue]
	2646238747824 -> 2655240951728
	2655240951728 [label=AccumulateGrad]
	2655240951584 -> 2655240951680
	2646238747344 [label="trunk_output.block3.block3-1.f.a.1.bias
 (208)" fillcolor=lightblue]
	2646238747344 -> 2655240951584
	2655240951584 [label=AccumulateGrad]
	2655240951488 -> 2655240951344
	2646238753504 [label="trunk_output.block3.block3-1.f.b.0.weight
 (208, 8, 3, 3)" fillcolor=lightblue]
	2646238753504 -> 2655240951488
	2655240951488 [label=AccumulateGrad]
	2655240951296 -> 2655240951248
	2646238756544 [label="trunk_output.block3.block3-1.f.b.1.weight
 (208)" fillcolor=lightblue]
	2646238756544 -> 2655240951296
	2655240951296 [label=AccumulateGrad]
	2655240951152 -> 2655240951248
	2646238741904 [label="trunk_output.block3.block3-1.f.b.1.bias
 (208)" fillcolor=lightblue]
	2646238741904 -> 2655240951152
	2655240951152 [label=AccumulateGrad]
	2655240950960 -> 2655240950720
	2646238744064 [label="trunk_output.block3.block3-1.f.se.fc1.weight
 (52, 208, 1, 1)" fillcolor=lightblue]
	2646238744064 -> 2655240950960
	2655240950960 [label=AccumulateGrad]
	2655240950912 -> 2655240950720
	2646238741344 [label="trunk_output.block3.block3-1.f.se.fc1.bias
 (52)" fillcolor=lightblue]
	2646238741344 -> 2655240950912
	2655240950912 [label=AccumulateGrad]
	2655240950768 -> 2655240950288
	2646238744384 [label="trunk_output.block3.block3-1.f.se.fc2.weight
 (208, 52, 1, 1)" fillcolor=lightblue]
	2646238744384 -> 2655240950768
	2655240950768 [label=AccumulateGrad]
	2655240949952 -> 2655240950288
	2646238741824 [label="trunk_output.block3.block3-1.f.se.fc2.bias
 (208)" fillcolor=lightblue]
	2646238741824 -> 2655240949952
	2655240949952 [label=AccumulateGrad]
	2655240949904 -> 2655240948032
	2655240948992 -> 2646243292208
	2646238756384 [label="trunk_output.block3.block3-1.f.c.0.weight
 (208, 208, 1, 1)" fillcolor=lightblue]
	2646238756384 -> 2655240948992
	2655240948992 [label=AccumulateGrad]
	2646243291584 -> 2646243291488
	2646238741504 [label="trunk_output.block3.block3-1.f.c.1.weight
 (208)" fillcolor=lightblue]
	2646238741504 -> 2646243291584
	2646243291584 [label=AccumulateGrad]
	2646243291632 -> 2646243291488
	2646238742864 [label="trunk_output.block3.block3-1.f.c.1.bias
 (208)" fillcolor=lightblue]
	2646238742864 -> 2646243291632
	2646243291632 [label=AccumulateGrad]
	2646243291248 -> 2646243291200
	2646243291248 [label=NativeBatchNormBackward0]
	2646243291344 -> 2646243291248
	2646243291344 [label=ConvolutionBackward0]
	2655240949424 -> 2646243291344
	2655240949424 [label=MulBackward0]
	2655240951200 -> 2655240949424
	2655240951200 [label=SigmoidBackward0]
	2655240951440 -> 2655240951200
	2655240951440 [label=ConvolutionBackward0]
	2655240951824 -> 2655240951440
	2655240951824 [label=ReluBackward0]
	2655240951872 -> 2655240951824
	2655240951872 [label=ConvolutionBackward0]
	2655240952160 -> 2655240951872
	2655240952160 [label=MeanBackward1]
	2655240951056 -> 2655240952160
	2655240951056 [label=ReluBackward0]
	2655240952400 -> 2655240951056
	2655240952400 [label=NativeBatchNormBackward0]
	2655240952496 -> 2655240952400
	2655240952496 [label=ConvolutionBackward0]
	2655240952688 -> 2655240952496
	2655240952688 [label=ReluBackward0]
	2655240952832 -> 2655240952688
	2655240952832 [label=NativeBatchNormBackward0]
	2655240952928 -> 2655240952832
	2655240952928 [label=ConvolutionBackward0]
	2646243291296 -> 2655240952928
	2655240953120 -> 2655240952928
	2646238748064 [label="trunk_output.block3.block3-2.f.a.0.weight
 (208, 208, 1, 1)" fillcolor=lightblue]
	2646238748064 -> 2655240953120
	2655240953120 [label=AccumulateGrad]
	2655240952880 -> 2655240952832
	2646238742544 [label="trunk_output.block3.block3-2.f.a.1.weight
 (208)" fillcolor=lightblue]
	2646238742544 -> 2655240952880
	2655240952880 [label=AccumulateGrad]
	2655240952736 -> 2655240952832
	2646238743664 [label="trunk_output.block3.block3-2.f.a.1.bias
 (208)" fillcolor=lightblue]
	2646238743664 -> 2655240952736
	2655240952736 [label=AccumulateGrad]
	2655240952640 -> 2655240952496
	2655235663696 [label="trunk_output.block3.block3-2.f.b.0.weight
 (208, 8, 3, 3)" fillcolor=lightblue]
	2655235663696 -> 2655240952640
	2655240952640 [label=AccumulateGrad]
	2655240952448 -> 2655240952400
	2646238748544 [label="trunk_output.block3.block3-2.f.b.1.weight
 (208)" fillcolor=lightblue]
	2646238748544 -> 2655240952448
	2655240952448 [label=AccumulateGrad]
	2655240952304 -> 2655240952400
	2646238750864 [label="trunk_output.block3.block3-2.f.b.1.bias
 (208)" fillcolor=lightblue]
	2646238750864 -> 2655240952304
	2655240952304 [label=AccumulateGrad]
	2655240952112 -> 2655240951872
	2646238754464 [label="trunk_output.block3.block3-2.f.se.fc1.weight
 (52, 208, 1, 1)" fillcolor=lightblue]
	2646238754464 -> 2655240952112
	2655240952112 [label=AccumulateGrad]
	2655240952064 -> 2655240951872
	2646238754624 [label="trunk_output.block3.block3-2.f.se.fc1.bias
 (52)" fillcolor=lightblue]
	2646238754624 -> 2655240952064
	2655240952064 [label=AccumulateGrad]
	2655240951920 -> 2655240951440
	2646238751024 [label="trunk_output.block3.block3-2.f.se.fc2.weight
 (208, 52, 1, 1)" fillcolor=lightblue]
	2646238751024 -> 2655240951920
	2655240951920 [label=AccumulateGrad]
	2655240951104 -> 2655240951440
	2646238753824 [label="trunk_output.block3.block3-2.f.se.fc2.bias
 (208)" fillcolor=lightblue]
	2646238753824 -> 2655240951104
	2655240951104 [label=AccumulateGrad]
	2655240951056 -> 2655240949424
	2655240950240 -> 2646243291344
	2646238751264 [label="trunk_output.block3.block3-2.f.c.0.weight
 (208, 208, 1, 1)" fillcolor=lightblue]
	2646238751264 -> 2655240950240
	2655240950240 [label=AccumulateGrad]
	2646243291392 -> 2646243291248
	2646238749664 [label="trunk_output.block3.block3-2.f.c.1.weight
 (208)" fillcolor=lightblue]
	2646238749664 -> 2646243291392
	2646243291392 [label=AccumulateGrad]
	2655240946352 -> 2646243291248
	2646238753344 [label="trunk_output.block3.block3-2.f.c.1.bias
 (208)" fillcolor=lightblue]
	2646238753344 -> 2655240946352
	2655240946352 [label=AccumulateGrad]
	2646243291008 -> 2646243290960
	2646243291008 [label=NativeBatchNormBackward0]
	2646243291104 -> 2646243291008
	2646243291104 [label=ConvolutionBackward0]
	2655240950864 -> 2646243291104
	2655240950864 [label=MulBackward0]
	2655240952352 -> 2655240950864
	2655240952352 [label=SigmoidBackward0]
	2655240952592 -> 2655240952352
	2655240952592 [label=ConvolutionBackward0]
	2655240952976 -> 2655240952592
	2655240952976 [label=ReluBackward0]
	2655240953024 -> 2655240952976
	2655240953024 [label=ConvolutionBackward0]
	2655240953312 -> 2655240953024
	2655240953312 [label=MeanBackward1]
	2655240952208 -> 2655240953312
	2655240952208 [label=ReluBackward0]
	2655240953552 -> 2655240952208
	2655240953552 [label=NativeBatchNormBackward0]
	2655240953648 -> 2655240953552
	2655240953648 [label=ConvolutionBackward0]
	2655240953840 -> 2655240953648
	2655240953840 [label=ReluBackward0]
	2655240953984 -> 2655240953840
	2655240953984 [label=NativeBatchNormBackward0]
	2655240954080 -> 2655240953984
	2655240954080 [label=ConvolutionBackward0]
	2646243291056 -> 2655240954080
	2655240954272 -> 2655240954080
	2646238755264 [label="trunk_output.block3.block3-3.f.a.0.weight
 (208, 208, 1, 1)" fillcolor=lightblue]
	2646238755264 -> 2655240954272
	2655240954272 [label=AccumulateGrad]
	2655240954032 -> 2655240953984
	2646238756304 [label="trunk_output.block3.block3-3.f.a.1.weight
 (208)" fillcolor=lightblue]
	2646238756304 -> 2655240954032
	2655240954032 [label=AccumulateGrad]
	2655240953888 -> 2655240953984
	2646238745984 [label="trunk_output.block3.block3-3.f.a.1.bias
 (208)" fillcolor=lightblue]
	2646238745984 -> 2655240953888
	2655240953888 [label=AccumulateGrad]
	2655240953792 -> 2655240953648
	2655238730784 [label="trunk_output.block3.block3-3.f.b.0.weight
 (208, 8, 3, 3)" fillcolor=lightblue]
	2655238730784 -> 2655240953792
	2655240953792 [label=AccumulateGrad]
	2655240953600 -> 2655240953552
	2655238731984 [label="trunk_output.block3.block3-3.f.b.1.weight
 (208)" fillcolor=lightblue]
	2655238731984 -> 2655240953600
	2655240953600 [label=AccumulateGrad]
	2655240953456 -> 2655240953552
	2646238503424 [label="trunk_output.block3.block3-3.f.b.1.bias
 (208)" fillcolor=lightblue]
	2646238503424 -> 2655240953456
	2655240953456 [label=AccumulateGrad]
	2655240953264 -> 2655240953024
	2646238509664 [label="trunk_output.block3.block3-3.f.se.fc1.weight
 (52, 208, 1, 1)" fillcolor=lightblue]
	2646238509664 -> 2655240953264
	2655240953264 [label=AccumulateGrad]
	2655240953216 -> 2655240953024
	2646238499984 [label="trunk_output.block3.block3-3.f.se.fc1.bias
 (52)" fillcolor=lightblue]
	2646238499984 -> 2655240953216
	2655240953216 [label=AccumulateGrad]
	2655240953072 -> 2655240952592
	2646238509904 [label="trunk_output.block3.block3-3.f.se.fc2.weight
 (208, 52, 1, 1)" fillcolor=lightblue]
	2646238509904 -> 2655240953072
	2655240953072 [label=AccumulateGrad]
	2655240952256 -> 2655240952592
	2646238507264 [label="trunk_output.block3.block3-3.f.se.fc2.bias
 (208)" fillcolor=lightblue]
	2646238507264 -> 2655240952256
	2655240952256 [label=AccumulateGrad]
	2655240952208 -> 2655240950864
	2655240951392 -> 2646243291104
	2646238505344 [label="trunk_output.block3.block3-3.f.c.0.weight
 (208, 208, 1, 1)" fillcolor=lightblue]
	2646238505344 -> 2655240951392
	2655240951392 [label=AccumulateGrad]
	2646243291152 -> 2646243291008
	2646238507744 [label="trunk_output.block3.block3-3.f.c.1.weight
 (208)" fillcolor=lightblue]
	2646238507744 -> 2646243291152
	2646243291152 [label=AccumulateGrad]
	2655240949712 -> 2646243291008
	2646238507504 [label="trunk_output.block3.block3-3.f.c.1.bias
 (208)" fillcolor=lightblue]
	2646238507504 -> 2655240949712
	2655240949712 [label=AccumulateGrad]
	2646243290768 -> 2646243290720
	2646243290768 [label=NativeBatchNormBackward0]
	2646243290864 -> 2646243290768
	2646243290864 [label=ConvolutionBackward0]
	2655240952016 -> 2646243290864
	2655240952016 [label=MulBackward0]
	2655240953504 -> 2655240952016
	2655240953504 [label=SigmoidBackward0]
	2655240953744 -> 2655240953504
	2655240953744 [label=ConvolutionBackward0]
	2655240954128 -> 2655240953744
	2655240954128 [label=ReluBackward0]
	2655240954176 -> 2655240954128
	2655240954176 [label=ConvolutionBackward0]
	2655240954464 -> 2655240954176
	2655240954464 [label=MeanBackward1]
	2655240953360 -> 2655240954464
	2655240953360 [label=ReluBackward0]
	2655240954704 -> 2655240953360
	2655240954704 [label=NativeBatchNormBackward0]
	2655240954800 -> 2655240954704
	2655240954800 [label=ConvolutionBackward0]
	2655240954992 -> 2655240954800
	2655240954992 [label=ReluBackward0]
	2655240955136 -> 2655240954992
	2655240955136 [label=NativeBatchNormBackward0]
	2655240955232 -> 2655240955136
	2655240955232 [label=ConvolutionBackward0]
	2646243290816 -> 2655240955232
	2655240955424 -> 2655240955232
	2646238510384 [label="trunk_output.block3.block3-4.f.a.0.weight
 (208, 208, 1, 1)" fillcolor=lightblue]
	2646238510384 -> 2655240955424
	2655240955424 [label=AccumulateGrad]
	2655240955184 -> 2655240955136
	2646238501344 [label="trunk_output.block3.block3-4.f.a.1.weight
 (208)" fillcolor=lightblue]
	2646238501344 -> 2655240955184
	2655240955184 [label=AccumulateGrad]
	2655240955040 -> 2655240955136
	2646238508944 [label="trunk_output.block3.block3-4.f.a.1.bias
 (208)" fillcolor=lightblue]
	2646238508944 -> 2655240955040
	2655240955040 [label=AccumulateGrad]
	2655240954944 -> 2655240954800
	2646238498864 [label="trunk_output.block3.block3-4.f.b.0.weight
 (208, 8, 3, 3)" fillcolor=lightblue]
	2646238498864 -> 2655240954944
	2655240954944 [label=AccumulateGrad]
	2655240954752 -> 2655240954704
	2646238505504 [label="trunk_output.block3.block3-4.f.b.1.weight
 (208)" fillcolor=lightblue]
	2646238505504 -> 2655240954752
	2655240954752 [label=AccumulateGrad]
	2655240954608 -> 2655240954704
	2646238499904 [label="trunk_output.block3.block3-4.f.b.1.bias
 (208)" fillcolor=lightblue]
	2646238499904 -> 2655240954608
	2655240954608 [label=AccumulateGrad]
	2655240954416 -> 2655240954176
	2646238509424 [label="trunk_output.block3.block3-4.f.se.fc1.weight
 (52, 208, 1, 1)" fillcolor=lightblue]
	2646238509424 -> 2655240954416
	2655240954416 [label=AccumulateGrad]
	2655240954368 -> 2655240954176
	2646238502384 [label="trunk_output.block3.block3-4.f.se.fc1.bias
 (52)" fillcolor=lightblue]
	2646238502384 -> 2655240954368
	2655240954368 [label=AccumulateGrad]
	2655240954224 -> 2655240953744
	2646238498144 [label="trunk_output.block3.block3-4.f.se.fc2.weight
 (208, 52, 1, 1)" fillcolor=lightblue]
	2646238498144 -> 2655240954224
	2655240954224 [label=AccumulateGrad]
	2655240953408 -> 2655240953744
	2646238496464 [label="trunk_output.block3.block3-4.f.se.fc2.bias
 (208)" fillcolor=lightblue]
	2646238496464 -> 2655240953408
	2655240953408 [label=AccumulateGrad]
	2655240953360 -> 2655240952016
	2655240952544 -> 2646243290864
	2646238495584 [label="trunk_output.block3.block3-4.f.c.0.weight
 (208, 208, 1, 1)" fillcolor=lightblue]
	2646238495584 -> 2655240952544
	2655240952544 [label=AccumulateGrad]
	2646243290912 -> 2646243290768
	2646238506304 [label="trunk_output.block3.block3-4.f.c.1.weight
 (208)" fillcolor=lightblue]
	2646238506304 -> 2646243290912
	2646243290912 [label=AccumulateGrad]
	2655240950480 -> 2646243290768
	2646238505584 [label="trunk_output.block3.block3-4.f.c.1.bias
 (208)" fillcolor=lightblue]
	2646238505584 -> 2655240950480
	2655240950480 [label=AccumulateGrad]
	2646243290528 -> 2646243290480
	2646243290528 [label=NativeBatchNormBackward0]
	2646243290624 -> 2646243290528
	2646243290624 [label=ConvolutionBackward0]
	2655240953168 -> 2646243290624
	2655240953168 [label=MulBackward0]
	2655240954656 -> 2655240953168
	2655240954656 [label=SigmoidBackward0]
	2655240954896 -> 2655240954656
	2655240954896 [label=ConvolutionBackward0]
	2655240955280 -> 2655240954896
	2655240955280 [label=ReluBackward0]
	2655240955328 -> 2655240955280
	2655240955328 [label=ConvolutionBackward0]
	2655240955616 -> 2655240955328
	2655240955616 [label=MeanBackward1]
	2655240954512 -> 2655240955616
	2655240954512 [label=ReluBackward0]
	2655240955856 -> 2655240954512
	2655240955856 [label=NativeBatchNormBackward0]
	2655240955952 -> 2655240955856
	2655240955952 [label=ConvolutionBackward0]
	2655240956144 -> 2655240955952
	2655240956144 [label=ReluBackward0]
	2655240956288 -> 2655240956144
	2655240956288 [label=NativeBatchNormBackward0]
	2655240956384 -> 2655240956288
	2655240956384 [label=ConvolutionBackward0]
	2646243290576 -> 2655240956384
	2655240956576 -> 2655240956384
	2646237906560 [label="trunk_output.block3.block3-5.f.a.0.weight
 (208, 208, 1, 1)" fillcolor=lightblue]
	2646237906560 -> 2655240956576
	2655240956576 [label=AccumulateGrad]
	2655240956336 -> 2655240956288
	2646238504544 [label="trunk_output.block3.block3-5.f.a.1.weight
 (208)" fillcolor=lightblue]
	2646238504544 -> 2655240956336
	2655240956336 [label=AccumulateGrad]
	2655240956192 -> 2655240956288
	2646238495424 [label="trunk_output.block3.block3-5.f.a.1.bias
 (208)" fillcolor=lightblue]
	2646238495424 -> 2655240956192
	2655240956192 [label=AccumulateGrad]
	2655240956096 -> 2655240955952
	2646237914080 [label="trunk_output.block3.block3-5.f.b.0.weight
 (208, 8, 3, 3)" fillcolor=lightblue]
	2646237914080 -> 2655240956096
	2655240956096 [label=AccumulateGrad]
	2655240955904 -> 2655240955856
	2646239395680 [label="trunk_output.block3.block3-5.f.b.1.weight
 (208)" fillcolor=lightblue]
	2646239395680 -> 2655240955904
	2655240955904 [label=AccumulateGrad]
	2655240955760 -> 2655240955856
	2646650699616 [label="trunk_output.block3.block3-5.f.b.1.bias
 (208)" fillcolor=lightblue]
	2646650699616 -> 2655240955760
	2655240955760 [label=AccumulateGrad]
	2655240955568 -> 2655240955328
	2646237912800 [label="trunk_output.block3.block3-5.f.se.fc1.weight
 (52, 208, 1, 1)" fillcolor=lightblue]
	2646237912800 -> 2655240955568
	2655240955568 [label=AccumulateGrad]
	2655240955520 -> 2655240955328
	2646650684336 [label="trunk_output.block3.block3-5.f.se.fc1.bias
 (52)" fillcolor=lightblue]
	2646650684336 -> 2655240955520
	2655240955520 [label=AccumulateGrad]
	2655240955376 -> 2655240954896
	2646650688496 [label="trunk_output.block3.block3-5.f.se.fc2.weight
 (208, 52, 1, 1)" fillcolor=lightblue]
	2646650688496 -> 2655240955376
	2655240955376 [label=AccumulateGrad]
	2655240954560 -> 2655240954896
	2646650690336 [label="trunk_output.block3.block3-5.f.se.fc2.bias
 (208)" fillcolor=lightblue]
	2646650690336 -> 2655240954560
	2655240954560 [label=AccumulateGrad]
	2655240954512 -> 2655240953168
	2655240953696 -> 2646243290624
	2646650697776 [label="trunk_output.block3.block3-5.f.c.0.weight
 (208, 208, 1, 1)" fillcolor=lightblue]
	2646650697776 -> 2655240953696
	2655240953696 [label=AccumulateGrad]
	2646243290672 -> 2646243290528
	2646650684576 [label="trunk_output.block3.block3-5.f.c.1.weight
 (208)" fillcolor=lightblue]
	2646650684576 -> 2646243290672
	2646243290672 [label=AccumulateGrad]
	2655240951632 -> 2646243290528
	2646650696096 [label="trunk_output.block3.block3-5.f.c.1.bias
 (208)" fillcolor=lightblue]
	2646650696096 -> 2655240951632
	2655240951632 [label=AccumulateGrad]
	2646243290288 -> 2646243290144
	2646238502144 [label="trunk_output.block4.block4-0.proj.0.weight
 (440, 208, 1, 1)" fillcolor=lightblue]
	2646238502144 -> 2646243290288
	2646243290288 [label=AccumulateGrad]
	2646243290096 -> 2646243290000
	2655238732624 [label="trunk_output.block4.block4-0.proj.1.weight
 (440)" fillcolor=lightblue]
	2655238732624 -> 2646243290096
	2646243290096 [label=AccumulateGrad]
	2646243290048 -> 2646243290000
	2655240257296 [label="trunk_output.block4.block4-0.proj.1.bias
 (440)" fillcolor=lightblue]
	2655240257296 -> 2646243290048
	2646243290048 [label=AccumulateGrad]
	2646243289952 -> 2646243289904
	2646243289952 [label=NativeBatchNormBackward0]
	2646243290384 -> 2646243289952
	2646243290384 [label=ConvolutionBackward0]
	2655240955088 -> 2646243290384
	2655240955088 [label=MulBackward0]
	2655240955472 -> 2655240955088
	2655240955472 [label=SigmoidBackward0]
	2655240955712 -> 2655240955472
	2655240955712 [label=ConvolutionBackward0]
	2655240956048 -> 2655240955712
	2655240956048 [label=ReluBackward0]
	2655240956672 -> 2655240956048
	2655240956672 [label=ConvolutionBackward0]
	2655240956480 -> 2655240956672
	2655240956480 [label=MeanBackward1]
	2655240954320 -> 2655240956480
	2655240954320 [label=ReluBackward0]
	2655240956912 -> 2655240954320
	2655240956912 [label=NativeBatchNormBackward0]
	2655240957008 -> 2655240956912
	2655240957008 [label=ConvolutionBackward0]
	2655240957200 -> 2655240957008
	2655240957200 [label=ReluBackward0]
	2655240957344 -> 2655240957200
	2655240957344 [label=NativeBatchNormBackward0]
	2655240957440 -> 2655240957344
	2655240957440 [label=ConvolutionBackward0]
	2646243290336 -> 2655240957440
	2655240957632 -> 2655240957440
	2646237185744 [label="trunk_output.block4.block4-0.f.a.0.weight
 (440, 208, 1, 1)" fillcolor=lightblue]
	2646237185744 -> 2655240957632
	2655240957632 [label=AccumulateGrad]
	2655240957392 -> 2655240957344
	2646237188144 [label="trunk_output.block4.block4-0.f.a.1.weight
 (440)" fillcolor=lightblue]
	2646237188144 -> 2655240957392
	2655240957392 [label=AccumulateGrad]
	2655240957248 -> 2655240957344
	2646237199024 [label="trunk_output.block4.block4-0.f.a.1.bias
 (440)" fillcolor=lightblue]
	2646237199024 -> 2655240957248
	2655240957248 [label=AccumulateGrad]
	2655240957152 -> 2655240957008
	2646237192944 [label="trunk_output.block4.block4-0.f.b.0.weight
 (440, 8, 3, 3)" fillcolor=lightblue]
	2646237192944 -> 2655240957152
	2655240957152 [label=AccumulateGrad]
	2655240956960 -> 2655240956912
	2646238503904 [label="trunk_output.block4.block4-0.f.b.1.weight
 (440)" fillcolor=lightblue]
	2646238503904 -> 2655240956960
	2655240956960 [label=AccumulateGrad]
	2655240956816 -> 2655240956912
	2646239121296 [label="trunk_output.block4.block4-0.f.b.1.bias
 (440)" fillcolor=lightblue]
	2646239121296 -> 2655240956816
	2655240956816 [label=AccumulateGrad]
	2655240956624 -> 2655240956672
	2646239133216 [label="trunk_output.block4.block4-0.f.se.fc1.weight
 (52, 440, 1, 1)" fillcolor=lightblue]
	2646239133216 -> 2655240956624
	2655240956624 [label=AccumulateGrad]
	2655240956432 -> 2655240956672
	2646239131296 [label="trunk_output.block4.block4-0.f.se.fc1.bias
 (52)" fillcolor=lightblue]
	2646239131296 -> 2655240956432
	2655240956432 [label=AccumulateGrad]
	2655240956000 -> 2655240955712
	2646239132496 [label="trunk_output.block4.block4-0.f.se.fc2.weight
 (440, 52, 1, 1)" fillcolor=lightblue]
	2646239132496 -> 2655240956000
	2655240956000 [label=AccumulateGrad]
	2655240955664 -> 2655240955712
	2646239131536 [label="trunk_output.block4.block4-0.f.se.fc2.bias
 (440)" fillcolor=lightblue]
	2646239131536 -> 2655240955664
	2655240955664 [label=AccumulateGrad]
	2655240954320 -> 2655240955088
	2655240953936 -> 2646243290384
	2646239130016 [label="trunk_output.block4.block4-0.f.c.0.weight
 (440, 440, 1, 1)" fillcolor=lightblue]
	2646239130016 -> 2655240953936
	2655240953936 [label=AccumulateGrad]
	2646243290240 -> 2646243289952
	2646239127776 [label="trunk_output.block4.block4-0.f.c.1.weight
 (440)" fillcolor=lightblue]
	2646239127776 -> 2646243290240
	2646243290240 [label=AccumulateGrad]
	2646243290192 -> 2646243289952
	2655238687696 [label="trunk_output.block4.block4-0.f.c.1.bias
 (440)" fillcolor=lightblue]
	2655238687696 -> 2646243290192
	2646243290192 [label=AccumulateGrad]
	2646243289712 -> 2646243289664
	2646243289712 [label=NativeBatchNormBackward0]
	2646243290432 -> 2646243289712
	2646243290432 [label=ConvolutionBackward0]
	2655240954848 -> 2646243290432
	2655240954848 [label=MulBackward0]
	2655240956864 -> 2655240954848
	2655240956864 [label=SigmoidBackward0]
	2655240957104 -> 2655240956864
	2655240957104 [label=ConvolutionBackward0]
	2655240957488 -> 2655240957104
	2655240957488 [label=ReluBackward0]
	2655240957536 -> 2655240957488
	2655240957536 [label=ConvolutionBackward0]
	2655240957824 -> 2655240957536
	2655240957824 [label=MeanBackward1]
	2655240956720 -> 2655240957824
	2655240956720 [label=ReluBackward0]
	2655240958064 -> 2655240956720
	2655240958064 [label=NativeBatchNormBackward0]
	2655240958160 -> 2655240958064
	2655240958160 [label=ConvolutionBackward0]
	2655240958352 -> 2655240958160
	2655240958352 [label=ReluBackward0]
	2655240958496 -> 2655240958352
	2655240958496 [label=NativeBatchNormBackward0]
	2655240958592 -> 2655240958496
	2655240958592 [label=ConvolutionBackward0]
	2646243289760 -> 2655240958592
	2655240958784 -> 2655240958592
	2646650695136 [label="trunk_output.block4.block4-1.f.a.0.weight
 (440, 440, 1, 1)" fillcolor=lightblue]
	2646650695136 -> 2655240958784
	2655240958784 [label=AccumulateGrad]
	2655240958544 -> 2655240958496
	2655238697616 [label="trunk_output.block4.block4-1.f.a.1.weight
 (440)" fillcolor=lightblue]
	2655238697616 -> 2655240958544
	2655240958544 [label=AccumulateGrad]
	2655240958400 -> 2655240958496
	2655238688576 [label="trunk_output.block4.block4-1.f.a.1.bias
 (440)" fillcolor=lightblue]
	2655238688576 -> 2655240958400
	2655240958400 [label=AccumulateGrad]
	2655240958304 -> 2655240958160
	2655238695776 [label="trunk_output.block4.block4-1.f.b.0.weight
 (440, 8, 3, 3)" fillcolor=lightblue]
	2655238695776 -> 2655240958304
	2655240958304 [label=AccumulateGrad]
	2655240958112 -> 2655240958064
	2655238691696 [label="trunk_output.block4.block4-1.f.b.1.weight
 (440)" fillcolor=lightblue]
	2655238691696 -> 2655240958112
	2655240958112 [label=AccumulateGrad]
	2655240957968 -> 2655240958064
	2655238690256 [label="trunk_output.block4.block4-1.f.b.1.bias
 (440)" fillcolor=lightblue]
	2655238690256 -> 2655240957968
	2655240957968 [label=AccumulateGrad]
	2655240957776 -> 2655240957536
	2646239119936 [label="trunk_output.block4.block4-1.f.se.fc1.weight
 (110, 440, 1, 1)" fillcolor=lightblue]
	2646239119936 -> 2655240957776
	2655240957776 [label=AccumulateGrad]
	2655240957728 -> 2655240957536
	2655238815808 [label="trunk_output.block4.block4-1.f.se.fc1.bias
 (110)" fillcolor=lightblue]
	2655238815808 -> 2655240957728
	2655240957728 [label=AccumulateGrad]
	2655240957584 -> 2655240957104
	2655238821808 [label="trunk_output.block4.block4-1.f.se.fc2.weight
 (440, 110, 1, 1)" fillcolor=lightblue]
	2655238821808 -> 2655240957584
	2655240957584 [label=AccumulateGrad]
	2655240956768 -> 2655240957104
	2655238829648 [label="trunk_output.block4.block4-1.f.se.fc2.bias
 (440)" fillcolor=lightblue]
	2655238829648 -> 2655240956768
	2655240956768 [label=AccumulateGrad]
	2655240956720 -> 2655240954848
	2655240955808 -> 2646243290432
	2655238823408 [label="trunk_output.block4.block4-1.f.c.0.weight
 (440, 440, 1, 1)" fillcolor=lightblue]
	2655238823408 -> 2655240955808
	2655240955808 [label=AccumulateGrad]
	2646243289808 -> 2646243289712
	2655238825648 [label="trunk_output.block4.block4-1.f.c.1.weight
 (440)" fillcolor=lightblue]
	2655238825648 -> 2646243289808
	2646243289808 [label=AccumulateGrad]
	2646243289856 -> 2646243289712
	2655238817408 [label="trunk_output.block4.block4-1.f.c.1.bias
 (440)" fillcolor=lightblue]
	2655238817408 -> 2646243289856
	2646243289856 [label=AccumulateGrad]
	2646243289472 -> 2646243289424
	2646243289472 [label=NativeBatchNormBackward0]
	2646243289568 -> 2646243289472
	2646243289568 [label=ConvolutionBackward0]
	2655240956240 -> 2646243289568
	2655240956240 [label=MulBackward0]
	2655240958016 -> 2655240956240
	2655240958016 [label=SigmoidBackward0]
	2655240958256 -> 2655240958016
	2655240958256 [label=ConvolutionBackward0]
	2655240958640 -> 2655240958256
	2655240958640 [label=ReluBackward0]
	2655240958688 -> 2655240958640
	2655240958688 [label=ConvolutionBackward0]
	2655240958976 -> 2655240958688
	2655240958976 [label=MeanBackward1]
	2655240957872 -> 2655240958976
	2655240957872 [label=ReluBackward0]
	2655240959216 -> 2655240957872
	2655240959216 [label=NativeBatchNormBackward0]
	2655240959312 -> 2655240959216
	2655240959312 [label=ConvolutionBackward0]
	2655240959504 -> 2655240959312
	2655240959504 [label=ReluBackward0]
	2655240959648 -> 2655240959504
	2655240959648 [label=NativeBatchNormBackward0]
	2655240959744 -> 2655240959648
	2655240959744 [label=ConvolutionBackward0]
	2646243289520 -> 2655240959744
	2655240959936 -> 2655240959744
	2655238687216 [label="trunk_output.block4.block4-2.f.a.0.weight
 (440, 440, 1, 1)" fillcolor=lightblue]
	2655238687216 -> 2655240959936
	2655240959936 [label=AccumulateGrad]
	2655240959696 -> 2655240959648
	2655238564944 [label="trunk_output.block4.block4-2.f.a.1.weight
 (440)" fillcolor=lightblue]
	2655238564944 -> 2655240959696
	2655240959696 [label=AccumulateGrad]
	2655240959552 -> 2655240959648
	2655238556864 [label="trunk_output.block4.block4-2.f.a.1.bias
 (440)" fillcolor=lightblue]
	2655238556864 -> 2655240959552
	2655240959552 [label=AccumulateGrad]
	2655240959456 -> 2655240959312
	2646237915360 [label="trunk_output.block4.block4-2.f.b.0.weight
 (440, 8, 3, 3)" fillcolor=lightblue]
	2646237915360 -> 2655240959456
	2655240959456 [label=AccumulateGrad]
	2655240959264 -> 2655240959216
	2655238561024 [label="trunk_output.block4.block4-2.f.b.1.weight
 (440)" fillcolor=lightblue]
	2655238561024 -> 2655240959264
	2655240959264 [label=AccumulateGrad]
	2655240959120 -> 2655240959216
	2655238568544 [label="trunk_output.block4.block4-2.f.b.1.bias
 (440)" fillcolor=lightblue]
	2655238568544 -> 2655240959120
	2655240959120 [label=AccumulateGrad]
	2655240958928 -> 2655240958688
	2646237906720 [label="trunk_output.block4.block4-2.f.se.fc1.weight
 (110, 440, 1, 1)" fillcolor=lightblue]
	2646237906720 -> 2655240958928
	2655240958928 [label=AccumulateGrad]
	2655240958880 -> 2655240958688
	2655238558704 [label="trunk_output.block4.block4-2.f.se.fc1.bias
 (110)" fillcolor=lightblue]
	2655238558704 -> 2655240958880
	2655240958880 [label=AccumulateGrad]
	2655240958736 -> 2655240958256
	2655238554784 [label="trunk_output.block4.block4-2.f.se.fc2.weight
 (440, 110, 1, 1)" fillcolor=lightblue]
	2655238554784 -> 2655240958736
	2655240958736 [label=AccumulateGrad]
	2655240957920 -> 2655240958256
	2655238561744 [label="trunk_output.block4.block4-2.f.se.fc2.bias
 (440)" fillcolor=lightblue]
	2655238561744 -> 2655240957920
	2655240957920 [label=AccumulateGrad]
	2655240957872 -> 2655240956240
	2655240957056 -> 2646243289568
	2655238563744 [label="trunk_output.block4.block4-2.f.c.0.weight
 (440, 440, 1, 1)" fillcolor=lightblue]
	2655238563744 -> 2655240957056
	2655240957056 [label=AccumulateGrad]
	2646243289616 -> 2646243289472
	2655238556144 [label="trunk_output.block4.block4-2.f.c.1.weight
 (440)" fillcolor=lightblue]
	2655238556144 -> 2646243289616
	2646243289616 [label=AccumulateGrad]
	2655240952784 -> 2646243289472
	2655238555024 [label="trunk_output.block4.block4-2.f.c.1.bias
 (440)" fillcolor=lightblue]
	2655238555024 -> 2655240952784
	2655240952784 [label=AccumulateGrad]
	2646243289232 -> 2646243289040
	2646243289232 [label=NativeBatchNormBackward0]
	2646243289328 -> 2646243289232
	2646243289328 [label=ConvolutionBackward0]
	2655240957680 -> 2646243289328
	2655240957680 [label=MulBackward0]
	2655240959168 -> 2655240957680
	2655240959168 [label=SigmoidBackward0]
	2655240959408 -> 2655240959168
	2655240959408 [label=ConvolutionBackward0]
	2655240959792 -> 2655240959408
	2655240959792 [label=ReluBackward0]
	2655240959840 -> 2655240959792
	2655240959840 [label=ConvolutionBackward0]
	2655240960128 -> 2655240959840
	2655240960128 [label=MeanBackward1]
	2655240959024 -> 2655240960128
	2655240959024 [label=ReluBackward0]
	2655240960368 -> 2655240959024
	2655240960368 [label=NativeBatchNormBackward0]
	2655240960464 -> 2655240960368
	2655240960464 [label=ConvolutionBackward0]
	2655240960656 -> 2655240960464
	2655240960656 [label=ReluBackward0]
	2655240960800 -> 2655240960656
	2655240960800 [label=NativeBatchNormBackward0]
	2655240960896 -> 2655240960800
	2655240960896 [label=ConvolutionBackward0]
	2646243289280 -> 2655240960896
	2655240961088 -> 2655240960896
	2646237918400 [label="trunk_output.block4.block4-3.f.a.0.weight
 (440, 440, 1, 1)" fillcolor=lightblue]
	2646237918400 -> 2655240961088
	2655240961088 [label=AccumulateGrad]
	2655240960848 -> 2655240960800
	2655238557104 [label="trunk_output.block4.block4-3.f.a.1.weight
 (440)" fillcolor=lightblue]
	2655238557104 -> 2655240960848
	2655240960848 [label=AccumulateGrad]
	2655240960704 -> 2655240960800
	2646237812496 [label="trunk_output.block4.block4-3.f.a.1.bias
 (440)" fillcolor=lightblue]
	2646237812496 -> 2655240960704
	2655240960704 [label=AccumulateGrad]
	2655240960608 -> 2655240960464
	2655238694256 [label="trunk_output.block4.block4-3.f.b.0.weight
 (440, 8, 3, 3)" fillcolor=lightblue]
	2655238694256 -> 2655240960608
	2655240960608 [label=AccumulateGrad]
	2655240960416 -> 2655240960368
	2646237816096 [label="trunk_output.block4.block4-3.f.b.1.weight
 (440)" fillcolor=lightblue]
	2646237816096 -> 2655240960416
	2655240960416 [label=AccumulateGrad]
	2655240960272 -> 2655240960368
	2646237812816 [label="trunk_output.block4.block4-3.f.b.1.bias
 (440)" fillcolor=lightblue]
	2646237812816 -> 2655240960272
	2655240960272 [label=AccumulateGrad]
	2655240960080 -> 2655240959840
	2646237815376 [label="trunk_output.block4.block4-3.f.se.fc1.weight
 (110, 440, 1, 1)" fillcolor=lightblue]
	2646237815376 -> 2655240960080
	2655240960080 [label=AccumulateGrad]
	2655240960032 -> 2655240959840
	2646237818176 [label="trunk_output.block4.block4-3.f.se.fc1.bias
 (110)" fillcolor=lightblue]
	2646237818176 -> 2655240960032
	2655240960032 [label=AccumulateGrad]
	2655240959888 -> 2655240959408
	2646237817376 [label="trunk_output.block4.block4-3.f.se.fc2.weight
 (440, 110, 1, 1)" fillcolor=lightblue]
	2646237817376 -> 2655240959888
	2655240959888 [label=AccumulateGrad]
	2655240959072 -> 2655240959408
	2646237817216 [label="trunk_output.block4.block4-3.f.se.fc2.bias
 (440)" fillcolor=lightblue]
	2646237817216 -> 2655240959072
	2655240959072 [label=AccumulateGrad]
	2655240959024 -> 2655240957680
	2655240958208 -> 2646243289328
	2646237806976 [label="trunk_output.block4.block4-3.f.c.0.weight
 (440, 440, 1, 1)" fillcolor=lightblue]
	2646237806976 -> 2655240958208
	2655240958208 [label=AccumulateGrad]
	2646243289376 -> 2646243289232
	2646237820416 [label="trunk_output.block4.block4-3.f.c.1.weight
 (440)" fillcolor=lightblue]
	2646237820416 -> 2646243289376
	2646243289376 [label=AccumulateGrad]
	2655240956528 -> 2646243289232
	2646237822576 [label="trunk_output.block4.block4-3.f.c.1.bias
 (440)" fillcolor=lightblue]
	2646237822576 -> 2655240956528
	2655240956528 [label=AccumulateGrad]
	2646243289184 -> 2646243288704
	2646243289184 [label=NativeBatchNormBackward0]
	2646243289136 -> 2646243289184
	2646243289136 [label=ConvolutionBackward0]
	2655240958832 -> 2646243289136
	2655240958832 [label=MulBackward0]
	2655240960320 -> 2655240958832
	2655240960320 [label=SigmoidBackward0]
	2655240960560 -> 2655240960320
	2655240960560 [label=ConvolutionBackward0]
	2655240960944 -> 2655240960560
	2655240960944 [label=ReluBackward0]
	2655240960992 -> 2655240960944
	2655240960992 [label=ConvolutionBackward0]
	2655240961280 -> 2655240960992
	2655240961280 [label=MeanBackward1]
	2655240960176 -> 2655240961280
	2655240960176 [label=ReluBackward0]
	2655240961520 -> 2655240960176
	2655240961520 [label=NativeBatchNormBackward0]
	2655240961616 -> 2655240961520
	2655240961616 [label=ConvolutionBackward0]
	2655240961808 -> 2655240961616
	2655240961808 [label=ReluBackward0]
	2655240961952 -> 2655240961808
	2655240961952 [label=NativeBatchNormBackward0]
	2655240962000 -> 2655240961952
	2655240962000 [label=ConvolutionBackward0]
	2646243288896 -> 2655240962000
	2646245343488 -> 2655240962000
	2646237820336 [label="trunk_output.block4.block4-4.f.a.0.weight
 (440, 440, 1, 1)" fillcolor=lightblue]
	2646237820336 -> 2646245343488
	2646245343488 [label=AccumulateGrad]
	2655240961856 -> 2655240961952
	2646237807456 [label="trunk_output.block4.block4-4.f.a.1.weight
 (440)" fillcolor=lightblue]
	2646237807456 -> 2655240961856
	2655240961856 [label=AccumulateGrad]
	2646245343296 -> 2655240961952
	2646237807376 [label="trunk_output.block4.block4-4.f.a.1.bias
 (440)" fillcolor=lightblue]
	2646237807376 -> 2646245343296
	2646245343296 [label=AccumulateGrad]
	2655240961760 -> 2655240961616
	2646237807056 [label="trunk_output.block4.block4-4.f.b.0.weight
 (440, 8, 3, 3)" fillcolor=lightblue]
	2646237807056 -> 2655240961760
	2655240961760 [label=AccumulateGrad]
	2655240961568 -> 2655240961520
	2646237807776 [label="trunk_output.block4.block4-4.f.b.1.weight
 (440)" fillcolor=lightblue]
	2646237807776 -> 2655240961568
	2655240961568 [label=AccumulateGrad]
	2655240961424 -> 2655240961520
	2646237806896 [label="trunk_output.block4.block4-4.f.b.1.bias
 (440)" fillcolor=lightblue]
	2646237806896 -> 2655240961424
	2655240961424 [label=AccumulateGrad]
	2655240961232 -> 2655240960992
	2646237809696 [label="trunk_output.block4.block4-4.f.se.fc1.weight
 (110, 440, 1, 1)" fillcolor=lightblue]
	2646237809696 -> 2655240961232
	2655240961232 [label=AccumulateGrad]
	2655240961184 -> 2655240960992
	2646237807136 [label="trunk_output.block4.block4-4.f.se.fc1.bias
 (110)" fillcolor=lightblue]
	2646237807136 -> 2655240961184
	2655240961184 [label=AccumulateGrad]
	2655240961040 -> 2655240960560
	2646237809136 [label="trunk_output.block4.block4-4.f.se.fc2.weight
 (440, 110, 1, 1)" fillcolor=lightblue]
	2646237809136 -> 2655240961040
	2655240961040 [label=AccumulateGrad]
	2655240960224 -> 2655240960560
	2646237809856 [label="trunk_output.block4.block4-4.f.se.fc2.bias
 (440)" fillcolor=lightblue]
	2646237809856 -> 2655240960224
	2655240960224 [label=AccumulateGrad]
	2655240960176 -> 2655240958832
	2655240959360 -> 2646243289136
	2646237808576 [label="trunk_output.block4.block4-4.f.c.0.weight
 (440, 440, 1, 1)" fillcolor=lightblue]
	2646237808576 -> 2655240959360
	2655240959360 [label=AccumulateGrad]
	2646243288992 -> 2646243289184
	2646237812416 [label="trunk_output.block4.block4-4.f.c.1.weight
 (440)" fillcolor=lightblue]
	2646237812416 -> 2646243288992
	2646243288992 [label=AccumulateGrad]
	2655240957296 -> 2646243289184
	2646237808896 [label="trunk_output.block4.block4-4.f.c.1.bias
 (440)" fillcolor=lightblue]
	2646237808896 -> 2655240957296
	2655240957296 [label=AccumulateGrad]
	2646243288416 -> 2646243288752
	2646243288416 [label=NativeBatchNormBackward0]
	2646243288032 -> 2646243288416
	2646243288032 [label=ConvolutionBackward0]
	2655240959984 -> 2646243288032
	2655240959984 [label=MulBackward0]
	2655240961472 -> 2655240959984
	2655240961472 [label=SigmoidBackward0]
	2655240961712 -> 2655240961472
	2655240961712 [label=ConvolutionBackward0]
	2655240961904 -> 2655240961712
	2655240961904 [label=ReluBackward0]
	2646245343392 -> 2655240961904
	2646245343392 [label=ConvolutionBackward0]
	2646245343680 -> 2646245343392
	2646245343680 [label=MeanBackward1]
	2655240961328 -> 2646245343680
	2655240961328 [label=ReluBackward0]
	2646245343920 -> 2655240961328
	2646245343920 [label=NativeBatchNormBackward0]
	2646245344016 -> 2646245343920
	2646245344016 [label=ConvolutionBackward0]
	2646245344208 -> 2646245344016
	2646245344208 [label=ReluBackward0]
	2646245344352 -> 2646245344208
	2646245344352 [label=NativeBatchNormBackward0]
	2646245344448 -> 2646245344352
	2646245344448 [label=ConvolutionBackward0]
	2646243288176 -> 2646245344448
	2646245344640 -> 2646245344448
	2646237809536 [label="trunk_output.block4.block4-5.f.a.0.weight
 (440, 440, 1, 1)" fillcolor=lightblue]
	2646237809536 -> 2646245344640
	2646245344640 [label=AccumulateGrad]
	2646245344400 -> 2646245344352
	2646237813936 [label="trunk_output.block4.block4-5.f.a.1.weight
 (440)" fillcolor=lightblue]
	2646237813936 -> 2646245344400
	2646245344400 [label=AccumulateGrad]
	2646245344256 -> 2646245344352
	2646237810016 [label="trunk_output.block4.block4-5.f.a.1.bias
 (440)" fillcolor=lightblue]
	2646237810016 -> 2646245344256
	2646245344256 [label=AccumulateGrad]
	2646245344160 -> 2646245344016
	2646237813456 [label="trunk_output.block4.block4-5.f.b.0.weight
 (440, 8, 3, 3)" fillcolor=lightblue]
	2646237813456 -> 2646245344160
	2646245344160 [label=AccumulateGrad]
	2646245343968 -> 2646245343920
	2646237814976 [label="trunk_output.block4.block4-5.f.b.1.weight
 (440)" fillcolor=lightblue]
	2646237814976 -> 2646245343968
	2646245343968 [label=AccumulateGrad]
	2646245343824 -> 2646245343920
	2646237816016 [label="trunk_output.block4.block4-5.f.b.1.bias
 (440)" fillcolor=lightblue]
	2646237816016 -> 2646245343824
	2646245343824 [label=AccumulateGrad]
	2646245343632 -> 2646245343392
	2646237815856 [label="trunk_output.block4.block4-5.f.se.fc1.weight
 (110, 440, 1, 1)" fillcolor=lightblue]
	2646237815856 -> 2646245343632
	2646245343632 [label=AccumulateGrad]
	2646245343584 -> 2646245343392
	2646237813136 [label="trunk_output.block4.block4-5.f.se.fc1.bias
 (110)" fillcolor=lightblue]
	2646237813136 -> 2646245343584
	2646245343584 [label=AccumulateGrad]
	2655240961376 -> 2655240961712
	2646237807936 [label="trunk_output.block4.block4-5.f.se.fc2.weight
 (440, 110, 1, 1)" fillcolor=lightblue]
	2646237807936 -> 2655240961376
	2655240961376 [label=AccumulateGrad]
	2646245343440 -> 2655240961712
	2646237820816 [label="trunk_output.block4.block4-5.f.se.fc2.bias
 (440)" fillcolor=lightblue]
	2646237820816 -> 2646245343440
	2646245343440 [label=AccumulateGrad]
	2655240961328 -> 2655240959984
	2655240960512 -> 2646243288032
	2646237814336 [label="trunk_output.block4.block4-5.f.c.0.weight
 (440, 440, 1, 1)" fillcolor=lightblue]
	2646237814336 -> 2655240960512
	2655240960512 [label=AccumulateGrad]
	2646243287744 -> 2646243288416
	2646237820736 [label="trunk_output.block4.block4-5.f.c.1.weight
 (440)" fillcolor=lightblue]
	2646237820736 -> 2646243287744
	2646243287744 [label=AccumulateGrad]
	2655240958448 -> 2646243288416
	2646237819936 [label="trunk_output.block4.block4-5.f.c.1.bias
 (440)" fillcolor=lightblue]
	2646237819936 -> 2655240958448
	2655240958448 [label=AccumulateGrad]
	2646243287216 -> 2646243288800
	2646243287216 [label=TBackward0]
	2646243288608 -> 2646243287216
	2646267358288 [label="fc.weight
 (10, 440)" fillcolor=lightblue]
	2646267358288 -> 2646243288608
	2646243288608 [label=AccumulateGrad]
	2646243288800 -> 2655240243536
}

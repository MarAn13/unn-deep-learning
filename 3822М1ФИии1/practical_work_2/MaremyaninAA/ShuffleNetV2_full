digraph {
	graph [size="178.35,178.35"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	2646238325360 [label="
 (128, 10)" fillcolor=darkolivegreen1]
	2646245071584 [label=AddmmBackward0]
	2646245074416 -> 2646245071584
	2646239187232 [label="fc.bias
 (10)" fillcolor=lightblue]
	2646239187232 -> 2646245074416
	2646245074416 [label=AccumulateGrad]
	2646245076960 -> 2646245071584
	2646245076960 [label=MeanBackward1]
	2646245065296 -> 2646245076960
	2646245065296 [label=ReluBackward0]
	2646245075904 -> 2646245065296
	2646245075904 [label=NativeBatchNormBackward0]
	2646245065632 -> 2646245075904
	2646245065632 [label=ConvolutionBackward0]
	2646245073888 -> 2646245065632
	2646245073888 [label=ViewBackward0]
	2646245069712 -> 2646245073888
	2646245069712 [label=CloneBackward0]
	2646245071920 -> 2646245069712
	2646245071920 [label=TransposeBackward0]
	2646245076528 -> 2646245071920
	2646245076528 [label=ViewBackward0]
	2646245080464 -> 2646245076528
	2646245080464 [label=CatBackward0]
	2646245073696 -> 2646245080464
	2646245073696 [label=SplitBackward0]
	2646245079984 -> 2646245073696
	2646245079984 [label=ViewBackward0]
	2646245069184 -> 2646245079984
	2646245069184 [label=CloneBackward0]
	2646245078736 -> 2646245069184
	2646245078736 [label=TransposeBackward0]
	2646245080224 -> 2646245078736
	2646245080224 [label=ViewBackward0]
	2646245075040 -> 2646245080224
	2646245075040 [label=CatBackward0]
	2646245073744 -> 2646245075040
	2646245073744 [label=SplitBackward0]
	2646245075664 -> 2646245073744
	2646245075664 [label=ViewBackward0]
	2646245068656 -> 2646245075664
	2646245068656 [label=CloneBackward0]
	2646245080656 -> 2646245068656
	2646245080656 [label=TransposeBackward0]
	2646245076912 -> 2646245080656
	2646245076912 [label=ViewBackward0]
	2646245066544 -> 2646245076912
	2646245066544 [label=CatBackward0]
	2646245066208 -> 2646245066544
	2646245066208 [label=SplitBackward0]
	2646245079552 -> 2646245066208
	2646245079552 [label=ViewBackward0]
	2646245079888 -> 2646245079552
	2646245079888 [label=CloneBackward0]
	2646245071248 -> 2646245079888
	2646245071248 [label=TransposeBackward0]
	2646245067408 -> 2646245071248
	2646245067408 [label=ViewBackward0]
	2646245067744 -> 2646245067408
	2646245067744 [label=CatBackward0]
	2646245065488 -> 2646245067744
	2646245065488 [label=ReluBackward0]
	2646245073360 -> 2646245065488
	2646245073360 [label=NativeBatchNormBackward0]
	2646245067936 -> 2646245073360
	2646245067936 [label=ConvolutionBackward0]
	2646245079216 -> 2646245067936
	2646245079216 [label=NativeBatchNormBackward0]
	2646245072352 -> 2646245079216
	2646245072352 [label=ConvolutionBackward0]
	2646245071344 -> 2646245072352
	2646245071344 [label=ViewBackward0]
	2646245069424 -> 2646245071344
	2646245069424 [label=CloneBackward0]
	2646245075280 -> 2646245069424
	2646245075280 [label=TransposeBackward0]
	2646245065104 -> 2646245075280
	2646245065104 [label=ViewBackward0]
	2646245071872 -> 2646245065104
	2646245071872 [label=CatBackward0]
	2646245066448 -> 2646245071872
	2646245066448 [label=SplitBackward0]
	2646245080512 -> 2646245066448
	2646245080512 [label=ViewBackward0]
	2646245075712 -> 2646245080512
	2646245075712 [label=CloneBackward0]
	2646245065728 -> 2646245075712
	2646245065728 [label=TransposeBackward0]
	2646245065344 -> 2646245065728
	2646245065344 [label=ViewBackward0]
	2646245068464 -> 2646245065344
	2646245068464 [label=CatBackward0]
	2655235925632 -> 2646245068464
	2655235925632 [label=SplitBackward0]
	2655235917664 -> 2655235925632
	2655235917664 [label=ViewBackward0]
	2655235915888 -> 2655235917664
	2655235915888 [label=CloneBackward0]
	2655235929088 -> 2655235915888
	2655235929088 [label=TransposeBackward0]
	2655235931872 -> 2655235929088
	2655235931872 [label=ViewBackward0]
	2655235921840 -> 2655235931872
	2655235921840 [label=CatBackward0]
	2655235700192 -> 2655235921840
	2655235700192 [label=SplitBackward0]
	2655235698656 -> 2655235700192
	2655235698656 [label=ViewBackward0]
	2655235693232 -> 2655235698656
	2655235693232 [label=CloneBackward0]
	2655235699808 -> 2655235693232
	2655235699808 [label=TransposeBackward0]
	2655235702736 -> 2655235699808
	2655235702736 [label=ViewBackward0]
	2655235695200 -> 2655235702736
	2655235695200 [label=CatBackward0]
	2655235696160 -> 2655235695200
	2655235696160 [label=SplitBackward0]
	2655235701296 -> 2655235696160
	2655235701296 [label=ViewBackward0]
	2655235701152 -> 2655235701296
	2655235701152 [label=CloneBackward0]
	2655235696688 -> 2655235701152
	2655235696688 [label=TransposeBackward0]
	2655235696544 -> 2655235696688
	2655235696544 [label=ViewBackward0]
	2655235699952 -> 2655235696544
	2655235699952 [label=CatBackward0]
	2655235694624 -> 2655235699952
	2655235694624 [label=SplitBackward0]
	2655235698272 -> 2655235694624
	2655235698272 [label=ViewBackward0]
	2655235697888 -> 2655235698272
	2655235697888 [label=CloneBackward0]
	2655235694192 -> 2655235697888
	2655235694192 [label=TransposeBackward0]
	2655235695392 -> 2655235694192
	2655235695392 [label=ViewBackward0]
	2655235695344 -> 2655235695392
	2655235695344 [label=CatBackward0]
	2655235696496 -> 2655235695344
	2655235696496 [label=SplitBackward0]
	2655235698032 -> 2655235696496
	2655235698032 [label=ViewBackward0]
	2655235693952 -> 2655235698032
	2655235693952 [label=CloneBackward0]
	2655235698080 -> 2655235693952
	2655235698080 [label=TransposeBackward0]
	2655235692368 -> 2655235698080
	2655235692368 [label=ViewBackward0]
	2655235696112 -> 2655235692368
	2655235696112 [label=CatBackward0]
	2655235693280 -> 2655235696112
	2655235693280 [label=SplitBackward0]
	2655235695536 -> 2655235693280
	2655235695536 [label=ViewBackward0]
	2655235694576 -> 2655235695536
	2655235694576 [label=CloneBackward0]
	2646243050448 -> 2655235694576
	2646243050448 [label=TransposeBackward0]
	2646243060624 -> 2646243050448
	2646243060624 [label=ViewBackward0]
	2646243049824 -> 2646243060624
	2646243049824 [label=CatBackward0]
	2646243056592 -> 2646243049824
	2646243056592 [label=ReluBackward0]
	2646243055776 -> 2646243056592
	2646243055776 [label=NativeBatchNormBackward0]
	2646243059232 -> 2646243055776
	2646243059232 [label=ConvolutionBackward0]
	2646243062928 -> 2646243059232
	2646243062928 [label=NativeBatchNormBackward0]
	2646243059856 -> 2646243062928
	2646243059856 [label=ConvolutionBackward0]
	2646243055584 -> 2646243059856
	2646243055584 [label=ViewBackward0]
	2646243061056 -> 2646243055584
	2646243061056 [label=CloneBackward0]
	2646243053136 -> 2646243061056
	2646243053136 [label=TransposeBackward0]
	2646243059088 -> 2646243053136
	2646243059088 [label=ViewBackward0]
	2646243063120 -> 2646243059088
	2646243063120 [label=CatBackward0]
	2646243061344 -> 2646243063120
	2646243061344 [label=SplitBackward0]
	2646243060000 -> 2646243061344
	2646243060000 [label=ViewBackward0]
	2646243063696 -> 2646243060000
	2646243063696 [label=CloneBackward0]
	2646243053664 -> 2646243063696
	2646243053664 [label=TransposeBackward0]
	2646243055824 -> 2646243053664
	2646243055824 [label=ViewBackward0]
	2646243051552 -> 2646243055824
	2646243051552 [label=CatBackward0]
	2646243055056 -> 2646243051552
	2646243055056 [label=SplitBackward0]
	2646243056736 -> 2646243055056
	2646243056736 [label=ViewBackward0]
	2646243056784 -> 2646243056736
	2646243056784 [label=CloneBackward0]
	2646243056016 -> 2646243056784
	2646243056016 [label=TransposeBackward0]
	2646243052704 -> 2646243056016
	2646243052704 [label=ViewBackward0]
	2646243053712 -> 2646243052704
	2646243053712 [label=CatBackward0]
	2646243064608 -> 2646243053712
	2646243064608 [label=SplitBackward0]
	2646243051648 -> 2646243064608
	2646243051648 [label=ViewBackward0]
	2646243062352 -> 2646243051648
	2646243062352 [label=CloneBackward0]
	2646243052320 -> 2646243062352
	2646243052320 [label=TransposeBackward0]
	2646243051696 -> 2646243052320
	2646243051696 [label=ViewBackward0]
	2646243053616 -> 2646243051696
	2646243053616 [label=CatBackward0]
	2646243055008 -> 2646243053616
	2646243055008 [label=ReluBackward0]
	2646243049680 -> 2646243055008
	2646243049680 [label=NativeBatchNormBackward0]
	2646243065232 -> 2646243049680
	2646243065232 [label=ConvolutionBackward0]
	2646243059424 -> 2646243065232
	2646243059424 [label=NativeBatchNormBackward0]
	2646243050256 -> 2646243059424
	2646243050256 [label=ConvolutionBackward0]
	2646243057120 -> 2646243050256
	2646243057120 [label=MaxPool2DWithIndicesBackward0]
	2646243051024 -> 2646243057120
	2646243051024 [label=ReluBackward0]
	2646243063648 -> 2646243051024
	2646243063648 [label=NativeBatchNormBackward0]
	2646243057696 -> 2646243063648
	2646243057696 [label=ConvolutionBackward0]
	2646243065808 -> 2646243057696
	2655235035424 [label="conv1.0.weight
 (24, 3, 3, 3)" fillcolor=lightblue]
	2655235035424 -> 2646243065808
	2646243065808 [label=AccumulateGrad]
	2646243051408 -> 2646243063648
	2655235656096 [label="conv1.1.weight
 (24)" fillcolor=lightblue]
	2655235656096 -> 2646243051408
	2646243051408 [label=AccumulateGrad]
	2646243054240 -> 2646243063648
	2646237634832 [label="conv1.1.bias
 (24)" fillcolor=lightblue]
	2646237634832 -> 2646243054240
	2646243054240 [label=AccumulateGrad]
	2646243055968 -> 2646243050256
	2646650684496 [label="stage2.0.branch1.0.weight
 (24, 1, 3, 3)" fillcolor=lightblue]
	2646650684496 -> 2646243055968
	2646243055968 [label=AccumulateGrad]
	2646243053568 -> 2646243059424
	2646650698576 [label="stage2.0.branch1.1.weight
 (24)" fillcolor=lightblue]
	2646650698576 -> 2646243053568
	2646243053568 [label=AccumulateGrad]
	2646243058320 -> 2646243059424
	2646650697376 [label="stage2.0.branch1.1.bias
 (24)" fillcolor=lightblue]
	2646650697376 -> 2646243058320
	2646243058320 [label=AccumulateGrad]
	2646243050160 -> 2646243065232
	2646650690336 [label="stage2.0.branch1.2.weight
 (24, 24, 1, 1)" fillcolor=lightblue]
	2646650690336 -> 2646243050160
	2646243050160 [label=AccumulateGrad]
	2646243050832 -> 2646243049680
	2646650696176 [label="stage2.0.branch1.3.weight
 (24)" fillcolor=lightblue]
	2646650696176 -> 2646243050832
	2646243050832 [label=AccumulateGrad]
	2646243051744 -> 2646243049680
	2646650697776 [label="stage2.0.branch1.3.bias
 (24)" fillcolor=lightblue]
	2646650697776 -> 2646243051744
	2646243051744 [label=AccumulateGrad]
	2646243054000 -> 2646243053616
	2646243054000 [label=ReluBackward0]
	2646243052128 -> 2646243054000
	2646243052128 [label=NativeBatchNormBackward0]
	2646243060528 -> 2646243052128
	2646243060528 [label=ConvolutionBackward0]
	2646243052368 -> 2646243060528
	2646243052368 [label=NativeBatchNormBackward0]
	2646243054192 -> 2646243052368
	2646243054192 [label=ConvolutionBackward0]
	2646243049872 -> 2646243054192
	2646243049872 [label=ReluBackward0]
	2646243065664 -> 2646243049872
	2646243065664 [label=NativeBatchNormBackward0]
	2646243057888 -> 2646243065664
	2646243057888 [label=ConvolutionBackward0]
	2646243057120 -> 2646243057888
	2646243059520 -> 2646243057888
	2646650695856 [label="stage2.0.branch2.0.weight
 (24, 24, 1, 1)" fillcolor=lightblue]
	2646650695856 -> 2646243059520
	2646243059520 [label=AccumulateGrad]
	2646243062016 -> 2646243065664
	2655240256336 [label="stage2.0.branch2.1.weight
 (24)" fillcolor=lightblue]
	2655240256336 -> 2646243062016
	2646243062016 [label=AccumulateGrad]
	2646243056208 -> 2646243065664
	2655240257456 [label="stage2.0.branch2.1.bias
 (24)" fillcolor=lightblue]
	2655240257456 -> 2646243056208
	2646243056208 [label=AccumulateGrad]
	2646243052176 -> 2646243054192
	2655240257216 [label="stage2.0.branch2.3.weight
 (24, 1, 3, 3)" fillcolor=lightblue]
	2655240257216 -> 2646243052176
	2646243052176 [label=AccumulateGrad]
	2646243057360 -> 2646243052368
	2655240253216 [label="stage2.0.branch2.4.weight
 (24)" fillcolor=lightblue]
	2655240253216 -> 2646243057360
	2646243057360 [label=AccumulateGrad]
	2646243058656 -> 2646243052368
	2655240246576 [label="stage2.0.branch2.4.bias
 (24)" fillcolor=lightblue]
	2655240246576 -> 2646243058656
	2646243058656 [label=AccumulateGrad]
	2646243053952 -> 2646243060528
	2655240243536 [label="stage2.0.branch2.5.weight
 (24, 24, 1, 1)" fillcolor=lightblue]
	2655240243536 -> 2646243053952
	2646243053952 [label=AccumulateGrad]
	2646243057168 -> 2646243052128
	2646650699616 [label="stage2.0.branch2.6.weight
 (24)" fillcolor=lightblue]
	2646650699616 -> 2646243057168
	2646243057168 [label=AccumulateGrad]
	2646243052512 -> 2646243052128
	2646239265392 [label="stage2.0.branch2.6.bias
 (24)" fillcolor=lightblue]
	2646239265392 -> 2646243052512
	2646243052512 [label=AccumulateGrad]
	2646243050208 -> 2646243053712
	2646243050208 [label=ReluBackward0]
	2646243063504 -> 2646243050208
	2646243063504 [label=NativeBatchNormBackward0]
	2646243052944 -> 2646243063504
	2646243052944 [label=ConvolutionBackward0]
	2646243060240 -> 2646243052944
	2646243060240 [label=NativeBatchNormBackward0]
	2646243056400 -> 2646243060240
	2646243056400 [label=ConvolutionBackward0]
	2646243053904 -> 2646243056400
	2646243053904 [label=ReluBackward0]
	2646243064512 -> 2646243053904
	2646243064512 [label=NativeBatchNormBackward0]
	2646243061536 -> 2646243064512
	2646243061536 [label=ConvolutionBackward0]
	2646243064608 -> 2646243061536
	2646243052896 -> 2646243061536
	2646650683776 [label="stage2.1.branch2.0.weight
 (24, 24, 1, 1)" fillcolor=lightblue]
	2646650683776 -> 2646243052896
	2646243052896 [label=AccumulateGrad]
	2646243060048 -> 2646243064512
	2646267198448 [label="stage2.1.branch2.1.weight
 (24)" fillcolor=lightblue]
	2646267198448 -> 2646243060048
	2646243060048 [label=AccumulateGrad]
	2646243064368 -> 2646243064512
	2646267197648 [label="stage2.1.branch2.1.bias
 (24)" fillcolor=lightblue]
	2646267197648 -> 2646243064368
	2646243064368 [label=AccumulateGrad]
	2646243054432 -> 2646243056400
	2646267185088 [label="stage2.1.branch2.3.weight
 (24, 1, 3, 3)" fillcolor=lightblue]
	2646267185088 -> 2646243054432
	2646243054432 [label=AccumulateGrad]
	2646243064320 -> 2646243060240
	2646267193168 [label="stage2.1.branch2.4.weight
 (24)" fillcolor=lightblue]
	2646267193168 -> 2646243064320
	2646243064320 [label=AccumulateGrad]
	2646243050016 -> 2646243060240
	2646267195568 [label="stage2.1.branch2.4.bias
 (24)" fillcolor=lightblue]
	2646267195568 -> 2646243050016
	2646243050016 [label=AccumulateGrad]
	2646243064848 -> 2646243052944
	2646267183808 [label="stage2.1.branch2.5.weight
 (24, 24, 1, 1)" fillcolor=lightblue]
	2646267183808 -> 2646243064848
	2646243064848 [label=AccumulateGrad]
	2646243062736 -> 2646243063504
	2646267189648 [label="stage2.1.branch2.6.weight
 (24)" fillcolor=lightblue]
	2646267189648 -> 2646243062736
	2646243062736 [label=AccumulateGrad]
	2646243050496 -> 2646243063504
	2646267192768 [label="stage2.1.branch2.6.bias
 (24)" fillcolor=lightblue]
	2646267192768 -> 2646243050496
	2646243050496 [label=AccumulateGrad]
	2646243057456 -> 2646243051552
	2646243057456 [label=ReluBackward0]
	2646243055248 -> 2646243057456
	2646243055248 [label=NativeBatchNormBackward0]
	2646243051984 -> 2646243055248
	2646243051984 [label=ConvolutionBackward0]
	2646243062544 -> 2646243051984
	2646243062544 [label=NativeBatchNormBackward0]
	2646243063840 -> 2646243062544
	2646243063840 [label=ConvolutionBackward0]
	2646243064272 -> 2646243063840
	2646243064272 [label=ReluBackward0]
	2655241284304 -> 2646243064272
	2655241284304 [label=NativeBatchNormBackward0]
	2655241289296 -> 2655241284304
	2655241289296 [label=ConvolutionBackward0]
	2646243055056 -> 2655241289296
	2655241287904 -> 2655241289296
	2646244115936 [label="stage2.2.branch2.0.weight
 (24, 24, 1, 1)" fillcolor=lightblue]
	2646244115936 -> 2655241287904
	2655241287904 [label=AccumulateGrad]
	2655241287472 -> 2655241284304
	2646267194208 [label="stage2.2.branch2.1.weight
 (24)" fillcolor=lightblue]
	2646267194208 -> 2655241287472
	2655241287472 [label=AccumulateGrad]
	2655241286704 -> 2655241284304
	2646242410016 [label="stage2.2.branch2.1.bias
 (24)" fillcolor=lightblue]
	2646242410016 -> 2655241286704
	2655241286704 [label=AccumulateGrad]
	2655241285840 -> 2646243063840
	2655235451264 [label="stage2.2.branch2.3.weight
 (24, 1, 3, 3)" fillcolor=lightblue]
	2655235451264 -> 2655241285840
	2655241285840 [label=AccumulateGrad]
	2646243062496 -> 2646243062544
	2646267354208 [label="stage2.2.branch2.4.weight
 (24)" fillcolor=lightblue]
	2646267354208 -> 2646243062496
	2646243062496 [label=AccumulateGrad]
	2646243065568 -> 2646243062544
	2646234090288 [label="stage2.2.branch2.4.bias
 (24)" fillcolor=lightblue]
	2646234090288 -> 2646243065568
	2646243065568 [label=AccumulateGrad]
	2646243053328 -> 2646243051984
	2646267186608 [label="stage2.2.branch2.5.weight
 (24, 24, 1, 1)" fillcolor=lightblue]
	2646267186608 -> 2646243053328
	2646243053328 [label=AccumulateGrad]
	2646243055392 -> 2646243055248
	2655235510240 [label="stage2.2.branch2.6.weight
 (24)" fillcolor=lightblue]
	2655235510240 -> 2646243055392
	2646243055392 [label=AccumulateGrad]
	2646243060816 -> 2646243055248
	2646239437152 [label="stage2.2.branch2.6.bias
 (24)" fillcolor=lightblue]
	2646239437152 -> 2646243060816
	2646243060816 [label=AccumulateGrad]
	2646243059568 -> 2646243063120
	2646243059568 [label=ReluBackward0]
	2646243062880 -> 2646243059568
	2646243062880 [label=NativeBatchNormBackward0]
	2646243057744 -> 2646243062880
	2646243057744 [label=ConvolutionBackward0]
	2646243064992 -> 2646243057744
	2646243064992 [label=NativeBatchNormBackward0]
	2646243052656 -> 2646243064992
	2646243052656 [label=ConvolutionBackward0]
	2655241285168 -> 2646243052656
	2655241285168 [label=ReluBackward0]
	2655241283152 -> 2655241285168
	2655241283152 [label=NativeBatchNormBackward0]
	2655241283584 -> 2655241283152
	2655241283584 [label=ConvolutionBackward0]
	2646243061344 -> 2655241283584
	2655241285024 -> 2655241283584
	2655235663696 [label="stage2.3.branch2.0.weight
 (24, 24, 1, 1)" fillcolor=lightblue]
	2655235663696 -> 2655241285024
	2655241285024 [label=AccumulateGrad]
	2655241288624 -> 2655241283152
	2655238606496 [label="stage2.3.branch2.1.weight
 (24)" fillcolor=lightblue]
	2655238606496 -> 2655241288624
	2655241288624 [label=AccumulateGrad]
	2655241280704 -> 2655241283152
	2655238615536 [label="stage2.3.branch2.1.bias
 (24)" fillcolor=lightblue]
	2655238615536 -> 2655241280704
	2655241280704 [label=AccumulateGrad]
	2655241286224 -> 2646243052656
	2655238605056 [label="stage2.3.branch2.3.weight
 (24, 1, 3, 3)" fillcolor=lightblue]
	2655238605056 -> 2655241286224
	2655241286224 [label=AccumulateGrad]
	2655241288480 -> 2646243064992
	2646234347488 [label="stage2.3.branch2.4.weight
 (24)" fillcolor=lightblue]
	2646234347488 -> 2655241288480
	2655241288480 [label=AccumulateGrad]
	2655241286512 -> 2646243064992
	2655238609376 [label="stage2.3.branch2.4.bias
 (24)" fillcolor=lightblue]
	2655238609376 -> 2655241286512
	2655241286512 [label=AccumulateGrad]
	2646243063312 -> 2646243057744
	2655238618016 [label="stage2.3.branch2.5.weight
 (24, 24, 1, 1)" fillcolor=lightblue]
	2655238618016 -> 2646243063312
	2646243063312 [label=AccumulateGrad]
	2646243060432 -> 2646243062880
	2646239395680 [label="stage2.3.branch2.6.weight
 (24)" fillcolor=lightblue]
	2646239395680 -> 2646243060432
	2646243060432 [label=AccumulateGrad]
	2646243061152 -> 2646243062880
	2646234345488 [label="stage2.3.branch2.6.bias
 (24)" fillcolor=lightblue]
	2646234345488 -> 2646243061152
	2646243061152 [label=AccumulateGrad]
	2646243056064 -> 2646243059856
	2646214074000 [label="stage3.0.branch1.0.weight
 (48, 1, 3, 3)" fillcolor=lightblue]
	2646214074000 -> 2646243056064
	2646243056064 [label=AccumulateGrad]
	2646243061104 -> 2646243062928
	2655238729904 [label="stage3.0.branch1.1.weight
 (48)" fillcolor=lightblue]
	2655238729904 -> 2646243061104
	2646243061104 [label=AccumulateGrad]
	2646243060864 -> 2646243062928
	2655238719104 [label="stage3.0.branch1.1.bias
 (48)" fillcolor=lightblue]
	2655238719104 -> 2646243060864
	2646243060864 [label=AccumulateGrad]
	2646243064800 -> 2646243059232
	2655238730784 [label="stage3.0.branch1.2.weight
 (48, 48, 1, 1)" fillcolor=lightblue]
	2655238730784 -> 2646243064800
	2646243064800 [label=AccumulateGrad]
	2646243063072 -> 2646243055776
	2655238718864 [label="stage3.0.branch1.3.weight
 (48)" fillcolor=lightblue]
	2655238718864 -> 2646243063072
	2646243063072 [label=AccumulateGrad]
	2646243057024 -> 2646243055776
	2655238717824 [label="stage3.0.branch1.3.bias
 (48)" fillcolor=lightblue]
	2655238717824 -> 2646243057024
	2646243057024 [label=AccumulateGrad]
	2646243050064 -> 2646243049824
	2646243050064 [label=ReluBackward0]
	2646243060384 -> 2646243050064
	2646243060384 [label=NativeBatchNormBackward0]
	2646243058560 -> 2646243060384
	2646243058560 [label=ConvolutionBackward0]
	2646243058128 -> 2646243058560
	2646243058128 [label=NativeBatchNormBackward0]
	2646243063456 -> 2646243058128
	2646243063456 [label=ConvolutionBackward0]
	2655241289536 -> 2646243063456
	2655241289536 [label=ReluBackward0]
	2655241281856 -> 2655241289536
	2655241281856 [label=NativeBatchNormBackward0]
	2655241284976 -> 2655241281856
	2655241284976 [label=ConvolutionBackward0]
	2646243055584 -> 2655241284976
	2655241277392 -> 2655241284976
	2655238732224 [label="stage3.0.branch2.0.weight
 (48, 48, 1, 1)" fillcolor=lightblue]
	2655238732224 -> 2655241277392
	2655241277392 [label=AccumulateGrad]
	2655241283728 -> 2655241281856
	2655238727904 [label="stage3.0.branch2.1.weight
 (48)" fillcolor=lightblue]
	2655238727904 -> 2655241283728
	2655241283728 [label=AccumulateGrad]
	2655241284256 -> 2655241281856
	2655238731024 [label="stage3.0.branch2.1.bias
 (48)" fillcolor=lightblue]
	2655238731024 -> 2655241284256
	2655241284256 [label=AccumulateGrad]
	2655241289200 -> 2646243063456
	2655238721104 [label="stage3.0.branch2.3.weight
 (48, 1, 3, 3)" fillcolor=lightblue]
	2655238721104 -> 2655241289200
	2655241289200 [label=AccumulateGrad]
	2646243058848 -> 2646243058128
	2655238727104 [label="stage3.0.branch2.4.weight
 (48)" fillcolor=lightblue]
	2655238727104 -> 2646243058848
	2646243058848 [label=AccumulateGrad]
	2646243056544 -> 2646243058128
	2655238723984 [label="stage3.0.branch2.4.bias
 (48)" fillcolor=lightblue]
	2655238723984 -> 2646243056544
	2646243056544 [label=AccumulateGrad]
	2646243051792 -> 2646243058560
	2655238724064 [label="stage3.0.branch2.5.weight
 (48, 48, 1, 1)" fillcolor=lightblue]
	2655238724064 -> 2646243051792
	2646243051792 [label=AccumulateGrad]
	2646243057936 -> 2646243060384
	2655238729744 [label="stage3.0.branch2.6.weight
 (48)" fillcolor=lightblue]
	2655238729744 -> 2646243057936
	2646243057936 [label=AccumulateGrad]
	2646243055440 -> 2646243060384
	2655238720624 [label="stage3.0.branch2.6.bias
 (48)" fillcolor=lightblue]
	2655238720624 -> 2646243055440
	2646243055440 [label=AccumulateGrad]
	2655235699040 -> 2655235696112
	2655235699040 [label=ReluBackward0]
	2655235695776 -> 2655235699040
	2655235695776 [label=NativeBatchNormBackward0]
	2646243050688 -> 2655235695776
	2646243050688 [label=ConvolutionBackward0]
	2646243056112 -> 2646243050688
	2646243056112 [label=NativeBatchNormBackward0]
	2646243058704 -> 2646243056112
	2646243058704 [label=ConvolutionBackward0]
	2655241274320 -> 2646243058704
	2655241274320 [label=ReluBackward0]
	2655241276816 -> 2655241274320
	2655241276816 [label=NativeBatchNormBackward0]
	2655241277824 -> 2655241276816
	2655241277824 [label=ConvolutionBackward0]
	2655235693280 -> 2655241277824
	2655241279936 -> 2655241277824
	2646239392160 [label="stage3.1.branch2.0.weight
 (48, 48, 1, 1)" fillcolor=lightblue]
	2646239392160 -> 2655241279936
	2655241279936 [label=AccumulateGrad]
	2655241276432 -> 2655241276816
	2646239119936 [label="stage3.1.branch2.1.weight
 (48)" fillcolor=lightblue]
	2646239119936 -> 2655241276432
	2655241276432 [label=AccumulateGrad]
	2655241275904 -> 2655241276816
	2646239127776 [label="stage3.1.branch2.1.bias
 (48)" fillcolor=lightblue]
	2646239127776 -> 2655241275904
	2655241275904 [label=AccumulateGrad]
	2655241275040 -> 2646243058704
	2646239129376 [label="stage3.1.branch2.3.weight
 (48, 1, 3, 3)" fillcolor=lightblue]
	2646239129376 -> 2655241275040
	2655241275040 [label=AccumulateGrad]
	2655241278832 -> 2646243056112
	2646239131536 [label="stage3.1.branch2.4.weight
 (48)" fillcolor=lightblue]
	2646239131536 -> 2655241278832
	2655241278832 [label=AccumulateGrad]
	2655241278400 -> 2646243056112
	2646239130656 [label="stage3.1.branch2.4.bias
 (48)" fillcolor=lightblue]
	2646239130656 -> 2655241278400
	2655241278400 [label=AccumulateGrad]
	2646243055152 -> 2646243050688
	2646239125776 [label="stage3.1.branch2.5.weight
 (48, 48, 1, 1)" fillcolor=lightblue]
	2646239125776 -> 2646243055152
	2646243055152 [label=AccumulateGrad]
	2646243053856 -> 2655235695776
	2655238733744 [label="stage3.1.branch2.6.weight
 (48)" fillcolor=lightblue]
	2655238733744 -> 2646243053856
	2646243053856 [label=AccumulateGrad]
	2646243064224 -> 2655235695776
	2655238830288 [label="stage3.1.branch2.6.bias
 (48)" fillcolor=lightblue]
	2655238830288 -> 2646243064224
	2646243064224 [label=AccumulateGrad]
	2655235701104 -> 2655235695344
	2655235701104 [label=ReluBackward0]
	2655235698608 -> 2655235701104
	2655235698608 [label=NativeBatchNormBackward0]
	2655235701536 -> 2655235698608
	2655235701536 [label=ConvolutionBackward0]
	2646243057408 -> 2655235701536
	2646243057408 [label=NativeBatchNormBackward0]
	2655241280128 -> 2646243057408
	2655241280128 [label=ConvolutionBackward0]
	2655241288768 -> 2655241280128
	2655241288768 [label=ReluBackward0]
	2655241287712 -> 2655241288768
	2655241287712 [label=NativeBatchNormBackward0]
	2655241285984 -> 2655241287712
	2655241285984 [label=ConvolutionBackward0]
	2655235696496 -> 2655241285984
	2655241283680 -> 2655241285984
	2655238817408 [label="stage3.2.branch2.0.weight
 (48, 48, 1, 1)" fillcolor=lightblue]
	2655238817408 -> 2655241283680
	2655241283680 [label=AccumulateGrad]
	2655241282768 -> 2655241287712
	2655238826288 [label="stage3.2.branch2.1.weight
 (48)" fillcolor=lightblue]
	2655238826288 -> 2655241282768
	2655241282768 [label=AccumulateGrad]
	2655241282528 -> 2655241287712
	2655238825648 [label="stage3.2.branch2.1.bias
 (48)" fillcolor=lightblue]
	2655238825648 -> 2655241282528
	2655241282528 [label=AccumulateGrad]
	2655241286992 -> 2655241280128
	2655238820768 [label="stage3.2.branch2.3.weight
 (48, 1, 3, 3)" fillcolor=lightblue]
	2655238820768 -> 2655241286992
	2655241286992 [label=AccumulateGrad]
	2655241286896 -> 2646243057408
	2655238829648 [label="stage3.2.branch2.4.weight
 (48)" fillcolor=lightblue]
	2655238829648 -> 2655241286896
	2655241286896 [label=AccumulateGrad]
	2655241281136 -> 2646243057408
	2655238820128 [label="stage3.2.branch2.4.bias
 (48)" fillcolor=lightblue]
	2655238820128 -> 2655241281136
	2655241281136 [label=AccumulateGrad]
	2646243057648 -> 2655235701536
	2646239132256 [label="stage3.2.branch2.5.weight
 (48, 48, 1, 1)" fillcolor=lightblue]
	2646239132256 -> 2646243057648
	2646243057648 [label=AccumulateGrad]
	2655235697408 -> 2655235698608
	2655238821968 [label="stage3.2.branch2.6.weight
 (48)" fillcolor=lightblue]
	2655238821968 -> 2655235697408
	2655235697408 [label=AccumulateGrad]
	2655235694768 -> 2655235698608
	2655238562144 [label="stage3.2.branch2.6.bias
 (48)" fillcolor=lightblue]
	2655238562144 -> 2655235694768
	2655235694768 [label=AccumulateGrad]
	2655235697360 -> 2655235699952
	2655235697360 [label=ReluBackward0]
	2655235699232 -> 2655235697360
	2655235699232 [label=NativeBatchNormBackward0]
	2655235702448 -> 2655235699232
	2655235702448 [label=ConvolutionBackward0]
	2655235694240 -> 2655235702448
	2655235694240 [label=NativeBatchNormBackward0]
	2655241276624 -> 2655235694240
	2655241276624 [label=ConvolutionBackward0]
	2655241289392 -> 2655241276624
	2655241289392 [label=ReluBackward0]
	2655241289584 -> 2655241289392
	2655241289584 [label=NativeBatchNormBackward0]
	2655241273792 -> 2655241289584
	2655241273792 [label=ConvolutionBackward0]
	2655235694624 -> 2655241273792
	2655241275136 -> 2655241273792
	2655238555024 [label="stage3.3.branch2.0.weight
 (48, 48, 1, 1)" fillcolor=lightblue]
	2655238555024 -> 2655241275136
	2655241275136 [label=AccumulateGrad]
	2655241274224 -> 2655241289584
	2655238555424 [label="stage3.3.branch2.1.weight
 (48)" fillcolor=lightblue]
	2655238555424 -> 2655241274224
	2655241274224 [label=AccumulateGrad]
	2655241280368 -> 2655241289584
	2655238556144 [label="stage3.3.branch2.1.bias
 (48)" fillcolor=lightblue]
	2655238556144 -> 2655241280368
	2655241280368 [label=AccumulateGrad]
	2655241285936 -> 2655241276624
	2655238568544 [label="stage3.3.branch2.3.weight
 (48, 1, 3, 3)" fillcolor=lightblue]
	2655238568544 -> 2655241285936
	2655241285936 [label=AccumulateGrad]
	2655241275088 -> 2655235694240
	2655238561744 [label="stage3.3.branch2.4.weight
 (48)" fillcolor=lightblue]
	2655238561744 -> 2655241275088
	2655241275088 [label=AccumulateGrad]
	2655241277008 -> 2655235694240
	2655238561024 [label="stage3.3.branch2.4.bias
 (48)" fillcolor=lightblue]
	2655238561024 -> 2655241277008
	2655241277008 [label=AccumulateGrad]
	2655235697840 -> 2655235702448
	2655238564144 [label="stage3.3.branch2.5.weight
 (48, 48, 1, 1)" fillcolor=lightblue]
	2655238564144 -> 2655235697840
	2655235697840 [label=AccumulateGrad]
	2655235701680 -> 2655235699232
	2655238556864 [label="stage3.3.branch2.6.weight
 (48)" fillcolor=lightblue]
	2655238556864 -> 2655235701680
	2655235701680 [label=AccumulateGrad]
	2655235700528 -> 2655235699232
	2655238557424 [label="stage3.3.branch2.6.bias
 (48)" fillcolor=lightblue]
	2655238557424 -> 2655235700528
	2655235700528 [label=AccumulateGrad]
	2655235698800 -> 2655235695200
	2655235698800 [label=ReluBackward0]
	2655235693616 -> 2655235698800
	2655235693616 [label=NativeBatchNormBackward0]
	2655235701728 -> 2655235693616
	2655235701728 [label=ConvolutionBackward0]
	2655235701488 -> 2655235701728
	2655235701488 [label=NativeBatchNormBackward0]
	2655241273888 -> 2655235701488
	2655241273888 [label=ConvolutionBackward0]
	2655241278160 -> 2655241273888
	2655241278160 [label=ReluBackward0]
	2655241274080 -> 2655241278160
	2655241274080 [label=NativeBatchNormBackward0]
	2655241288672 -> 2655241274080
	2655241288672 [label=ConvolutionBackward0]
	2655235696160 -> 2655241288672
	2655241280608 -> 2655241288672
	2655238822288 [label="stage3.4.branch2.0.weight
 (48, 48, 1, 1)" fillcolor=lightblue]
	2655238822288 -> 2655241280608
	2655241280608 [label=AccumulateGrad]
	2655241288864 -> 2655241274080
	2655240751280 [label="stage3.4.branch2.1.weight
 (48)" fillcolor=lightblue]
	2655240751280 -> 2655241288864
	2655241288864 [label=AccumulateGrad]
	2655241289152 -> 2655241274080
	2655240752720 [label="stage3.4.branch2.1.bias
 (48)" fillcolor=lightblue]
	2655240752720 -> 2655241289152
	2655241289152 [label=AccumulateGrad]
	2655241280464 -> 2655241273888
	2655238557104 [label="stage3.4.branch2.3.weight
 (48, 1, 3, 3)" fillcolor=lightblue]
	2655238557104 -> 2655241280464
	2655241280464 [label=AccumulateGrad]
	2655241286656 -> 2655235701488
	2655240765200 [label="stage3.4.branch2.4.weight
 (48)" fillcolor=lightblue]
	2655240765200 -> 2655241286656
	2655241286656 [label=AccumulateGrad]
	2655241287376 -> 2655235701488
	2655240765280 [label="stage3.4.branch2.4.bias
 (48)" fillcolor=lightblue]
	2655240765280 -> 2655241287376
	2655241287376 [label=AccumulateGrad]
	2655235701344 -> 2655235701728
	2655240764560 [label="stage3.4.branch2.5.weight
 (48, 48, 1, 1)" fillcolor=lightblue]
	2655240764560 -> 2655235701344
	2655235701344 [label=AccumulateGrad]
	2655235702496 -> 2655235693616
	2655240752320 [label="stage3.4.branch2.6.weight
 (48)" fillcolor=lightblue]
	2655240752320 -> 2655235702496
	2655235702496 [label=AccumulateGrad]
	2655235699184 -> 2655235693616
	2655240759600 [label="stage3.4.branch2.6.bias
 (48)" fillcolor=lightblue]
	2655240759600 -> 2655235699184
	2655235699184 [label=AccumulateGrad]
	2655235692224 -> 2655235921840
	2655235692224 [label=ReluBackward0]
	2655235697120 -> 2655235692224
	2655235697120 [label=NativeBatchNormBackward0]
	2655235695152 -> 2655235697120
	2655235695152 [label=ConvolutionBackward0]
	2655235700576 -> 2655235695152
	2655235700576 [label=NativeBatchNormBackward0]
	2655241273696 -> 2655235700576
	2655241273696 [label=ConvolutionBackward0]
	2655241288720 -> 2655241273696
	2655241288720 [label=ReluBackward0]
	2655241287664 -> 2655241288720
	2655241287664 [label=NativeBatchNormBackward0]
	2655241276096 -> 2655241287664
	2655241276096 [label=ConvolutionBackward0]
	2655235700192 -> 2655241276096
	2655241278784 -> 2655241276096
	2646239131296 [label="stage3.5.branch2.0.weight
 (48, 48, 1, 1)" fillcolor=lightblue]
	2646239131296 -> 2655241278784
	2655241278784 [label=AccumulateGrad]
	2655241281952 -> 2655241287664
	2655240760800 [label="stage3.5.branch2.1.weight
 (48)" fillcolor=lightblue]
	2655240760800 -> 2655241281952
	2655241281952 [label=AccumulateGrad]
	2655241278016 -> 2655241287664
	2655240754160 [label="stage3.5.branch2.1.bias
 (48)" fillcolor=lightblue]
	2655240754160 -> 2655241278016
	2655241278016 [label=AccumulateGrad]
	2655241280512 -> 2655241273696
	2646267189968 [label="stage3.5.branch2.3.weight
 (48, 1, 3, 3)" fillcolor=lightblue]
	2646267189968 -> 2655241280512
	2655241280512 [label=AccumulateGrad]
	2655241289104 -> 2655235700576
	2655240762960 [label="stage3.5.branch2.4.weight
 (48)" fillcolor=lightblue]
	2655240762960 -> 2655241289104
	2655241289104 [label=AccumulateGrad]
	2655241281568 -> 2655235700576
	2655240759280 [label="stage3.5.branch2.4.bias
 (48)" fillcolor=lightblue]
	2655240759280 -> 2655241281568
	2655241281568 [label=AccumulateGrad]
	2655235699760 -> 2655235695152
	2655240755440 [label="stage3.5.branch2.5.weight
 (48, 48, 1, 1)" fillcolor=lightblue]
	2655240755440 -> 2655235699760
	2655235699760 [label=AccumulateGrad]
	2655235698224 -> 2655235697120
	2655240761280 [label="stage3.5.branch2.6.weight
 (48)" fillcolor=lightblue]
	2655240761280 -> 2655235698224
	2655235698224 [label=AccumulateGrad]
	2655235702688 -> 2655235697120
	2655240749520 [label="stage3.5.branch2.6.bias
 (48)" fillcolor=lightblue]
	2655240749520 -> 2655235702688
	2655235702688 [label=AccumulateGrad]
	2655235917088 -> 2646245068464
	2655235917088 [label=ReluBackward0]
	2655235919344 -> 2655235917088
	2655235919344 [label=NativeBatchNormBackward0]
	2655235922752 -> 2655235919344
	2655235922752 [label=ConvolutionBackward0]
	2655235694816 -> 2655235922752
	2655235694816 [label=NativeBatchNormBackward0]
	2655241273504 -> 2655235694816
	2655241273504 [label=ConvolutionBackward0]
	2655241274992 -> 2655241273504
	2655241274992 [label=ReluBackward0]
	2655241282048 -> 2655241274992
	2655241282048 [label=NativeBatchNormBackward0]
	2655241281232 -> 2655241282048
	2655241281232 [label=ConvolutionBackward0]
	2655235925632 -> 2655241281232
	2655241281760 -> 2655241281232
	2655240756160 [label="stage3.6.branch2.0.weight
 (48, 48, 1, 1)" fillcolor=lightblue]
	2655240756160 -> 2655241281760
	2655241281760 [label=AccumulateGrad]
	2655241278496 -> 2655241282048
	2655240753200 [label="stage3.6.branch2.1.weight
 (48)" fillcolor=lightblue]
	2655240753200 -> 2655241278496
	2655241278496 [label=AccumulateGrad]
	2655241279744 -> 2655241282048
	2655240751760 [label="stage3.6.branch2.1.bias
 (48)" fillcolor=lightblue]
	2655240751760 -> 2655241279744
	2655241279744 [label=AccumulateGrad]
	2655241278736 -> 2655241273504
	2655240763600 [label="stage3.6.branch2.3.weight
 (48, 1, 3, 3)" fillcolor=lightblue]
	2655240763600 -> 2655241278736
	2655241278736 [label=AccumulateGrad]
	2655241282384 -> 2655235694816
	2655240749440 [label="stage3.6.branch2.4.weight
 (48)" fillcolor=lightblue]
	2655240749440 -> 2655241282384
	2655241282384 [label=AccumulateGrad]
	2655241280272 -> 2655235694816
	2655240763520 [label="stage3.6.branch2.4.bias
 (48)" fillcolor=lightblue]
	2655240763520 -> 2655241280272
	2655241280272 [label=AccumulateGrad]
	2655235702304 -> 2655235922752
	2655240760880 [label="stage3.6.branch2.5.weight
 (48, 48, 1, 1)" fillcolor=lightblue]
	2655240760880 -> 2655235702304
	2655235702304 [label=AccumulateGrad]
	2655235916464 -> 2655235919344
	2655240750000 [label="stage3.6.branch2.6.weight
 (48)" fillcolor=lightblue]
	2655240750000 -> 2655235916464
	2655235916464 [label=AccumulateGrad]
	2655235924720 -> 2655235919344
	2655240753760 [label="stage3.6.branch2.6.bias
 (48)" fillcolor=lightblue]
	2655240753760 -> 2655235924720
	2655235924720 [label=AccumulateGrad]
	2646245077440 -> 2646245071872
	2646245077440 [label=ReluBackward0]
	2646245070288 -> 2646245077440
	2646245070288 [label=NativeBatchNormBackward0]
	2646245071104 -> 2646245070288
	2646245071104 [label=ConvolutionBackward0]
	2655235702064 -> 2646245071104
	2655235702064 [label=NativeBatchNormBackward0]
	2655241289248 -> 2655235702064
	2655241289248 [label=ConvolutionBackward0]
	2655241283776 -> 2655241289248
	2655241283776 [label=ReluBackward0]
	2655241277776 -> 2655241283776
	2655241277776 [label=NativeBatchNormBackward0]
	2655241285648 -> 2655241277776
	2655241285648 [label=ConvolutionBackward0]
	2646245066448 -> 2655241285648
	2655241279072 -> 2655241285648
	2646239121856 [label="stage3.7.branch2.0.weight
 (48, 48, 1, 1)" fillcolor=lightblue]
	2646239121856 -> 2655241279072
	2655241279072 [label=AccumulateGrad]
	2655241274272 -> 2655241277776
	2655240756320 [label="stage3.7.branch2.1.weight
 (48)" fillcolor=lightblue]
	2655240756320 -> 2655241274272
	2655241274272 [label=AccumulateGrad]
	2655241276768 -> 2655241277776
	2655240757680 [label="stage3.7.branch2.1.bias
 (48)" fillcolor=lightblue]
	2655240757680 -> 2655241276768
	2655241276768 [label=AccumulateGrad]
	2655241283008 -> 2655241289248
	2655238561424 [label="stage3.7.branch2.3.weight
 (48, 1, 3, 3)" fillcolor=lightblue]
	2655238561424 -> 2655241283008
	2655241283008 [label=AccumulateGrad]
	2655241273984 -> 2655235702064
	2655238691616 [label="stage3.7.branch2.4.weight
 (48)" fillcolor=lightblue]
	2655238691616 -> 2655241273984
	2655241273984 [label=AccumulateGrad]
	2655241288240 -> 2655235702064
	2655238686576 [label="stage3.7.branch2.4.bias
 (48)" fillcolor=lightblue]
	2655238686576 -> 2655241288240
	2655241288240 [label=AccumulateGrad]
	2655235691792 -> 2646245071104
	2655238695776 [label="stage3.7.branch2.5.weight
 (48, 48, 1, 1)" fillcolor=lightblue]
	2655238695776 -> 2655235691792
	2655235691792 [label=AccumulateGrad]
	2646245071200 -> 2646245070288
	2655238687216 [label="stage3.7.branch2.6.weight
 (48)" fillcolor=lightblue]
	2655238687216 -> 2646245071200
	2646245071200 [label=AccumulateGrad]
	2655235918096 -> 2646245070288
	2655238693776 [label="stage3.7.branch2.6.bias
 (48)" fillcolor=lightblue]
	2655238693776 -> 2655235918096
	2655235918096 [label=AccumulateGrad]
	2646245071632 -> 2646245072352
	2655238685856 [label="stage4.0.branch1.0.weight
 (96, 1, 3, 3)" fillcolor=lightblue]
	2655238685856 -> 2646245071632
	2646245071632 [label=AccumulateGrad]
	2646245068512 -> 2646245079216
	2655238697616 [label="stage4.0.branch1.1.weight
 (96)" fillcolor=lightblue]
	2655238697616 -> 2646245068512
	2646245068512 [label=AccumulateGrad]
	2646245066256 -> 2646245079216
	2655238695056 [label="stage4.0.branch1.1.bias
 (96)" fillcolor=lightblue]
	2655238695056 -> 2646245066256
	2646245066256 [label=AccumulateGrad]
	2646245065392 -> 2646245067936
	2655238691136 [label="stage4.0.branch1.2.weight
 (96, 96, 1, 1)" fillcolor=lightblue]
	2655238691136 -> 2646245065392
	2646245065392 [label=AccumulateGrad]
	2646245079648 -> 2646245073360
	2655238689456 [label="stage4.0.branch1.3.weight
 (96)" fillcolor=lightblue]
	2655238689456 -> 2646245079648
	2646245079648 [label=AccumulateGrad]
	2646245067696 -> 2646245073360
	2655238696976 [label="stage4.0.branch1.3.bias
 (96)" fillcolor=lightblue]
	2655238696976 -> 2646245067696
	2646245067696 [label=AccumulateGrad]
	2646245073792 -> 2646245067744
	2646245073792 [label=ReluBackward0]
	2646245078064 -> 2646245073792
	2646245078064 [label=NativeBatchNormBackward0]
	2646245074608 -> 2646245078064
	2646245074608 [label=ConvolutionBackward0]
	2646245068560 -> 2646245074608
	2646245068560 [label=NativeBatchNormBackward0]
	2646245065200 -> 2646245068560
	2646245065200 [label=ConvolutionBackward0]
	2655241285312 -> 2646245065200
	2655241285312 [label=ReluBackward0]
	2655241288960 -> 2655241285312
	2655241288960 [label=NativeBatchNormBackward0]
	2655241279024 -> 2655241288960
	2655241279024 [label=ConvolutionBackward0]
	2646245071344 -> 2655241279024
	2655241278688 -> 2655241279024
	2655238690016 [label="stage4.0.branch2.0.weight
 (96, 96, 1, 1)" fillcolor=lightblue]
	2655238690016 -> 2655241278688
	2655241278688 [label=AccumulateGrad]
	2655241276528 -> 2655241288960
	2655238695616 [label="stage4.0.branch2.1.weight
 (96)" fillcolor=lightblue]
	2655238695616 -> 2655241276528
	2655241276528 [label=AccumulateGrad]
	2655241276192 -> 2655241288960
	2646237497280 [label="stage4.0.branch2.1.bias
 (96)" fillcolor=lightblue]
	2646237497280 -> 2655241276192
	2655241276192 [label=AccumulateGrad]
	2655241286080 -> 2646245065200
	2646237508640 [label="stage4.0.branch2.3.weight
 (96, 1, 3, 3)" fillcolor=lightblue]
	2646237508640 -> 2655241286080
	2655241286080 [label=AccumulateGrad]
	2646245075088 -> 2646245068560
	2646237500800 [label="stage4.0.branch2.4.weight
 (96)" fillcolor=lightblue]
	2646237500800 -> 2646245075088
	2646245075088 [label=AccumulateGrad]
	2655235916176 -> 2646245068560
	2646237505280 [label="stage4.0.branch2.4.bias
 (96)" fillcolor=lightblue]
	2646237505280 -> 2655235916176
	2655235916176 [label=AccumulateGrad]
	2646245076336 -> 2646245074608
	2655238688256 [label="stage4.0.branch2.5.weight
 (96, 96, 1, 1)" fillcolor=lightblue]
	2655238688256 -> 2646245076336
	2646245076336 [label=AccumulateGrad]
	2646245067072 -> 2646245078064
	2646239016848 [label="stage4.0.branch2.6.weight
 (96)" fillcolor=lightblue]
	2646239016848 -> 2646245067072
	2646245067072 [label=AccumulateGrad]
	2646245075808 -> 2646245078064
	2646239011648 [label="stage4.0.branch2.6.bias
 (96)" fillcolor=lightblue]
	2646239011648 -> 2646245075808
	2646245075808 [label=AccumulateGrad]
	2646245072544 -> 2646245066544
	2646245072544 [label=ReluBackward0]
	2646245068752 -> 2646245072544
	2646245068752 [label=NativeBatchNormBackward0]
	2646245075184 -> 2646245068752
	2646245075184 [label=ConvolutionBackward0]
	2646245065152 -> 2646245075184
	2646245065152 [label=NativeBatchNormBackward0]
	2655235923712 -> 2646245065152
	2655235923712 [label=ConvolutionBackward0]
	2655241289632 -> 2655235923712
	2655241289632 [label=ReluBackward0]
	2655241281808 -> 2655241289632
	2655241281808 [label=NativeBatchNormBackward0]
	2655241284544 -> 2655241281808
	2655241284544 [label=ConvolutionBackward0]
	2646245066208 -> 2655241284544
	2655241287088 -> 2655241284544
	2646239010928 [label="stage4.1.branch2.0.weight
 (96, 96, 1, 1)" fillcolor=lightblue]
	2646239010928 -> 2655241287088
	2655241287088 [label=AccumulateGrad]
	2655241278352 -> 2655241281808
	2646239007328 [label="stage4.1.branch2.1.weight
 (96)" fillcolor=lightblue]
	2646239007328 -> 2655241278352
	2655241278352 [label=AccumulateGrad]
	2655241275568 -> 2655241281808
	2646245867040 [label="stage4.1.branch2.1.bias
 (96)" fillcolor=lightblue]
	2646245867040 -> 2655241275568
	2655241275568 [label=AccumulateGrad]
	2655241286464 -> 2655235923712
	2646245864720 [label="stage4.1.branch2.3.weight
 (96, 1, 3, 3)" fillcolor=lightblue]
	2646245864720 -> 2655241286464
	2655241286464 [label=AccumulateGrad]
	2655241283440 -> 2646245065152
	2646245865360 [label="stage4.1.branch2.4.weight
 (96)" fillcolor=lightblue]
	2646245865360 -> 2655241283440
	2655241283440 [label=AccumulateGrad]
	2655241275664 -> 2646245065152
	2646245861200 [label="stage4.1.branch2.4.bias
 (96)" fillcolor=lightblue]
	2646245861200 -> 2655241275664
	2655241275664 [label=AccumulateGrad]
	2646245064864 -> 2646245075184
	2646245853840 [label="stage4.1.branch2.5.weight
 (96, 96, 1, 1)" fillcolor=lightblue]
	2646245853840 -> 2646245064864
	2646245064864 [label=AccumulateGrad]
	2646245077872 -> 2646245068752
	2646245859920 [label="stage4.1.branch2.6.weight
 (96)" fillcolor=lightblue]
	2646245859920 -> 2646245077872
	2646245077872 [label=AccumulateGrad]
	2646245075952 -> 2646245068752
	2646245866800 [label="stage4.1.branch2.6.bias
 (96)" fillcolor=lightblue]
	2646245866800 -> 2646245075952
	2646245075952 [label=AccumulateGrad]
	2646245078592 -> 2646245075040
	2646245078592 [label=ReluBackward0]
	2646245064816 -> 2646245078592
	2646245064816 [label=NativeBatchNormBackward0]
	2646245067264 -> 2646245064816
	2646245067264 [label=ConvolutionBackward0]
	2646245074368 -> 2646245067264
	2646245074368 [label=NativeBatchNormBackward0]
	2655241282720 -> 2646245074368
	2655241282720 [label=ConvolutionBackward0]
	2655241275712 -> 2655241282720
	2655241275712 [label=ReluBackward0]
	2655241283632 -> 2655241275712
	2655241283632 [label=NativeBatchNormBackward0]
	2655241280896 -> 2655241283632
	2655241280896 [label=ConvolutionBackward0]
	2646245073744 -> 2655241280896
	2655241274416 -> 2655241280896
	2646245854640 [label="stage4.2.branch2.0.weight
 (96, 96, 1, 1)" fillcolor=lightblue]
	2646245854640 -> 2655241274416
	2655241274416 [label=AccumulateGrad]
	2655241279504 -> 2655241283632
	2646245858800 [label="stage4.2.branch2.1.weight
 (96)" fillcolor=lightblue]
	2646245858800 -> 2655241279504
	2655241279504 [label=AccumulateGrad]
	2655241287232 -> 2655241283632
	2646245852640 [label="stage4.2.branch2.1.bias
 (96)" fillcolor=lightblue]
	2646245852640 -> 2655241287232
	2655241287232 [label=AccumulateGrad]
	2655241282480 -> 2655241282720
	2646245863120 [label="stage4.2.branch2.3.weight
 (96, 1, 3, 3)" fillcolor=lightblue]
	2646245863120 -> 2655241282480
	2655241282480 [label=AccumulateGrad]
	2655241276000 -> 2646245074368
	2646245865760 [label="stage4.2.branch2.4.weight
 (96)" fillcolor=lightblue]
	2646245865760 -> 2655241276000
	2655241276000 [label=AccumulateGrad]
	2655241287760 -> 2646245074368
	2646245863920 [label="stage4.2.branch2.4.bias
 (96)" fillcolor=lightblue]
	2646245863920 -> 2655241287760
	2655241287760 [label=AccumulateGrad]
	2646245068800 -> 2646245067264
	2646267358288 [label="stage4.2.branch2.5.weight
 (96, 96, 1, 1)" fillcolor=lightblue]
	2646267358288 -> 2646245068800
	2646245068800 [label=AccumulateGrad]
	2646245065440 -> 2646245064816
	2646245866400 [label="stage4.2.branch2.6.weight
 (96)" fillcolor=lightblue]
	2646245866400 -> 2646245065440
	2646245065440 [label=AccumulateGrad]
	2646245073120 -> 2646245064816
	2646245866480 [label="stage4.2.branch2.6.bias
 (96)" fillcolor=lightblue]
	2646245866480 -> 2646245073120
	2646245073120 [label=AccumulateGrad]
	2646245072880 -> 2646245080464
	2646245072880 [label=ReluBackward0]
	2646245072736 -> 2646245072880
	2646245072736 [label=NativeBatchNormBackward0]
	2646245078544 -> 2646245072736
	2646245078544 [label=ConvolutionBackward0]
	2646245079072 -> 2646245078544
	2646245079072 [label=NativeBatchNormBackward0]
	2655241278976 -> 2646245079072
	2655241278976 [label=ConvolutionBackward0]
	2655241287040 -> 2655241278976
	2655241287040 [label=ReluBackward0]
	2655241287280 -> 2655241287040
	2655241287280 [label=NativeBatchNormBackward0]
	2655241281328 -> 2655241287280
	2655241281328 [label=ConvolutionBackward0]
	2646245073696 -> 2655241281328
	2655241283296 -> 2655241281328
	2646245867280 [label="stage4.3.branch2.0.weight
 (96, 96, 1, 1)" fillcolor=lightblue]
	2646245867280 -> 2655241283296
	2655241283296 [label=AccumulateGrad]
	2655241282240 -> 2655241287280
	2646245854560 [label="stage4.3.branch2.1.weight
 (96)" fillcolor=lightblue]
	2646245854560 -> 2655241282240
	2655241282240 [label=AccumulateGrad]
	2655241283392 -> 2655241287280
	2646245852160 [label="stage4.3.branch2.1.bias
 (96)" fillcolor=lightblue]
	2646245852160 -> 2655241283392
	2655241283392 [label=AccumulateGrad]
	2655241274608 -> 2655241278976
	2646245866160 [label="stage4.3.branch2.3.weight
 (96, 1, 3, 3)" fillcolor=lightblue]
	2646245866160 -> 2655241274608
	2655241274608 [label=AccumulateGrad]
	2655241281616 -> 2646245079072
	2646245860880 [label="stage4.3.branch2.4.weight
 (96)" fillcolor=lightblue]
	2646245860880 -> 2655241281616
	2655241281616 [label=AccumulateGrad]
	2655241280320 -> 2646245079072
	2646245854880 [label="stage4.3.branch2.4.bias
 (96)" fillcolor=lightblue]
	2646245854880 -> 2655241280320
	2655241280320 [label=AccumulateGrad]
	2646245078112 -> 2646245078544
	2646245856000 [label="stage4.3.branch2.5.weight
 (96, 96, 1, 1)" fillcolor=lightblue]
	2646245856000 -> 2646245078112
	2646245078112 [label=AccumulateGrad]
	2646245065968 -> 2646245072736
	2646245855760 [label="stage4.3.branch2.6.weight
 (96)" fillcolor=lightblue]
	2646245855760 -> 2646245065968
	2646245065968 [label=AccumulateGrad]
	2646245067792 -> 2646245072736
	2646245855520 [label="stage4.3.branch2.6.bias
 (96)" fillcolor=lightblue]
	2646245855520 -> 2646245067792
	2646245067792 [label=AccumulateGrad]
	2646245072160 -> 2646245065632
	2646239278112 [label="conv5.0.weight
 (1024, 192, 1, 1)" fillcolor=lightblue]
	2646239278112 -> 2646245072160
	2646245072160 [label=AccumulateGrad]
	2646245067456 -> 2646245075904
	2646237628752 [label="conv5.1.weight
 (1024)" fillcolor=lightblue]
	2646237628752 -> 2646245067456
	2646245067456 [label=AccumulateGrad]
	2646245076480 -> 2646245075904
	2646650685616 [label="conv5.1.bias
 (1024)" fillcolor=lightblue]
	2646650685616 -> 2646245076480
	2646245076480 [label=AccumulateGrad]
	2646245066880 -> 2646245071584
	2646245066880 [label=TBackward0]
	2646245077344 -> 2646245066880
	2646239186912 [label="fc.weight
 (10, 1024)" fillcolor=lightblue]
	2646239186912 -> 2646245077344
	2646245077344 [label=AccumulateGrad]
	2646245071584 -> 2646238325360
}
